[
  {
    "objectID": "scripts/03_faq/rstudio.html",
    "href": "scripts/03_faq/rstudio.html",
    "title": "1 RStudio",
    "section": "",
    "text": "Fragen zu RStudio\nUnabhängig von konkreten Fragen zu RStudio kannst du hier noch mal das Skript zur Einführung in R Studio von Andrew Ellis und Boris Mayer abrufen.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#was-gibt-es-alles-für-funktionen-zum-einlesen-der-daten-und-welche-davon-ist-am-besten-geeignet",
    "href": "scripts/03_faq/rstudio.html#was-gibt-es-alles-für-funktionen-zum-einlesen-der-daten-und-welche-davon-ist-am-besten-geeignet",
    "title": "1 RStudio",
    "section": "Was gibt es alles für Funktionen zum Einlesen der Daten und welche davon ist am besten geeignet?",
    "text": "Was gibt es alles für Funktionen zum Einlesen der Daten und welche davon ist am besten geeignet?\nDer einfachste Weg die Daten zu laden, geht über das Environment oben rechts in RStudio. Welche Funktion benötigt wird bzw. welche Funktion verwenden werden kann hängt vom Dateiformat der zu ladende Datei ab. Häufig verwendete Dateiformate sind .xlsx, .csv und .sav. Bei .csv handelt es sich um eine Textdatei, bei welcher die Spalten durch Kommas (csv = Comma-separated values) oder Semikolons getrennt sind. .sav ist die Dateiendung für eine SPSS-Datei und .xlsx ist die Dateiendung für eine Excel-Datei.\n\n\n\n\n\n\nNote\n\n\n\nWeiterführende Informationen und Beispiele können hier nachgelesen werden.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wofür-stehen-die-zusätzlichen-argumente-wie-escape_double-oder-trim_ws-beim-einlesen-von-dateien",
    "href": "scripts/03_faq/rstudio.html#wofür-stehen-die-zusätzlichen-argumente-wie-escape_double-oder-trim_ws-beim-einlesen-von-dateien",
    "title": "1 RStudio",
    "section": "Wofür stehen die zusätzlichen Argumente wie escape_double oder trim_ws beim Einlesen von Dateien?",
    "text": "Wofür stehen die zusätzlichen Argumente wie escape_double oder trim_ws beim Einlesen von Dateien?\n\n\n\n\n\n\nImportant\n\n\n\nDu kannst anhand der Syntax ?Funktionsname()die Dokumentation einer Funktion aufrufen. Hier wird beschrieben, welche Argumente die Funktion erwartet, was die Default-Einstellungen sind und was die Funktion ausgibt.\n\n\nWenn man mit read_delim() aus dem readr Paket die Daten einliest, interpretiert das Argument escape_double = TRUE doppelte Anführungsstriche als einfache Anführungsstriche (““ = “). Mit dem Argument trim_ws = TRUE werden Leerzeichen vor oder nach einer Zeichenkette gelöscht („ Vor dem „V“ befindet sich ein Leerzeichen = „Vor dem „V“ befindet sich ein Leerzeichen). Beide Optionen sind per Default auf TRUE gesetzt. Die folgenden beiden Varianten sind somit identisch:\n\ndata &lt;- readr::read_delim(\"data.csv\", delim = \";\", escape_double = TRUE, trim_ws = TRUE)\n\ndata &lt;- readr::read_delim(\"data.csv\", delim = \";\")",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#was-ist-der-unterschied-zwischen-cbind-und-den-xy_join-funktionen",
    "href": "scripts/03_faq/rstudio.html#was-ist-der-unterschied-zwischen-cbind-und-den-xy_join-funktionen",
    "title": "1 RStudio",
    "section": "Was ist der Unterschied zwischen cbind() und den xy_join()-Funktionen?",
    "text": "Was ist der Unterschied zwischen cbind() und den xy_join()-Funktionen?\nDie Funktion cbind() kann man sich wie „Kleber“ vorstellen. Die Datensätze werden ohne Berücksichtigung der Reihenfolgen der Zeilen aneinandergeklebt. Hierdurch könnten im zusammengefügten Datensatz Werte derselben Zeile von verschiedenen Versuchspersonen stammen. Mit der Funktion xy_join() wird vor dem Zusammenfügen der beiden Datensätze die Reihenfolge der Zeilen über beide Datensätze hinweg kontrolliert und angeglichen. Hierfür wird jene Spalte verwendet, die im Argument xy_join(data, by = „…“) genannt wurde. Damit wird sichergestellt, dass im resultierenden Datensatz Werte derselben Zeile auch von einer einzelnen Versuchsperson stammen.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#was-ist-der-unterschied-zwischen-inner_join-left_join-right_join-full_join",
    "href": "scripts/03_faq/rstudio.html#was-ist-der-unterschied-zwischen-inner_join-left_join-right_join-full_join",
    "title": "1 RStudio",
    "section": "Was ist der Unterschied zwischen inner_join(), left_join(), right_join(), full_join()?",
    "text": "Was ist der Unterschied zwischen inner_join(), left_join(), right_join(), full_join()?\nDie Funktionen unterscheiden sich dahingehend, was von den beiden Datensätzen nach der Zusammenfügung erhalten bleiben soll. inner_join() übernimmt nur Zeilen, welche in beiden Datensätzen vorhanden sind. full_join() übernimmt alle Zeilen, auch wenn sie nur in einen der beiden Datensätze auftaucht. Der Eintrag in der Spalte des anderen Datensatzes wird einfach mit NA ergänzt. Die verbleibenden beiden Funktionen “bevorzugen” sozusagen ihren entsprechenden Datensatz, übernehmen von diesem alle Zeilen und vom anderen Datensatz lediglich die damit übereinstimmenden.\n\n\n\n\n\n\nNote\n\n\n\nEine ausführlichere Beschreibung zu dem Thema findet sich auch noch mal hier unter Kapitel 19.4. Hier sind animierte Abbildungen zu den Funktionsweisen.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wann-verwendet-man-welche-der-xy_join-funktionen-und-anhand-welcher-variable-sollen-die-datensätze-zusammengefügt-werden",
    "href": "scripts/03_faq/rstudio.html#wann-verwendet-man-welche-der-xy_join-funktionen-und-anhand-welcher-variable-sollen-die-datensätze-zusammengefügt-werden",
    "title": "1 RStudio",
    "section": "Wann verwendet man welche der xy_join()-Funktionen und anhand welcher Variable sollen die Datensätze zusammengefügt werden?",
    "text": "Wann verwendet man welche der xy_join()-Funktionen und anhand welcher Variable sollen die Datensätze zusammengefügt werden?\nWelche der xy_join()-Funktionen man am sinnvollsten nutzen sollte hängt von der Datenstruktur ab und was man mit den Daten im Folgenden noch machen möchte. Ein Datensatz mit full_join() erstellt würde beispielsweise die meisten Einträge (inkl. NAs) aufweisen, andererseits wäre dieser Datensatz aber auch vermutlich am unübersichtlichsten. Ob man right_join() oder left_join() verwendet kann beispielsweise einfach nur davon abhängen, welchen Datensatz man als links (bzw. zuerst) vorliegend oder als rechts (bzw. als zweites) vorliegend definiert. Das hängt von den Argumenten in der Funktion ab. Kurzum: Welche Funktion am passendsten ist hängt von der spezifischen Fragestellung ab und davon, in welcher Reihenfolge man die Datensätze betrachtet und der Funktion übergeben möchte. Anhand welcher Variable die Zusammenfügung der Datensätze erfolgen soll lässt sich ebenfalls nicht pauschal sagen. Jeder Datensatz kann andere Spaltennamen oder Strukturen aufweisen. In der Psychologie ist es allerdings üblich, dass man jeder Versuchsperson über Datenerhebungen hinweg einen individuellen Code zuweist. Dieser wird dann zum Zusammenfügen verwendet. Oft heisst diese Variable Code oder ID – sie kann aber auch komplett anders heissen. Unabhängig vom konkreten Namen sollte das Codebook anzeigen, ob es eine solche Variable gibt und um welche es sich handelt.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wie-kann-man-ein-bereits-gesetztes-working-directory-also-den-arbeitsspeicher-des-skriptes-verschieben-idealerweise-sogar-von-ausserhalb-eines-projektes-in-ein-projekt-hinein",
    "href": "scripts/03_faq/rstudio.html#wie-kann-man-ein-bereits-gesetztes-working-directory-also-den-arbeitsspeicher-des-skriptes-verschieben-idealerweise-sogar-von-ausserhalb-eines-projektes-in-ein-projekt-hinein",
    "title": "1 RStudio",
    "section": "Wie kann man ein bereits gesetztes working directory (also den Arbeitsspeicher des Skriptes) verschieben, idealerweise sogar von ausserhalb eines Projektes in ein Projekt hinein?",
    "text": "Wie kann man ein bereits gesetztes working directory (also den Arbeitsspeicher des Skriptes) verschieben, idealerweise sogar von ausserhalb eines Projektes in ein Projekt hinein?\nAm einfachsten schliesst man das Skript und verschiebt es innerhalb deines Ordnersystems in das Projekt. Dann öffnet man RStudio (aber nicht das Skript, sondern nur das Programm) und wählt im gestarteten RStudio über File – Open File… das Skript aus und speichert es ab. Das working directory sollte nun innerhalb des Projektes liegen.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#was-ist-der-unterschied-zwischen-der-funktion-mutate-und-der-funktion-summarize-wie-kombiniert-man-diese-funktionen-am-besten-mit-group_by",
    "href": "scripts/03_faq/rstudio.html#was-ist-der-unterschied-zwischen-der-funktion-mutate-und-der-funktion-summarize-wie-kombiniert-man-diese-funktionen-am-besten-mit-group_by",
    "title": "1 RStudio",
    "section": "Was ist der Unterschied zwischen der Funktion mutate() und der Funktion summarize()? Wie kombiniert man diese Funktionen am besten mit group_by()?",
    "text": "Was ist der Unterschied zwischen der Funktion mutate() und der Funktion summarize()? Wie kombiniert man diese Funktionen am besten mit group_by()?\n\n\n\n\n\n\nImportant\n\n\n\nVorweg: Du kannst anhand der Syntax ?Funktionsname()die Dokumentation einer Funktion aufrufen. Hier wird beschrieben, welche Argumente die Funktion erwartet, was die Default-Einstellungen sind und was die Funktion ausgibt.\n\n\nMit mutate() fügst du Spalten hinzu oder änderst sie, während alle Zeilen erhalten bleiben; summarise() verdichtet hingegen die Zeilen zu Aggregaten – ohne Gruppierung zu einer Zeile für den gesamten Datensatz und mit group_by() zu einer Zeile pro Gruppe – und gibt dabei nur die Gruppenvariablen sowie die neu berechneten Kennwerte zurück.\n\n\n\n\n\n\nNote\n\n\n\nVisualisierungen finden sich hier.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wie-funktioniert-die-umwandlung-eines-wide-datensatzes-hin-zu-einem-long-datensatz-und-welche-argumente-beinhaltet-die-hierfür-angewendete-funktion-pivot_longer",
    "href": "scripts/03_faq/rstudio.html#wie-funktioniert-die-umwandlung-eines-wide-datensatzes-hin-zu-einem-long-datensatz-und-welche-argumente-beinhaltet-die-hierfür-angewendete-funktion-pivot_longer",
    "title": "1 RStudio",
    "section": "Wie funktioniert die Umwandlung eines wide-Datensatzes hin zu einem long-Datensatz und welche Argumente beinhaltet die hierfür angewendete Funktion pivot_longer()?",
    "text": "Wie funktioniert die Umwandlung eines wide-Datensatzes hin zu einem long-Datensatz und welche Argumente beinhaltet die hierfür angewendete Funktion pivot_longer()?\n\n\n\n\n\n\nImportant\n\n\n\nDu kannst anhand der Syntax ?Funktionsname()die Dokumentation einer Funktion aufrufen. Hier wird beschrieben, welche Argumente die Funktion erwartet, was die Default-Einstellungen sind und was die Funktion ausgibt.\n\n\nWie schon in der Frage erwähnt, die passende Funktion zur Umwandlung eines Datensatzes vom wide-Format in das long-Format erfolgt anhand der Funktion pivot_longer(). Die Funktion nimmt als die ersten beiden Argumente den Datensatz (data) und die Spalten, welche transformiert werden sollen (cols). Mit den anderen beiden Argumenten werden die Namen bestimmt, welche die Spalten haben sollen, in welcher die früheren Spaltenüberschriften (names_to = \"name\") und die Werte (values_to = \"value\") eingetragen werden.\n\ndata_long &lt;- data_wide |&gt; \n  pivot_longer(\n    cols = c(Spalte1, Spalte2, Spalte3), \n    names_to = \"Hier kommt der Name der Spalte rein, in welcher die früheren Spaltenüberschriften abgelegt sind\", \n    values_to = \"Hier kommt der Name der Spalte rein, in welcher die Werte der entsprechenden früheren Spalten abgelegt sind\"\n  )\n\n\n\n\n\n\n\nNote\n\n\n\nWeitere Informationen und Beispiele finden sich hier.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wie-funktioniert-der-pipe-operator-bzw.-und-was-ist-der-unterschied-zwischen-den-beiden",
    "href": "scripts/03_faq/rstudio.html#wie-funktioniert-der-pipe-operator-bzw.-und-was-ist-der-unterschied-zwischen-den-beiden",
    "title": "1 RStudio",
    "section": "Wie funktioniert der Pipe Operator |> bzw. %>% und was ist der Unterschied zwischen den beiden?",
    "text": "Wie funktioniert der Pipe Operator |&gt; bzw. %&gt;% und was ist der Unterschied zwischen den beiden?\nDer Pipe Operator nimmt das Resultat von oben bzw. links und übergibt dieses Zwischenergebnis nach unten bzw. rechts. Was helfen könnte: Die Syntax erst ohne Pipe aufschreiben und dann die Klammern nach und nach auflösen und mit der Pipe ersetzen. Die folgenden Code-Snippets sind äquivalent:\n\nsummarize(\n  filter(data, Variable == \"A\"),\n  mean = mean(Wert, na.rm = TRUE),\n  sd = sd(Wert, na.rm = TRUE)\n)\n\ndata %&gt;%\n  filter(Variable == \"A\") %&gt;%\n  summarize(mean = mean(Wert, na.rm = TRUE), sd = sd(Wert, na.rm = TRUE))\n\ndata |&gt; \n  filter(Variable == \"A\") |&gt; \n  summarize(mean = mean(Wert, na.rm = TRUE), sd = sd(Wert, na.rm = TRUE))\n\n\n\n\n\n\n\nNote\n\n\n\nDie Pipe Operatoren unterscheiden sich nur geringfügig und die Unterschiede sind für den Rahmen des Seminars nicht relevant, können jedoch hier nachgelesen werden.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wie-funktioniert-die-t.test-funktion",
    "href": "scripts/03_faq/rstudio.html#wie-funktioniert-die-t.test-funktion",
    "title": "1 RStudio",
    "section": "Wie funktioniert die t.test()-Funktion?",
    "text": "Wie funktioniert die t.test()-Funktion?\n\n\n\n\n\n\nImportant\n\n\n\nDu kannst anhand der Syntax ?Funktionsname()die Dokumentation einer Funktion aufrufen. Hier wird beschrieben, welche Argumente die Funktion erwartet, was die Default-Einstellungen sind und was die Funktion ausgibt.\n\n\nBei der t.test()-Funktion werden die Mittelwerte von Gruppen verglichen. Das Argument x ist verpflichtend und erwartet einen nummerischen Vektor (üblicherweise der Wert von Versuchspersonen auf der relevanten Variable). Das Argument y ist ein optionaler weiterer nummerischer Vektor, falls es sich um einen Zwei-Stichproben-Tests handelt. Das Argument alternative spezifiziert wie der t-Test ausgerichtet ist (≤, ≥ oder ≠). Das Argument mu gibt den erwarteten Mittelwert unter H0 an (Default = 0). Das Argument var.equal bestimmt, ob der Test unter der Annahme von Varianzhomogenität durch wird. Sprich, ob zwischen den beiden Gruppen die Varianzen gleich sind. Ist diese Annahme erfüllt, so wird ein students t-Test gerechnet. Ansonsten wird ein Welch t-Test gerechnet. Mit conf.level kann das Konfidenzintervall beliebig angepasst werden (Default = 0.95). Hier ein Beispiel Code-Snippet:\n\nt.test(x = data$Wert[data$Gruppe == \"A\"], \n       y = data$Wert[data$Gruppe == \"B\"], \n       alternative = \"two.sided\", # in diesem Fall ist der Test ungerichtet\n       mu = 0, # H0: Mittelwertunterschied = 0 (Default)\n       var.equal = FALSE, # Ablehnung der Varianzhomogenität (Defualt) und damit ein Welch`s t-Test\n       conf.level = 0.95) # Default",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#was-ist-der-unterschied-zwischen-as_factor-und-as.factor",
    "href": "scripts/03_faq/rstudio.html#was-ist-der-unterschied-zwischen-as_factor-und-as.factor",
    "title": "1 RStudio",
    "section": "Was ist der Unterschied zwischen as_factor() und as.factor()?",
    "text": "Was ist der Unterschied zwischen as_factor() und as.factor()?\n\n\n\n\n\n\nImportant\n\n\n\nDu kannst anhand der Syntax ?Funktionsname()die Dokumentation einer Funktion aufrufen. Hier wird beschrieben, welche Argumente die Funktion erwartet, was die Default-Einstellungen sind und was die Funktion ausgibt. Hierüber lassen sich auch Unterschiede zwischen ähnlichen Funktionen feststellen.\n\n\nBeide Funktionen formatieren Werte einer Spalte hin zu Faktoren. as.factor() ist in Base R vorhanden und erstellt die Faktoren anhand des Alphabets. as_factor() stammt aus dem Tidyverse, kann bereits in SPSS-Dateien enthaltene Faktorisierungen auslesen und erstellt neue Faktoren anhand der Auftrittsreihenfolge im Vektor.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#was-gibt-es-bei-ggplot-alles-für-visualisierungsmöglichkeiten",
    "href": "scripts/03_faq/rstudio.html#was-gibt-es-bei-ggplot-alles-für-visualisierungsmöglichkeiten",
    "title": "1 RStudio",
    "section": "Was gibt es bei ggplot alles für Visualisierungsmöglichkeiten?",
    "text": "Was gibt es bei ggplot alles für Visualisierungsmöglichkeiten?\nMit ggplot kann eine ganze Reihe an Visualisierungen manuell festgelegt werden, von der Art des Graphen, mehrdimensionale Darstellungen, Formatierung wie Farben, Grössen uvm. Eine grobe Übersicht gibt es hier.\n\n\n\n\n\n\nNote\n\n\n\nBeispiele und Übungen finden sich hier.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wie-kann-man-sicherstellen-dass-bei-der-visualisierung-von-graphen-die-apa-guidelines-eingehalten-werden",
    "href": "scripts/03_faq/rstudio.html#wie-kann-man-sicherstellen-dass-bei-der-visualisierung-von-graphen-die-apa-guidelines-eingehalten-werden",
    "title": "1 RStudio",
    "section": "Wie kann man sicherstellen, dass bei der Visualisierung von Graphen die APA-Guidelines eingehalten werden?",
    "text": "Wie kann man sicherstellen, dass bei der Visualisierung von Graphen die APA-Guidelines eingehalten werden?\nHierfür gibt es ein extra [theme_apa()](https://rdrr.io/cran/jtools/man/theme_apa.html). Dieses nimmt einem viele der Formatierungen ab. Einzelheiten muss man trotzdem noch prüfen bzw. je nach Abbildung müssen manche Formatierungen auch noch selbst ergänzt werden. Die genaueren APA-Guidelines sind auch noch mal hier zu finden.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wann-wird-ein-element-mit-und-wann-wird-ein-element-ohne-anführungszeichen-angesprochen",
    "href": "scripts/03_faq/rstudio.html#wann-wird-ein-element-mit-und-wann-wird-ein-element-ohne-anführungszeichen-angesprochen",
    "title": "1 RStudio",
    "section": "Wann wird ein Element mit und wann wird ein Element ohne Anführungszeichen angesprochen?",
    "text": "Wann wird ein Element mit und wann wird ein Element ohne Anführungszeichen angesprochen?\nAls Regel: Spricht man ein Objekt aus der Environment an, dann werden keine Anführungszeichen verwendet. Spricht man numerische Elemente aus einer Spalte an, dann werden ebenfalls keine Anführungszeichen verwendet. Spricht man Spaltenelemente an, welche als Faktor oder als Character formatiert sind, dann werden auch Anführungszeichen verwendet.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wie-funktionieren-die-relativen-pfade-und-wie-stellt-man-sicher-dass-diese-auch-bei-fremden-personen-funktionieren",
    "href": "scripts/03_faq/rstudio.html#wie-funktionieren-die-relativen-pfade-und-wie-stellt-man-sicher-dass-diese-auch-bei-fremden-personen-funktionieren",
    "title": "1 RStudio",
    "section": "Wie funktionieren die relativen Pfade und wie stellt man sicher, dass diese auch bei fremden Personen funktionieren?",
    "text": "Wie funktionieren die relativen Pfade und wie stellt man sicher, dass diese auch bei fremden Personen funktionieren?\nRelative Pfade gehen immer vom working directory (Arbeitsspeicher des Skripts) aus. Wenn man also Daten laden möchtest, dann muss man immer schauen, wo sich – ausgehend vom working directory – die Datenfiles befindet. Bei der Syntax des dann angegebenen Pfades gilt folgendes: 1. “Datensatz.Dateiendung” bildet ausnahmslos das Ende des Pfades. 2. “/” bilden den nächsten Step, also den Übergang von einem Ordner zum nächsten oder vom finalen Ordner zur Datei. 3. Soll im Ordnersystem in einen Ordner auf einer Ebene weiter oben gewechselt werden, dann kann ein “.” zusätzlich verwendet werden. Hier ein beispielhaftes Code-Snipet:\n\ndata &lt;- readr::read_csv(\"../data/Datensatz.Dateiendung\") # Starte im working directory (deswegen der erste \".\") und gehe eine Ordnerebene hoch (deswegen der zweite \".\"). Von dort aus gehe in den Ordner \"data\" und wähle dort die Datei \"Datensatz\" aus, welche dem Format \"Dateiendung\" entspricht.\n\nWird einer fremden Person nun das gesamte Ordnersystem mit all seinen Inhalten unverändert übergeben, so kann der Dateipfad innerhalb dieses Ordnersystems immer auch den Datensatz einlesen.\n\n\n\nAbb. 2.: Dateipfade",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wann-wird-die-tilde-und-das-dollarzeichen-verwendet",
    "href": "scripts/03_faq/rstudio.html#wann-wird-die-tilde-und-das-dollarzeichen-verwendet",
    "title": "1 RStudio",
    "section": "Wann wird die Tilde (~) und das Dollarzeichen ($) verwendet?",
    "text": "Wann wird die Tilde (~) und das Dollarzeichen ($) verwendet?\nDie Tilde bedeutet, was links von ihr steht, wird von dem, was rechts von ihr steht, vorhergesagt. Beispielsweise wird die Tilde üblicherweise bei Regressionen verwendet: lm(AV ~ UV). Das Dollarzeichen dient vor allem, um Spalten anhand ihrer Namen anzusprechen: data$Spaltenname. Manche Funktionen arbeiten mit beiden Schreibweisen. Beispielsweise sind die folgenden Schreibweisen äquivalent:\n\nt.test(data$variable1, data$variable2)\n      \nt.test(data, formula = variable ~ group)\n\nAllerdings müssen bei letzterer Schreibweise die Werte beider Gruppen zwingend im selben Datensatz vorliegen.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wann-wird-die-tilde-verwendet-und-wann-wird-ein-komma-verwendet",
    "href": "scripts/03_faq/rstudio.html#wann-wird-die-tilde-verwendet-und-wann-wird-ein-komma-verwendet",
    "title": "1 RStudio",
    "section": "Wann wird die Tilde (~) verwendet und wann wird ein Komma (,) verwendet?",
    "text": "Wann wird die Tilde (~) verwendet und wann wird ein Komma (,) verwendet?\nDie Tilde bedeutet, was links von ihr steht, wird von dem, was rechts von ihr steht, vorhergesagt. Beispielsweise wird die Tilde üblicherweise bei Regressionen verwendet: lm(AV ~ UV). Das Komma wird verwendet, um Argumente in einer Funktion zu trennen. Beispiel:\n\nresult &lt;- lm(AV ~ UV, data = datensatz)\n\nresult &lt;- t.test(x = datensatz$variable1, y = datensatz$variable2)\n\n\n\n\n\n\n\nWarning\n\n\n\nDas Komma sollte nicht verwendet werden um Dezimalzahlen zu definieren! Dies führt zu einer Fehlermeldung. Für Dezimalzahlen wird immer der Punkt verwendet (z.B. 3.14).",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wie-berechnet-man-das-generalisierte-η²",
    "href": "scripts/03_faq/rstudio.html#wie-berechnet-man-das-generalisierte-η²",
    "title": "1 RStudio",
    "section": "Wie berechnet man das generalisierte η²?",
    "text": "Wie berechnet man das generalisierte η²?\nMan erhält das generalisierte η² indem man erst eine ANOVA berechnet, abspeichert und dann über summary(anova_ergebnis, es = ges) ausgeben lässt.\n\nanova_ergebnis &lt;- afex::aov_car(value ~ treatment, data = example_data)\n\nsummary(anova_ergebnis, es = ges)",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wie-bereitet-man-die-daten-für-eine-mixed-anova-vor",
    "href": "scripts/03_faq/rstudio.html#wie-bereitet-man-die-daten-für-eine-mixed-anova-vor",
    "title": "1 RStudio",
    "section": "Wie bereitet man die Daten für eine mixed-ANOVA vor?",
    "text": "Wie bereitet man die Daten für eine mixed-ANOVA vor?\nEine mixed-ANOVA besteht aus der Varianzerklärung aufgrund unterschiedlicher Gruppenzugehörigkeiten (bspw. Kontrollgruppe und Experimentalgruppe) und einer Messwiederholung (mehrerer Messwerte pro Person, unabhängig von der Gruppenzugehörigkeit). Beides muss auch bereits in den Daten erkennbar sein. Sprich, pro Versuchsperson muss anhand einer Variable codiert sein, zu welcher Gruppe diese Versuchsperson gehört. Darüber hinaus muss es für jede Versuchsperson zu jedem Messzeitpunkt einen Wert geben. Angenommen die Daten liegen ursprünglich im wide-Format vor, dann müssen diese erst ins long-Format übertragen werden (siehe auch Fragen zum long-Format). Erst dann können die entsprechenden ANOVA-Funktionen die Daten entsprechend interpretieren.\n\n\n\n\n\n\nNote\n\n\n\nInhalte zu ANOVAs mit Messwiederholung oder mixed-ANOVAs könnt ihr auch noch mal über die Inhalte aus Statistik IV von Boris Mayer und Stefan Thoma wiederholen",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wofür-gibt-es-bei-der-funktion-aov_4-das-argument-1-personenidentifikationscode.-bzw.-das-argument-wiederholungsfaktor-personenidentifikationscode",
    "href": "scripts/03_faq/rstudio.html#wofür-gibt-es-bei-der-funktion-aov_4-das-argument-1-personenidentifikationscode.-bzw.-das-argument-wiederholungsfaktor-personenidentifikationscode",
    "title": "1 RStudio",
    "section": "Wofür gibt es bei der Funktion aov_4() das Argument (1 | Personenidentifikationscode). bzw. das Argument (Wiederholungsfaktor | Personenidentifikationscode)?",
    "text": "Wofür gibt es bei der Funktion aov_4() das Argument (1 | Personenidentifikationscode). bzw. das Argument (Wiederholungsfaktor | Personenidentifikationscode)?\n\n\n\n\n\n\nImportant\n\n\n\nDu kannst anhand der Syntax ?Funktionsname()die Dokumentation einer Funktion aufrufen. Hier wird beschrieben, welche Argumente die Funktion erwartet, was die Default-Einstellungen sind und was die Funktion ausgibt.\n\n\nDie Funktion aov_4() ist auf ANOVAs mit Messwiederholung ausgelegt und erwartet die zusätzliche Syntax (x | y). Die genaue Formulierung dieses Arguments hängt dann davon ab, ob es keine Messwiederholung gibt (1 | Personenidentifikationscode) oder ob es eine Messwiederholung gibt (Wiederholungsfaktor | Personenidentifikationscode).\n\nafex::aov_4(value ~ treatment + (1 | Personenidentifikationscode), data = example_data) # Beispiel ohne(!) Messwiederholung\n\nafex::aov_4(value ~ treatment + (time | Personenidentifikationscode), data = example_data) # Beispiel mit(!) Messwiederholung\n\n\n\n\n\n\n\nNote\n\n\n\nFür die Funktion aov_4() gibt es aus Statistik-IV von Boris Mayer und Stefan Thoma noch tiefere und beispielhafte Ausführungen.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wie-stellt-man-ein-dass-in-markdown-oder-quarto-der-output-meines-codes-unterbunden-wird",
    "href": "scripts/03_faq/rstudio.html#wie-stellt-man-ein-dass-in-markdown-oder-quarto-der-output-meines-codes-unterbunden-wird",
    "title": "1 RStudio",
    "section": "Wie stellt man ein, dass in Markdown oder Quarto der Output meines Codes unterbunden wird?",
    "text": "Wie stellt man ein, dass in Markdown oder Quarto der Output meines Codes unterbunden wird?\nEs kann entweder im ersten Chunk des Dokuments als globale Einstellung knitr::opts_chunk$set(output = FALSE) oder im entsprechend gewünschten Chunk einzeln die Option {r, output = FALSE} gesetzt werden den Output zu unterdrücken. Mittlerweile können solche Optionen auch über die Schreibweise #| explizit innerhalb des Chunks geschrieben werden. Ähnliche Befehle existieren auch, wenn man stattdessen oder zusätzlich Warnmeldungen oder den Code unterbinden möchte. Stellt bei der Endabgabe aber bitte sicher, dass der Code und mögliche Warnmeldungen sichtbar sind!\n\n# Hierdurch würde der Code zwar angezeigt, aber nicht mehr durchgeführt werden\n# #| eval: FALSE\n# Hierdurch würde der Code dann zusätzlich auch nicht mehr angezeigt werden\n# #| echo: FALSE",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#was-bedeutet-die-meldung-summarise-has-grouped-output-by-group.-you-can-override-using-the-.groups-argument.-und-was-muss-ich-dabei-beachten",
    "href": "scripts/03_faq/rstudio.html#was-bedeutet-die-meldung-summarise-has-grouped-output-by-group.-you-can-override-using-the-.groups-argument.-und-was-muss-ich-dabei-beachten",
    "title": "1 RStudio",
    "section": "Was bedeutet die Meldung „summarise() has grouped output by ‘group’. You can override using the .groups argument.“ und was muss ich dabei beachten?",
    "text": "Was bedeutet die Meldung „summarise() has grouped output by ‘group’. You can override using the .groups argument.“ und was muss ich dabei beachten?\nÜblicherweise werden deskriptive Werte (auch) für Subgruppen der Gesamtstichprobe angegeben (beispielsweise getrennt für Männer und Frauen, für die Kontrollgruppe oder die Experimentalgruppe etc.). Um entsprechende Änderungen vorzunehmen, wird daher vor der Anwendung von summarise() noch die Funktion group_by() verwendet. Nach der Berechnung der Deskriptivstatistik wird die Gruppierung nicht aufgehoben. Sie bleibt im Hintergrund, nicht direkt sichtbar, erhalten. Die Warnmeldung weisst genau darauf hin. Möchte man die Gruppierung aufheben, dann kann entweder die Funktion ungroup() verwendet werden oder summarise() wird um das Argument summarise(.group = „drop) ergänzt. Gruppierungen aufzulösen kann für manche Vorgänge, wie beispielsweise das Löschen von noch gruppierten Spalten relevant sein.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wann-soll-eine-neue-variable-bzw.-ein-neuer-datensatz-erstellt-werden-und-wann-soll-die-alte-variable-bzw.-der-neue-datensatz-überspeichert-werden",
    "href": "scripts/03_faq/rstudio.html#wann-soll-eine-neue-variable-bzw.-ein-neuer-datensatz-erstellt-werden-und-wann-soll-die-alte-variable-bzw.-der-neue-datensatz-überspeichert-werden",
    "title": "1 RStudio",
    "section": "Wann soll eine neue Variable bzw. ein neuer Datensatz erstellt werden und wann soll die alte Variable bzw. der neue Datensatz überspeichert werden?",
    "text": "Wann soll eine neue Variable bzw. ein neuer Datensatz erstellt werden und wann soll die alte Variable bzw. der neue Datensatz überspeichert werden?\nGrundsätzlich ist es vorzuziehen neue Variablen oder Datensätze zu erstellen. Zum einen kann so bei Bedarf noch auf die ursprünglichen Variablen oder Datensätze zugegriffen werden. Zum anderen ist die Analyse so für aussenstehende leichter nachzuvollziehen. Ausnahmen sind ästhetische Änderungen oder wiederholte Berechnungen, welche für die weitere Analyse nicht weiter relevant sind.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wann-eignet-es-sich-ein-projekt-anzulegen",
    "href": "scripts/03_faq/rstudio.html#wann-eignet-es-sich-ein-projekt-anzulegen",
    "title": "1 RStudio",
    "section": "Wann eignet es sich ein Projekt anzulegen?",
    "text": "Wann eignet es sich ein Projekt anzulegen?\nEin Projekt anzulegen, lohnt sich vor allem dann, wenn in mehreren Skripten gearbeitet wird. Dann muss nicht in jedem Skript einzeln das working directory (Arbeitsspeicher des Skripts) gesetzt werden. Wird in nur einem Skript gearbeitet, dann macht das Anlegen des Projekts keinen Unterschied.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wenn-ich-mein-quarto-dokument-zu-einer-pdf-datei-rendern-möchte-erhalte-ich-die-fehlermeldung-dass-latex-nicht-installiert-ist.-wie-kann-ich-latex-installieren",
    "href": "scripts/03_faq/rstudio.html#wenn-ich-mein-quarto-dokument-zu-einer-pdf-datei-rendern-möchte-erhalte-ich-die-fehlermeldung-dass-latex-nicht-installiert-ist.-wie-kann-ich-latex-installieren",
    "title": "1 RStudio",
    "section": "Wenn ich mein Quarto-Dokument zu einer PDF-Datei rendern möchte, erhalte ich die Fehlermeldung, dass LaTeX nicht installiert ist. Wie kann ich LaTeX installieren?",
    "text": "Wenn ich mein Quarto-Dokument zu einer PDF-Datei rendern möchte, erhalte ich die Fehlermeldung, dass LaTeX nicht installiert ist. Wie kann ich LaTeX installieren?\nLaTeX ist eine Software um individuelle, professionelle Formatierungen für PDFs oder andere Dateien zu erstellen. Was für unsere Zwecke bereits ausreichen sollte ist die Installation von tinytex. tinytex ist keine eigenständige Software, sondern schlichtweg um ein Paket von vielen in R.\n\n#install.packages(\"tinytex\")\n\nNach der Installation des Pakets ruft ihr dann folgendene Funktion auf:\n\n#tinytex::install_tinytex() \n#tinytex:: stellt sicher, dass die Funktion aus dem entsprechenden Paket aufgerufen wird\n\nHierdurch wird temporär die eigentliche Software installiert, mit welcher aus eurem Quarto-Dokument eine PDF erstellt werden kann. Dies kann einige Minuten dauern. Im Anschluss sollte das Rendern hin zu einer PDF funktionieren.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/fehlermeldungen.html",
    "href": "scripts/03_faq/fehlermeldungen.html",
    "title": "Fehlermeldungen",
    "section": "",
    "text": "Rendering in Quarto zu einer PDF funktioniert nicht\nIn der Vergangenheit gab es öfter Probleme mit der Installation von tinytex. Eine beispielhafte Fehlermeldung hierfür sah folgendermassen aus:\nprocessing file: skript.qmd\n|…………………………………. | x% [unnamed-chunk-x]\nError in contrib.url():\n! trying to use CRAN without setting a mirror\nBacktrace:\nx\n-utils::install.packages(“tinytex”) -utils::contrib.url(repos, “source”)\nQuitting from skript.qmd:Zeile-Zeile [unnamed-chunk-x]\nExecution halted\nDer Kern der Fehlermeldung lautet: “! trying ot use CRAN without setting a mirror”. CRAN ist die Plattform, von welcher standardmässig Pakete heruntergeladen werden. Die URL, also die Internetadressse von CRAN, ist dafür im Hintergrund in R eingestellt. Hier scheint es nun aber so, dass es unter der gesetzten URL kein Paket tinytex gibt. Dieses Problem lässt sich temporär (also einmalig für eure laufende Sitzung in RStudio) oder dauerhaft (also auch, wenn ihr RStudio schliesst und wieder neu startet) beheben. Um das Problem temporär zu lösen kann man einfach die URL zu CRAN explizit in der Console angeben:\n\n #| eval: false\n #| echo: true\n\noptions(repos = c(CRAN = \"https://cloud.r-project.org\"))\n\nMöchte man die Einstellung dauerhaft behalten braucht es einen weiteren Schritt. Erst wird über die Console eine globale Einstellungsdatei von RStudio geöffnet:\n\nIn diese Datei kann dann der Befehl zur expliziten Setzung der URL\nplatziert werden. Diese Datei abspeichern und RStudio neu starten. Jetzt\nsollte `tinytex` von der korrekten URL abgerufen, gefunden und\nschlussendlich auch erfolgreich installiert werden können.\n\n# Das Objekt mit dem ich etwas machen möchte kann nicht gefunden werden\n\n\"==\\&gt; quarto preview Hands on - Block 3.qmd --to html --no-watch-inputs\n--no-browse\n\nprocessing file: Hands-on---Block-3.rmarkdown\n\\|................................................. \\| 96%\n\\[unnamed-chunk-10\\] Error:! object 'dat_full' not foundBacktrace: ▆ 1.\n└─dplyr::rename(dat_full, cvstm_sum = \"csvtm_sum\") Quitting from\nHands-on---Block-3.rmarkdown:331-343 \\[unnamed-chunk-10\\] Execution\nhalted\"\n\nNetterweise gibt uns die Fehlermeldung die Stelle im Code aus, an\nwelcher das Problem aufrat:\n\n::: {.cell}\n\n```{.r .cell-code}\ndplyr::rename(dat_full, cvstm_sum = \"csvtm_sum\")\n:::\n\nDer zentrale Teil der Fehlermeldung ist hierbei “Error:! object dat_full not found”. Der Datensatz dat_full ist vor der Ausführung scheinbar noch nicht vorhanden. Stellt also unbedingt sicher, vor der Ausführung von dplyr::rename(dat_full, cvstm_sum = \"csvtm_sum\")den Datensatz eingelesen und den dafür vorgesehenen Chunk zum Einlesen nicht auf eval = FALSE gesetzt zu haben.\n\n\nBeim Rendern einer html werden noch einige weitere Ordner und Dateien erstellt\nUm zu grosse html-files oder Ladezeiten eines html-files zu vermeiden, weicht Quarto ggf. beim Rendern dazu aus nicht einen einzelnen html-file zu erstellen, sondern einen Ordner mit mehreren Dateien. Der html-file ruft diese dann beim Laden allesamt auf. Wenn das nicht gewünscht ist, dann gibt es mindestens zwei Möglichkeiten Quarto zu zwingen einen einzelnen und unabhängigen html-file zu erstellen. Als erste Variante kann der YAML-Header (der ganz oben im Quarto-file positioniert ist) um die Zeile embed-resources: true ergänzt werden:\n\n# vorher\n  format:\n    html:\n\n# nachher\n  format:\n    html:\n      embed-resources: true\n\nSollte sich auch damit das Problem nicht lösen, dann kann der Quarto-file auch manuell über das Terminal gerendert werden. Das Terminal beachten wir sonst im Seminar nicht, ist hierfür aber ausnahmsweise eine elegante Lösung. Das Terminal befindet sich unten links, wo sich auch die euch bereits vertraute Console und beim Rendern das Fenster Background Jobs befinden. Ist das Terminal noch nicht vorhanden, kann es über Tools –&gt; Terminal –&gt; New Terminal (Alt+ Umschalttaste + R) geöffnet werden. Dort wird dann folgender Befehl eingegeben:\n\nquarto render meinDokument.qmd --embed-resources\n\nHierbei muss natürlich noch der Dateiname des .qmd-file entsprechend angepasst werden. Weitere Informationen gibt es hier (am besten auf der Seite selbst noch nach dem Begriff embed-resources suchen).",
    "crumbs": [
      "FAQ",
      "1  RStudio",
      "1.1  Fehlermeldungen"
    ]
  },
  {
    "objectID": "scripts/03_faq/endabgabe.html",
    "href": "scripts/03_faq/endabgabe.html",
    "title": "5 Abschlussprojekt",
    "section": "",
    "text": "Note\n\n\n\nLies dir neben den folgenden Fragen auch noch mal die allgemeinen Infos zum Abschlussprojekt unter “Leistungsnachweis” durch.",
    "crumbs": [
      "FAQ",
      "5  Abschlussprojekt"
    ]
  },
  {
    "objectID": "scripts/03_faq/endabgabe.html#was-gibt-es-für-formatvorgaben-für-das-skript-schriftgrösse-fettmarkierungen-etc.",
    "href": "scripts/03_faq/endabgabe.html#was-gibt-es-für-formatvorgaben-für-das-skript-schriftgrösse-fettmarkierungen-etc.",
    "title": "5 Abschlussprojekt",
    "section": "Was gibt es für Formatvorgaben für das Skript (Schriftgrösse, Fettmarkierungen etc.)?",
    "text": "Was gibt es für Formatvorgaben für das Skript (Schriftgrösse, Fettmarkierungen etc.)?\nEs gibt keine exakten Formatvorgaben für das Skript. Vielmehr gilt: Das Skript sollte übersichtlich sein und keine ungewöhnlichen Formatierungen enthalten. Mit den Vorgaben von APA 7 ist das Skript sicher passend formatiert.",
    "crumbs": [
      "FAQ",
      "5  Abschlussprojekt"
    ]
  },
  {
    "objectID": "scripts/03_faq/endabgabe.html#welche-stilvorgaben-gibt-es-bei-der-erstellung-des-skripts-zu-beachten",
    "href": "scripts/03_faq/endabgabe.html#welche-stilvorgaben-gibt-es-bei-der-erstellung-des-skripts-zu-beachten",
    "title": "5 Abschlussprojekt",
    "section": "Welche Stilvorgaben gibt es bei der Erstellung des Skripts zu beachten?",
    "text": "Welche Stilvorgaben gibt es bei der Erstellung des Skripts zu beachten?\nDas Skript sollte sinnvolle Überschriften und eine sinnvolle Gliederung enthalten. Der Code sollte kommentiert sein, so dass die Auswahl von Funktionen und das Vorgehen begründet sind. Sofern LLMs oder andere externe Tools zur Hilfe herangezogen worden sind, muss dies angemerkt werden. Hierfür kann ggf. eine getrennte Kopie des Chatverlaufes eingereicht oder ein Link nach APA-Guidelines ergänzt werden.",
    "crumbs": [
      "FAQ",
      "5  Abschlussprojekt"
    ]
  },
  {
    "objectID": "scripts/03_faq/endabgabe.html#in-welcher-sprache-zeitform-perspektive-und-in-welchem-stil-soll-der-datenanalyseplan-geschrieben-werden",
    "href": "scripts/03_faq/endabgabe.html#in-welcher-sprache-zeitform-perspektive-und-in-welchem-stil-soll-der-datenanalyseplan-geschrieben-werden",
    "title": "5 Abschlussprojekt",
    "section": "In welcher Sprache, Zeitform, Perspektive und in welchem Stil soll der Datenanalyseplan geschrieben werden?",
    "text": "In welcher Sprache, Zeitform, Perspektive und in welchem Stil soll der Datenanalyseplan geschrieben werden?\nAlle für die Abgabe relevanten Unterlagen dürfen auf Englisch oder Deutsch eingereicht werden. Wichtig ist lediglich, dass die Unterlagen untereinander einer einheitlichen Sprache folgen. Als Zeitform gilt das Präsens. Bitte schreibe in der Wir-Form und im wissenschaftlichen Stil.",
    "crumbs": [
      "FAQ",
      "5  Abschlussprojekt"
    ]
  },
  {
    "objectID": "scripts/03_faq/endabgabe.html#wie-umfangreich-sollen-die-kommentare-des-codes-im-skript-sein",
    "href": "scripts/03_faq/endabgabe.html#wie-umfangreich-sollen-die-kommentare-des-codes-im-skript-sein",
    "title": "5 Abschlussprojekt",
    "section": "Wie umfangreich sollen die Kommentare des Codes im Skript sein?",
    "text": "Wie umfangreich sollen die Kommentare des Codes im Skript sein?\nDie Funktionsweise von üblicher Syntax (wie beispielsweise dem Pipe Operator) oder einer Funktion muss nicht kommentiert werden. Aber: Das Dokument muss für fremde Wissenschaftler:innen der Psychologie ohne weiteres nachvollziehbar sein. Bedeutet, Kommentare sollten das Vorgehen im Skript ausreichend begründen.",
    "crumbs": [
      "FAQ",
      "5  Abschlussprojekt"
    ]
  },
  {
    "objectID": "scripts/03_faq/endabgabe.html#sollen-im-skript-warn--undoder-fehlermeldungen-unterbunden-werden-oder-sichtbar-sein",
    "href": "scripts/03_faq/endabgabe.html#sollen-im-skript-warn--undoder-fehlermeldungen-unterbunden-werden-oder-sichtbar-sein",
    "title": "5 Abschlussprojekt",
    "section": "Sollen im Skript Warn- und/oder Fehlermeldungen unterbunden werden oder sichtbar sein?",
    "text": "Sollen im Skript Warn- und/oder Fehlermeldungen unterbunden werden oder sichtbar sein?\nDamit wir die Abgabe leichter kontrollieren können sollen die Warn- und Fehlermeldungen bitte sichtbar sein und nicht ausgeschaltet sein. Auch unabhängig von der Abgabe ist zu empfehlen die Meldungen sichtbar zu lassen. Das erleichtert Unbeteiligten die Analyse nachzuvollziehen und sie auf mögliche Fehler zu untersuchen.",
    "crumbs": [
      "FAQ",
      "5  Abschlussprojekt"
    ]
  },
  {
    "objectID": "scripts/03_faq/endabgabe.html#darf-im-skript-auch-noch-code-von-übungsaufgaben-vorhanden-sein",
    "href": "scripts/03_faq/endabgabe.html#darf-im-skript-auch-noch-code-von-übungsaufgaben-vorhanden-sein",
    "title": "5 Abschlussprojekt",
    "section": "Darf im Skript auch noch Code von Übungsaufgaben vorhanden sein?",
    "text": "Darf im Skript auch noch Code von Übungsaufgaben vorhanden sein?\nHier gilt der Grundsatz: Euer Skript, wie auch alle anderen Unterlagen, sollten für fremde Wissenschaftler:innen der Psychologie ohne weiteres nachvollziehbar sein. Code, welcher nicht im Zusammenhang mit der Endabgabe steht - und dementsprechend auch nicht im Datenanalyseplan erwähnt wird – würde nur vom wesentlichen Ablenken und soll daher nicht im Skript vorhanden sein.",
    "crumbs": [
      "FAQ",
      "5  Abschlussprojekt"
    ]
  },
  {
    "objectID": "scripts/03_faq/endabgabe.html#wie-exakt-sollen-die-tabellen-und-abbildungen-denen-aus-dem-paper-von-grinschgl-et-al.-2020-entsprechen",
    "href": "scripts/03_faq/endabgabe.html#wie-exakt-sollen-die-tabellen-und-abbildungen-denen-aus-dem-paper-von-grinschgl-et-al.-2020-entsprechen",
    "title": "5 Abschlussprojekt",
    "section": "Wie exakt sollen die Tabellen und Abbildungen denen aus dem Paper von Grinschgl et al. (2020) entsprechen?",
    "text": "Wie exakt sollen die Tabellen und Abbildungen denen aus dem Paper von Grinschgl et al. (2020) entsprechen?\nDie Tabellen und Abbildungen aus dem Originalpaper von Grinschgl et al. (2020) müssen nicht exakt repliziert werden. Wichtig ist allerdings, dass die Aussage der Abbildung bzw. der Tabelle korrekt ist und keine wichtigen Details ausgelassen werden.",
    "crumbs": [
      "FAQ",
      "5  Abschlussprojekt"
    ]
  },
  {
    "objectID": "scripts/03_faq/endabgabe.html#soll-die-berechnung-von-cronbachs-alpha-aus-dem-paper-von-grinschgl-et-al.-2020-auch-durchgeführt-werden",
    "href": "scripts/03_faq/endabgabe.html#soll-die-berechnung-von-cronbachs-alpha-aus-dem-paper-von-grinschgl-et-al.-2020-auch-durchgeführt-werden",
    "title": "5 Abschlussprojekt",
    "section": "Soll die Berechnung von Cronbachs Alpha aus dem Paper von Grinschgl et al. (2020) auch durchgeführt werden?",
    "text": "Soll die Berechnung von Cronbachs Alpha aus dem Paper von Grinschgl et al. (2020) auch durchgeführt werden?\nNein, die Berechnung von Cronbachs-Alpha aus dem Paper von Grinschgl et al. (2020) ist nicht Teil des Abschlussprojekts.",
    "crumbs": [
      "FAQ",
      "5  Abschlussprojekt"
    ]
  },
  {
    "objectID": "scripts/03_faq/codebook.html",
    "href": "scripts/03_faq/codebook.html",
    "title": "2 Codebook",
    "section": "",
    "text": "Fragen zum Codebook",
    "crumbs": [
      "FAQ",
      "2  Codebook"
    ]
  },
  {
    "objectID": "scripts/03_faq/codebook.html#sollen-im-codebook-alle-variablen-eines-datensatzes-beschrieben-werden-oder-nur-diejenigen-welche-auch-im-rahmen-der-analyse-verwendet-werden",
    "href": "scripts/03_faq/codebook.html#sollen-im-codebook-alle-variablen-eines-datensatzes-beschrieben-werden-oder-nur-diejenigen-welche-auch-im-rahmen-der-analyse-verwendet-werden",
    "title": "2 Codebook",
    "section": "Sollen im Codebook alle Variablen eines Datensatzes beschrieben werden oder nur diejenigen, welche auch im Rahmen der Analyse verwendet werden?",
    "text": "Sollen im Codebook alle Variablen eines Datensatzes beschrieben werden oder nur diejenigen, welche auch im Rahmen der Analyse verwendet werden?\nAls Grundsatz gilt: Das Codebook soll fremden Wissenschaftler:innen aus der Psychologie dabei helfen ohne weiteren Aufwand eure Arbeit zu beurteilen und ggf. zu replizieren. Für eine Replikation würde eine genaue Beschreibung der von euch in der Analyse verwendeten Variablen ausreichend. Eine allgemeine Beurteilung ist aber erst dann vollständig möglich, wenn auch alle anderen Variablen umfangreich beschrieben sind. Deswegen müssen im Codebook alle Variablen eures Datensatzes beschrieben werden, auch jene, die in der Analyse nicht weiter Beachtung finden.",
    "crumbs": [
      "FAQ",
      "2  Codebook"
    ]
  },
  {
    "objectID": "scripts/03_faq/codebook.html#sollten-unter-questionnaire-wirklich-nur-fragebögen-aufgelistet-werden-oder-kann-man-hier-auch-die-namen-möglicher-kognitiver-tests-angeben",
    "href": "scripts/03_faq/codebook.html#sollten-unter-questionnaire-wirklich-nur-fragebögen-aufgelistet-werden-oder-kann-man-hier-auch-die-namen-möglicher-kognitiver-tests-angeben",
    "title": "2 Codebook",
    "section": "Sollten unter „questionnaire“ wirklich nur Fragebögen aufgelistet werden oder kann man hier auch die Namen möglicher kognitiver Tests angeben?",
    "text": "Sollten unter „questionnaire“ wirklich nur Fragebögen aufgelistet werden oder kann man hier auch die Namen möglicher kognitiver Tests angeben?\nBei Angaben im Codebook sollte immer gelten: Sie erklären für unbeteiligte Wissenschaftler:innen aus der Psychologie mehr als das sie Verwirrung stiften. Unter „questionnaire“ auch die Namen von ggf. angewendeten kognitiven Tests anzugeben, unterstützt die Nachvollziehbarkeit und kann daher so gemacht werden.",
    "crumbs": [
      "FAQ",
      "2  Codebook"
    ]
  },
  {
    "objectID": "scripts/03_faq/codebook.html#wo-liegt-der-unterschied-zwischen-description-und-composition-of-item",
    "href": "scripts/03_faq/codebook.html#wo-liegt-der-unterschied-zwischen-description-und-composition-of-item",
    "title": "2 Codebook",
    "section": "Wo liegt der Unterschied zwischen „description“ und „Composition of item…“?",
    "text": "Wo liegt der Unterschied zwischen „description“ und „Composition of item…“?\nBei „description“ geht es um eine kurze inhaltliche Beschreibung der Variable, also was für einen Zweck die Variable in der Studie einnimmt oder mit welchem Konstrukt die Variable im Zusammenhang steht. Bei „composition of item“ geht es um die mathematische Zusammensetzung der Variable (z.B. Mittelwert aus Items XYZ).",
    "crumbs": [
      "FAQ",
      "2  Codebook"
    ]
  },
  {
    "objectID": "scripts/03_faq/codebook.html#wann-sind-response_labels-zu-verwenden-und-wann-nicht",
    "href": "scripts/03_faq/codebook.html#wann-sind-response_labels-zu-verwenden-und-wann-nicht",
    "title": "2 Codebook",
    "section": "Wann sind „response_labels“ zu verwenden und wann nicht?",
    "text": "Wann sind „response_labels“ zu verwenden und wann nicht?\nDie Labels der Antwortmöglichkeiten direkt zu benennen ist dann wichtig, wenn diese nicht logisch erschliessbar sind. Dies ist z.B. bei einer Likert-Skala der Fall, da diese unterschiedlich streng formuliert sein kann. Selbst wenn diese im Datenanalyseplan aufgeführt werden, ist es sicherer diese auch noch mal im Codebook zu erwähnen.",
    "crumbs": [
      "FAQ",
      "2  Codebook"
    ]
  },
  {
    "objectID": "scripts/03_faq/codebook.html#was-ist-mit-der-spalte-dimensions-gemeint",
    "href": "scripts/03_faq/codebook.html#was-ist-mit-der-spalte-dimensions-gemeint",
    "title": "2 Codebook",
    "section": "Was ist mit der Spalte „dimensions“ gemeint?",
    "text": "Was ist mit der Spalte „dimensions“ gemeint?\nUnter „dimensions“ soll das Konstrukt aufgeführt werden, welches sich hinter Items eines Fragebogens verbirgt (z.B. Item XY gehört zur dimension „Extraversion“ in einem Big 5 Fragebogen).",
    "crumbs": [
      "FAQ",
      "2  Codebook"
    ]
  },
  {
    "objectID": "scripts/03_faq/codebook.html#wie-soll-man-vorgehen-wenn-zu-manchen-dimensionen-der-variable-weder-im-paper-noch-in-der-präregistrierung-genaue-angaben-zu-finden-sind",
    "href": "scripts/03_faq/codebook.html#wie-soll-man-vorgehen-wenn-zu-manchen-dimensionen-der-variable-weder-im-paper-noch-in-der-präregistrierung-genaue-angaben-zu-finden-sind",
    "title": "2 Codebook",
    "section": "Wie soll man vorgehen, wenn zu manchen Dimensionen der Variable weder im Paper noch in der Präregistrierung genaue Angaben zu finden sind?",
    "text": "Wie soll man vorgehen, wenn zu manchen Dimensionen der Variable weder im Paper noch in der Präregistrierung genaue Angaben zu finden sind?\nFür den Fall, dass zu einer Angabe genaue Informationen fehlen, gibt es zwei Möglichkeiten. Zum einen kann man „reverse Engineering“ anwenden. Manche Informationen sind nirgendwo explizit angegeben, lassen sich aber beispielsweise anhand der gegebenen Informationen schlussfolgern. Hierzu zählen beispielsweise die minimalen und maximalen Werte einer Skala, welche mit einer hohen Wahrscheinlichkeit aus den Rohdaten ablesbar sind. Hierzu kann aber auch zählen, sich zu überlegen, was logisch oder mögliche Angaben sind. Das bedeutet nicht, dass in der ursprünglichen Studie auch tatsächlich so gearbeitet wurde, gibt aber trotzdem einen guten Anhaltspunkt. Unabhängig davon, wie man vorgeht, müsste dies kenntlich gemacht werden. Nur so können andere Personen mögliche Fehler in den Schlussfolgerungen oder Annahmen finden, anhand welcher die entsprechenden Informationen ergänzt wurden.",
    "crumbs": [
      "FAQ",
      "2  Codebook"
    ]
  },
  {
    "objectID": "scripts/03_faq/codebook.html#welche-informationen-sind-für-das-codebook-relevant-die-studie-von-grinschgl-et-al.-2020-undoder-die-präregistrierung-von-grinschgl-et-al.-2020",
    "href": "scripts/03_faq/codebook.html#welche-informationen-sind-für-das-codebook-relevant-die-studie-von-grinschgl-et-al.-2020-undoder-die-präregistrierung-von-grinschgl-et-al.-2020",
    "title": "2 Codebook",
    "section": "Welche Informationen sind für das Codebook relevant? Die Studie von Grinschgl et al. (2020) und/oder die Präregistrierung von Grinschgl et al. (2020)?",
    "text": "Welche Informationen sind für das Codebook relevant? Die Studie von Grinschgl et al. (2020) und/oder die Präregistrierung von Grinschgl et al. (2020)?\nFür das Ausfüllen des Codebook sind beide Quellen relevant, die Studie von Grinschgl et al. 2020 und die Präregistrierung zu Grinschgl et al. (2020).",
    "crumbs": [
      "FAQ",
      "2  Codebook"
    ]
  },
  {
    "objectID": "scripts/03_faq/codebook.html#sollen-alle-messwiederholungen-im-codebook-einzeln-aufgeführt-werden-oder-soll-es-eine-einzelne-variable-für-die-messwiederholung-im-codebook-geben",
    "href": "scripts/03_faq/codebook.html#sollen-alle-messwiederholungen-im-codebook-einzeln-aufgeführt-werden-oder-soll-es-eine-einzelne-variable-für-die-messwiederholung-im-codebook-geben",
    "title": "2 Codebook",
    "section": "Sollen alle Messwiederholungen im Codebook einzeln aufgeführt werden oder soll es eine einzelne Variable für die Messwiederholung im Codebook geben?",
    "text": "Sollen alle Messwiederholungen im Codebook einzeln aufgeführt werden oder soll es eine einzelne Variable für die Messwiederholung im Codebook geben?\nPrinzipiell gilt: Das Codebook soll es aussenstehenden möglichst einfach machen, sich mit den Daten und der Analyse der Daten vertraut zu machen und diese replizieren zu können. Daher gilt: Angaben sollten vollständig sein und so exakt wie möglich. Abweichungen – wie beispielsweise Zusammenfassungen mehrerer Variablen – sind demnach nur dann möglich und sinnvoll, wenn sich die einzelnen Variablen nicht voneinander unterscheiden und dies so klarer dargestellt werden kann.",
    "crumbs": [
      "FAQ",
      "2  Codebook"
    ]
  },
  {
    "objectID": "scripts/04_misc/here.html",
    "href": "scripts/04_misc/here.html",
    "title": "Probleme beim Rendern",
    "section": "",
    "text": "Beim Rendern von Quarto-Files treten Probleme auf, die auf der Auswertung von Filepaths zurückzuführen sind.\nWährend Code beim einfachen Ausführen in RStudio relativ zum Projektordner interpretiert wird, erfolgt die Pfadauswertung beim Rendern relativ zum Skript selbst. Dies kann zu Render-Fehlern wie dem folgenden führen.",
    "crumbs": [
      "Probleme beim Rendern"
    ]
  },
  {
    "objectID": "scripts/04_misc/here.html#problem",
    "href": "scripts/04_misc/here.html#problem",
    "title": "Probleme beim Rendern",
    "section": "",
    "text": "Beim Rendern von Quarto-Files treten Probleme auf, die auf der Auswertung von Filepaths zurückzuführen sind.\nWährend Code beim einfachen Ausführen in RStudio relativ zum Projektordner interpretiert wird, erfolgt die Pfadauswertung beim Rendern relativ zum Skript selbst. Dies kann zu Render-Fehlern wie dem folgenden führen.",
    "crumbs": [
      "Probleme beim Rendern"
    ]
  },
  {
    "objectID": "scripts/04_misc/here.html#lösung-mit-here",
    "href": "scripts/04_misc/here.html#lösung-mit-here",
    "title": "Probleme beim Rendern",
    "section": "Lösung mit here",
    "text": "Lösung mit here\nUm dieses Problem zu beheben, kann das here-Package verwendet werden.\nhere evaluiert Pfade konsistent relativ zum Projektordner und verhindert dadurch solche Render-Probleme.\nDurch die Verwendung von here ändern sich die Angaben des Filepfades beim Einlesen und Schreiben von Dateien leicht. Die einzige Veränderung ist dass wir den Filepfad in die here Funktion übergeben (in Klammern). Siehe dafür das Beispiel unten.\nDazu muss das Package here zunächst installiert werden:\n\ninstall.packages(\"here\")\nlibrary(here)\n\nUnd aus diesem Code der zu Problemen führen kann\n\ndata_cb &lt;- read_csv(\"data/raw/data_cb.csv\") #Kann zu Problemen beim Rendern führen. \n\nwird:\n\ndata_cb &lt;- read_csv(here(\"data/raw/data_cb.csv\")) # Sichere Variante\n\nDas gleiche gilt für das schreiben von daten mit write.csv\n\n# Kann zu Problemen führen\nwrite.csv(dat_full, \"data/processed/dat_full.csv\")\n\n# Sicherer: Pfad wird immer relativ zum Projekt-Root aufgelöst\nwrite.csv(dat_full, here(\"data/processed/dat_full.csv\"))\n\nDas sollte die Probleme lösen!",
    "crumbs": [
      "Probleme beim Rendern"
    ]
  },
  {
    "objectID": "scripts/04_misc/muddiest_points_2.html",
    "href": "scripts/04_misc/muddiest_points_2.html",
    "title": "Muddiest Points 2",
    "section": "",
    "text": "Bei mir gibt es beim Einlesen des Datensatzes immer noch eine zusätzliche Spalte, welche nochmal durchnummeriert ist (also wie eine ID, aber ohne Namen). Wie lese ich den Datensatz richtig ein, damit ich diese Spalte nicht immer noch zusätzlich löschen muss?\nAntwort:\nWahrscheinlich hast du beim Speichern der Daten mit write.csv() das Argument row.names nicht gesetzt. Wenn du row.names = FALSE angibst, entsteht diese zusätzliche Spalte nicht. Genauere Erklärung findest du hier. Das Problem liegt also vermutlich nicht am Einlesen der Daten, sondern daran wie du die Daten abgespeichert hast. Wenn dem nicht so ist - bitte komm noch mal auf uns zu!\n\n\n\n\nManchmal sind mir die Pfade, die ich beim Einlesen und Abspeichern einer Datei angeben muss, nicht klar. Die kürzere Version funktioniert oft nicht, deshalb muss ich immer den ganzen Pfad eingeben.\nAntwort:\nWenn relative Pfade nicht funktionieren, überprüfe zuerst, ob du dein Projekt korrekt geöffnet hast. Falls das Problem bleibt, kannst du mit getwd() dein aktuelles Arbeitsverzeichnis ausgeben lassen. Dieses sollte auf deinen Projektordner zeigen.\nWenn das nicht funktionieren sollte prüfe ob du diese Einstellung unter “Tools - Global Options” vorgenommen hast: Evaluate Chunks in directory: Projekt\n\n\n\n\n\nWeitere Möglichkeiten:\nWenn du dich zum Beispiel im Ordner grinschgl2020/code/ befindest, aber eine Datei aus einem übergeordneten Ordner einlesen möchtest (z. B. grinschgl2020/data/), kannst du beim Einlesen .. verwenden. Damit geht R eine Ebene nach oben, und relative Pfade funktionieren wie erwartet.\nBeispiel:\n\n# Wir befinden uns in: grinschgl2020/code/\n\n# Eine Ebene nach oben gehen (..) und in den data-Ordner wechseln\ndaten &lt;- read.csv(\"../data/raw/daten_roh.csv\")\n\n\n\n\n\nEinige Funktionen wie across() werden in anderen Funktionen verschachtelt verwendet und brauchen zusätzliche Argumente. Die Logik der Verschachtelung ist mir noch nicht klar.\nAntwort:\nFunktionen wie across() werden verschachtelt, weil sie nur innerhalb von dplyr-Funktionen wie mutate() oder summarise() arbeiten. Die äussere Funktion bestimmt, was passieren soll (z. B. Spalten verändern). across() legt dann fest, welche Spalten betroffen sind und welche Transformation angewendet wird. Deshalb braucht across() Argumente wie .cols und .fns. Die äussere Funktion gibt den Rahmen vor, across() steuert die konkrete Operation.\nBeispiel:\nacross() hat zwei wichtige Argumente:\n\n.cols → Welche Spalten sollen ausgewählt werden?\nIm Beispiel: alle Spalten, die auf “_r” enden. Across geht wert für wert durch diese Spalten\n.fns → Welche Operation soll auf jeden einzelnen Wert dieser Spalten angewendet werden?\nIm Beispiel: Für jeden Wert wird 6 – Wert berechnet (Umkehrkodierung).\nDas .x steht für den aktuellen Wert durch den across durchgeht. Manchmal wird auch nur ein Punkt ausgeschrieben da beide Schreibweisen funktionieren.\n\n\ndata_reversed &lt;- data_numeric |&gt;\n  mutate(\n    across(ends_with(\"_r\"), ~ 6 - .x) #~ 6 - . --&gt; Für jede wert der col -6 \n  )\n\n\n\n\n\nIch habe manchmal ein Data Frame an eine Funktion übergeben, obwohl diese einen Vektor erwartet, oder umgekehrt. Mir ist noch nicht klar, welche Funktionen Vektoren und welche Data Frames erwarten.\nGibt es irgendeine “Merkhilfe” um zu wissen bei welchen Packages/ Funktionen ich die Variablen auf welche Art auflisten muss? –&gt; Also ob mit “Variable” oder c(Variable)?\nAntwort:\nEs gibt keine feste Regel, aber die Hilfeseite (?funktion) zeigt immer, welcher Datentyp erwartet wird. Grundsätzlich gilt: Funktionen, die Spaltenweise etwas berechnen (z. B. mean, sum, skew), erwarten Vektoren – oft extrahiert man diese mit $ aus einen Dataframe.\nFunktionen, die Daten transformieren (summarise, mutate, filter, select), erwarten dagegen Data Frames, da sie auf mehreren Variablen gleichzeitig arbeiten.\nDas c bei Vektoren steht für concatenate und wird verwendet, wenn wir mit Vektoren arbeiten. Wenn nur ein Element im Vektor vorhanden ist, brauchen wir kein c() (Skalar). Sobald mehrere Elemente enthalten sind, benötigen wir c().\n\n\n\n\nIch bin mir noch unsicher darin, wann bestimmte Datenstrukturen notwendig sind – zum Beispiel die Umwandlung von Variablen in Faktoren.\nAntwort:\nViele Transformationen sind notwendig, weil statistische Funktionen bestimmte Datentypen voraussetzen. Die ANOVA etwa benötigt Faktoren, wenn Gruppen verglichen werden sollen, damit R die Gruppen-Variable als kategorial erkennt. Solche Transformationen sind also Teil der korrekten Vorbereitung der Daten. Wenn du z.B. eine ANOVA durchführst und vergisst die Gruppen-Variable als Faktor umzuwandeln, bekommst du eine Warnung. Durch diese erkennst du dann, dass ein Faktor benötigt wird - es ist also nicht allzu schlimm, wenn du die Umwandlung zunächst verpasst hast.\nEs ist eine gute Faustregel, Variablen in Faktoren umzuwandeln, wenn sie klar kategoriale Gruppen darstellen – zum Beispiel eine Gruppenzugehörigkeit wie “above”, “below” oder “control”.\n\n\n\n\nIch wäre froh, wenn wir allgemeine Fehler beim Codieren durchgehen könnten – also häufige Syntaxfehler und worauf man achten sollte.\nAntwort:\n(Dieser Punkt ist als Wunsch notiert.)\n\n\n\n\nDaten korrekt einlesen, abspeichern, und im Projektkontext richtig organisieren. / Abspeichern der Daten, gute Ordnerstruktur? Das ist nur ein “kleiner” Punkt, aber ich habe immer ein bisschen ein Durcheinander, wie ich Skripts und Projekte am besten abspeichere, damit auch immer alles funktioniert bei der Analyse. Oft habe ich bspw. zu lange Dateipfade\nAntwort:\nGrundsätzlich gilt: Alle Rohdaten werden im raw/-Ordner gespeichert (und niemals überschrieben). Diese Daten werden dann im processing-Skript bereinigt und verarbeitet. Die verarbeiteten Datensaetze werden anschliessend mit write.csv() im processed/-Ordner gespeichert.\nIm analysis-Skript werden keine Bereinigungen mehr vorgenommen, sondern nur noch die eigentlichen Analyseschritte durchgefuehrt (mit Ausnahme kleiner Anpassungen wie das Setzen von Faktoren, da diese Aenderungen nicht gespeichert werden).\nDiese Struktur orientiert sich am PsychDS-Standard.\nHausübungen und Hands on: Da wir mit vielen verschiedenen Datensätzen und Skripten arbeiten, ist es sinnvoll, eine klare Ordnerstruktur zu verwenden, zum Beispiel einen Ordner für Skripte und einen für Daten. Man kann sich dabei an der PsychDS-Struktur orientieren und diese übernehmen, auch wenn wir nicht mit den dat_full-Daten arbeiten.\nZu den Pfaden: Achte darauf, relative Pfade zu verwenden. Lange Pfade sind grundsätzlich kein Problem, solange sie relativ, nachvollziehbar und konsistent aufgebaut sind.\n\n\n\n\nWide to long: Weshalb ist das notwendig, weshalb kann man nicht beim einen Format bleiben?\nAntwort:\nViele Funktionen setzen ein bestimmtes Datenformat voraus. Repeated-Measures-Funktionen sind das beste Beispiel – sie benötigen Long-Format, weil jede Zeile eine Beobachtung darstellt. Das wird in den nächsten Wochen noch verständlicher - wenn wir dann Berechnungen mit dem Wide als auch Long Format durchführen.\n\n\n\n\nWas ist der Unterschied zwischen class(), attributes() und table()?\nAntwort:\n\nclass() zeigt den Typ eines Objekts\n\n\n  class(penguins)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n  class(penguins$species)\n\n[1] \"factor\"\n\n\n\ntable() zeigt Häufigkeiten\n\n\ntable(penguins$island)\n\n\n   Biscoe     Dream Torgersen \n      168       124        52 \n\n\n\nattributes() zeigt die Attribute eines Objekts\n\nbei Data Frames: Variablennamen, rownames, Datentypen\nbei Faktoren: Levels und Klasse\n\n\n\nattributes(penguins)\n\n$class\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n$row.names\n  [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n [91]  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n[109] 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126\n[127] 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144\n[145] 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162\n[163] 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180\n[181] 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198\n[199] 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216\n[217] 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234\n[235] 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252\n[253] 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270\n[271] 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288\n[289] 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306\n[307] 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324\n[325] 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342\n[343] 343 344\n\n$names\n[1] \"species\"           \"island\"            \"bill_length_mm\"   \n[4] \"bill_depth_mm\"     \"flipper_length_mm\" \"body_mass_g\"      \n[7] \"sex\"               \"year\"             \n\nattributes(penguins$species)\n\n$levels\n[1] \"Adelie\"    \"Chinstrap\" \"Gentoo\"   \n\n$class\n[1] \"factor\"\n\n\n\n\n\n\nWie kann ich nachhaltige Anpassungen an Variablen im Datensatz vornehmen?\nAntwort:\nUm Änderungen im Datensatz festzuhalten, muss eine Zuweisung mit &lt;- vorgenommen werden. Wenn ein Befehl ohne Zuweisung ausgeführt wird, wird das Resultat nicht im Environment abgespeichert. Wenn ein Objekt im Environment ist, heisst das nicht, dass dieses automatisch als z. B. CSV gespeichert wird. Dafür sollte es mit einer passenden Write-Funktion gespeichert werden. Im Processing-Skript führt ihr alle Aufbereitungsschritte (z. B. Variablen umbenennen) durch und speichert am Ende den bereinigten Datensatz mit write.csv() oder einer ähnlichen Funktion ab, damit alle Änderungen nachhaltig gesichert sind.\nBeispiel –&gt; Keine Veränderung am Datensatzt weil keine Zuweisung\n\npenguins |&gt;  \n  mutate(mean_bill_length = mean(bill_length_mm, na.rm = TRUE))\n\nBeispiel mit Zuweisung: Gleicher Datensatz wird verändert\n\npenguins &lt;- penguins |&gt; \n  mutate(mean_bill_length = mean(bill_length_mm, na.rm = TRUE))\n\n\n\n\n\nFür mich persönlich ist die group_by() Funktion irgendwie nicht ganz klar. Die Vorstellung, wie die Daten sortiert werden, ist nicht so intuitiv. \nAntwort:\nFür viele ist die Funktion anfangs nicht intuitiv. Die Vorstellung, wie die Daten intern in Gruppen „aufgeteilt“ werden, ohne dass sie tatsächlich sortiert oder neu angeordnet werden, fühlt sich ungewohnt an. Das ist völlig normal – die Logik hinter group_by() entwickelt sich meist erst, wenn man sieht, wie sie gemeinsam mit Funktionen wie summarise() oder mutate() wirkt. Kategoriale Daten werden in ihre kategorien augeteilt, kontinuierliche Daten werden in ihre einzigartigen werte gruppiert.\nBeispiel Kontinuierliche Variable: Gruppe für jedes Gewicht\n\npenguins_summary &lt;- penguins |&gt; \n  group_by(body_mass_g) |&gt; \n  summarize(mean_bill_length = mean(bill_length_mm, na.rm = TRUE))\n  \npenguins_summary[1:10, 1:2]\n\n# A tibble: 10 × 2\n   body_mass_g mean_bill_length\n         &lt;int&gt;            &lt;dbl&gt;\n 1        2700             46.9\n 2        2850             36.4\n 3        2900             37.4\n 4        2925             37.9\n 5        2975             37.5\n 6        3000             37.2\n 7        3050             35.6\n 8        3075             37.7\n 9        3100             36  \n10        3150             36.6\n\n\nBeispiel kategoriale Variable\n\npenguins_summary_2 &lt;- penguins |&gt; \n  group_by(island) |&gt; \n  summarize(mean_bill_length = mean(bill_length_mm, na.rm = TRUE))\n  \npenguins_summary_2\n\n# A tibble: 3 × 2\n  island    mean_bill_length\n  &lt;fct&gt;                &lt;dbl&gt;\n1 Biscoe                45.3\n2 Dream                 44.2\n3 Torgersen             39.0\n\n\n\n\n\n\nIch habe auch ein bisschen ein Durcheinander, wann die Daten am besten wie abgespeichert/eingelesen werden. Also mit read_delim(), row.names = FALSE, csv2 vs csv usw. \n\nEinlesen:\nKurz zusammengefasst: Am einfachsten ist es, zunächst die Point-and-Click-Oberfläche in RStudio zu nutzen und die Optionen so einzustellen, dass die Daten sinnvoll eingelesen werden, und anschliessend den generierten Code zu übernehmen. read_csv() ist im Prinzip das Gleiche wie read_delim(), nur dass es standardmässig ein Komma als Trennzeichen verwendet (CSV bedeutet comma separated values). Bei read_delim() muss das Trennzeichen hingegen explizit angegeben werden, zum Beispiel ein Semikolon.\nSpeichern:\nZum Speichern nutzt ihr am besten write.csv(). Von write.csv2() sollte man eher die Finger lassen, da es historische Spezialfälle abdeckt und meist eher zu Verwirrung führt.",
    "crumbs": [
      "Muddiest Points"
    ]
  },
  {
    "objectID": "scripts/04_misc/muddiest_points_2.html#muddiest-points-session-2",
    "href": "scripts/04_misc/muddiest_points_2.html#muddiest-points-session-2",
    "title": "Muddiest Points 2",
    "section": "",
    "text": "Bei mir gibt es beim Einlesen des Datensatzes immer noch eine zusätzliche Spalte, welche nochmal durchnummeriert ist (also wie eine ID, aber ohne Namen). Wie lese ich den Datensatz richtig ein, damit ich diese Spalte nicht immer noch zusätzlich löschen muss?\nAntwort:\nWahrscheinlich hast du beim Speichern der Daten mit write.csv() das Argument row.names nicht gesetzt. Wenn du row.names = FALSE angibst, entsteht diese zusätzliche Spalte nicht. Genauere Erklärung findest du hier. Das Problem liegt also vermutlich nicht am Einlesen der Daten, sondern daran wie du die Daten abgespeichert hast. Wenn dem nicht so ist - bitte komm noch mal auf uns zu!\n\n\n\n\nManchmal sind mir die Pfade, die ich beim Einlesen und Abspeichern einer Datei angeben muss, nicht klar. Die kürzere Version funktioniert oft nicht, deshalb muss ich immer den ganzen Pfad eingeben.\nAntwort:\nWenn relative Pfade nicht funktionieren, überprüfe zuerst, ob du dein Projekt korrekt geöffnet hast. Falls das Problem bleibt, kannst du mit getwd() dein aktuelles Arbeitsverzeichnis ausgeben lassen. Dieses sollte auf deinen Projektordner zeigen.\nWenn das nicht funktionieren sollte prüfe ob du diese Einstellung unter “Tools - Global Options” vorgenommen hast: Evaluate Chunks in directory: Projekt\n\n\n\n\n\nWeitere Möglichkeiten:\nWenn du dich zum Beispiel im Ordner grinschgl2020/code/ befindest, aber eine Datei aus einem übergeordneten Ordner einlesen möchtest (z. B. grinschgl2020/data/), kannst du beim Einlesen .. verwenden. Damit geht R eine Ebene nach oben, und relative Pfade funktionieren wie erwartet.\nBeispiel:\n\n# Wir befinden uns in: grinschgl2020/code/\n\n# Eine Ebene nach oben gehen (..) und in den data-Ordner wechseln\ndaten &lt;- read.csv(\"../data/raw/daten_roh.csv\")\n\n\n\n\n\nEinige Funktionen wie across() werden in anderen Funktionen verschachtelt verwendet und brauchen zusätzliche Argumente. Die Logik der Verschachtelung ist mir noch nicht klar.\nAntwort:\nFunktionen wie across() werden verschachtelt, weil sie nur innerhalb von dplyr-Funktionen wie mutate() oder summarise() arbeiten. Die äussere Funktion bestimmt, was passieren soll (z. B. Spalten verändern). across() legt dann fest, welche Spalten betroffen sind und welche Transformation angewendet wird. Deshalb braucht across() Argumente wie .cols und .fns. Die äussere Funktion gibt den Rahmen vor, across() steuert die konkrete Operation.\nBeispiel:\nacross() hat zwei wichtige Argumente:\n\n.cols → Welche Spalten sollen ausgewählt werden?\nIm Beispiel: alle Spalten, die auf “_r” enden. Across geht wert für wert durch diese Spalten\n.fns → Welche Operation soll auf jeden einzelnen Wert dieser Spalten angewendet werden?\nIm Beispiel: Für jeden Wert wird 6 – Wert berechnet (Umkehrkodierung).\nDas .x steht für den aktuellen Wert durch den across durchgeht. Manchmal wird auch nur ein Punkt ausgeschrieben da beide Schreibweisen funktionieren.\n\n\ndata_reversed &lt;- data_numeric |&gt;\n  mutate(\n    across(ends_with(\"_r\"), ~ 6 - .x) #~ 6 - . --&gt; Für jede wert der col -6 \n  )\n\n\n\n\n\nIch habe manchmal ein Data Frame an eine Funktion übergeben, obwohl diese einen Vektor erwartet, oder umgekehrt. Mir ist noch nicht klar, welche Funktionen Vektoren und welche Data Frames erwarten.\nGibt es irgendeine “Merkhilfe” um zu wissen bei welchen Packages/ Funktionen ich die Variablen auf welche Art auflisten muss? –&gt; Also ob mit “Variable” oder c(Variable)?\nAntwort:\nEs gibt keine feste Regel, aber die Hilfeseite (?funktion) zeigt immer, welcher Datentyp erwartet wird. Grundsätzlich gilt: Funktionen, die Spaltenweise etwas berechnen (z. B. mean, sum, skew), erwarten Vektoren – oft extrahiert man diese mit $ aus einen Dataframe.\nFunktionen, die Daten transformieren (summarise, mutate, filter, select), erwarten dagegen Data Frames, da sie auf mehreren Variablen gleichzeitig arbeiten.\nDas c bei Vektoren steht für concatenate und wird verwendet, wenn wir mit Vektoren arbeiten. Wenn nur ein Element im Vektor vorhanden ist, brauchen wir kein c() (Skalar). Sobald mehrere Elemente enthalten sind, benötigen wir c().\n\n\n\n\nIch bin mir noch unsicher darin, wann bestimmte Datenstrukturen notwendig sind – zum Beispiel die Umwandlung von Variablen in Faktoren.\nAntwort:\nViele Transformationen sind notwendig, weil statistische Funktionen bestimmte Datentypen voraussetzen. Die ANOVA etwa benötigt Faktoren, wenn Gruppen verglichen werden sollen, damit R die Gruppen-Variable als kategorial erkennt. Solche Transformationen sind also Teil der korrekten Vorbereitung der Daten. Wenn du z.B. eine ANOVA durchführst und vergisst die Gruppen-Variable als Faktor umzuwandeln, bekommst du eine Warnung. Durch diese erkennst du dann, dass ein Faktor benötigt wird - es ist also nicht allzu schlimm, wenn du die Umwandlung zunächst verpasst hast.\nEs ist eine gute Faustregel, Variablen in Faktoren umzuwandeln, wenn sie klar kategoriale Gruppen darstellen – zum Beispiel eine Gruppenzugehörigkeit wie “above”, “below” oder “control”.\n\n\n\n\nIch wäre froh, wenn wir allgemeine Fehler beim Codieren durchgehen könnten – also häufige Syntaxfehler und worauf man achten sollte.\nAntwort:\n(Dieser Punkt ist als Wunsch notiert.)\n\n\n\n\nDaten korrekt einlesen, abspeichern, und im Projektkontext richtig organisieren. / Abspeichern der Daten, gute Ordnerstruktur? Das ist nur ein “kleiner” Punkt, aber ich habe immer ein bisschen ein Durcheinander, wie ich Skripts und Projekte am besten abspeichere, damit auch immer alles funktioniert bei der Analyse. Oft habe ich bspw. zu lange Dateipfade\nAntwort:\nGrundsätzlich gilt: Alle Rohdaten werden im raw/-Ordner gespeichert (und niemals überschrieben). Diese Daten werden dann im processing-Skript bereinigt und verarbeitet. Die verarbeiteten Datensaetze werden anschliessend mit write.csv() im processed/-Ordner gespeichert.\nIm analysis-Skript werden keine Bereinigungen mehr vorgenommen, sondern nur noch die eigentlichen Analyseschritte durchgefuehrt (mit Ausnahme kleiner Anpassungen wie das Setzen von Faktoren, da diese Aenderungen nicht gespeichert werden).\nDiese Struktur orientiert sich am PsychDS-Standard.\nHausübungen und Hands on: Da wir mit vielen verschiedenen Datensätzen und Skripten arbeiten, ist es sinnvoll, eine klare Ordnerstruktur zu verwenden, zum Beispiel einen Ordner für Skripte und einen für Daten. Man kann sich dabei an der PsychDS-Struktur orientieren und diese übernehmen, auch wenn wir nicht mit den dat_full-Daten arbeiten.\nZu den Pfaden: Achte darauf, relative Pfade zu verwenden. Lange Pfade sind grundsätzlich kein Problem, solange sie relativ, nachvollziehbar und konsistent aufgebaut sind.\n\n\n\n\nWide to long: Weshalb ist das notwendig, weshalb kann man nicht beim einen Format bleiben?\nAntwort:\nViele Funktionen setzen ein bestimmtes Datenformat voraus. Repeated-Measures-Funktionen sind das beste Beispiel – sie benötigen Long-Format, weil jede Zeile eine Beobachtung darstellt. Das wird in den nächsten Wochen noch verständlicher - wenn wir dann Berechnungen mit dem Wide als auch Long Format durchführen.\n\n\n\n\nWas ist der Unterschied zwischen class(), attributes() und table()?\nAntwort:\n\nclass() zeigt den Typ eines Objekts\n\n\n  class(penguins)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n  class(penguins$species)\n\n[1] \"factor\"\n\n\n\ntable() zeigt Häufigkeiten\n\n\ntable(penguins$island)\n\n\n   Biscoe     Dream Torgersen \n      168       124        52 \n\n\n\nattributes() zeigt die Attribute eines Objekts\n\nbei Data Frames: Variablennamen, rownames, Datentypen\nbei Faktoren: Levels und Klasse\n\n\n\nattributes(penguins)\n\n$class\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n$row.names\n  [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n [91]  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n[109] 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126\n[127] 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144\n[145] 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162\n[163] 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180\n[181] 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198\n[199] 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216\n[217] 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234\n[235] 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252\n[253] 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270\n[271] 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288\n[289] 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306\n[307] 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324\n[325] 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342\n[343] 343 344\n\n$names\n[1] \"species\"           \"island\"            \"bill_length_mm\"   \n[4] \"bill_depth_mm\"     \"flipper_length_mm\" \"body_mass_g\"      \n[7] \"sex\"               \"year\"             \n\nattributes(penguins$species)\n\n$levels\n[1] \"Adelie\"    \"Chinstrap\" \"Gentoo\"   \n\n$class\n[1] \"factor\"\n\n\n\n\n\n\nWie kann ich nachhaltige Anpassungen an Variablen im Datensatz vornehmen?\nAntwort:\nUm Änderungen im Datensatz festzuhalten, muss eine Zuweisung mit &lt;- vorgenommen werden. Wenn ein Befehl ohne Zuweisung ausgeführt wird, wird das Resultat nicht im Environment abgespeichert. Wenn ein Objekt im Environment ist, heisst das nicht, dass dieses automatisch als z. B. CSV gespeichert wird. Dafür sollte es mit einer passenden Write-Funktion gespeichert werden. Im Processing-Skript führt ihr alle Aufbereitungsschritte (z. B. Variablen umbenennen) durch und speichert am Ende den bereinigten Datensatz mit write.csv() oder einer ähnlichen Funktion ab, damit alle Änderungen nachhaltig gesichert sind.\nBeispiel –&gt; Keine Veränderung am Datensatzt weil keine Zuweisung\n\npenguins |&gt;  \n  mutate(mean_bill_length = mean(bill_length_mm, na.rm = TRUE))\n\nBeispiel mit Zuweisung: Gleicher Datensatz wird verändert\n\npenguins &lt;- penguins |&gt; \n  mutate(mean_bill_length = mean(bill_length_mm, na.rm = TRUE))\n\n\n\n\n\nFür mich persönlich ist die group_by() Funktion irgendwie nicht ganz klar. Die Vorstellung, wie die Daten sortiert werden, ist nicht so intuitiv. \nAntwort:\nFür viele ist die Funktion anfangs nicht intuitiv. Die Vorstellung, wie die Daten intern in Gruppen „aufgeteilt“ werden, ohne dass sie tatsächlich sortiert oder neu angeordnet werden, fühlt sich ungewohnt an. Das ist völlig normal – die Logik hinter group_by() entwickelt sich meist erst, wenn man sieht, wie sie gemeinsam mit Funktionen wie summarise() oder mutate() wirkt. Kategoriale Daten werden in ihre kategorien augeteilt, kontinuierliche Daten werden in ihre einzigartigen werte gruppiert.\nBeispiel Kontinuierliche Variable: Gruppe für jedes Gewicht\n\npenguins_summary &lt;- penguins |&gt; \n  group_by(body_mass_g) |&gt; \n  summarize(mean_bill_length = mean(bill_length_mm, na.rm = TRUE))\n  \npenguins_summary[1:10, 1:2]\n\n# A tibble: 10 × 2\n   body_mass_g mean_bill_length\n         &lt;int&gt;            &lt;dbl&gt;\n 1        2700             46.9\n 2        2850             36.4\n 3        2900             37.4\n 4        2925             37.9\n 5        2975             37.5\n 6        3000             37.2\n 7        3050             35.6\n 8        3075             37.7\n 9        3100             36  \n10        3150             36.6\n\n\nBeispiel kategoriale Variable\n\npenguins_summary_2 &lt;- penguins |&gt; \n  group_by(island) |&gt; \n  summarize(mean_bill_length = mean(bill_length_mm, na.rm = TRUE))\n  \npenguins_summary_2\n\n# A tibble: 3 × 2\n  island    mean_bill_length\n  &lt;fct&gt;                &lt;dbl&gt;\n1 Biscoe                45.3\n2 Dream                 44.2\n3 Torgersen             39.0\n\n\n\n\n\n\nIch habe auch ein bisschen ein Durcheinander, wann die Daten am besten wie abgespeichert/eingelesen werden. Also mit read_delim(), row.names = FALSE, csv2 vs csv usw. \n\nEinlesen:\nKurz zusammengefasst: Am einfachsten ist es, zunächst die Point-and-Click-Oberfläche in RStudio zu nutzen und die Optionen so einzustellen, dass die Daten sinnvoll eingelesen werden, und anschliessend den generierten Code zu übernehmen. read_csv() ist im Prinzip das Gleiche wie read_delim(), nur dass es standardmässig ein Komma als Trennzeichen verwendet (CSV bedeutet comma separated values). Bei read_delim() muss das Trennzeichen hingegen explizit angegeben werden, zum Beispiel ein Semikolon.\nSpeichern:\nZum Speichern nutzt ihr am besten write.csv(). Von write.csv2() sollte man eher die Finger lassen, da es historische Spezialfälle abdeckt und meist eher zu Verwirrung führt.",
    "crumbs": [
      "Muddiest Points"
    ]
  },
  {
    "objectID": "scripts/04_misc/index.html",
    "href": "scripts/04_misc/index.html",
    "title": "Einleitung",
    "section": "",
    "text": "In diesem E-Book findest du alle wichtigen Informationen zum Methodenseminar “R u Ready”. Du kannst hier u. a. die wöchentlichen Folien, Hands-On R Übungen, den Leistungsnachweis, und Frequently Asked Questions einsehen. Du kannst über die Unterkapitel (links) zu den entsprechenden Inhalten navigieren, oder auch die Suchfunktion oben links verwenden, um nach einem bestimmten Begriff zu suchen.\n\nHinweisboxen\nHier einen Überblick über die auf den Seiten enthaltenen Hinweisboxen:\n\n\n\n\n\n\nNote\n\n\n\nVertiefung: Hier geht es in die Tiefe.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWichtig: Dies ist eine wichtige Information.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAchtung: Hier ist Vorsicht geboten.\n\n\n\n\n\n\n\n\nCaution\n\n\n\nVorsicht: Diese Information ist noch in Bearbeitung.\n\n\n\n\nSyllabus\n\n\n\n\n\n\nCaution\n\n\n\nVorsicht: Der Syllabus dient als grobe Richtlinie und kann angepasst werden, falls wir in einzelnen Einheiten mehr oder weniger Zeit benötigen.\n\n\n\n\nLetztes Update January 15, 2026 at 16:37"
  },
  {
    "objectID": "scripts/04_misc/front_page.html",
    "href": "scripts/04_misc/front_page.html",
    "title": "Einleitung",
    "section": "",
    "text": "In diesem E-Book findest du alle wichtigen Informationen zum Methodenseminar “R u Ready”. Du kannst hier u. a. die wöchentlichen Folien, Hands-On R Übungen, den Leistungsnachweis, und Frequently Asked Questions einsehen. Du kannst über die Unterkapitel (links) zu den entsprechenden Inhalten navigieren, oder auch die Suchfunktion oben links verwenden, um nach einem bestimmten Begriff zu suchen.\n\nHinweisboxen\nHier einen Überblick über die auf den Seiten enthaltenen Hinweisboxen:\n\n\n\n\n\n\nNote\n\n\n\nVertiefung: Hier geht es in die Tiefe.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWichtig: Dies ist eine wichtige Information.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAchtung: Hier ist Vorsicht geboten.\n\n\n\n\n\n\n\n\nCaution\n\n\n\nVorsicht: Diese Information ist noch in Bearbeitung.\n\n\n\n\nSyllabus\n\n\n\n\n\n\nCaution\n\n\n\nVorsicht: Der Syllabus dient als grobe Richtlinie und kann angepasst werden, falls wir in einzelnen Einheiten mehr oder weniger Zeit benötigen.\n\n\n\n\nLetztes Update January 15, 2026 at 16:37",
    "crumbs": [
      "Einleitung"
    ]
  },
  {
    "objectID": "scripts/04_misc/Memes.html",
    "href": "scripts/04_misc/Memes.html",
    "title": "Memes",
    "section": "",
    "text": "You did it! Viel Spass beim Memes anschauen!\n🔗\n🔗\n🔗\n🔗\n🔗\n🔗\n🔗\n🔗\n🔗\n🔗",
    "crumbs": [
      "Links und Ressourcen",
      "Memes :)"
    ]
  },
  {
    "objectID": "scripts/04_misc/Memes.html#memes",
    "href": "scripts/04_misc/Memes.html#memes",
    "title": "Memes",
    "section": "",
    "text": "You did it! Viel Spass beim Memes anschauen!\n🔗\n🔗\n🔗\n🔗\n🔗\n🔗\n🔗\n🔗\n🔗\n🔗",
    "crumbs": [
      "Links und Ressourcen",
      "Memes :)"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Webseite_FS26",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "scripts/04_misc/requirements.html",
    "href": "scripts/04_misc/requirements.html",
    "title": "requirements",
    "section": "",
    "text": "# requirements.R\n\n# Nutze das benutzerdefinierte Library-Verzeichnis, falls gesetzt\nif (!is.na(Sys.getenv(\"R_LIBS_USER\", unset = NA))) {\n  .libPaths(Sys.getenv(\"R_LIBS_USER\"))\n}\n\ninstall_if_missing &lt;- function(pkg) {\n  if (!pkg %in% rownames(installed.packages())) {\n    install.packages(pkg, repos = \"https://cloud.r-project.org\")\n  }\n}\n\n# Liste der benötigten Pakete – hier kannst du jederzeit erweitern\npkgs &lt;- c(\n  \"tidyverse\",\n  \"knitr\",\n  \"rmarkdown\"\n)\n\nsapply(pkgs, install_if_missing)\n\n$tidyverse\nNULL\n\n$knitr\nNULL\n\n$rmarkdown\nNULL"
  },
  {
    "objectID": "scripts/04_misc/links_und_ressourcen.html",
    "href": "scripts/04_misc/links_und_ressourcen.html",
    "title": "Links und Ressourcen",
    "section": "",
    "text": "Auf dieser Seite finden sich die Links zu den Ressourcen, die wir im Rahmen dieses Seminars empfehlen.",
    "crumbs": [
      "Links und Ressourcen"
    ]
  },
  {
    "objectID": "scripts/04_misc/links_und_ressourcen.html#open-science-und-replikationskrise",
    "href": "scripts/04_misc/links_und_ressourcen.html#open-science-und-replikationskrise",
    "title": "Links und Ressourcen",
    "section": "Open Science und Replikationskrise",
    "text": "Open Science und Replikationskrise\n\n🎥 Is there a reproducibility crisis in science? – Matt Anticole\n📘 The Seven Deadly Sins of Psychology (Chris Chambers, 2017)\n🏛️ Universitätsbibliothek Bern – Open Science\n🌐 Data Colada\n☕ ReproducibiliTea\n🎓 Universität Bern – Lehrveranstaltungen Institut für Psychologie\n🎥 Charlotte Pennington – A Student’s Guide to Open Science",
    "crumbs": [
      "Links und Ressourcen"
    ]
  },
  {
    "objectID": "scripts/04_misc/links_und_ressourcen.html#r-und-r-studio",
    "href": "scripts/04_misc/links_und_ressourcen.html#r-und-r-studio",
    "title": "Links und Ressourcen",
    "section": "R und R-Studio",
    "text": "R und R-Studio\n\n📗 Einführung in R – Methodenlehre Uni Bern (Andrew Ellis & Boris Mayer)\n📘 R for Data Science – Basics wie Import, Aufbereitung, Visualisierung\n📖 R für Einsteiger – Maike Luhmann\n📊 Psychometrics in Exercises using R and RStudio – EFA, CFA, SEM\n📦 Informationen zu R-Paketen (CRAN)\n🤖 Psyteacher AI Tutor\n💡 Learnr Shinyapps\n📋 RStudio Cheatsheets\n💬 Stack Overflow – R Community\n🎓 DataCamp – Interactive R Courses\n📰 Newsletter zu R – Aktuelle News, Pakete und Tutorials aus der R-Community\n📚 Überblick über weitere Ressourcen – Arslan (2025)",
    "crumbs": [
      "Links und Ressourcen"
    ]
  },
  {
    "objectID": "scripts/04_misc/checkliste_abschlussarbeit.html",
    "href": "scripts/04_misc/checkliste_abschlussarbeit.html",
    "title": "Checkliste Abschlussarbeit",
    "section": "",
    "text": "Abgabe bis 11.1.2026 - 23:55\nAbgabe als ZIP-File: vorname_nachname_abschlussarbeit.zip\nFür die Abschlussarbeit erhaltet ihr simulierte Daten. Diese werden den Daten des Originalpapers in den meisten Aspekten sehr ähnlich sein. Allerdings müssen einige Teile davon zusätzlich bereinigt werden, bevor sie ausgewertet werden können. Die folgende Checkliste soll euch dabei helfen, an alle relevanten Aspekte der Datenbereinigung zu denken.\nDie Datensatzaufbereitung erfolgt im processing-Skript. Der final aufbereitete Datensatz (dat_full) sowie der Long-Datensatz (dat_long) werden im Ordner data/processed gespeichert.",
    "crumbs": [
      "Checkliste Abschlussarbeit"
    ]
  },
  {
    "objectID": "scripts/04_misc/checkliste_abschlussarbeit.html#aspekte-die-bei-der-bereinigung-processing-beachtet-werden-sollten",
    "href": "scripts/04_misc/checkliste_abschlussarbeit.html#aspekte-die-bei-der-bereinigung-processing-beachtet-werden-sollten",
    "title": "Checkliste Abschlussarbeit",
    "section": "Aspekte, die bei der Bereinigung (processing) beachtet werden sollten",
    "text": "Aspekte, die bei der Bereinigung (processing) beachtet werden sollten\n\nHaben alle Daten die gleiche Anzahl an Beobachtungen?\n\n-   Gibt es Personen mit fehlenden Werten, die ausgeschlossen werden müssen?\n\n-   Gibt es Personen doppelt im Datensatz?\n\nGibt es unmögliche Werte in den Daten, z. B. -999? Wie können diese Daten ersetzt werden z.B aus anderen Variablen berechnet werden?\nGibt es reverse-kodierte Fragebogenvariablen (var_name_r)?\nGibt es Variablen, die nicht den korrekten Datentyp haben, z. B. numerische Variablen, die als Character angezeigt werden? Schaut euch diese Variablen genau an!\n(Beispiel: drei = 3, stimme voll und ganz zu = höchster Wert)",
    "crumbs": [
      "Checkliste Abschlussarbeit"
    ]
  },
  {
    "objectID": "scripts/04_misc/checkliste_abschlussarbeit.html#weitere-vorbereitende-schritte-im-processed-datensatz",
    "href": "scripts/04_misc/checkliste_abschlussarbeit.html#weitere-vorbereitende-schritte-im-processed-datensatz",
    "title": "Checkliste Abschlussarbeit",
    "section": "Weitere vorbereitende Schritte im processed-Datensatz",
    "text": "Weitere vorbereitende Schritte im processed-Datensatz\n\nMergen der 7 Einzeldatensätze\nDroppen von redundanten Variablen\nUmbenennen von Variablen, die nicht im snake_case-Format sind\nBerechnung der mmq_mean Variable\nErstellung Long-Datensatz\nSpeichern der Daten (Wide & Long)!",
    "crumbs": [
      "Checkliste Abschlussarbeit"
    ]
  },
  {
    "objectID": "scripts/04_misc/checkliste_abschlussarbeit.html#im-analyseskript-analysis-werden",
    "href": "scripts/04_misc/checkliste_abschlussarbeit.html#im-analyseskript-analysis-werden",
    "title": "Checkliste Abschlussarbeit",
    "section": "Im Analyseskript (analysis) werden",
    "text": "Im Analyseskript (analysis) werden\n\nNötige Vorbereitungen gemacht, die nicht zum processing gehören (z.B. Faktoren setzen)\nDie Analysen aus dem Datenanlyseplan durchgeführt!\n\nDeskriptive Statistik (M & SD) berechnen so wie in Table 1 (siehe Grinschgl et al., 2021)\n2x3 mixed ANOVA für subj. Leistungseinschätzungen mit post-hoc t-Tests, inkl.Effektstärken (η2 und Cohen’s d)\nOne-Way ANOVA für jede Offloading Variable (3x), inkl. Effektstärke (η2)\nOne-Way ANOVA für Trial Duration in Pattern Copy Task, inkl. Effektstärke (η2)\nOne-Way ANOVA für MMQ mit post-hoc t-Tests, inkl. Effektstärken (η2 und Cohen’sd)\nOne-Way ANOVA für Arbeitsgedächtnisleistung im Feature Switch Detection Task,inkl. Effektstärke (η2)\n1 Tabelle oder 1 Abbildung nach Wahl erstellen\nOptional: Testen der Voraussetzungen bei jeder Analyse – wenn diese gemacht wird, soll es auch im Datenanalyseplan beschrieben werden und die Analysen bei Voraussetzungsverletzungen entsprechend angepasst werden.\n\n\nPost-hoc-t-Tests werden nur für die 2x3-ANOVA und die MMQ-ANOVA erwartet. Sollte eine weitere ANOVA zufällig signifikante Werte aufweisen, werden hierfür keine Post-hoc-t-Tests verlangt.",
    "crumbs": [
      "Checkliste Abschlussarbeit"
    ]
  },
  {
    "objectID": "scripts/04_misc/checkliste_abschlussarbeit.html#dinge-die-im-datenanalyseplan-angepasst-werden-müssen",
    "href": "scripts/04_misc/checkliste_abschlussarbeit.html#dinge-die-im-datenanalyseplan-angepasst-werden-müssen",
    "title": "Checkliste Abschlussarbeit",
    "section": "Dinge, die im Datenanalyseplan angepasst werden müssen:",
    "text": "Dinge, die im Datenanalyseplan angepasst werden müssen:\n\nData Collection Procedures\nMissing Data\nUnit of Analyses/Data Exclusion",
    "crumbs": [
      "Checkliste Abschlussarbeit"
    ]
  },
  {
    "objectID": "scripts/04_misc/checkliste_abschlussarbeit.html#dinge-die-im-codebook-angepasst-werden-müssen",
    "href": "scripts/04_misc/checkliste_abschlussarbeit.html#dinge-die-im-codebook-angepasst-werden-müssen",
    "title": "Checkliste Abschlussarbeit",
    "section": "Dinge, die im Codebook angepasst werden müssen:",
    "text": "Dinge, die im Codebook angepasst werden müssen:\n\nCoding of item → reverse-kodierte Items\nCoding of Missing Data (falls vorhanden)\n1stes Blatt: Data Collection Procedures → Simulierte Daten.",
    "crumbs": [
      "Checkliste Abschlussarbeit"
    ]
  },
  {
    "objectID": "scripts/04_misc/checkliste_abschlussarbeit.html#ordnerstruktur-für-die-abgabe",
    "href": "scripts/04_misc/checkliste_abschlussarbeit.html#ordnerstruktur-für-die-abgabe",
    "title": "Checkliste Abschlussarbeit",
    "section": "Ordnerstruktur für die Abgabe",
    "text": "Ordnerstruktur für die Abgabe\nDie (für unser Seminar leicht abgeänderte) Psych-DS-Struktur wird eingehalten. Das bedeutet:\n\nDaten im Ordner data.\n\n-   Rohdaten in `data/raw` (werden nicht verändert).\n\n-   Aufbereitete Daten (`dat_full`) in `data/processed`\n\nAnalyseskripte (processing und analysis) im Ordner code\nGerenderte Analyseskripte (html) ebenfalls im Ordner code\nDatenanalyseplan im Ordner preregistration\nCodebook im Ordner data",
    "crumbs": [
      "Checkliste Abschlussarbeit"
    ]
  },
  {
    "objectID": "scripts/04_misc/checkliste_abschlussarbeit.html#self-check-wie-sehen-plausible-ergebnisse-aus",
    "href": "scripts/04_misc/checkliste_abschlussarbeit.html#self-check-wie-sehen-plausible-ergebnisse-aus",
    "title": "Checkliste Abschlussarbeit",
    "section": "Self-Check: Wie sehen plausible Ergebnisse aus?",
    "text": "Self-Check: Wie sehen plausible Ergebnisse aus?\nDie grundsätzliche Struktur der Daten sollte sehr ähnlich zu den Originaldaten sein.\n\nBeispiel aus einem simulierten Datensatz vs Originaldaten\n\nDie Ergebnisse bewegen sich alle in einem ähnlichen Rahmen wie die Daten aus der Originalstudie.\nOriginale Ergebnisse\n\n\n\n\n\nSimulierter Datensatz\n\n\n\n\n\nDementsprechend werden auch die Effekte der Analysen ähnlich ausfallen:",
    "crumbs": [
      "Checkliste Abschlussarbeit"
    ]
  },
  {
    "objectID": "scripts/04_misc/checkliste_abschlussarbeit.html#zu-erwartende-abweichungen-der-ergebnisse-von-der-originalstudie",
    "href": "scripts/04_misc/checkliste_abschlussarbeit.html#zu-erwartende-abweichungen-der-ergebnisse-von-der-originalstudie",
    "title": "Checkliste Abschlussarbeit",
    "section": "Zu erwartende Abweichungen der Ergebnisse von der Originalstudie:",
    "text": "Zu erwartende Abweichungen der Ergebnisse von der Originalstudie:\n\nZufällig signifikante Effekte, die in der Originalstudie nicht signifikant waren, sind möglich. In der Originalstudie zeigte diese Variable keinen signifikanten Effekt. Post-hoc-t-Tests werden hierfür jedoch nicht erwartet.\n\n\n\nEinzelne Werte werden sich unterscheiden! Deskriptiva, Effektgrössen usw. werden sich unterscheiden! Eta2 sind hier grösser als in der Originalstudie.\n\n\n\n\n\n\n\nDeskriptiva: Unterschiede in den Means und SDs!\n\n\n\n\n\n\n##Unplausible Resultate\nErgebnisse die ein komplett anderes Gesamtbild hinterlassen sind nicht zu erwarten!",
    "crumbs": [
      "Checkliste Abschlussarbeit"
    ]
  },
  {
    "objectID": "scripts/04_misc/ChatGPT.html",
    "href": "scripts/04_misc/ChatGPT.html",
    "title": "ChatGPT in RStudio",
    "section": "",
    "text": "Damit ihr ChatGPT in RStudio einbinden könnt ist ein Account bei OpenAI / ChatGPT notwendig (falls ihr ChatGPT bisher ohne Anmeldung genutzt habt): https://chatgpt.com/\nNeben dieser Anleitung gibt es auch noch dieses YouTube-Tutorial [2:36 - 5:08] welches euch bei der Einrichtung behilflich sein könnte.\nRechtliche Informationen zum Umgang mit ChatGPT und anderen generativen KI-Anwendungen findet ihr hier.",
    "crumbs": [
      "Links und Ressourcen",
      "ChatGPT in RStudio"
    ]
  },
  {
    "objectID": "scripts/04_misc/ChatGPT.html#installieren-von-paketen-welche-chattr-im-hintergrund-benötigt",
    "href": "scripts/04_misc/ChatGPT.html#installieren-von-paketen-welche-chattr-im-hintergrund-benötigt",
    "title": "ChatGPT in RStudio",
    "section": "Installieren von Paketen, welche chattr im Hintergrund benötigt",
    "text": "Installieren von Paketen, welche chattr im Hintergrund benötigt\nEventuell habt ihr diese schon installiert und ihr könnt diesen Schritt dann überspringen. Ansonsten müsst ihr diese Pakete, wie auch alle anderen, nur einmalig installieren.\n\ninstall.packages(\"shiny\")\ninstall.packages(\"httr2\")\ninstall.packages(\"jsonlite\")",
    "crumbs": [
      "Links und Ressourcen",
      "ChatGPT in RStudio"
    ]
  },
  {
    "objectID": "scripts/04_misc/ChatGPT.html#installieren-des-chattr-pakets-von-github",
    "href": "scripts/04_misc/ChatGPT.html#installieren-des-chattr-pakets-von-github",
    "title": "ChatGPT in RStudio",
    "section": "Installieren des chattr-Pakets von GitHub",
    "text": "Installieren des chattr-Pakets von GitHub\nAuch hier gilt, die Installation des Paketes müsst ihr nur einmalig vornehmen.\n\ninstall.packages(\"remotes\") # Hier werdet ihr in der Console möglicherweise gefragt, ob ihr das Paket unter dem vorgeschlagenen Dateipfad abspeichern wollt. Sofern dieser für euch passt könnt ihr einfach mit \"Y\" unten in der Console eingeben und mit Enter bestätigen.\n\n\nremotes::install_github(\"mlverse/chattr\") # Hier werdet ihr möglicherweise gefragt, welche der betroffenen Pakete ihr updaten wollt. Es empfehlt sich, alle zu updaten. Ihr könnt dies tun, indem ihr \"1\" in der Console eingebt und mit Enter bestätigt.",
    "crumbs": [
      "Links und Ressourcen",
      "ChatGPT in RStudio"
    ]
  },
  {
    "objectID": "scripts/04_misc/ChatGPT.html#laden-von-chattr",
    "href": "scripts/04_misc/ChatGPT.html#laden-von-chattr",
    "title": "ChatGPT in RStudio",
    "section": "Laden von chattr",
    "text": "Laden von chattr\nDie Schritte ab hier, also das Laden des Paketes und das Starten des Chat-Interface, müsst ihr bei jedem Start von RStudio erneut durchführen.\n\nlibrary(chattr) # So wie ihr es auch bereits von anderen Paketen kennt",
    "crumbs": [
      "Links und Ressourcen",
      "ChatGPT in RStudio"
    ]
  },
  {
    "objectID": "scripts/04_misc/ChatGPT.html#erstellen-des-chat-interface",
    "href": "scripts/04_misc/ChatGPT.html#erstellen-des-chat-interface",
    "title": "ChatGPT in RStudio",
    "section": "Erstellen des Chat-Interface",
    "text": "Erstellen des Chat-Interface\n\nSys.setenv(OPENAI_API_KEY = \"Hier müsst ihr euren eigenen OpenAI API-Key einsetzen\") # Ihr erhaltet euren OpenAI API Key, indem ihr euch bei OpenAI anmeldet und unter https://platform.openai.com/account/api-keys einen neuen Key generiert.\n\nchattr_app() # Hier werdet ihr möglicherweise gefragt, welche Version von ChatGPT ihr verwenden mögt. Mit Eingabe der Nummer wählt ihr das entsprechende Modell aus. Mit Enter bestätigt ihr die Eingabe.",
    "crumbs": [
      "Links und Ressourcen",
      "ChatGPT in RStudio"
    ]
  },
  {
    "objectID": "scripts/04_misc/ChatGPT.html#prompt-beispiel",
    "href": "scripts/04_misc/ChatGPT.html#prompt-beispiel",
    "title": "ChatGPT in RStudio",
    "section": "Prompt-Beispiel",
    "text": "Prompt-Beispiel\nWofür braucht das Paket chattr im Hintergrund noch die Pakete shiny, httr2 und jsonlite?",
    "crumbs": [
      "Links und Ressourcen",
      "ChatGPT in RStudio"
    ]
  },
  {
    "objectID": "scripts/04_misc/about.html",
    "href": "scripts/04_misc/about.html",
    "title": "About",
    "section": "",
    "text": "Diese Website wurde im Rahmen des Seminars “R u Ready” an der Universität Bern erstellt.\nSollte deine Frage nicht beantwortet worden sein, dann wende dich gerne direkt an die Autor:innen:\n\n\n\nlars.schilling@unibe.ch\n\n\naaron.friedli@unibe.ch\n\n\nsandra.grinschgl@unibe.ch\n\n\n\n\nThis work is licensed under CC BY-SA 4.0",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "scripts/04_misc/muddiest_points_3.html",
    "href": "scripts/04_misc/muddiest_points_3.html",
    "title": "Muddiest Points 3",
    "section": "",
    "text": "Ich habe mich gefragt (v.a. auch in Bezug auf unsere spezialisierten Daten), ob man zuerst die einzelnen Dataframes bereinigen muss (v.a. in Bezug auf die duplizierten Zeilen) oder ob mann zuerst einen dat_full erstellen soll und dann diesen bereinigen?\nMir ist nicht ganz klar in welcher Reihenfolge man fehlende Werte, duplizierte Werte und das mergen macht.\nSicherheit im Umgang mit den verschiedenen Schritten der Datenbereinigung\n\nAntwort:\nEinige Schritte der Datenaufbereitung sollten vor dem Mergen durchgeführt werden, da das Zusammenführen der Datensätze sonst unnötig kompliziert werden kann. Beispielsweise können Duplikate oder fehlende Werte (NAs) beim Mergen zu Problemen führen und sollten daher idealerweise bereits vorher behandelt werden. Für viele andere Schritte, wie etwa Rekodierungen, spielt es hingegen keine Rolle, ob sie im einzelnen Datensatz oder erst im gemergten Datensatz durchgeführt werden. Es gibt dabei keine festgelegte Reihenfolge, die zwingend eingehalten werden muss. Ob das Vorgehen korrekt war, kann man abschliessend überprüfen, indem man den gemergten Datensatz inspiziert und auf Plausibilität prüft (z. B. ob N = 159).\n\n\n\n\n\nCodebook: Muss es für die einzelnen Datensätze gemacht werden? Ich habe nämlich alles zuerst bereinigt, umgepoolt und dann gemerged und als dat_full.csv abgespeichert. Bedeutet, dass in dat_full keine NAs und revers kodierte Items mehr sind und auch nicht mehr im Codebook wären, sollte dat_full im Codebook verwendet werden müssen (zumind. bei mir). Zudem wurde in dat_full noch mmq_mean hinzugefügt, muss das auch ins Codebook?\n\nAntwort:\n\nDas Codebook für den gemergten Datensatz ist ausreichend. Reverse-kodierte Items sollten dennoch angegeben werden, wobei im Codebook vermerkt werden sollte, dass diese bereits rekodiert wurden. Wenn keine NAs vorhanden sind müssen diese auch nicht vermerkt werden. Jede Variable sollte im Codebook enthalten sein, einschliesslich zusammengesetzter Variablen wie mmq_mean.\n\n\n\n\n\nEs steht man soll eine Tabelle/Abbildung nach Wahl erstellen. Heisst, wir müssen nicht alle Plots nachmachen?\n\nAntwort: Eine Tabelle oder eine Abbildung genügt. Ihr müsst nicht alle Plots des Papers nachmachen!\n\n\n\n\nMüssen Resultate interpretiert werden und wenn ja, wie müssen diese verschriftlicht werden?\nAntwort: Es werden keine inhaltlichen Interpretationen der Ergebnisse gefordert. Kurze Zusammenfassungen der Resultate direkt nach den jeweiligen Codechunks können jedoch das Verständnis erleichtern und illustrieren, dass ihr die Analysen richtig lesen könnt.\nZum Beispiel: The one-way ANOVA indicated that there were no significant group differences in this working memory performance measure, F(2, 156) = 0.07, p = 0.929, η² &lt; 0.01.\n\n\n\n\n\nWenn man etwas umkodiert (z.B. umgekehrt kodierte Items) und es eine ungerade Anzahl hat, muss man dann das mittlere Item bei der Umkodierung auch angeben (z.B. bei fünf Stufen wäre es die 3, die gleich bleibt - müsste ich das bei der Umkodierung dennoch notieren?)\n\nAntwort: Nein, solange die Rekodierung klar nachvollziehbar ist ist es nicht zwingend nötig (aber schadet auch nicht).\n\n\n\n\nOrdner- und Pfadstruktur: Wo genau sollten die Quartoskripte relativ zu den eingelesenen Daten abgespeichert werden? -&gt; Wenn man die Quartoskripte im Ordner Grinschgl2020 abspeichert geht das zwar gut, jedoch sind dann die Quartoskripte nicht in einem eignen Ordner. Wenn ich sie in einen eignen Ordner lege, dann stimmt der Pfad aber nicht mehr. Gibt es hier eine gute Lösung?\nAntwort: Öffne die Skripte innerhalb des Projekts. Dann wird der Dateipfad automatisch relativ zum Projektverzeichnis ausgewertet, auch wenn sich die Skripte nicht im gleichen Ordner befinden. Falls dies nicht funktioniert, überprüfe in den Einstellungen, ob die Option „Evaluate chunks in directory“ auf „Project“ gesetzt ist.\n\n\n\n\n\n\n\n\n\n\n\n\n\nBitte nochmals die Logik der ANOVA sowohl für One-way ANOVA wie v.a. auch 2x3 mixed ANOVA erklären. Welcher Output liefert nun welche Inhalte? Und welche Codes sind alle wichtig?\nIch finde es schwierig, die Outputs der verschiedenen Anovas und t-tests zu verstehen.\nIch würde gerne die Mixed Anovas und t-Tests noch einmal anschauen, vielleicht einfach noch einmal kurz repetieren, worauf man da bei den Codes und der Interpretation achten muss.\n\nAntwort:\n🌐Erklärvideo ANOVA\n🌐Erklärvideo ANOVA + t-Test\n🌐Erklärvideo: Using Linear Models for t tests and ANOVA, Clearly Explained!!!\n\n\nDie ANOVA prüft generell die Frage, ob die beobachtete Variation in den Daten größer ist, als man sie durch Zufall erwarten würde. Der zentrale Gedanke der ANOVA ist, dass Unterschiede zwischen Gruppen dann als bedeutsam gelten, wenn die Gruppenmittelwerte stark voneinander abweichen, während die Streuung innerhalb der Gruppen gering ist, sodass es unwahrscheinlich ist, dass diese Unterschiede nur durch Zufall entstanden sind.\nDieses Verhältnis wird durch den F-Wert ausgedrückt:\n\\(F = \\frac{\\text{Varianz zwischen den Gruppen}}{\\text{Varianz innerhalb der Gruppen}}\\).\nDie One-Way ANOVA beantwortet die Frage:\n\nUnterscheiden sich mehr als zwei Gruppen in einer abhängigen Variable?\n\nBeispiel:\nBeispielsweise wird untersucht, ob sich Pinguine in ihrer Schnabellänge zwischen mehreren Gruppen (z. B. Inseln) unterscheiden. Da mehr als zwei Gruppen verglichen werden, ist eine One-Way ANOVA angemessen.\nDa der p-Wert &lt; 0.05 ist, ist die ANOVA signifikant. Das bedeutet, dass sich mindestens zwei der Gruppen signifikant voneinander unterscheiden. Welche Gruppen sich konkret unterscheiden, kann jedoch erst mit Post-hoc-t-Tests überprüft werden.\nDas generalized η² (ges) gibt an, wie viel Varianz der abhängigen Variable durch den Faktor erklärt wird. In diesem Fall erklärt die Gruppenzugehörigkeit (z. B. Spezies) ca. 70 % der Varianz der Schnabellänge.\n\nmodel_1 &lt;- aov_4(bill_length_mm ~ species + (1 |id), data = penguins)\n\nWarning: Missing values for 2 ID(s), which were removed before analysis:\n272, 4\nBelow the first few rows (in wide format) of the removed cases with missing data.\n       id species  .\n# 193 272  Gentoo NA\n# 279   4  Adelie NA\n\n\nContrasts set to contr.sum for the following variables: species\n\nsummary(model_1)\n\nAnova Table (Type 3 tests)\n\nResponse: bill_length_mm\n        num Df den Df    MSE     F     ges                Pr(&gt;F)    \nspecies      2    339 8.7607 410.6 0.70781 &lt; 0.00000000000000022 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nDer Post-hoc t-Test hier ist die logische Konsequenz aus der signifikanten ANOVA.\nDa es drei Spezies (Gentoo, Chinstrap, Adelie) gibt können wir drei verschiedene Gruppenvergleiche berechnen. Hier zeigen wir ein Beispiel.\nDer t-Test prüft, ob sich die Mittelwerte zweier Gruppen in der abhängigen Variable (Schnabellänge) unterscheiden. Auf Basis von Stichprobendaten wird untersucht, ob sich Pinguine der Spezies Adelie und Chinstrap in ihrer Schnabellänge (bill_length_mm) unterscheiden. Das signifikante Ergebnis (p &lt; 0.05) spricht dafür, dass sich die mittlere Schnabellänge dieser beiden Gruppen auf Populationsebene unterscheidet.\n\npenguins_filtered &lt;- penguins |&gt;\n  filter(species != \"Gentoo\")\n\nt.test(bill_length_mm ~ species, data = penguins_filtered)\n\n\n    Welch Two Sample t-test\n\ndata:  bill_length_mm by species\nt = -21.865, df = 106.97, p-value &lt; 0.00000000000000022\nalternative hypothesis: true difference in means between group Adelie and group Chinstrap is not equal to 0\n95 percent confidence interval:\n -10.952948  -9.131917\nsample estimates:\n   mean in group Adelie mean in group Chinstrap \n               38.79139                48.83382 \n\n\n\n\n\n\nWieso braucht man bei t.test() “~” und nicht “,” bzw. wovon hängt dies ab?\n\nAntwort: Bei t.test() wird das ~ verwendet, wenn der Test in der Formel-Schreibweise durchgeführt wird. Diese Schreibweise trennt die abhängige Variable (links vom ~) von der Gruppierungsvariable (rechts vom ~) und ist typisch für viele statistische Funktionen in R. Sie wird vor allem dann genutzt, wenn die Daten in einem Dataframe vorliegen.\nEin Komma wird hingegen verwendet, wenn man die beiden Gruppen direkt als separate Vektoren übergibt. Welche Schreibweise man verwendet, hängt also davon ab, wie die Daten strukturiert sind (Dataframe vs. einzelne Vektoren) und welche Schnittstelle die Funktion anbietet.\nBeispiele mit Formelschreibweise:\n\n# Datensatz auf zwei Arten beschränken\npenguins_2 &lt;- subset(\n  penguins,\n  species %in% c(\"Adelie\", \"Chinstrap\")\n)\n\n# t-Test mit Formel-Schreibweise\nt.test(flipper_length_mm ~ species, data = penguins_2)\n\n\n    Welch Two Sample t-test\n\ndata:  flipper_length_mm by species\nt = -5.7804, df = 119.68, p-value = 0.00000006049\nalternative hypothesis: true difference in means between group Adelie and group Chinstrap is not equal to 0\n95 percent confidence interval:\n -7.880530 -3.859244\nsample estimates:\n   mean in group Adelie mean in group Chinstrap \n               189.9536                195.8235 \n\n\nMit Komma:\n\n# Vektoren für die zwei Gruppen\nadelie_flipper &lt;- penguins$flipper_length_mm[\n  penguins$species == \"Adelie\"\n]\n\nchinstrap_flipper &lt;- penguins$flipper_length_mm[\n  penguins$species == \"Chinstrap\"\n]\n\n# t-Test mit Vektoren\nt.test(adelie_flipper, chinstrap_flipper)\n\n\n    Welch Two Sample t-test\n\ndata:  adelie_flipper and chinstrap_flipper\nt = -5.7804, df = 119.68, p-value = 0.00000006049\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -7.880530 -3.859244\nsample estimates:\nmean of x mean of y \n 189.9536  195.8235 \n\n\n\n\n\n\nDie 2×3 ANOVA im Grinschgl et al. (2021) Paper beantwortet die folgenden Fragen:\nGibt es Unterschiede zwischen den Feedbackgruppen, gibt es Veränderungen über die Zeit (Pre1 vs. Pre4), und unterscheiden sich diese zeitlichen Veränderungen zwischen den Gruppen (above vs. control vs. below)?\n\nmixed_anova &lt;- aov_4(rating ~ group_all + (time_rating | code), data = dat_long)\n\nConverting to factor: group_all\n\n\nContrasts set to contr.sum for the following variables: group_all\n\nsummary(mixed_anova)\n\n\nUnivariate Type III Repeated-Measures ANOVA Assuming Sphericity\n\n                      Sum Sq num Df Error SS den Df  F value\n(Intercept)           8198.9      1   500.58    156 2555.113\ngroup_all              126.7      2   500.58    156   19.736\ntime_rating             42.0      1   288.70    156   22.668\ngroup_all:time_rating   74.4      2   288.70    156   20.090\n                                     Pr(&gt;F)    \n(Intercept)           &lt; 0.00000000000000022 ***\ngroup_all                     0.00000002286 ***\ntime_rating                   0.00000436406 ***\ngroup_all:time_rating         0.00000001724 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nDer signifikante Haupteffekt der Feedbackgruppe (group_all) zeigt, dass sich die mittleren Ratings zwischen den Gruppen unterscheiden, unabhängig vom Zeitpunkt der Messung.\nDer signifikante Haupteffekt der Feedbackgruppe (group_all) zeigt, dass sich die mittleren Ratings zwischen den Gruppen unterscheiden, unabhängig vom Zeitpunkt der Messung.\nDer signifikante Interaktionseffekt zeigt, dass sich die Veränderung der Ratings über die Zeit zwischen den Feedbackgruppen unterscheidet. 👉Der Effekt der Zeit ist nicht für alle Gruppen gleich.\n\n\n\n\n\n\nbitte Berechnung von Cohens d erneut für spezifisch 2x3 mixed ANOVA erklären. Hier sehe ich weder in den Hands On noch in den Foliensätze einen passenden Code, der bei mir funktioniert.\n\nAntwort: Cohen’s d wird für die Post-hoc-t-Tests berechnet, nicht für die 2×3-ANOVA selbst. (Für die ANOVA selbst berechnen wir Eta2). Cohen’s d ist ein Effektstärkenmaß, das angibt, wie groß der Unterschied zwischen zwei Gruppen ist, unabhängig von der Stichprobengröße. Hier ein Beispiel aus den Hands On Übungen. ​​\n\ndat_full_below_above &lt;- dat_full |&gt; \n  filter(group_all != \"control\")\n\ndat_full_below_above$group_all &lt;- as.factor(dat_full_below_above$group_all)\n\nt.test(pre4 ~ group_all, data = dat_full_below_above, var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  pre4 by group_all\nt = 7.9845, df = 104, p-value = 0.000000000001991\nalternative hypothesis: true difference in means between group above and group below is not equal to 0\n95 percent confidence interval:\n 2.025170 3.363509\nsample estimates:\nmean in group above mean in group below \n           5.966038            3.271698 \n\neffsize::cohen.d(pre4 ~ group_all, data = dat_full_below_above)\n\n\nCohen's d\n\nd estimate: 1.551045 (large)\n95 percent confidence interval:\n   lower    upper \n1.111706 1.990383 \n\n\n\n\n\n\n\nWas macht es aus, dass man explizit na.rm = TRUE bei mean() und sd() angibt\n\nAntwort: Mittelwerte und Standardabweichungen können nicht korrekt berechnet werden, wenn sich fehlende Werte (NAs) in den Daten befinden. Mit na.rm = TRUE werden diese fehlenden Werte bei der Berechnung ausgeschlossen. Wurden die NAs bereits zuvor bereinigt, ist dieser Befehl zwar redundant, schadet jedoch nicht.\n\nx &lt;- c(1,2,3,4,5,6,NA)\n\nmean(x)\n\n[1] NA\n\nmean(x, na.rm = TRUE)\n\n[1] 3.5\n\n\n\n\n\n\n\nWoher weiss man, ob man rowMeans() und(/oder) mean() anwenden soll?\n\nrowMeans(df) berechnet die Zeilenmittelwerte, also den Mittelwert pro Zeile über alle Spalten hinweg.\nIn einem Wide-Datensatz entspricht das typischerweise dem Mittelwert pro Person über mehrere Variablen / Messungen.\nmean(df$V1) berechnet den Mittelwert einer einzelnen Spalte (V1) über alle Zeilen hinweg.\nDas entspricht dem Mittelwert einer Variable über alle Personen\nrowMeans bietet sich also dafür an z.B. Skalenwerte zu berechnen (z.B. Durschnitt mehrerer Skalenitems) zu berechnen, während mean besser für Durschnittswerte über das gesamte Sample geeignet ist.\n\n\n\nV1\nV2\nV3\n\n\n\n\n1\n2\n3\n\n\n4\n5\n6\n\n\n7\n8\n9\n\n\n\n\ndf &lt;- data.frame(\n  V1 = c(1, 4, 7),\n  V2 = c(2, 5, 8),\n  V3 = c(3, 6, 9)\n)\n\n# Zeilenmittelwerte (Mittelwert pro Zeile über V1–V3)\nrowMeans(df)\n\n[1] 2 5 8\n\n# Mittelwert über Variable\nmean((df$V1))\n\n[1] 4\n\n\n\n\n\n\n\nMir ist noch nicht richtig klar, wie man APA konforme ANOVA Tabellen erzeugt, die man gerade abspeichern kann und dann in eine Word Datei einfügen kann. Z.B für eine dreifaktorielle ANOVA?\n\nAntwort: Tabellen für ANOVAs haben wir nicht behandelt. In der Praxis werden ANOVAs meist auch nicht in Tabellenform berichtet, sondern direkt im Text. Es ist jedoch möglich, APA-konforme ANOVA-Tabellen mit Packages apaTables wie Papaja zu erstellen.\nBeispiel aus Grinschgl et al. (2021)\n\nlibrary(apaTables)\n\nmodel_1 &lt;- aov(bill_length_mm ~ island + sex + species, data = penguins_filtered)\n\napa.aov.table(\n  lm_output = model_1,\n  filename  = \"anova_table.doc\"\n)\n\n\n\nANOVA results using bill_length_mm as the dependent variable\n \n\n   Predictor       SS  df       MS       F    p partial_eta2 CI_90_partial_eta2\n (Intercept) 50463.39   1 50463.39 9751.90 .000                                \n      island    10.22   2     5.11    0.99 .374          .01         [.00, .04]\n         sex   685.30   1   685.30  132.43 .000          .39         [.30, .46]\n     species  3254.78   1  3254.78  628.98 .000          .75         [.71, .78]\n       Error  1081.52 209     5.17                                             \n\nNote: Values in square brackets indicate the bounds of the 90% confidence interval for partial eta-squared \n\n\n\n\n\n\n\n\n\n\n\n\nBesseres Verständnis dafür, welche statistischen Tests in welcher Situation angemessen sind\n\nAntwort: Sprengt hier leider den Rahmen. Wir verweisen hier gerne auf den Statistikbaum der UZH. Jedoch kann auch dieser eine tiefergehende Auseinandersetzung mit der Fragestellung und dem Datenformat nicht ersetzen! Für spezifische Fragen zu diesem Thema, kann auch gerne die Methodenberatung genutzt werden!",
    "crumbs": [
      "Muddiest Points",
      "Muddiest Points 3"
    ]
  },
  {
    "objectID": "scripts/04_misc/muddiest_points_3.html#abschlussarbeit",
    "href": "scripts/04_misc/muddiest_points_3.html#abschlussarbeit",
    "title": "Muddiest Points 3",
    "section": "",
    "text": "Ich habe mich gefragt (v.a. auch in Bezug auf unsere spezialisierten Daten), ob man zuerst die einzelnen Dataframes bereinigen muss (v.a. in Bezug auf die duplizierten Zeilen) oder ob mann zuerst einen dat_full erstellen soll und dann diesen bereinigen?\nMir ist nicht ganz klar in welcher Reihenfolge man fehlende Werte, duplizierte Werte und das mergen macht.\nSicherheit im Umgang mit den verschiedenen Schritten der Datenbereinigung\n\nAntwort:\nEinige Schritte der Datenaufbereitung sollten vor dem Mergen durchgeführt werden, da das Zusammenführen der Datensätze sonst unnötig kompliziert werden kann. Beispielsweise können Duplikate oder fehlende Werte (NAs) beim Mergen zu Problemen führen und sollten daher idealerweise bereits vorher behandelt werden. Für viele andere Schritte, wie etwa Rekodierungen, spielt es hingegen keine Rolle, ob sie im einzelnen Datensatz oder erst im gemergten Datensatz durchgeführt werden. Es gibt dabei keine festgelegte Reihenfolge, die zwingend eingehalten werden muss. Ob das Vorgehen korrekt war, kann man abschliessend überprüfen, indem man den gemergten Datensatz inspiziert und auf Plausibilität prüft (z. B. ob N = 159).\n\n\n\n\n\nCodebook: Muss es für die einzelnen Datensätze gemacht werden? Ich habe nämlich alles zuerst bereinigt, umgepoolt und dann gemerged und als dat_full.csv abgespeichert. Bedeutet, dass in dat_full keine NAs und revers kodierte Items mehr sind und auch nicht mehr im Codebook wären, sollte dat_full im Codebook verwendet werden müssen (zumind. bei mir). Zudem wurde in dat_full noch mmq_mean hinzugefügt, muss das auch ins Codebook?\n\nAntwort:\n\nDas Codebook für den gemergten Datensatz ist ausreichend. Reverse-kodierte Items sollten dennoch angegeben werden, wobei im Codebook vermerkt werden sollte, dass diese bereits rekodiert wurden. Wenn keine NAs vorhanden sind müssen diese auch nicht vermerkt werden. Jede Variable sollte im Codebook enthalten sein, einschliesslich zusammengesetzter Variablen wie mmq_mean.\n\n\n\n\n\nEs steht man soll eine Tabelle/Abbildung nach Wahl erstellen. Heisst, wir müssen nicht alle Plots nachmachen?\n\nAntwort: Eine Tabelle oder eine Abbildung genügt. Ihr müsst nicht alle Plots des Papers nachmachen!\n\n\n\n\nMüssen Resultate interpretiert werden und wenn ja, wie müssen diese verschriftlicht werden?\nAntwort: Es werden keine inhaltlichen Interpretationen der Ergebnisse gefordert. Kurze Zusammenfassungen der Resultate direkt nach den jeweiligen Codechunks können jedoch das Verständnis erleichtern und illustrieren, dass ihr die Analysen richtig lesen könnt.\nZum Beispiel: The one-way ANOVA indicated that there were no significant group differences in this working memory performance measure, F(2, 156) = 0.07, p = 0.929, η² &lt; 0.01.\n\n\n\n\n\nWenn man etwas umkodiert (z.B. umgekehrt kodierte Items) und es eine ungerade Anzahl hat, muss man dann das mittlere Item bei der Umkodierung auch angeben (z.B. bei fünf Stufen wäre es die 3, die gleich bleibt - müsste ich das bei der Umkodierung dennoch notieren?)\n\nAntwort: Nein, solange die Rekodierung klar nachvollziehbar ist ist es nicht zwingend nötig (aber schadet auch nicht).\n\n\n\n\nOrdner- und Pfadstruktur: Wo genau sollten die Quartoskripte relativ zu den eingelesenen Daten abgespeichert werden? -&gt; Wenn man die Quartoskripte im Ordner Grinschgl2020 abspeichert geht das zwar gut, jedoch sind dann die Quartoskripte nicht in einem eignen Ordner. Wenn ich sie in einen eignen Ordner lege, dann stimmt der Pfad aber nicht mehr. Gibt es hier eine gute Lösung?\nAntwort: Öffne die Skripte innerhalb des Projekts. Dann wird der Dateipfad automatisch relativ zum Projektverzeichnis ausgewertet, auch wenn sich die Skripte nicht im gleichen Ordner befinden. Falls dies nicht funktioniert, überprüfe in den Einstellungen, ob die Option „Evaluate chunks in directory“ auf „Project“ gesetzt ist.",
    "crumbs": [
      "Muddiest Points",
      "Muddiest Points 3"
    ]
  },
  {
    "objectID": "scripts/04_misc/muddiest_points_3.html#statistik",
    "href": "scripts/04_misc/muddiest_points_3.html#statistik",
    "title": "Muddiest Points 3",
    "section": "",
    "text": "Bitte nochmals die Logik der ANOVA sowohl für One-way ANOVA wie v.a. auch 2x3 mixed ANOVA erklären. Welcher Output liefert nun welche Inhalte? Und welche Codes sind alle wichtig?\nIch finde es schwierig, die Outputs der verschiedenen Anovas und t-tests zu verstehen.\nIch würde gerne die Mixed Anovas und t-Tests noch einmal anschauen, vielleicht einfach noch einmal kurz repetieren, worauf man da bei den Codes und der Interpretation achten muss.\n\nAntwort:\n🌐Erklärvideo ANOVA\n🌐Erklärvideo ANOVA + t-Test\n🌐Erklärvideo: Using Linear Models for t tests and ANOVA, Clearly Explained!!!\n\n\nDie ANOVA prüft generell die Frage, ob die beobachtete Variation in den Daten größer ist, als man sie durch Zufall erwarten würde. Der zentrale Gedanke der ANOVA ist, dass Unterschiede zwischen Gruppen dann als bedeutsam gelten, wenn die Gruppenmittelwerte stark voneinander abweichen, während die Streuung innerhalb der Gruppen gering ist, sodass es unwahrscheinlich ist, dass diese Unterschiede nur durch Zufall entstanden sind.\nDieses Verhältnis wird durch den F-Wert ausgedrückt:\n\\(F = \\frac{\\text{Varianz zwischen den Gruppen}}{\\text{Varianz innerhalb der Gruppen}}\\).\nDie One-Way ANOVA beantwortet die Frage:\n\nUnterscheiden sich mehr als zwei Gruppen in einer abhängigen Variable?\n\nBeispiel:\nBeispielsweise wird untersucht, ob sich Pinguine in ihrer Schnabellänge zwischen mehreren Gruppen (z. B. Inseln) unterscheiden. Da mehr als zwei Gruppen verglichen werden, ist eine One-Way ANOVA angemessen.\nDa der p-Wert &lt; 0.05 ist, ist die ANOVA signifikant. Das bedeutet, dass sich mindestens zwei der Gruppen signifikant voneinander unterscheiden. Welche Gruppen sich konkret unterscheiden, kann jedoch erst mit Post-hoc-t-Tests überprüft werden.\nDas generalized η² (ges) gibt an, wie viel Varianz der abhängigen Variable durch den Faktor erklärt wird. In diesem Fall erklärt die Gruppenzugehörigkeit (z. B. Spezies) ca. 70 % der Varianz der Schnabellänge.\n\nmodel_1 &lt;- aov_4(bill_length_mm ~ species + (1 |id), data = penguins)\n\nWarning: Missing values for 2 ID(s), which were removed before analysis:\n272, 4\nBelow the first few rows (in wide format) of the removed cases with missing data.\n       id species  .\n# 193 272  Gentoo NA\n# 279   4  Adelie NA\n\n\nContrasts set to contr.sum for the following variables: species\n\nsummary(model_1)\n\nAnova Table (Type 3 tests)\n\nResponse: bill_length_mm\n        num Df den Df    MSE     F     ges                Pr(&gt;F)    \nspecies      2    339 8.7607 410.6 0.70781 &lt; 0.00000000000000022 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nDer Post-hoc t-Test hier ist die logische Konsequenz aus der signifikanten ANOVA.\nDa es drei Spezies (Gentoo, Chinstrap, Adelie) gibt können wir drei verschiedene Gruppenvergleiche berechnen. Hier zeigen wir ein Beispiel.\nDer t-Test prüft, ob sich die Mittelwerte zweier Gruppen in der abhängigen Variable (Schnabellänge) unterscheiden. Auf Basis von Stichprobendaten wird untersucht, ob sich Pinguine der Spezies Adelie und Chinstrap in ihrer Schnabellänge (bill_length_mm) unterscheiden. Das signifikante Ergebnis (p &lt; 0.05) spricht dafür, dass sich die mittlere Schnabellänge dieser beiden Gruppen auf Populationsebene unterscheidet.\n\npenguins_filtered &lt;- penguins |&gt;\n  filter(species != \"Gentoo\")\n\nt.test(bill_length_mm ~ species, data = penguins_filtered)\n\n\n    Welch Two Sample t-test\n\ndata:  bill_length_mm by species\nt = -21.865, df = 106.97, p-value &lt; 0.00000000000000022\nalternative hypothesis: true difference in means between group Adelie and group Chinstrap is not equal to 0\n95 percent confidence interval:\n -10.952948  -9.131917\nsample estimates:\n   mean in group Adelie mean in group Chinstrap \n               38.79139                48.83382 \n\n\n\n\n\n\nWieso braucht man bei t.test() “~” und nicht “,” bzw. wovon hängt dies ab?\n\nAntwort: Bei t.test() wird das ~ verwendet, wenn der Test in der Formel-Schreibweise durchgeführt wird. Diese Schreibweise trennt die abhängige Variable (links vom ~) von der Gruppierungsvariable (rechts vom ~) und ist typisch für viele statistische Funktionen in R. Sie wird vor allem dann genutzt, wenn die Daten in einem Dataframe vorliegen.\nEin Komma wird hingegen verwendet, wenn man die beiden Gruppen direkt als separate Vektoren übergibt. Welche Schreibweise man verwendet, hängt also davon ab, wie die Daten strukturiert sind (Dataframe vs. einzelne Vektoren) und welche Schnittstelle die Funktion anbietet.\nBeispiele mit Formelschreibweise:\n\n# Datensatz auf zwei Arten beschränken\npenguins_2 &lt;- subset(\n  penguins,\n  species %in% c(\"Adelie\", \"Chinstrap\")\n)\n\n# t-Test mit Formel-Schreibweise\nt.test(flipper_length_mm ~ species, data = penguins_2)\n\n\n    Welch Two Sample t-test\n\ndata:  flipper_length_mm by species\nt = -5.7804, df = 119.68, p-value = 0.00000006049\nalternative hypothesis: true difference in means between group Adelie and group Chinstrap is not equal to 0\n95 percent confidence interval:\n -7.880530 -3.859244\nsample estimates:\n   mean in group Adelie mean in group Chinstrap \n               189.9536                195.8235 \n\n\nMit Komma:\n\n# Vektoren für die zwei Gruppen\nadelie_flipper &lt;- penguins$flipper_length_mm[\n  penguins$species == \"Adelie\"\n]\n\nchinstrap_flipper &lt;- penguins$flipper_length_mm[\n  penguins$species == \"Chinstrap\"\n]\n\n# t-Test mit Vektoren\nt.test(adelie_flipper, chinstrap_flipper)\n\n\n    Welch Two Sample t-test\n\ndata:  adelie_flipper and chinstrap_flipper\nt = -5.7804, df = 119.68, p-value = 0.00000006049\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -7.880530 -3.859244\nsample estimates:\nmean of x mean of y \n 189.9536  195.8235 \n\n\n\n\n\n\nDie 2×3 ANOVA im Grinschgl et al. (2021) Paper beantwortet die folgenden Fragen:\nGibt es Unterschiede zwischen den Feedbackgruppen, gibt es Veränderungen über die Zeit (Pre1 vs. Pre4), und unterscheiden sich diese zeitlichen Veränderungen zwischen den Gruppen (above vs. control vs. below)?\n\nmixed_anova &lt;- aov_4(rating ~ group_all + (time_rating | code), data = dat_long)\n\nConverting to factor: group_all\n\n\nContrasts set to contr.sum for the following variables: group_all\n\nsummary(mixed_anova)\n\n\nUnivariate Type III Repeated-Measures ANOVA Assuming Sphericity\n\n                      Sum Sq num Df Error SS den Df  F value\n(Intercept)           8198.9      1   500.58    156 2555.113\ngroup_all              126.7      2   500.58    156   19.736\ntime_rating             42.0      1   288.70    156   22.668\ngroup_all:time_rating   74.4      2   288.70    156   20.090\n                                     Pr(&gt;F)    \n(Intercept)           &lt; 0.00000000000000022 ***\ngroup_all                     0.00000002286 ***\ntime_rating                   0.00000436406 ***\ngroup_all:time_rating         0.00000001724 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nDer signifikante Haupteffekt der Feedbackgruppe (group_all) zeigt, dass sich die mittleren Ratings zwischen den Gruppen unterscheiden, unabhängig vom Zeitpunkt der Messung.\nDer signifikante Haupteffekt der Feedbackgruppe (group_all) zeigt, dass sich die mittleren Ratings zwischen den Gruppen unterscheiden, unabhängig vom Zeitpunkt der Messung.\nDer signifikante Interaktionseffekt zeigt, dass sich die Veränderung der Ratings über die Zeit zwischen den Feedbackgruppen unterscheidet. 👉Der Effekt der Zeit ist nicht für alle Gruppen gleich.\n\n\n\n\n\n\nbitte Berechnung von Cohens d erneut für spezifisch 2x3 mixed ANOVA erklären. Hier sehe ich weder in den Hands On noch in den Foliensätze einen passenden Code, der bei mir funktioniert.\n\nAntwort: Cohen’s d wird für die Post-hoc-t-Tests berechnet, nicht für die 2×3-ANOVA selbst. (Für die ANOVA selbst berechnen wir Eta2). Cohen’s d ist ein Effektstärkenmaß, das angibt, wie groß der Unterschied zwischen zwei Gruppen ist, unabhängig von der Stichprobengröße. Hier ein Beispiel aus den Hands On Übungen. ​​\n\ndat_full_below_above &lt;- dat_full |&gt; \n  filter(group_all != \"control\")\n\ndat_full_below_above$group_all &lt;- as.factor(dat_full_below_above$group_all)\n\nt.test(pre4 ~ group_all, data = dat_full_below_above, var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  pre4 by group_all\nt = 7.9845, df = 104, p-value = 0.000000000001991\nalternative hypothesis: true difference in means between group above and group below is not equal to 0\n95 percent confidence interval:\n 2.025170 3.363509\nsample estimates:\nmean in group above mean in group below \n           5.966038            3.271698 \n\neffsize::cohen.d(pre4 ~ group_all, data = dat_full_below_above)\n\n\nCohen's d\n\nd estimate: 1.551045 (large)\n95 percent confidence interval:\n   lower    upper \n1.111706 1.990383 \n\n\n\n\n\n\n\nWas macht es aus, dass man explizit na.rm = TRUE bei mean() und sd() angibt\n\nAntwort: Mittelwerte und Standardabweichungen können nicht korrekt berechnet werden, wenn sich fehlende Werte (NAs) in den Daten befinden. Mit na.rm = TRUE werden diese fehlenden Werte bei der Berechnung ausgeschlossen. Wurden die NAs bereits zuvor bereinigt, ist dieser Befehl zwar redundant, schadet jedoch nicht.\n\nx &lt;- c(1,2,3,4,5,6,NA)\n\nmean(x)\n\n[1] NA\n\nmean(x, na.rm = TRUE)\n\n[1] 3.5\n\n\n\n\n\n\n\nWoher weiss man, ob man rowMeans() und(/oder) mean() anwenden soll?\n\nrowMeans(df) berechnet die Zeilenmittelwerte, also den Mittelwert pro Zeile über alle Spalten hinweg.\nIn einem Wide-Datensatz entspricht das typischerweise dem Mittelwert pro Person über mehrere Variablen / Messungen.\nmean(df$V1) berechnet den Mittelwert einer einzelnen Spalte (V1) über alle Zeilen hinweg.\nDas entspricht dem Mittelwert einer Variable über alle Personen\nrowMeans bietet sich also dafür an z.B. Skalenwerte zu berechnen (z.B. Durschnitt mehrerer Skalenitems) zu berechnen, während mean besser für Durschnittswerte über das gesamte Sample geeignet ist.\n\n\n\nV1\nV2\nV3\n\n\n\n\n1\n2\n3\n\n\n4\n5\n6\n\n\n7\n8\n9\n\n\n\n\ndf &lt;- data.frame(\n  V1 = c(1, 4, 7),\n  V2 = c(2, 5, 8),\n  V3 = c(3, 6, 9)\n)\n\n# Zeilenmittelwerte (Mittelwert pro Zeile über V1–V3)\nrowMeans(df)\n\n[1] 2 5 8\n\n# Mittelwert über Variable\nmean((df$V1))\n\n[1] 4\n\n\n\n\n\n\n\nMir ist noch nicht richtig klar, wie man APA konforme ANOVA Tabellen erzeugt, die man gerade abspeichern kann und dann in eine Word Datei einfügen kann. Z.B für eine dreifaktorielle ANOVA?\n\nAntwort: Tabellen für ANOVAs haben wir nicht behandelt. In der Praxis werden ANOVAs meist auch nicht in Tabellenform berichtet, sondern direkt im Text. Es ist jedoch möglich, APA-konforme ANOVA-Tabellen mit Packages apaTables wie Papaja zu erstellen.\nBeispiel aus Grinschgl et al. (2021)\n\nlibrary(apaTables)\n\nmodel_1 &lt;- aov(bill_length_mm ~ island + sex + species, data = penguins_filtered)\n\napa.aov.table(\n  lm_output = model_1,\n  filename  = \"anova_table.doc\"\n)\n\n\n\nANOVA results using bill_length_mm as the dependent variable\n \n\n   Predictor       SS  df       MS       F    p partial_eta2 CI_90_partial_eta2\n (Intercept) 50463.39   1 50463.39 9751.90 .000                                \n      island    10.22   2     5.11    0.99 .374          .01         [.00, .04]\n         sex   685.30   1   685.30  132.43 .000          .39         [.30, .46]\n     species  3254.78   1  3254.78  628.98 .000          .75         [.71, .78]\n       Error  1081.52 209     5.17                                             \n\nNote: Values in square brackets indicate the bounds of the 90% confidence interval for partial eta-squared \n\n\n\n\n\n\n\n\n\n\n\n\nBesseres Verständnis dafür, welche statistischen Tests in welcher Situation angemessen sind\n\nAntwort: Sprengt hier leider den Rahmen. Wir verweisen hier gerne auf den Statistikbaum der UZH. Jedoch kann auch dieser eine tiefergehende Auseinandersetzung mit der Fragestellung und dem Datenformat nicht ersetzen! Für spezifische Fragen zu diesem Thema, kann auch gerne die Methodenberatung genutzt werden!",
    "crumbs": [
      "Muddiest Points",
      "Muddiest Points 3"
    ]
  },
  {
    "objectID": "scripts/03_faq/datenanalyseplan.html",
    "href": "scripts/03_faq/datenanalyseplan.html",
    "title": "3 Datenanalyseplan",
    "section": "",
    "text": "Fragen zum Datenanalyseplan",
    "crumbs": [
      "FAQ",
      "3  Datenanalyseplan"
    ]
  },
  {
    "objectID": "scripts/03_faq/datenanalyseplan.html#müssen-die-anmerkungen-im-datenanalyseplan-nach-der-bearbeitung-gelöscht-werden-so-dass-nur-die-frage-und-der-titel-verbleiben",
    "href": "scripts/03_faq/datenanalyseplan.html#müssen-die-anmerkungen-im-datenanalyseplan-nach-der-bearbeitung-gelöscht-werden-so-dass-nur-die-frage-und-der-titel-verbleiben",
    "title": "3 Datenanalyseplan",
    "section": "Müssen die Anmerkungen im Datenanalyseplan nach der Bearbeitung gelöscht werden, so dass nur die Frage und der Titel verbleiben?",
    "text": "Müssen die Anmerkungen im Datenanalyseplan nach der Bearbeitung gelöscht werden, so dass nur die Frage und der Titel verbleiben?\nÜblicherweise werden Datenanalysepläne auf OSF (dem Open Science Framework) mitsamt den Anmerkungen veröffentlicht. Für das Seminar ist es möglich die Anmerkungen zu behalten oder zu löschen.",
    "crumbs": [
      "FAQ",
      "3  Datenanalyseplan"
    ]
  },
  {
    "objectID": "scripts/03_faq/datenanalyseplan.html#müssen-auch-zu-explorativen-fragestellungen-hypothesen-aufgestellt-werden",
    "href": "scripts/03_faq/datenanalyseplan.html#müssen-auch-zu-explorativen-fragestellungen-hypothesen-aufgestellt-werden",
    "title": "3 Datenanalyseplan",
    "section": "Müssen auch zu explorativen Fragestellungen Hypothesen aufgestellt werden?",
    "text": "Müssen auch zu explorativen Fragestellungen Hypothesen aufgestellt werden?\nKurzgesagt, nein. Bei explorativen Fragestellungen kann man auch einfach anmerken, dass diese explorativ sind – es also keine bisherige Theorie oder Evidenz für einen bestimmte Richtung gibt. Wichtig ist hierbei vor allem, transparent und vorausschauend zu arbeiten, in diesem Fall also den Umstand, explorativ zu arbeiten, klar zu benennen.",
    "crumbs": [
      "FAQ",
      "3  Datenanalyseplan"
    ]
  },
  {
    "objectID": "scripts/03_faq/datenanalyseplan.html#wenn-voraussetzungsprüfungen-oder-post-hoc-tests-durchgeführt-werden-müssen-diese-auch-im-datenanalyseplan-ergänzt-werden",
    "href": "scripts/03_faq/datenanalyseplan.html#wenn-voraussetzungsprüfungen-oder-post-hoc-tests-durchgeführt-werden-müssen-diese-auch-im-datenanalyseplan-ergänzt-werden",
    "title": "3 Datenanalyseplan",
    "section": "Wenn Voraussetzungsprüfungen oder post-hoc Tests durchgeführt werden, müssen diese auch im Datenanalyseplan ergänzt werden?",
    "text": "Wenn Voraussetzungsprüfungen oder post-hoc Tests durchgeführt werden, müssen diese auch im Datenanalyseplan ergänzt werden?\nGrundsätzlich gilt: Der Datenanalyseplan soll fremden Wissenschaftler:innen aus der Psychologie ermöglichen die Studie und die Datenanalyse ohne weiteren Aufwand nachvollziehen zu können. Dafür sollte auf Vollständigkeit und Genauigkeit geachtet werden. Dementsprechend gilt es, die Voraussetzungsprüfungen entweder komplett wegzulassen oder sie sowohl im Skript als auch im Datenanalyseplan zu ergänzen.",
    "crumbs": [
      "FAQ",
      "3  Datenanalyseplan"
    ]
  },
  {
    "objectID": "scripts/03_faq/datenanalyseplan.html#soll-der-abstract-bereits-die-resultate-von-grinschgl-et-al.-2020-erwähnen-oder-offenlassen-welche-resultate-zu-erwarten-sind",
    "href": "scripts/03_faq/datenanalyseplan.html#soll-der-abstract-bereits-die-resultate-von-grinschgl-et-al.-2020-erwähnen-oder-offenlassen-welche-resultate-zu-erwarten-sind",
    "title": "3 Datenanalyseplan",
    "section": "Soll der Abstract bereits die Resultate von Grinschgl et al. (2020) erwähnen oder offenlassen, welche Resultate zu erwarten sind?",
    "text": "Soll der Abstract bereits die Resultate von Grinschgl et al. (2020) erwähnen oder offenlassen, welche Resultate zu erwarten sind?\nÜblicherweise lässt der Datenanalyseplan die Resultate der beschriebenen Analyse im Abstract noch offen, da diese zu dem Zeitpunkt, zu welchem der Datenanalyseplan erstellt wird, noch nicht bekannt sind. Bei einer Replikation der Originalstudie – wie es hier der Fall ist – können die Ergebnisse aus dieser aber auch bereits genannt werden. Bezüglich der eigenen Datenanalyse sollte wiederum von erwarteten Ergebnissen ausgehen. Da die Analyse der Daten erst nach Verfassen des Datenanalyseplans folgt sind die Resultate bis dahin nicht bekannt.",
    "crumbs": [
      "FAQ",
      "3  Datenanalyseplan"
    ]
  },
  {
    "objectID": "scripts/03_faq/faq.html",
    "href": "scripts/03_faq/faq.html",
    "title": "FAQ",
    "section": "",
    "text": "Hier findest du häufig gestellte Fragen und Antworten. Wir updaten diese Sammlung laufend.",
    "crumbs": [
      "FAQ"
    ]
  },
  {
    "objectID": "scripts/03_faq/statistic.html",
    "href": "scripts/03_faq/statistic.html",
    "title": "4 Statistik",
    "section": "",
    "text": "Fragen zu Statistik",
    "crumbs": [
      "FAQ",
      "4  Statistik"
    ]
  },
  {
    "objectID": "scripts/03_faq/statistic.html#was-ist-das-partielle-η²-und-wie-unterscheidet-es-sich-von-dem-generalisierten-η²",
    "href": "scripts/03_faq/statistic.html#was-ist-das-partielle-η²-und-wie-unterscheidet-es-sich-von-dem-generalisierten-η²",
    "title": "4 Statistik",
    "section": "Was ist das partielle η² und wie unterscheidet es sich von dem generalisierten η²?",
    "text": "Was ist das partielle η² und wie unterscheidet es sich von dem generalisierten η²?\nDas generalisierte und partielle η² sind beides Masse, welche den Anteil an erklärter Varianz einer abhängigen Variable angeben. Das generalisierte η² berechnet den Anteil der erklärten Varianz einer abhängigen Variable unter Einbezug der gesamten Varianz, also aller Effekte. Das partielle η² beachtet bei der Berechnung des Anteils an erklärter Varianz für die abhängige Variable nicht die gesamte Varianz, sondern nur jene, welche dem zuvor definierten Effekt zugeschrieben werden kann.\n\n\n\n\n\n\nNote\n\n\n\nWeiterführende Informationen finden sich hier.",
    "crumbs": [
      "FAQ",
      "4  Statistik"
    ]
  },
  {
    "objectID": "scripts/03_faq/statistic.html#wozu-muss-sphärizität-gegeben-sein-und-wie-kann-man-diese-testen",
    "href": "scripts/03_faq/statistic.html#wozu-muss-sphärizität-gegeben-sein-und-wie-kann-man-diese-testen",
    "title": "4 Statistik",
    "section": "Wozu muss Sphärizität gegeben sein und wie kann man diese testen?",
    "text": "Wozu muss Sphärizität gegeben sein und wie kann man diese testen?\nUnter Sphärizität versteht man die Annahme, dass bei Messwiederholungen die Differenzen von zwei beliebigen Messwiederholungen ähnliche Varianzen aufweisen. Dies kann mit dem Mauchly-Test geprüft werden. Laut Nullhypothese sind die entsprechenden Varianzen gleich, laut Alternativhypothese sind die entsprechenden Varianzen unterschiedlich. Dementsprechend spricht ein signifikanter Mauchly-Test für eine Verletzung der Sphärizitätsannahme. In diesem Fall kann auf die Greenhouse-Geisser Korrektur zurückgegriffen werden.",
    "crumbs": [
      "FAQ",
      "4  Statistik"
    ]
  },
  {
    "objectID": "scripts/03_faq/statistic.html#was-macht-eine-tukey-korrektur-und-was-sagt-uns-das-ergebnis",
    "href": "scripts/03_faq/statistic.html#was-macht-eine-tukey-korrektur-und-was-sagt-uns-das-ergebnis",
    "title": "4 Statistik",
    "section": "Was macht eine Tukey-Korrektur und was sagt uns das Ergebnis?",
    "text": "Was macht eine Tukey-Korrektur und was sagt uns das Ergebnis?\nDie Tukey-Korrektur wird angewendet, um im Anschluss an eine signifikante ANOVA die Mittelwertsunterschiede der einzelnen Gruppen unter Kontrolle für multiples Testen einzeln zu untersuchen. Hierdurch wird eine Inflation der falsch-negativen Rate bzw. des p-Wertes vermieden. Bei Verwendung dieses Tests können die Ergebnisse der Mittelwertsvergleiche somit unmittelbar auf ihre Signifikanz hin bewertet werden.",
    "crumbs": [
      "FAQ",
      "4  Statistik"
    ]
  },
  {
    "objectID": "scripts/03_faq/statistic.html#wann-benötigt-die-berechnung-einer-anova-einen-wide-datensatz-und-wann-benötigt-die-berechnung-einer-anova-einen-long-datensatz",
    "href": "scripts/03_faq/statistic.html#wann-benötigt-die-berechnung-einer-anova-einen-wide-datensatz-und-wann-benötigt-die-berechnung-einer-anova-einen-long-datensatz",
    "title": "4 Statistik",
    "section": "Wann benötigt die Berechnung einer ANOVA einen wide-Datensatz und wann benötigt die Berechnung einer ANOVA einen long-Datensatz?",
    "text": "Wann benötigt die Berechnung einer ANOVA einen wide-Datensatz und wann benötigt die Berechnung einer ANOVA einen long-Datensatz?\nIn welchem Format der Datensatz vor der Berechnung einer ANOVA vorliegen muss hängt von der verwendeten ANOVA-Funktion ab und kann nicht pauschal beantwortet werden. Grundsätzlich gilt aber, für eine ANOVA ohne Messwiederholung ist ein wide-Datensatz meist ausreichend. Die Funktion aov_4(), welche bei ANOVAs mit Messwiederholung verwendet werden kann, benötigt eine gesonderte Variable, welche den Zeitpunkt der Messung angibt, sprich das long-Format. Hier ein Beispiel wie die Umwandlug in ein long-Format und eine anschliessende Berechnung von einer ANOVA mit Messwiederholung aussehen könnte:\n\ndata_long &lt;- data_wide |&gt; \n  pivot_longer(\n    cols = c(Spalte1, Spalte2, Spalte3), \n    names_to = \"Hier kommt der Name der Spalte rein, in welcher die früheren Spaltenüberschriften abgelegt sind\", \n    values_to = \"Hier kommt der Name der Spalte rein, in welcher die Werte der entsprechenden früheren Spalten abgelegt sind\"\n  )\n\nafex::aov_4(value ~ treatment + (time | Personenidentifikationscode), data = data_long) # Beispiel mit(!) Messwiederholung\n\n\n\n\n\n\n\nNote\n\n\n\nFür die Funktion aov_4() gibt es aus Statistik-IV von Boris Mayer und Stefan Thoma noch tiefere und beispielhafte Ausführungen.",
    "crumbs": [
      "FAQ",
      "4  Statistik"
    ]
  },
  {
    "objectID": "scripts/03_faq/statistic.html#was-wird-bei-einem-levene-test-berechnet-bzw.-geprüft",
    "href": "scripts/03_faq/statistic.html#was-wird-bei-einem-levene-test-berechnet-bzw.-geprüft",
    "title": "4 Statistik",
    "section": "Was wird bei einem Levene-Test berechnet bzw. geprüft?",
    "text": "Was wird bei einem Levene-Test berechnet bzw. geprüft?\nDer Levene-Test prüft die Varianzhomogenität zwischen Gruppen. Als Nullhypothese gilt hierbei, dass die Varianzen zwischen den Gruppen gleich sind. Als Alternativhypothese gilt, dass die Varianzen zwischen den Gruppen unterschiedlich sind. Dementsprechend besagt ein signifikanter Levene-Test, dass es Varianzunterschiede zwischen den Gruppen gibt und die Annahme der Varianzhomogenität verworfen werden muss.",
    "crumbs": [
      "FAQ",
      "4  Statistik"
    ]
  },
  {
    "objectID": "scripts/03_faq/statistic.html#wird-ein-levene-test-für-den-between-faktor-berechnet-und-muss-diese-berechnung-für-jede-abhängige-variable-einzeln-gemacht-werden",
    "href": "scripts/03_faq/statistic.html#wird-ein-levene-test-für-den-between-faktor-berechnet-und-muss-diese-berechnung-für-jede-abhängige-variable-einzeln-gemacht-werden",
    "title": "4 Statistik",
    "section": "Wird ein Levene-Test für den between-Faktor berechnet und muss diese Berechnung für jede abhängige Variable einzeln gemacht werden?",
    "text": "Wird ein Levene-Test für den between-Faktor berechnet und muss diese Berechnung für jede abhängige Variable einzeln gemacht werden?\nFür beide Fragen gilt: Ja! Der Levene-Test vergleicht die Varianzen von mindestens zwei Gruppen. Dementsprechend kann ein Levene-Test nur für einen between-Faktor durchgeführt werden. Darüber hinaus kann ein einzelner Levene-Test nur die Varianzverteilung einer abhängigen Variable (über alle Gruppen hinweg) betrachten. Daher muss für jede abhängige Variable, für die die Annahme der Varianzhomogenität benötigt wird und infrage steht, ein Levene-Test berechnet werden.",
    "crumbs": [
      "FAQ",
      "4  Statistik"
    ]
  },
  {
    "objectID": "scripts/03_faq/statistic.html#ist-vor-der-berechnung-einer-anova-notwendigerweise-ein-levene-test-durchzuführen",
    "href": "scripts/03_faq/statistic.html#ist-vor-der-berechnung-einer-anova-notwendigerweise-ein-levene-test-durchzuführen",
    "title": "4 Statistik",
    "section": "Ist vor der Berechnung einer ANOVA notwendigerweise ein Levene-Test durchzuführen?",
    "text": "Ist vor der Berechnung einer ANOVA notwendigerweise ein Levene-Test durchzuführen?\nDie Durchführung eines Levene-Tests vor der ANOVA ist dann notwendig, wenn die Varianzhomogenität zwischen Gruppen nicht anderweitig ersichtlich ist. Zeigen die Daten beispielsweise gleich grosse Stichproben und normalverteilte Verteilungen der Werte innerhalb der Gruppen, dann kann von Varianzhomogenität auch ohne den Levene-Test ausgegangen werden. Auf alle Fälle sollte man vor der Datenanalyse festlegen, ob ein Levene Test berechnet wird oder nicht, Und gegebenenfalls ein Verfahren definieren für den Fall das die Varianzhomogenität nicht gegeben ist (z.B. ein nichtparametrisches Verfahren wie die Welch-ANOVA)",
    "crumbs": [
      "FAQ",
      "4  Statistik"
    ]
  },
  {
    "objectID": "scripts/03_faq/statistic.html#welche-masse-für-effektstärken-werden-üblicherweise-bei-einer-anova-und-einem-post-hoc-t-test-berichtet",
    "href": "scripts/03_faq/statistic.html#welche-masse-für-effektstärken-werden-üblicherweise-bei-einer-anova-und-einem-post-hoc-t-test-berichtet",
    "title": "4 Statistik",
    "section": "Welche Masse für Effektstärken werden üblicherweise bei einer ANOVA und einem (post-hoc) t-Test berichtet?",
    "text": "Welche Masse für Effektstärken werden üblicherweise bei einer ANOVA und einem (post-hoc) t-Test berichtet?\nBei einer ANOVA wird im Rahmen des Seminars, sofern nicht anders verlangt, das Effektstärkemass η² berichtet. Bei (post-hoc) t-Tests wird im Rahmen des Seminars, sofern nicht anders verlangt, das Effektstärkemass von Cohens` d verwendet.",
    "crumbs": [
      "FAQ",
      "4  Statistik"
    ]
  },
  {
    "objectID": "scripts/03_faq/statistic.html#bei-der-analyse-der-internen-konsistenz-mit-der-funktion-alpha-erscheint-die-fehlermeldung-warnung-some-items-were-negatively-correlated-with-the-first-principal-component-and-probably-should-be-reversed.-to-do-this-run-the-function-again-with-the-check.keystrue-option.-was-bedeutet-diese-warnmeldung-und-kann-man-sie-einfach-ignorieren-oder-muss-sie-weiter-berücksichtigt-werden",
    "href": "scripts/03_faq/statistic.html#bei-der-analyse-der-internen-konsistenz-mit-der-funktion-alpha-erscheint-die-fehlermeldung-warnung-some-items-were-negatively-correlated-with-the-first-principal-component-and-probably-should-be-reversed.-to-do-this-run-the-function-again-with-the-check.keystrue-option.-was-bedeutet-diese-warnmeldung-und-kann-man-sie-einfach-ignorieren-oder-muss-sie-weiter-berücksichtigt-werden",
    "title": "4 Statistik",
    "section": "Bei der Analyse der internen Konsistenz mit der Funktion alpha() erscheint die Fehlermeldung: „Warnung: Some items were negatively correlated with the first principal component and probably should be reversed. To do this, run the function again with the ‘check.keys=TRUE’ option“. Was bedeutet diese Warnmeldung und kann man sie einfach ignorieren oder muss sie weiter berücksichtigt werden?",
    "text": "Bei der Analyse der internen Konsistenz mit der Funktion alpha() erscheint die Fehlermeldung: „Warnung: Some items were negatively correlated with the first principal component and probably should be reversed. To do this, run the function again with the ‘check.keys=TRUE’ option“. Was bedeutet diese Warnmeldung und kann man sie einfach ignorieren oder muss sie weiter berücksichtigt werden?\nDiese Warnmeldung - in Verbindung mit der Funktion alpha() zur Berechnung der internen Konsistenz - weist darauf hin, dass ein Item invers codiert sein könnte, da es nur einen geringen oder sogar negativen Zusammenhang zu den anderen Items aufweist. Dies kann daran liegen, dass das Item den Versuchspersonen invers vorgelegt worden war und lediglich vergessen wurde, die Skala anschliessend erneut zu invertieren. Das Item kann aber auch in die „richtige“ Richtung codiert sein und die Kennwerte des Items erklären sich durch weitere Umstände wie beispielsweise eine kleine Stichprobe. Abhängig davon welcher Fall zutrifft müsste das Item vor der Berechnung der internen Konsistenz entweder noch invertiert oder die Warnmeldung kann ignoriert werden.",
    "crumbs": [
      "FAQ",
      "4  Statistik"
    ]
  }
]