[
  {
    "objectID": "scripts/04_misc/here.html",
    "href": "scripts/04_misc/here.html",
    "title": "Probleme beim Rendern",
    "section": "",
    "text": "Beim Rendern von Quarto-Files treten Probleme auf, die auf der Auswertung von Filepaths zurÃ¼ckzufÃ¼hren sind.\nWÃ¤hrend Code beim einfachen AusfÃ¼hren in RStudio relativ zum Projektordner interpretiert wird, erfolgt die Pfadauswertung beim Rendern relativ zum Skript selbst. Dies kann zu Render-Fehlern wie dem folgenden fÃ¼hren.",
    "crumbs": [
      "Probleme beim Rendern"
    ]
  },
  {
    "objectID": "scripts/04_misc/here.html#problem",
    "href": "scripts/04_misc/here.html#problem",
    "title": "Probleme beim Rendern",
    "section": "",
    "text": "Beim Rendern von Quarto-Files treten Probleme auf, die auf der Auswertung von Filepaths zurÃ¼ckzufÃ¼hren sind.\nWÃ¤hrend Code beim einfachen AusfÃ¼hren in RStudio relativ zum Projektordner interpretiert wird, erfolgt die Pfadauswertung beim Rendern relativ zum Skript selbst. Dies kann zu Render-Fehlern wie dem folgenden fÃ¼hren.",
    "crumbs": [
      "Probleme beim Rendern"
    ]
  },
  {
    "objectID": "scripts/04_misc/here.html#lÃ¶sung-mit-here",
    "href": "scripts/04_misc/here.html#lÃ¶sung-mit-here",
    "title": "Probleme beim Rendern",
    "section": "LÃ¶sung mit here",
    "text": "LÃ¶sung mit here\nUm dieses Problem zu beheben, kann das here-Package verwendet werden.\nhere evaluiert Pfade konsistent relativ zum Projektordner und verhindert dadurch solche Render-Probleme.\nDurch die Verwendung von here Ã¤ndern sich die Angaben des Filepfades beim Einlesen und Schreiben von Dateien leicht. Die einzige VerÃ¤nderung ist dass wir den Filepfad in die here Funktion Ã¼bergeben (in Klammern). Siehe dafÃ¼r das Beispiel unten.\nDazu muss das Package here zunÃ¤chst installiert werden:\n\ninstall.packages(\"here\")\nlibrary(here)\n\nUnd aus diesem Code der zu Problemen fÃ¼hren kann\n\ndata_cb &lt;- read_csv(\"data/raw/data_cb.csv\") #Kann zu Problemen beim Rendern fÃ¼hren. \n\nwird:\n\ndata_cb &lt;- read_csv(here(\"data/raw/data_cb.csv\")) # Sichere Variante\n\nDas gleiche gilt fÃ¼r das schreiben von daten mit write.csv\n\n# Kann zu Problemen fÃ¼hren\nwrite.csv(dat_full, \"data/processed/dat_full.csv\")\n\n# Sicherer: Pfad wird immer relativ zum Projekt-Root aufgelÃ¶st\nwrite.csv(dat_full, here(\"data/processed/dat_full.csv\"))\n\nDas sollte die Probleme lÃ¶sen!",
    "crumbs": [
      "Probleme beim Rendern"
    ]
  },
  {
    "objectID": "scripts/04_misc/muddiest_points_2.html",
    "href": "scripts/04_misc/muddiest_points_2.html",
    "title": "Muddiest Points 2",
    "section": "",
    "text": "Bei mir gibt es beim Einlesen des Datensatzes immer noch eine zusÃ¤tzliche Spalte, welche nochmal durchnummeriert ist (also wie eine ID, aber ohne Namen). Wie lese ich den Datensatz richtig ein, damit ich diese Spalte nicht immer noch zusÃ¤tzlich lÃ¶schen muss?\nAntwort:\nWahrscheinlich hast du beim Speichern der Daten mit write.csv() das Argument row.names nicht gesetzt. Wenn du row.names = FALSE angibst, entsteht diese zusÃ¤tzliche Spalte nicht. Genauere ErklÃ¤rung findest du hier. Das Problem liegt also vermutlich nicht am Einlesen der Daten, sondern daran wie du die Daten abgespeichert hast. Wenn dem nicht so ist - bitte komm noch mal auf uns zu!\n\n\n\n\nManchmal sind mir die Pfade, die ich beim Einlesen und Abspeichern einer Datei angeben muss, nicht klar. Die kÃ¼rzere Version funktioniert oft nicht, deshalb muss ich immer den ganzen Pfad eingeben.\nAntwort:\nWenn relative Pfade nicht funktionieren, Ã¼berprÃ¼fe zuerst, ob du dein Projekt korrekt geÃ¶ffnet hast. Falls das Problem bleibt, kannst du mit getwd() dein aktuelles Arbeitsverzeichnis ausgeben lassen. Dieses sollte auf deinen Projektordner zeigen.\nWenn das nicht funktionieren sollte prÃ¼fe ob du diese Einstellung unter â€œTools - Global Optionsâ€ vorgenommen hast: Evaluate Chunks in directory: Projekt\n\n\n\n\n\nWeitere MÃ¶glichkeiten:\nWenn du dich zum Beispiel im Ordner grinschgl2020/code/ befindest, aber eine Datei aus einem Ã¼bergeordneten Ordner einlesen mÃ¶chtest (z. B. grinschgl2020/data/), kannst du beim Einlesen .. verwenden. Damit geht R eine Ebene nach oben, und relative Pfade funktionieren wie erwartet.\nBeispiel:\n\n# Wir befinden uns in: grinschgl2020/code/\n\n# Eine Ebene nach oben gehen (..) und in den data-Ordner wechseln\ndaten &lt;- read.csv(\"../data/raw/daten_roh.csv\")\n\n\n\n\n\nEinige Funktionen wie across() werden in anderen Funktionen verschachtelt verwendet und brauchen zusÃ¤tzliche Argumente. Die Logik der Verschachtelung ist mir noch nicht klar.\nAntwort:\nFunktionen wie across() werden verschachtelt, weil sie nur innerhalb von dplyr-Funktionen wie mutate() oder summarise() arbeiten. Die Ã¤ussere Funktion bestimmt, was passieren soll (z. B. Spalten verÃ¤ndern). across() legt dann fest, welche Spalten betroffen sind und welche Transformation angewendet wird. Deshalb braucht across() Argumente wie .cols und .fns. Die Ã¤ussere Funktion gibt den Rahmen vor, across() steuert die konkrete Operation.\nBeispiel:\nacross() hat zwei wichtige Argumente:\n\n.cols â†’ Welche Spalten sollen ausgewÃ¤hlt werden?\nIm Beispiel: alle Spalten, die auf â€œ_râ€ enden. Across geht wert fÃ¼r wert durch diese Spalten\n.fns â†’ Welche Operation soll auf jeden einzelnen Wert dieser Spalten angewendet werden?\nIm Beispiel: FÃ¼r jeden Wert wird 6 â€“ Wert berechnet (Umkehrkodierung).\nDas .x steht fÃ¼r den aktuellen Wert durch den across durchgeht. Manchmal wird auch nur ein Punkt ausgeschrieben da beide Schreibweisen funktionieren.\n\n\ndata_reversed &lt;- data_numeric |&gt;\n  mutate(\n    across(ends_with(\"_r\"), ~ 6 - .x) #~ 6 - . --&gt; FÃ¼r jede wert der col -6 \n  )\n\n\n\n\n\nIch habe manchmal ein Data Frame an eine Funktion Ã¼bergeben, obwohl diese einen Vektor erwartet, oder umgekehrt. Mir ist noch nicht klar, welche Funktionen Vektoren und welche Data Frames erwarten.\nGibt es irgendeine â€œMerkhilfeâ€ um zu wissen bei welchen Packages/ Funktionen ich die Variablen auf welche Art auflisten muss?Â â€“&gt; Also ob mit â€œVariableâ€ oder c(Variable)?\nAntwort:\nEs gibt keine feste Regel, aber die Hilfeseite (?funktion) zeigt immer, welcher Datentyp erwartet wird. GrundsÃ¤tzlich gilt: Funktionen, die Spaltenweise etwas berechnen (z. B. mean, sum, skew), erwarten Vektoren â€“ oft extrahiert man diese mit $ aus einen Dataframe.\nFunktionen, die Daten transformieren (summarise, mutate, filter, select), erwarten dagegen Data Frames, da sie auf mehreren Variablen gleichzeitig arbeiten.\nDas c bei Vektoren steht fÃ¼r concatenate und wird verwendet, wenn wir mit Vektoren arbeiten. Wenn nur ein Element im Vektor vorhanden ist, brauchen wir kein c() (Skalar). Sobald mehrere Elemente enthalten sind, benÃ¶tigen wir c().\n\n\n\n\nIch bin mir noch unsicher darin, wann bestimmte Datenstrukturen notwendig sind â€“ zum Beispiel die Umwandlung von Variablen in Faktoren.\nAntwort:\nViele Transformationen sind notwendig, weil statistische Funktionen bestimmte Datentypen voraussetzen. Die ANOVA etwa benÃ¶tigt Faktoren, wenn Gruppen verglichen werden sollen, damit R die Gruppen-Variable als kategorial erkennt. Solche Transformationen sind also Teil der korrekten Vorbereitung der Daten. Wenn du z.B. eine ANOVA durchfÃ¼hrst und vergisst die Gruppen-Variable als Faktor umzuwandeln, bekommst du eine Warnung. Durch diese erkennst du dann, dass ein Faktor benÃ¶tigt wird - es ist also nicht allzu schlimm, wenn du die Umwandlung zunÃ¤chst verpasst hast.\nEs ist eine gute Faustregel, Variablen in Faktoren umzuwandeln, wenn sie klar kategoriale Gruppen darstellen â€“ zum Beispiel eine GruppenzugehÃ¶rigkeit wie â€œaboveâ€, â€œbelowâ€ oder â€œcontrolâ€.\n\n\n\n\nIch wÃ¤re froh, wenn wir allgemeine Fehler beim Codieren durchgehen kÃ¶nnten â€“ also hÃ¤ufige Syntaxfehler und worauf man achten sollte.\nAntwort:\n(Dieser Punkt ist als Wunsch notiert.)\n\n\n\n\nDaten korrekt einlesen, abspeichern, und im Projektkontext richtig organisieren. / Abspeichern der Daten, gute Ordnerstruktur? Das ist nur ein â€œkleinerâ€ Punkt, aber ich habe immer ein bisschen ein Durcheinander, wie ich Skripts und Projekte am besten abspeichere, damit auch immer alles funktioniert bei der Analyse. Oft habe ich bspw. zu lange Dateipfade\nAntwort:\nGrundsÃ¤tzlich gilt: Alle Rohdaten werden im raw/-Ordner gespeichert (und niemals Ã¼berschrieben). Diese Daten werden dann im processing-Skript bereinigt und verarbeitet. Die verarbeiteten Datensaetze werden anschliessend mit write.csv() im processed/-Ordner gespeichert.\nIm analysis-Skript werden keine Bereinigungen mehr vorgenommen, sondern nur noch die eigentlichen Analyseschritte durchgefuehrt (mit Ausnahme kleiner Anpassungen wie das Setzen von Faktoren, da diese Aenderungen nicht gespeichert werden).\nDiese Struktur orientiert sich am PsychDS-Standard.\nHausÃ¼bungen und Hands on: Da wir mit vielen verschiedenen DatensÃ¤tzen und Skripten arbeiten, ist es sinnvoll, eine klare Ordnerstruktur zu verwenden, zum Beispiel einen Ordner fÃ¼r Skripte und einen fÃ¼r Daten. Man kann sich dabei an der PsychDS-Struktur orientieren und diese Ã¼bernehmen, auch wenn wir nicht mit den dat_full-Daten arbeiten.\nZu den Pfaden: Achte darauf, relative Pfade zu verwenden. Lange Pfade sind grundsÃ¤tzlich kein Problem, solange sie relativ, nachvollziehbar und konsistent aufgebaut sind.\n\n\n\n\nWide to long: Weshalb ist das notwendig, weshalb kann man nicht beim einen Format bleiben?\nAntwort:\nViele Funktionen setzen ein bestimmtes Datenformat voraus. Repeated-Measures-Funktionen sind das beste Beispiel â€“ sie benÃ¶tigen Long-Format, weil jede Zeile eine Beobachtung darstellt. Das wird in den nÃ¤chsten Wochen noch verstÃ¤ndlicher - wenn wir dann Berechnungen mit dem Wide als auch Long Format durchfÃ¼hren.\n\n\n\n\nWas ist der Unterschied zwischen class(), attributes() und table()?\nAntwort:\n\nclass() zeigt den Typ eines Objekts\n\n\n  class(penguins)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n  class(penguins$species)\n\n[1] \"factor\"\n\n\n\ntable() zeigt HÃ¤ufigkeiten\n\n\ntable(penguins$island)\n\n\n   Biscoe     Dream Torgersen \n      168       124        52 \n\n\n\nattributes() zeigt die Attribute eines Objekts\n\nbei Data Frames: Variablennamen, rownames, Datentypen\nbei Faktoren: Levels und Klasse\n\n\n\nattributes(penguins)\n\n$class\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n$row.names\n  [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n [91]  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n[109] 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126\n[127] 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144\n[145] 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162\n[163] 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180\n[181] 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198\n[199] 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216\n[217] 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234\n[235] 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252\n[253] 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270\n[271] 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288\n[289] 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306\n[307] 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324\n[325] 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342\n[343] 343 344\n\n$names\n[1] \"species\"           \"island\"            \"bill_length_mm\"   \n[4] \"bill_depth_mm\"     \"flipper_length_mm\" \"body_mass_g\"      \n[7] \"sex\"               \"year\"             \n\nattributes(penguins$species)\n\n$levels\n[1] \"Adelie\"    \"Chinstrap\" \"Gentoo\"   \n\n$class\n[1] \"factor\"\n\n\n\n\n\n\nWie kann ich nachhaltige Anpassungen an Variablen im Datensatz vornehmen?\nAntwort:\nUm Ã„nderungen im Datensatz festzuhalten, muss eine Zuweisung mit &lt;- vorgenommen werden. Wenn ein Befehl ohne Zuweisung ausgefÃ¼hrt wird, wird das Resultat nicht im Environment abgespeichert. Wenn ein Objekt im Environment ist, heisst das nicht, dass dieses automatisch als z. B. CSV gespeichert wird. DafÃ¼r sollte es mit einer passenden Write-Funktion gespeichert werden. Im Processing-Skript fÃ¼hrt ihr alle Aufbereitungsschritte (z. B. Variablen umbenennen) durch und speichert am Ende den bereinigten Datensatz mit write.csv() oder einer Ã¤hnlichen Funktion ab, damit alle Ã„nderungen nachhaltig gesichert sind.\nBeispiel â€“&gt; Keine VerÃ¤nderung am Datensatzt weil keine Zuweisung\n\npenguins |&gt;  \n  mutate(mean_bill_length = mean(bill_length_mm, na.rm = TRUE))\n\nBeispiel mit Zuweisung: Gleicher Datensatz wird verÃ¤ndert\n\npenguins &lt;- penguins |&gt; \n  mutate(mean_bill_length = mean(bill_length_mm, na.rm = TRUE))\n\n\n\n\n\nFÃ¼r mich persÃ¶nlich ist die group_by() Funktion irgendwie nicht ganz klar. Die Vorstellung, wie die Daten sortiert werden, ist nicht so intuitiv.Â \nAntwort:\nFÃ¼r viele ist die Funktion anfangs nicht intuitiv. Die Vorstellung, wie die Daten intern in Gruppen â€aufgeteiltâ€œ werden, ohne dass sie tatsÃ¤chlich sortiert oder neu angeordnet werden, fÃ¼hlt sich ungewohnt an. Das ist vÃ¶llig normal â€“ die Logik hinter group_by() entwickelt sich meist erst, wenn man sieht, wie sie gemeinsam mit Funktionen wie summarise() oder mutate() wirkt. Kategoriale Daten werden in ihre kategorien augeteilt, kontinuierliche Daten werden in ihre einzigartigen werte gruppiert.\nBeispiel Kontinuierliche Variable: Gruppe fÃ¼r jedes Gewicht\n\npenguins_summary &lt;- penguins |&gt; \n  group_by(body_mass_g) |&gt; \n  summarize(mean_bill_length = mean(bill_length_mm, na.rm = TRUE))\n  \npenguins_summary[1:10, 1:2]\n\n# A tibble: 10 Ã— 2\n   body_mass_g mean_bill_length\n         &lt;int&gt;            &lt;dbl&gt;\n 1        2700             46.9\n 2        2850             36.4\n 3        2900             37.4\n 4        2925             37.9\n 5        2975             37.5\n 6        3000             37.2\n 7        3050             35.6\n 8        3075             37.7\n 9        3100             36  \n10        3150             36.6\n\n\nBeispiel kategoriale Variable\n\npenguins_summary_2 &lt;- penguins |&gt; \n  group_by(island) |&gt; \n  summarize(mean_bill_length = mean(bill_length_mm, na.rm = TRUE))\n  \npenguins_summary_2\n\n# A tibble: 3 Ã— 2\n  island    mean_bill_length\n  &lt;fct&gt;                &lt;dbl&gt;\n1 Biscoe                45.3\n2 Dream                 44.2\n3 Torgersen             39.0\n\n\n\n\n\n\nIch habe auch ein bisschen ein Durcheinander, wann die Daten am besten wie abgespeichert/eingelesen werden. Also mit read_delim(), row.names = FALSE, csv2 vs csv usw.Â \n\nEinlesen:\nKurz zusammengefasst: Am einfachsten ist es, zunÃ¤chst die Point-and-Click-OberflÃ¤che in RStudio zu nutzen und die Optionen so einzustellen, dass die Daten sinnvoll eingelesen werden, und anschliessend den generierten Code zu Ã¼bernehmen. read_csv() ist im Prinzip das Gleiche wie read_delim(), nur dass es standardmÃ¤ssig ein Komma als Trennzeichen verwendet (CSV bedeutet comma separated values). Bei read_delim() muss das Trennzeichen hingegen explizit angegeben werden, zum Beispiel ein Semikolon.\nSpeichern:\nZum Speichern nutzt ihr am besten write.csv(). Von write.csv2() sollte man eher die Finger lassen, da es historische SpezialfÃ¤lle abdeckt und meist eher zu Verwirrung fÃ¼hrt.",
    "crumbs": [
      "Muddiest Points"
    ]
  },
  {
    "objectID": "scripts/04_misc/muddiest_points_2.html#muddiest-points-session-2",
    "href": "scripts/04_misc/muddiest_points_2.html#muddiest-points-session-2",
    "title": "Muddiest Points 2",
    "section": "",
    "text": "Bei mir gibt es beim Einlesen des Datensatzes immer noch eine zusÃ¤tzliche Spalte, welche nochmal durchnummeriert ist (also wie eine ID, aber ohne Namen). Wie lese ich den Datensatz richtig ein, damit ich diese Spalte nicht immer noch zusÃ¤tzlich lÃ¶schen muss?\nAntwort:\nWahrscheinlich hast du beim Speichern der Daten mit write.csv() das Argument row.names nicht gesetzt. Wenn du row.names = FALSE angibst, entsteht diese zusÃ¤tzliche Spalte nicht. Genauere ErklÃ¤rung findest du hier. Das Problem liegt also vermutlich nicht am Einlesen der Daten, sondern daran wie du die Daten abgespeichert hast. Wenn dem nicht so ist - bitte komm noch mal auf uns zu!\n\n\n\n\nManchmal sind mir die Pfade, die ich beim Einlesen und Abspeichern einer Datei angeben muss, nicht klar. Die kÃ¼rzere Version funktioniert oft nicht, deshalb muss ich immer den ganzen Pfad eingeben.\nAntwort:\nWenn relative Pfade nicht funktionieren, Ã¼berprÃ¼fe zuerst, ob du dein Projekt korrekt geÃ¶ffnet hast. Falls das Problem bleibt, kannst du mit getwd() dein aktuelles Arbeitsverzeichnis ausgeben lassen. Dieses sollte auf deinen Projektordner zeigen.\nWenn das nicht funktionieren sollte prÃ¼fe ob du diese Einstellung unter â€œTools - Global Optionsâ€ vorgenommen hast: Evaluate Chunks in directory: Projekt\n\n\n\n\n\nWeitere MÃ¶glichkeiten:\nWenn du dich zum Beispiel im Ordner grinschgl2020/code/ befindest, aber eine Datei aus einem Ã¼bergeordneten Ordner einlesen mÃ¶chtest (z. B. grinschgl2020/data/), kannst du beim Einlesen .. verwenden. Damit geht R eine Ebene nach oben, und relative Pfade funktionieren wie erwartet.\nBeispiel:\n\n# Wir befinden uns in: grinschgl2020/code/\n\n# Eine Ebene nach oben gehen (..) und in den data-Ordner wechseln\ndaten &lt;- read.csv(\"../data/raw/daten_roh.csv\")\n\n\n\n\n\nEinige Funktionen wie across() werden in anderen Funktionen verschachtelt verwendet und brauchen zusÃ¤tzliche Argumente. Die Logik der Verschachtelung ist mir noch nicht klar.\nAntwort:\nFunktionen wie across() werden verschachtelt, weil sie nur innerhalb von dplyr-Funktionen wie mutate() oder summarise() arbeiten. Die Ã¤ussere Funktion bestimmt, was passieren soll (z. B. Spalten verÃ¤ndern). across() legt dann fest, welche Spalten betroffen sind und welche Transformation angewendet wird. Deshalb braucht across() Argumente wie .cols und .fns. Die Ã¤ussere Funktion gibt den Rahmen vor, across() steuert die konkrete Operation.\nBeispiel:\nacross() hat zwei wichtige Argumente:\n\n.cols â†’ Welche Spalten sollen ausgewÃ¤hlt werden?\nIm Beispiel: alle Spalten, die auf â€œ_râ€ enden. Across geht wert fÃ¼r wert durch diese Spalten\n.fns â†’ Welche Operation soll auf jeden einzelnen Wert dieser Spalten angewendet werden?\nIm Beispiel: FÃ¼r jeden Wert wird 6 â€“ Wert berechnet (Umkehrkodierung).\nDas .x steht fÃ¼r den aktuellen Wert durch den across durchgeht. Manchmal wird auch nur ein Punkt ausgeschrieben da beide Schreibweisen funktionieren.\n\n\ndata_reversed &lt;- data_numeric |&gt;\n  mutate(\n    across(ends_with(\"_r\"), ~ 6 - .x) #~ 6 - . --&gt; FÃ¼r jede wert der col -6 \n  )\n\n\n\n\n\nIch habe manchmal ein Data Frame an eine Funktion Ã¼bergeben, obwohl diese einen Vektor erwartet, oder umgekehrt. Mir ist noch nicht klar, welche Funktionen Vektoren und welche Data Frames erwarten.\nGibt es irgendeine â€œMerkhilfeâ€ um zu wissen bei welchen Packages/ Funktionen ich die Variablen auf welche Art auflisten muss?Â â€“&gt; Also ob mit â€œVariableâ€ oder c(Variable)?\nAntwort:\nEs gibt keine feste Regel, aber die Hilfeseite (?funktion) zeigt immer, welcher Datentyp erwartet wird. GrundsÃ¤tzlich gilt: Funktionen, die Spaltenweise etwas berechnen (z. B. mean, sum, skew), erwarten Vektoren â€“ oft extrahiert man diese mit $ aus einen Dataframe.\nFunktionen, die Daten transformieren (summarise, mutate, filter, select), erwarten dagegen Data Frames, da sie auf mehreren Variablen gleichzeitig arbeiten.\nDas c bei Vektoren steht fÃ¼r concatenate und wird verwendet, wenn wir mit Vektoren arbeiten. Wenn nur ein Element im Vektor vorhanden ist, brauchen wir kein c() (Skalar). Sobald mehrere Elemente enthalten sind, benÃ¶tigen wir c().\n\n\n\n\nIch bin mir noch unsicher darin, wann bestimmte Datenstrukturen notwendig sind â€“ zum Beispiel die Umwandlung von Variablen in Faktoren.\nAntwort:\nViele Transformationen sind notwendig, weil statistische Funktionen bestimmte Datentypen voraussetzen. Die ANOVA etwa benÃ¶tigt Faktoren, wenn Gruppen verglichen werden sollen, damit R die Gruppen-Variable als kategorial erkennt. Solche Transformationen sind also Teil der korrekten Vorbereitung der Daten. Wenn du z.B. eine ANOVA durchfÃ¼hrst und vergisst die Gruppen-Variable als Faktor umzuwandeln, bekommst du eine Warnung. Durch diese erkennst du dann, dass ein Faktor benÃ¶tigt wird - es ist also nicht allzu schlimm, wenn du die Umwandlung zunÃ¤chst verpasst hast.\nEs ist eine gute Faustregel, Variablen in Faktoren umzuwandeln, wenn sie klar kategoriale Gruppen darstellen â€“ zum Beispiel eine GruppenzugehÃ¶rigkeit wie â€œaboveâ€, â€œbelowâ€ oder â€œcontrolâ€.\n\n\n\n\nIch wÃ¤re froh, wenn wir allgemeine Fehler beim Codieren durchgehen kÃ¶nnten â€“ also hÃ¤ufige Syntaxfehler und worauf man achten sollte.\nAntwort:\n(Dieser Punkt ist als Wunsch notiert.)\n\n\n\n\nDaten korrekt einlesen, abspeichern, und im Projektkontext richtig organisieren. / Abspeichern der Daten, gute Ordnerstruktur? Das ist nur ein â€œkleinerâ€ Punkt, aber ich habe immer ein bisschen ein Durcheinander, wie ich Skripts und Projekte am besten abspeichere, damit auch immer alles funktioniert bei der Analyse. Oft habe ich bspw. zu lange Dateipfade\nAntwort:\nGrundsÃ¤tzlich gilt: Alle Rohdaten werden im raw/-Ordner gespeichert (und niemals Ã¼berschrieben). Diese Daten werden dann im processing-Skript bereinigt und verarbeitet. Die verarbeiteten Datensaetze werden anschliessend mit write.csv() im processed/-Ordner gespeichert.\nIm analysis-Skript werden keine Bereinigungen mehr vorgenommen, sondern nur noch die eigentlichen Analyseschritte durchgefuehrt (mit Ausnahme kleiner Anpassungen wie das Setzen von Faktoren, da diese Aenderungen nicht gespeichert werden).\nDiese Struktur orientiert sich am PsychDS-Standard.\nHausÃ¼bungen und Hands on: Da wir mit vielen verschiedenen DatensÃ¤tzen und Skripten arbeiten, ist es sinnvoll, eine klare Ordnerstruktur zu verwenden, zum Beispiel einen Ordner fÃ¼r Skripte und einen fÃ¼r Daten. Man kann sich dabei an der PsychDS-Struktur orientieren und diese Ã¼bernehmen, auch wenn wir nicht mit den dat_full-Daten arbeiten.\nZu den Pfaden: Achte darauf, relative Pfade zu verwenden. Lange Pfade sind grundsÃ¤tzlich kein Problem, solange sie relativ, nachvollziehbar und konsistent aufgebaut sind.\n\n\n\n\nWide to long: Weshalb ist das notwendig, weshalb kann man nicht beim einen Format bleiben?\nAntwort:\nViele Funktionen setzen ein bestimmtes Datenformat voraus. Repeated-Measures-Funktionen sind das beste Beispiel â€“ sie benÃ¶tigen Long-Format, weil jede Zeile eine Beobachtung darstellt. Das wird in den nÃ¤chsten Wochen noch verstÃ¤ndlicher - wenn wir dann Berechnungen mit dem Wide als auch Long Format durchfÃ¼hren.\n\n\n\n\nWas ist der Unterschied zwischen class(), attributes() und table()?\nAntwort:\n\nclass() zeigt den Typ eines Objekts\n\n\n  class(penguins)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n  class(penguins$species)\n\n[1] \"factor\"\n\n\n\ntable() zeigt HÃ¤ufigkeiten\n\n\ntable(penguins$island)\n\n\n   Biscoe     Dream Torgersen \n      168       124        52 \n\n\n\nattributes() zeigt die Attribute eines Objekts\n\nbei Data Frames: Variablennamen, rownames, Datentypen\nbei Faktoren: Levels und Klasse\n\n\n\nattributes(penguins)\n\n$class\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n$row.names\n  [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n [91]  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n[109] 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126\n[127] 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144\n[145] 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162\n[163] 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180\n[181] 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198\n[199] 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216\n[217] 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234\n[235] 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252\n[253] 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270\n[271] 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288\n[289] 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306\n[307] 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324\n[325] 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342\n[343] 343 344\n\n$names\n[1] \"species\"           \"island\"            \"bill_length_mm\"   \n[4] \"bill_depth_mm\"     \"flipper_length_mm\" \"body_mass_g\"      \n[7] \"sex\"               \"year\"             \n\nattributes(penguins$species)\n\n$levels\n[1] \"Adelie\"    \"Chinstrap\" \"Gentoo\"   \n\n$class\n[1] \"factor\"\n\n\n\n\n\n\nWie kann ich nachhaltige Anpassungen an Variablen im Datensatz vornehmen?\nAntwort:\nUm Ã„nderungen im Datensatz festzuhalten, muss eine Zuweisung mit &lt;- vorgenommen werden. Wenn ein Befehl ohne Zuweisung ausgefÃ¼hrt wird, wird das Resultat nicht im Environment abgespeichert. Wenn ein Objekt im Environment ist, heisst das nicht, dass dieses automatisch als z. B. CSV gespeichert wird. DafÃ¼r sollte es mit einer passenden Write-Funktion gespeichert werden. Im Processing-Skript fÃ¼hrt ihr alle Aufbereitungsschritte (z. B. Variablen umbenennen) durch und speichert am Ende den bereinigten Datensatz mit write.csv() oder einer Ã¤hnlichen Funktion ab, damit alle Ã„nderungen nachhaltig gesichert sind.\nBeispiel â€“&gt; Keine VerÃ¤nderung am Datensatzt weil keine Zuweisung\n\npenguins |&gt;  \n  mutate(mean_bill_length = mean(bill_length_mm, na.rm = TRUE))\n\nBeispiel mit Zuweisung: Gleicher Datensatz wird verÃ¤ndert\n\npenguins &lt;- penguins |&gt; \n  mutate(mean_bill_length = mean(bill_length_mm, na.rm = TRUE))\n\n\n\n\n\nFÃ¼r mich persÃ¶nlich ist die group_by() Funktion irgendwie nicht ganz klar. Die Vorstellung, wie die Daten sortiert werden, ist nicht so intuitiv.Â \nAntwort:\nFÃ¼r viele ist die Funktion anfangs nicht intuitiv. Die Vorstellung, wie die Daten intern in Gruppen â€aufgeteiltâ€œ werden, ohne dass sie tatsÃ¤chlich sortiert oder neu angeordnet werden, fÃ¼hlt sich ungewohnt an. Das ist vÃ¶llig normal â€“ die Logik hinter group_by() entwickelt sich meist erst, wenn man sieht, wie sie gemeinsam mit Funktionen wie summarise() oder mutate() wirkt. Kategoriale Daten werden in ihre kategorien augeteilt, kontinuierliche Daten werden in ihre einzigartigen werte gruppiert.\nBeispiel Kontinuierliche Variable: Gruppe fÃ¼r jedes Gewicht\n\npenguins_summary &lt;- penguins |&gt; \n  group_by(body_mass_g) |&gt; \n  summarize(mean_bill_length = mean(bill_length_mm, na.rm = TRUE))\n  \npenguins_summary[1:10, 1:2]\n\n# A tibble: 10 Ã— 2\n   body_mass_g mean_bill_length\n         &lt;int&gt;            &lt;dbl&gt;\n 1        2700             46.9\n 2        2850             36.4\n 3        2900             37.4\n 4        2925             37.9\n 5        2975             37.5\n 6        3000             37.2\n 7        3050             35.6\n 8        3075             37.7\n 9        3100             36  \n10        3150             36.6\n\n\nBeispiel kategoriale Variable\n\npenguins_summary_2 &lt;- penguins |&gt; \n  group_by(island) |&gt; \n  summarize(mean_bill_length = mean(bill_length_mm, na.rm = TRUE))\n  \npenguins_summary_2\n\n# A tibble: 3 Ã— 2\n  island    mean_bill_length\n  &lt;fct&gt;                &lt;dbl&gt;\n1 Biscoe                45.3\n2 Dream                 44.2\n3 Torgersen             39.0\n\n\n\n\n\n\nIch habe auch ein bisschen ein Durcheinander, wann die Daten am besten wie abgespeichert/eingelesen werden. Also mit read_delim(), row.names = FALSE, csv2 vs csv usw.Â \n\nEinlesen:\nKurz zusammengefasst: Am einfachsten ist es, zunÃ¤chst die Point-and-Click-OberflÃ¤che in RStudio zu nutzen und die Optionen so einzustellen, dass die Daten sinnvoll eingelesen werden, und anschliessend den generierten Code zu Ã¼bernehmen. read_csv() ist im Prinzip das Gleiche wie read_delim(), nur dass es standardmÃ¤ssig ein Komma als Trennzeichen verwendet (CSV bedeutet comma separated values). Bei read_delim() muss das Trennzeichen hingegen explizit angegeben werden, zum Beispiel ein Semikolon.\nSpeichern:\nZum Speichern nutzt ihr am besten write.csv(). Von write.csv2() sollte man eher die Finger lassen, da es historische SpezialfÃ¤lle abdeckt und meist eher zu Verwirrung fÃ¼hrt.",
    "crumbs": [
      "Muddiest Points"
    ]
  },
  {
    "objectID": "scripts/04_misc/index.html",
    "href": "scripts/04_misc/index.html",
    "title": "Einleitung",
    "section": "",
    "text": "In diesem E-Book findest du alle wichtigen Informationen zum Methodenseminar â€œR u Readyâ€. Du kannst hier u. a. die wÃ¶chentlichen Folien, Hands-On R Ãœbungen, den Leistungsnachweis, und Frequently Asked Questions einsehen. Du kannst Ã¼ber die Unterkapitel (links) zu den entsprechenden Inhalten navigieren, oder auch die Suchfunktion oben links verwenden, um nach einem bestimmten Begriff zu suchen.\n\nHinweisboxen\nHier einen Ãœberblick Ã¼ber die auf den Seiten enthaltenen Hinweisboxen:\n\n\n\n\n\n\nNote\n\n\n\nVertiefung: Hier geht es in die Tiefe.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWichtig: Dies ist eine wichtige Information.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAchtung: Hier ist Vorsicht geboten.\n\n\n\n\n\n\n\n\nCaution\n\n\n\nVorsicht: Diese Information ist noch in Bearbeitung.\n\n\n\n\nSyllabus\n\n\n\n\n\n\nCaution\n\n\n\nVorsicht: Der Syllabus dient als grobe Richtlinie und kann angepasst werden, falls wir in einzelnen Einheiten mehr oder weniger Zeit benÃ¶tigen.\n\n\n\n\nLetztes Update January 15, 2026 at 15:32"
  },
  {
    "objectID": "scripts/04_misc/front_page.html",
    "href": "scripts/04_misc/front_page.html",
    "title": "Einleitung",
    "section": "",
    "text": "In diesem E-Book findest du alle wichtigen Informationen zum Methodenseminar â€œR u Readyâ€. Du kannst hier u. a. die wÃ¶chentlichen Folien, Hands-On R Ãœbungen, den Leistungsnachweis, und Frequently Asked Questions einsehen. Du kannst Ã¼ber die Unterkapitel (links) zu den entsprechenden Inhalten navigieren, oder auch die Suchfunktion oben links verwenden, um nach einem bestimmten Begriff zu suchen.\n\nHinweisboxen\nHier einen Ãœberblick Ã¼ber die auf den Seiten enthaltenen Hinweisboxen:\n\n\n\n\n\n\nNote\n\n\n\nVertiefung: Hier geht es in die Tiefe.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWichtig: Dies ist eine wichtige Information.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAchtung: Hier ist Vorsicht geboten.\n\n\n\n\n\n\n\n\nCaution\n\n\n\nVorsicht: Diese Information ist noch in Bearbeitung.\n\n\n\n\nSyllabus\n\n\n\n\n\n\nCaution\n\n\n\nVorsicht: Der Syllabus dient als grobe Richtlinie und kann angepasst werden, falls wir in einzelnen Einheiten mehr oder weniger Zeit benÃ¶tigen.\n\n\n\n\nLetztes Update January 15, 2026 at 15:32",
    "crumbs": [
      "Einleitung"
    ]
  },
  {
    "objectID": "scripts/04_misc/Memes.html",
    "href": "scripts/04_misc/Memes.html",
    "title": "Memes",
    "section": "",
    "text": "You did it! Viel Spass beim Memes anschauen!\nğŸ”—\nğŸ”—\nğŸ”—\nğŸ”—\nğŸ”—\nğŸ”—\nğŸ”—\nğŸ”—\nğŸ”—\nğŸ”—",
    "crumbs": [
      "Links und Ressourcen",
      "Memes :)"
    ]
  },
  {
    "objectID": "scripts/04_misc/Memes.html#memes",
    "href": "scripts/04_misc/Memes.html#memes",
    "title": "Memes",
    "section": "",
    "text": "You did it! Viel Spass beim Memes anschauen!\nğŸ”—\nğŸ”—\nğŸ”—\nğŸ”—\nğŸ”—\nğŸ”—\nğŸ”—\nğŸ”—\nğŸ”—\nğŸ”—",
    "crumbs": [
      "Links und Ressourcen",
      "Memes :)"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Webseite_FS26",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "scripts/04_misc/requirements.html",
    "href": "scripts/04_misc/requirements.html",
    "title": "requirements",
    "section": "",
    "text": "# requirements.R\n\n# Nutze das benutzerdefinierte Library-Verzeichnis, falls gesetzt\nif (!is.na(Sys.getenv(\"R_LIBS_USER\", unset = NA))) {\n  .libPaths(Sys.getenv(\"R_LIBS_USER\"))\n}\n\ninstall_if_missing &lt;- function(pkg) {\n  if (!pkg %in% rownames(installed.packages())) {\n    install.packages(pkg, repos = \"https://cloud.r-project.org\")\n  }\n}\n\n# Liste der benÃ¶tigten Pakete â€“ hier kannst du jederzeit erweitern\npkgs &lt;- c(\n  \"tidyverse\",\n  \"knitr\",\n  \"rmarkdown\"\n)\n\nsapply(pkgs, install_if_missing)\n\n$tidyverse\nNULL\n\n$knitr\nNULL\n\n$rmarkdown\nNULL"
  },
  {
    "objectID": "scripts/04_misc/links_und_ressourcen.html",
    "href": "scripts/04_misc/links_und_ressourcen.html",
    "title": "Links und Ressourcen",
    "section": "",
    "text": "Auf dieser Seite finden sich die Links zu den Ressourcen, die wir im Rahmen dieses Seminars empfehlen.",
    "crumbs": [
      "Links und Ressourcen"
    ]
  },
  {
    "objectID": "scripts/04_misc/links_und_ressourcen.html#open-science-und-replikationskrise",
    "href": "scripts/04_misc/links_und_ressourcen.html#open-science-und-replikationskrise",
    "title": "Links und Ressourcen",
    "section": "Open Science und Replikationskrise",
    "text": "Open Science und Replikationskrise\n\nğŸ¥ Is there a reproducibility crisis in science? â€“ Matt Anticole\nğŸ“˜ The Seven Deadly Sins of Psychology (Chris Chambers, 2017)\nğŸ›ï¸ UniversitÃ¤tsbibliothek Bern â€“ Open Science\nğŸŒ Data Colada\nâ˜• ReproducibiliTea\nğŸ“ UniversitÃ¤t Bern â€“ Lehrveranstaltungen Institut fÃ¼r Psychologie\nğŸ¥ Charlotte Pennington â€“ A Studentâ€™s Guide to Open Science",
    "crumbs": [
      "Links und Ressourcen"
    ]
  },
  {
    "objectID": "scripts/04_misc/links_und_ressourcen.html#r-und-r-studio",
    "href": "scripts/04_misc/links_und_ressourcen.html#r-und-r-studio",
    "title": "Links und Ressourcen",
    "section": "R und R-Studio",
    "text": "R und R-Studio\n\nğŸ“— EinfÃ¼hrung in R â€“ Methodenlehre Uni Bern (Andrew Ellis & Boris Mayer)\nğŸ“˜ R for Data Science â€“ Basics wie Import, Aufbereitung, Visualisierung\nğŸ“– R fÃ¼r Einsteiger â€“ Maike Luhmann\nğŸ“Š Psychometrics in Exercises using R and RStudio â€“ EFA, CFA, SEM\nğŸ“¦ Informationen zu R-Paketen (CRAN)\nğŸ¤– Psyteacher AI Tutor\nğŸ’¡ Learnr Shinyapps\nğŸ“‹ RStudio Cheatsheets\nğŸ’¬ Stack Overflow â€“ R Community\nğŸ“ DataCamp â€“ Interactive R Courses\nğŸ“° Newsletter zu R â€“ Aktuelle News, Pakete und Tutorials aus der R-Community\nğŸ“š Ãœberblick Ã¼ber weitere Ressourcen â€“ Arslan (2025)",
    "crumbs": [
      "Links und Ressourcen"
    ]
  },
  {
    "objectID": "scripts/04_misc/checkliste_abschlussarbeit.html",
    "href": "scripts/04_misc/checkliste_abschlussarbeit.html",
    "title": "Checkliste Abschlussarbeit",
    "section": "",
    "text": "Abgabe bis 11.1.2026 - 23:55\nAbgabe als ZIP-File: vorname_nachname_abschlussarbeit.zip\nFÃ¼r die Abschlussarbeit erhaltet ihr simulierte Daten. Diese werden den Daten des Originalpapers in den meisten Aspekten sehr Ã¤hnlich sein. Allerdings mÃ¼ssen einige Teile davon zusÃ¤tzlich bereinigt werden, bevor sie ausgewertet werden kÃ¶nnen. Die folgende Checkliste soll euch dabei helfen, an alle relevanten Aspekte der Datenbereinigung zu denken.\nDie Datensatzaufbereitung erfolgt im processing-Skript. Der final aufbereitete Datensatz (dat_full) sowie der Long-Datensatz (dat_long) werden im Ordner data/processed gespeichert.",
    "crumbs": [
      "Checkliste Abschlussarbeit"
    ]
  },
  {
    "objectID": "scripts/04_misc/checkliste_abschlussarbeit.html#aspekte-die-bei-der-bereinigung-processing-beachtet-werden-sollten",
    "href": "scripts/04_misc/checkliste_abschlussarbeit.html#aspekte-die-bei-der-bereinigung-processing-beachtet-werden-sollten",
    "title": "Checkliste Abschlussarbeit",
    "section": "Aspekte, die bei der Bereinigung (processing) beachtet werden sollten",
    "text": "Aspekte, die bei der Bereinigung (processing) beachtet werden sollten\n\nHaben alle Daten die gleiche Anzahl an Beobachtungen?\n\n-   Gibt es Personen mit fehlenden Werten, die ausgeschlossen werden mÃ¼ssen?\n\n-   Gibt es Personen doppelt im Datensatz?\n\nGibt es unmÃ¶gliche Werte in den Daten, z. B. -999? Wie kÃ¶nnen diese Daten ersetzt werden z.B aus anderen Variablen berechnet werden?\nGibt es reverse-kodierte Fragebogenvariablen (var_name_r)?\nGibt es Variablen, die nicht den korrekten Datentyp haben, z. B. numerische Variablen, die als Character angezeigt werden? Schaut euch diese Variablen genau an!\n(Beispiel: drei = 3, stimme voll und ganz zu = hÃ¶chster Wert)",
    "crumbs": [
      "Checkliste Abschlussarbeit"
    ]
  },
  {
    "objectID": "scripts/04_misc/checkliste_abschlussarbeit.html#weitere-vorbereitende-schritte-im-processed-datensatz",
    "href": "scripts/04_misc/checkliste_abschlussarbeit.html#weitere-vorbereitende-schritte-im-processed-datensatz",
    "title": "Checkliste Abschlussarbeit",
    "section": "Weitere vorbereitende Schritte im processed-Datensatz",
    "text": "Weitere vorbereitende Schritte im processed-Datensatz\n\nMergen der 7 EinzeldatensÃ¤tze\nDroppen von redundanten Variablen\nUmbenennen von Variablen, die nicht im snake_case-Format sind\nBerechnung der mmq_mean Variable\nErstellung Long-Datensatz\nSpeichern der Daten (Wide & Long)!",
    "crumbs": [
      "Checkliste Abschlussarbeit"
    ]
  },
  {
    "objectID": "scripts/04_misc/checkliste_abschlussarbeit.html#im-analyseskript-analysis-werden",
    "href": "scripts/04_misc/checkliste_abschlussarbeit.html#im-analyseskript-analysis-werden",
    "title": "Checkliste Abschlussarbeit",
    "section": "Im Analyseskript (analysis) werden",
    "text": "Im Analyseskript (analysis) werden\n\nNÃ¶tige Vorbereitungen gemacht, die nicht zum processing gehÃ¶ren (z.B. Faktoren setzen)\nDie Analysen aus dem Datenanlyseplan durchgefÃ¼hrt!\n\nDeskriptive Statistik (M & SD) berechnen so wie in Table 1 (siehe Grinschgl et al., 2021)\n2x3 mixed ANOVA fÃ¼r subj. LeistungseinschÃ¤tzungen mit post-hoc t-Tests, inkl.EffektstÃ¤rken (Î·2 und Cohenâ€™s d)\nOne-Way ANOVA fÃ¼r jede Offloading Variable (3x), inkl. EffektstÃ¤rke (Î·2)\nOne-Way ANOVA fÃ¼r Trial Duration in Pattern Copy Task, inkl. EffektstÃ¤rke (Î·2)\nOne-Way ANOVA fÃ¼r MMQ mit post-hoc t-Tests, inkl. EffektstÃ¤rken (Î·2 und Cohenâ€™sd)\nOne-Way ANOVA fÃ¼r ArbeitsgedÃ¤chtnisleistung im Feature Switch Detection Task,inkl. EffektstÃ¤rke (Î·2)\n1 Tabelle oder 1 Abbildung nach Wahl erstellen\nOptional: Testen der Voraussetzungen bei jeder Analyse â€“ wenn diese gemacht wird, soll es auch im Datenanalyseplan beschrieben werden und die Analysen bei Voraussetzungsverletzungen entsprechend angepasst werden.\n\n\nPost-hoc-t-Tests werden nur fÃ¼r die 2x3-ANOVA und die MMQ-ANOVA erwartet. Sollte eine weitere ANOVA zufÃ¤llig signifikante Werte aufweisen, werden hierfÃ¼r keine Post-hoc-t-Tests verlangt.",
    "crumbs": [
      "Checkliste Abschlussarbeit"
    ]
  },
  {
    "objectID": "scripts/04_misc/checkliste_abschlussarbeit.html#dinge-die-im-datenanalyseplan-angepasst-werden-mÃ¼ssen",
    "href": "scripts/04_misc/checkliste_abschlussarbeit.html#dinge-die-im-datenanalyseplan-angepasst-werden-mÃ¼ssen",
    "title": "Checkliste Abschlussarbeit",
    "section": "Dinge, die im Datenanalyseplan angepasst werden mÃ¼ssen:",
    "text": "Dinge, die im Datenanalyseplan angepasst werden mÃ¼ssen:\n\nData Collection Procedures\nMissing Data\nUnit of Analyses/Data Exclusion",
    "crumbs": [
      "Checkliste Abschlussarbeit"
    ]
  },
  {
    "objectID": "scripts/04_misc/checkliste_abschlussarbeit.html#dinge-die-im-codebook-angepasst-werden-mÃ¼ssen",
    "href": "scripts/04_misc/checkliste_abschlussarbeit.html#dinge-die-im-codebook-angepasst-werden-mÃ¼ssen",
    "title": "Checkliste Abschlussarbeit",
    "section": "Dinge, die im Codebook angepasst werden mÃ¼ssen:",
    "text": "Dinge, die im Codebook angepasst werden mÃ¼ssen:\n\nCoding of item â†’ reverse-kodierte Items\nCoding of Missing Data (falls vorhanden)\n1stes Blatt: Data Collection Procedures â†’ Simulierte Daten.",
    "crumbs": [
      "Checkliste Abschlussarbeit"
    ]
  },
  {
    "objectID": "scripts/04_misc/checkliste_abschlussarbeit.html#ordnerstruktur-fÃ¼r-die-abgabe",
    "href": "scripts/04_misc/checkliste_abschlussarbeit.html#ordnerstruktur-fÃ¼r-die-abgabe",
    "title": "Checkliste Abschlussarbeit",
    "section": "Ordnerstruktur fÃ¼r die Abgabe",
    "text": "Ordnerstruktur fÃ¼r die Abgabe\nDie (fÃ¼r unser Seminar leicht abgeÃ¤nderte) Psych-DS-Struktur wird eingehalten. Das bedeutet:\n\nDaten im Ordner data.\n\n-   Rohdaten in `data/raw` (werden nicht verÃ¤ndert).\n\n-   Aufbereitete Daten (`dat_full`) in `data/processed`\n\nAnalyseskripte (processing und analysis) im Ordner code\nGerenderte Analyseskripte (html) ebenfalls im Ordner code\nDatenanalyseplan im Ordner preregistration\nCodebook im Ordner data",
    "crumbs": [
      "Checkliste Abschlussarbeit"
    ]
  },
  {
    "objectID": "scripts/04_misc/checkliste_abschlussarbeit.html#self-check-wie-sehen-plausible-ergebnisse-aus",
    "href": "scripts/04_misc/checkliste_abschlussarbeit.html#self-check-wie-sehen-plausible-ergebnisse-aus",
    "title": "Checkliste Abschlussarbeit",
    "section": "Self-Check: Wie sehen plausible Ergebnisse aus?",
    "text": "Self-Check: Wie sehen plausible Ergebnisse aus?\nDie grundsÃ¤tzliche Struktur der Daten sollte sehr Ã¤hnlich zu den Originaldaten sein.\n\nBeispiel aus einem simulierten Datensatz vs Originaldaten\n\nDie Ergebnisse bewegen sich alle in einem Ã¤hnlichen Rahmen wie die Daten aus der Originalstudie.\nOriginale Ergebnisse\n\n\n\n\n\nSimulierter Datensatz\n\n\n\n\n\nDementsprechend werden auch die Effekte der Analysen Ã¤hnlich ausfallen:",
    "crumbs": [
      "Checkliste Abschlussarbeit"
    ]
  },
  {
    "objectID": "scripts/04_misc/checkliste_abschlussarbeit.html#zu-erwartende-abweichungen-der-ergebnisse-von-der-originalstudie",
    "href": "scripts/04_misc/checkliste_abschlussarbeit.html#zu-erwartende-abweichungen-der-ergebnisse-von-der-originalstudie",
    "title": "Checkliste Abschlussarbeit",
    "section": "Zu erwartende Abweichungen der Ergebnisse von der Originalstudie:",
    "text": "Zu erwartende Abweichungen der Ergebnisse von der Originalstudie:\n\nZufÃ¤llig signifikante Effekte, die in der Originalstudie nicht signifikant waren, sind mÃ¶glich. In der Originalstudie zeigte diese Variable keinen signifikanten Effekt. Post-hoc-t-Tests werden hierfÃ¼r jedoch nicht erwartet.\n\n\n\nEinzelne Werte werden sich unterscheiden! Deskriptiva, EffektgrÃ¶ssen usw. werden sich unterscheiden! Eta2 sind hier grÃ¶sser als in der Originalstudie.\n\n\n\n\n\n\n\nDeskriptiva: Unterschiede in den Means und SDs!\n\n\n\n\n\n\n##Unplausible Resultate\nErgebnisse die ein komplett anderes Gesamtbild hinterlassen sind nicht zu erwarten!",
    "crumbs": [
      "Checkliste Abschlussarbeit"
    ]
  },
  {
    "objectID": "scripts/04_misc/ChatGPT.html",
    "href": "scripts/04_misc/ChatGPT.html",
    "title": "ChatGPT in RStudio",
    "section": "",
    "text": "Damit ihr ChatGPT in RStudio einbinden kÃ¶nnt ist ein Account bei OpenAI / ChatGPT notwendig (falls ihr ChatGPT bisher ohne Anmeldung genutzt habt): https://chatgpt.com/\nNeben dieser Anleitung gibt es auch noch dieses YouTube-Tutorial [2:36 - 5:08] welches euch bei der Einrichtung behilflich sein kÃ¶nnte.\nRechtliche Informationen zum Umgang mit ChatGPT und anderen generativen KI-Anwendungen findet ihr hier.",
    "crumbs": [
      "Links und Ressourcen",
      "ChatGPT in RStudio"
    ]
  },
  {
    "objectID": "scripts/04_misc/ChatGPT.html#installieren-von-paketen-welche-chattr-im-hintergrund-benÃ¶tigt",
    "href": "scripts/04_misc/ChatGPT.html#installieren-von-paketen-welche-chattr-im-hintergrund-benÃ¶tigt",
    "title": "ChatGPT in RStudio",
    "section": "Installieren von Paketen, welche chattr im Hintergrund benÃ¶tigt",
    "text": "Installieren von Paketen, welche chattr im Hintergrund benÃ¶tigt\nEventuell habt ihr diese schon installiert und ihr kÃ¶nnt diesen Schritt dann Ã¼berspringen. Ansonsten mÃ¼sst ihr diese Pakete, wie auch alle anderen, nur einmalig installieren.\n\ninstall.packages(\"shiny\")\ninstall.packages(\"httr2\")\ninstall.packages(\"jsonlite\")",
    "crumbs": [
      "Links und Ressourcen",
      "ChatGPT in RStudio"
    ]
  },
  {
    "objectID": "scripts/04_misc/ChatGPT.html#installieren-des-chattr-pakets-von-github",
    "href": "scripts/04_misc/ChatGPT.html#installieren-des-chattr-pakets-von-github",
    "title": "ChatGPT in RStudio",
    "section": "Installieren des chattr-Pakets von GitHub",
    "text": "Installieren des chattr-Pakets von GitHub\nAuch hier gilt, die Installation des Paketes mÃ¼sst ihr nur einmalig vornehmen.\n\ninstall.packages(\"remotes\") # Hier werdet ihr in der Console mÃ¶glicherweise gefragt, ob ihr das Paket unter dem vorgeschlagenen Dateipfad abspeichern wollt. Sofern dieser fÃ¼r euch passt kÃ¶nnt ihr einfach mit \"Y\" unten in der Console eingeben und mit Enter bestÃ¤tigen.\n\n\nremotes::install_github(\"mlverse/chattr\") # Hier werdet ihr mÃ¶glicherweise gefragt, welche der betroffenen Pakete ihr updaten wollt. Es empfehlt sich, alle zu updaten. Ihr kÃ¶nnt dies tun, indem ihr \"1\" in der Console eingebt und mit Enter bestÃ¤tigt.",
    "crumbs": [
      "Links und Ressourcen",
      "ChatGPT in RStudio"
    ]
  },
  {
    "objectID": "scripts/04_misc/ChatGPT.html#laden-von-chattr",
    "href": "scripts/04_misc/ChatGPT.html#laden-von-chattr",
    "title": "ChatGPT in RStudio",
    "section": "Laden von chattr",
    "text": "Laden von chattr\nDie Schritte ab hier, also das Laden des Paketes und das Starten des Chat-Interface, mÃ¼sst ihr bei jedem Start von RStudio erneut durchfÃ¼hren.\n\nlibrary(chattr) # So wie ihr es auch bereits von anderen Paketen kennt",
    "crumbs": [
      "Links und Ressourcen",
      "ChatGPT in RStudio"
    ]
  },
  {
    "objectID": "scripts/04_misc/ChatGPT.html#erstellen-des-chat-interface",
    "href": "scripts/04_misc/ChatGPT.html#erstellen-des-chat-interface",
    "title": "ChatGPT in RStudio",
    "section": "Erstellen des Chat-Interface",
    "text": "Erstellen des Chat-Interface\n\nSys.setenv(OPENAI_API_KEY = \"Hier mÃ¼sst ihr euren eigenen OpenAI API-Key einsetzen\") # Ihr erhaltet euren OpenAI API Key, indem ihr euch bei OpenAI anmeldet und unter https://platform.openai.com/account/api-keys einen neuen Key generiert.\n\nchattr_app() # Hier werdet ihr mÃ¶glicherweise gefragt, welche Version von ChatGPT ihr verwenden mÃ¶gt. Mit Eingabe der Nummer wÃ¤hlt ihr das entsprechende Modell aus. Mit Enter bestÃ¤tigt ihr die Eingabe.",
    "crumbs": [
      "Links und Ressourcen",
      "ChatGPT in RStudio"
    ]
  },
  {
    "objectID": "scripts/04_misc/ChatGPT.html#prompt-beispiel",
    "href": "scripts/04_misc/ChatGPT.html#prompt-beispiel",
    "title": "ChatGPT in RStudio",
    "section": "Prompt-Beispiel",
    "text": "Prompt-Beispiel\nWofÃ¼r braucht das Paket chattr im Hintergrund noch die Pakete shiny, httr2 und jsonlite?",
    "crumbs": [
      "Links und Ressourcen",
      "ChatGPT in RStudio"
    ]
  },
  {
    "objectID": "scripts/04_misc/about.html",
    "href": "scripts/04_misc/about.html",
    "title": "About",
    "section": "",
    "text": "Diese Website wurde im Rahmen des Seminars â€œR u Readyâ€ an der UniversitÃ¤t Bern erstellt.\nSollte deine Frage nicht beantwortet worden sein, dann wende dich gerne direkt an die Autor:innen:\n\n\n\nlars.schilling@unibe.ch\n\n\naaron.friedli@unibe.ch\n\n\nsandra.grinschgl@unibe.ch\n\n\n\n\nThis work is licensed under CC BY-SA 4.0",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "scripts/04_misc/muddiest_points_3.html",
    "href": "scripts/04_misc/muddiest_points_3.html",
    "title": "Muddiest Points 3",
    "section": "",
    "text": "Ich habe mich gefragt (v.a. auch in Bezug auf unsere spezialisierten Daten), ob man zuerst die einzelnen Dataframes bereinigen muss (v.a. in Bezug auf die duplizierten Zeilen) oder ob mann zuerst einen dat_full erstellen soll und dann diesen bereinigen?\nMir ist nicht ganz klar in welcher Reihenfolge man fehlende Werte, duplizierte Werte und das mergen macht.\nSicherheit im Umgang mit den verschiedenen Schritten der Datenbereinigung\n\nAntwort:\nEinige Schritte der Datenaufbereitung sollten vor dem Mergen durchgefÃ¼hrt werden, da das ZusammenfÃ¼hren der DatensÃ¤tze sonst unnÃ¶tig kompliziert werden kann. Beispielsweise kÃ¶nnen Duplikate oder fehlende Werte (NAs) beim Mergen zu Problemen fÃ¼hren und sollten daher idealerweise bereits vorher behandelt werden. FÃ¼r viele andere Schritte, wie etwa Rekodierungen, spielt es hingegen keine Rolle, ob sie im einzelnen Datensatz oder erst im gemergten Datensatz durchgefÃ¼hrt werden. Es gibt dabei keine festgelegte Reihenfolge, die zwingend eingehalten werden muss. Ob das Vorgehen korrekt war, kann man abschliessend Ã¼berprÃ¼fen, indem man den gemergten Datensatz inspiziert und auf PlausibilitÃ¤t prÃ¼ft (z. B. ob N = 159).\n\n\n\n\n\nCodebook: Muss es fÃ¼r die einzelnen DatensÃ¤tze gemacht werden? Ich habe nÃ¤mlich alles zuerst bereinigt, umgepoolt und dann gemerged und als dat_full.csv abgespeichert. Bedeutet, dass in dat_full keine NAs und revers kodierte Items mehr sind und auch nicht mehr im Codebook wÃ¤ren, sollte dat_full im Codebook verwendet werden mÃ¼ssen (zumind. bei mir). Zudem wurde in dat_full noch mmq_mean hinzugefÃ¼gt, muss das auch ins Codebook?\n\nAntwort:\n\nDas Codebook fÃ¼r den gemergten Datensatz ist ausreichend. Reverse-kodierte Items sollten dennoch angegeben werden, wobei im Codebook vermerkt werden sollte, dass diese bereits rekodiert wurden. Wenn keine NAs vorhanden sind mÃ¼ssen diese auch nicht vermerkt werden. Jede Variable sollte im Codebook enthalten sein, einschliesslich zusammengesetzter Variablen wie mmq_mean.\n\n\n\n\n\nEs steht man soll eine Tabelle/Abbildung nach Wahl erstellen. Heisst, wir mÃ¼ssen nicht alle Plots nachmachen?\n\nAntwort: Eine Tabelle oder eine Abbildung genÃ¼gt. Ihr mÃ¼sst nicht alle Plots des Papers nachmachen!\n\n\n\n\nMÃ¼ssen Resultate interpretiert werden und wenn ja, wie mÃ¼ssen diese verschriftlicht werden?\nAntwort: Es werden keine inhaltlichen Interpretationen der Ergebnisse gefordert. Kurze Zusammenfassungen der Resultate direkt nach den jeweiligen Codechunks kÃ¶nnen jedoch das VerstÃ¤ndnis erleichtern und illustrieren, dass ihr die Analysen richtig lesen kÃ¶nnt.\nZum Beispiel: The one-way ANOVA indicated that there were no significant group differences in this working memory performance measure, F(2, 156) = 0.07, p = 0.929, Î·Â² &lt; 0.01.\n\n\n\n\n\nWenn man etwas umkodiert (z.B. umgekehrt kodierte Items) und es eine ungerade Anzahl hat, muss man dann das mittlere Item bei der Umkodierung auch angeben (z.B. bei fÃ¼nf Stufen wÃ¤re es die 3, die gleich bleibt - mÃ¼sste ich das bei der Umkodierung dennoch notieren?)\n\nAntwort: Nein, solange die Rekodierung klar nachvollziehbar ist ist es nicht zwingend nÃ¶tig (aber schadet auch nicht).\n\n\n\n\nOrdner- und Pfadstruktur: Wo genau sollten die Quartoskripte relativ zu den eingelesenen Daten abgespeichert werden? -&gt; Wenn man die Quartoskripte im Ordner Grinschgl2020 abspeichert geht das zwar gut, jedoch sind dann die Quartoskripte nicht in einem eignen Ordner. Wenn ich sie in einen eignen Ordner lege, dann stimmt der Pfad aber nicht mehr. Gibt es hier eine gute LÃ¶sung?\nAntwort: Ã–ffne die Skripte innerhalb des Projekts. Dann wird der Dateipfad automatisch relativ zum Projektverzeichnis ausgewertet, auch wenn sich die Skripte nicht im gleichen Ordner befinden. Falls dies nicht funktioniert, Ã¼berprÃ¼fe in den Einstellungen, ob die Option â€Evaluate chunks in directoryâ€œ auf â€Projectâ€œ gesetzt ist.\n\n\n\n\n\n\n\n\n\n\n\n\n\nBitte nochmals die Logik der ANOVA sowohl fÃ¼r One-way ANOVA wie v.a. auch 2x3 mixed ANOVA erklÃ¤ren. Welcher Output liefert nun welche Inhalte? Und welche Codes sind alle wichtig?\nIch finde es schwierig, die Outputs der verschiedenen Anovas und t-tests zu verstehen.\nIch wÃ¼rde gerne die Mixed Anovas und t-Tests noch einmal anschauen, vielleicht einfach noch einmal kurz repetieren, worauf man da bei den Codes und der Interpretation achten muss.\n\nAntwort:\nğŸŒErklÃ¤rvideo ANOVA\nğŸŒErklÃ¤rvideo ANOVA + t-Test\nğŸŒErklÃ¤rvideo: Using Linear Models for t tests and ANOVA, Clearly Explained!!!\n\n\nDie ANOVA prÃ¼ft generell die Frage, ob die beobachtete Variation in den Daten grÃ¶ÃŸer ist, als man sie durch Zufall erwarten wÃ¼rde. Der zentrale Gedanke der ANOVA ist, dass Unterschiede zwischen Gruppen dann als bedeutsam gelten, wenn die Gruppenmittelwerte stark voneinander abweichen, wÃ¤hrend die Streuung innerhalb der Gruppen gering ist, sodass es unwahrscheinlich ist, dass diese Unterschiede nur durch Zufall entstanden sind.\nDieses VerhÃ¤ltnis wird durch den F-Wert ausgedrÃ¼ckt:\n\\(F = \\frac{\\text{Varianz zwischen den Gruppen}}{\\text{Varianz innerhalb der Gruppen}}\\).\nDie One-Way ANOVA beantwortet die Frage:\n\nUnterscheiden sich mehr als zwei Gruppen in einer abhÃ¤ngigen Variable?\n\nBeispiel:\nBeispielsweise wird untersucht, ob sich Pinguine in ihrer SchnabellÃ¤nge zwischen mehreren Gruppen (z. B. Inseln) unterscheiden. Da mehr als zwei Gruppen verglichen werden, ist eine One-Way ANOVA angemessen.\nDa der p-Wert &lt; 0.05 ist, ist die ANOVA signifikant. Das bedeutet, dass sich mindestens zwei der Gruppen signifikant voneinander unterscheiden. Welche Gruppen sich konkret unterscheiden, kann jedoch erst mit Post-hoc-t-Tests Ã¼berprÃ¼ft werden.\nDas generalized Î·Â² (ges) gibt an, wie viel Varianz der abhÃ¤ngigen Variable durch den Faktor erklÃ¤rt wird. In diesem Fall erklÃ¤rt die GruppenzugehÃ¶rigkeit (z. B. Spezies) ca. 70 % der Varianz der SchnabellÃ¤nge.\n\nmodel_1 &lt;- aov_4(bill_length_mm ~ species + (1 |id), data = penguins)\n\nWarning: Missing values for 2 ID(s), which were removed before analysis:\n272, 4\nBelow the first few rows (in wide format) of the removed cases with missing data.\n       id species  .\n# 193 272  Gentoo NA\n# 279   4  Adelie NA\n\n\nContrasts set to contr.sum for the following variables: species\n\nsummary(model_1)\n\nAnova Table (Type 3 tests)\n\nResponse: bill_length_mm\n        num Df den Df    MSE     F     ges                Pr(&gt;F)    \nspecies      2    339 8.7607 410.6 0.70781 &lt; 0.00000000000000022 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nDer Post-hoc t-Test hier ist die logische Konsequenz aus der signifikanten ANOVA.\nDa es drei Spezies (Gentoo, Chinstrap, Adelie) gibt kÃ¶nnen wir drei verschiedene Gruppenvergleiche berechnen. Hier zeigen wir ein Beispiel.\nDer t-Test prÃ¼ft, ob sich die Mittelwerte zweier Gruppen in der abhÃ¤ngigen Variable (SchnabellÃ¤nge) unterscheiden. Auf Basis von Stichprobendaten wird untersucht, ob sich Pinguine der Spezies Adelie und Chinstrap in ihrer SchnabellÃ¤nge (bill_length_mm) unterscheiden. Das signifikante Ergebnis (p &lt; 0.05) spricht dafÃ¼r, dass sich die mittlere SchnabellÃ¤nge dieser beiden Gruppen auf Populationsebene unterscheidet.\n\npenguins_filtered &lt;- penguins |&gt;\n  filter(species != \"Gentoo\")\n\nt.test(bill_length_mm ~ species, data = penguins_filtered)\n\n\n    Welch Two Sample t-test\n\ndata:  bill_length_mm by species\nt = -21.865, df = 106.97, p-value &lt; 0.00000000000000022\nalternative hypothesis: true difference in means between group Adelie and group Chinstrap is not equal to 0\n95 percent confidence interval:\n -10.952948  -9.131917\nsample estimates:\n   mean in group Adelie mean in group Chinstrap \n               38.79139                48.83382 \n\n\n\n\n\n\nWieso braucht man bei t.test() â€œ~â€ und nicht â€œ,â€ bzw. wovon hÃ¤ngt dies ab?\n\nAntwort: Bei t.test() wird das ~ verwendet, wenn der Test in der Formel-Schreibweise durchgefÃ¼hrt wird. Diese Schreibweise trennt die abhÃ¤ngige Variable (links vom ~) von der Gruppierungsvariable (rechts vom ~) und ist typisch fÃ¼r viele statistische Funktionen in R. Sie wird vor allem dann genutzt, wenn die Daten in einem Dataframe vorliegen.\nEin Komma wird hingegen verwendet, wenn man die beiden Gruppen direkt als separate Vektoren Ã¼bergibt. Welche Schreibweise man verwendet, hÃ¤ngt also davon ab, wie die Daten strukturiert sind (Dataframe vs.Â einzelne Vektoren) und welche Schnittstelle die Funktion anbietet.\nBeispiele mit Formelschreibweise:\n\n# Datensatz auf zwei Arten beschrÃ¤nken\npenguins_2 &lt;- subset(\n  penguins,\n  species %in% c(\"Adelie\", \"Chinstrap\")\n)\n\n# t-Test mit Formel-Schreibweise\nt.test(flipper_length_mm ~ species, data = penguins_2)\n\n\n    Welch Two Sample t-test\n\ndata:  flipper_length_mm by species\nt = -5.7804, df = 119.68, p-value = 0.00000006049\nalternative hypothesis: true difference in means between group Adelie and group Chinstrap is not equal to 0\n95 percent confidence interval:\n -7.880530 -3.859244\nsample estimates:\n   mean in group Adelie mean in group Chinstrap \n               189.9536                195.8235 \n\n\nMit Komma:\n\n# Vektoren fÃ¼r die zwei Gruppen\nadelie_flipper &lt;- penguins$flipper_length_mm[\n  penguins$species == \"Adelie\"\n]\n\nchinstrap_flipper &lt;- penguins$flipper_length_mm[\n  penguins$species == \"Chinstrap\"\n]\n\n# t-Test mit Vektoren\nt.test(adelie_flipper, chinstrap_flipper)\n\n\n    Welch Two Sample t-test\n\ndata:  adelie_flipper and chinstrap_flipper\nt = -5.7804, df = 119.68, p-value = 0.00000006049\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -7.880530 -3.859244\nsample estimates:\nmean of x mean of y \n 189.9536  195.8235 \n\n\n\n\n\n\nDie 2Ã—3 ANOVA im Grinschgl et al.Â (2021) Paper beantwortet die folgenden Fragen:\nGibt es Unterschiede zwischen den Feedbackgruppen, gibt es VerÃ¤nderungen Ã¼ber die Zeit (Pre1 vs.Â Pre4), und unterscheiden sich diese zeitlichen VerÃ¤nderungen zwischen den Gruppen (above vs.Â control vs.Â below)?\n\nmixed_anova &lt;- aov_4(rating ~ group_all + (time_rating | code), data = dat_long)\n\nConverting to factor: group_all\n\n\nContrasts set to contr.sum for the following variables: group_all\n\nsummary(mixed_anova)\n\n\nUnivariate Type III Repeated-Measures ANOVA Assuming Sphericity\n\n                      Sum Sq num Df Error SS den Df  F value\n(Intercept)           8198.9      1   500.58    156 2555.113\ngroup_all              126.7      2   500.58    156   19.736\ntime_rating             42.0      1   288.70    156   22.668\ngroup_all:time_rating   74.4      2   288.70    156   20.090\n                                     Pr(&gt;F)    \n(Intercept)           &lt; 0.00000000000000022 ***\ngroup_all                     0.00000002286 ***\ntime_rating                   0.00000436406 ***\ngroup_all:time_rating         0.00000001724 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nDer signifikante Haupteffekt der Feedbackgruppe (group_all) zeigt, dass sich die mittleren Ratings zwischen den Gruppen unterscheiden, unabhÃ¤ngig vom Zeitpunkt der Messung.\nDer signifikante Haupteffekt der Feedbackgruppe (group_all) zeigt, dass sich die mittleren Ratings zwischen den Gruppen unterscheiden, unabhÃ¤ngig vom Zeitpunkt der Messung.\nDer signifikante Interaktionseffekt zeigt, dass sich die VerÃ¤nderung der Ratings Ã¼ber die Zeit zwischen den Feedbackgruppen unterscheidet. ğŸ‘‰Der Effekt der Zeit ist nicht fÃ¼r alle Gruppen gleich.\n\n\n\n\n\n\nbitte Berechnung von Cohens d erneut fÃ¼r spezifisch 2x3 mixed ANOVA erklÃ¤ren. Hier sehe ich weder in den Hands On noch in den FoliensÃ¤tze einen passenden Code, der bei mir funktioniert.\n\nAntwort: Cohenâ€™s d wird fÃ¼r die Post-hoc-t-Tests berechnet, nicht fÃ¼r die 2Ã—3-ANOVA selbst. (FÃ¼r die ANOVA selbst berechnen wir Eta2). Cohenâ€™s d ist ein EffektstÃ¤rkenmaÃŸ, das angibt, wie groÃŸ der Unterschied zwischen zwei Gruppen ist, unabhÃ¤ngig von der StichprobengrÃ¶ÃŸe. Hier ein Beispiel aus den Hands On Ãœbungen. â€‹â€‹\n\ndat_full_below_above &lt;- dat_full |&gt; \n  filter(group_all != \"control\")\n\ndat_full_below_above$group_all &lt;- as.factor(dat_full_below_above$group_all)\n\nt.test(pre4 ~ group_all, data = dat_full_below_above, var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  pre4 by group_all\nt = 7.9845, df = 104, p-value = 0.000000000001991\nalternative hypothesis: true difference in means between group above and group below is not equal to 0\n95 percent confidence interval:\n 2.025170 3.363509\nsample estimates:\nmean in group above mean in group below \n           5.966038            3.271698 \n\neffsize::cohen.d(pre4 ~ group_all, data = dat_full_below_above)\n\n\nCohen's d\n\nd estimate: 1.551045 (large)\n95 percent confidence interval:\n   lower    upper \n1.111706 1.990383 \n\n\n\n\n\n\n\nWas macht es aus, dass man explizit na.rm = TRUE bei mean() und sd() angibt\n\nAntwort: Mittelwerte und Standardabweichungen kÃ¶nnen nicht korrekt berechnet werden, wenn sich fehlende Werte (NAs) in den Daten befinden. Mit na.rm = TRUE werden diese fehlenden Werte bei der Berechnung ausgeschlossen. Wurden die NAs bereits zuvor bereinigt, ist dieser Befehl zwar redundant, schadet jedoch nicht.\n\nx &lt;- c(1,2,3,4,5,6,NA)\n\nmean(x)\n\n[1] NA\n\nmean(x, na.rm = TRUE)\n\n[1] 3.5\n\n\n\n\n\n\n\nWoher weiss man, ob man rowMeans() und(/oder) mean() anwenden soll?\n\nrowMeans(df) berechnet die Zeilenmittelwerte, also den Mittelwert pro Zeile Ã¼ber alle Spalten hinweg.\nIn einem Wide-Datensatz entspricht das typischerweise dem Mittelwert pro Person Ã¼ber mehrere Variablen / Messungen.\nmean(df$V1) berechnet den Mittelwert einer einzelnen Spalte (V1) Ã¼ber alle Zeilen hinweg.\nDas entspricht dem Mittelwert einer Variable Ã¼ber alle Personen\nrowMeans bietet sich also dafÃ¼r an z.B. Skalenwerte zu berechnen (z.B. Durschnitt mehrerer Skalenitems) zu berechnen, wÃ¤hrend mean besser fÃ¼r Durschnittswerte Ã¼ber das gesamte Sample geeignet ist.\n\n\n\nV1\nV2\nV3\n\n\n\n\n1\n2\n3\n\n\n4\n5\n6\n\n\n7\n8\n9\n\n\n\n\ndf &lt;- data.frame(\n  V1 = c(1, 4, 7),\n  V2 = c(2, 5, 8),\n  V3 = c(3, 6, 9)\n)\n\n# Zeilenmittelwerte (Mittelwert pro Zeile Ã¼ber V1â€“V3)\nrowMeans(df)\n\n[1] 2 5 8\n\n# Mittelwert Ã¼ber Variable\nmean((df$V1))\n\n[1] 4\n\n\n\n\n\n\n\nMir ist noch nicht richtig klar, wie man APA konforme ANOVA Tabellen erzeugt, die man gerade abspeichern kann und dann in eine Word Datei einfÃ¼gen kann. Z.B fÃ¼r eine dreifaktorielle ANOVA?\n\nAntwort: Tabellen fÃ¼r ANOVAs haben wir nicht behandelt. In der Praxis werden ANOVAs meist auch nicht in Tabellenform berichtet, sondern direkt im Text. Es ist jedoch mÃ¶glich, APA-konforme ANOVA-Tabellen mit Packages apaTables wie Papaja zu erstellen.\nBeispiel aus Grinschgl et al. (2021)\n\nlibrary(apaTables)\n\nmodel_1 &lt;- aov(bill_length_mm ~ island + sex + species, data = penguins_filtered)\n\napa.aov.table(\n  lm_output = model_1,\n  filename  = \"anova_table.doc\"\n)\n\n\n\nANOVA results using bill_length_mm as the dependent variable\n \n\n   Predictor       SS  df       MS       F    p partial_eta2 CI_90_partial_eta2\n (Intercept) 50463.39   1 50463.39 9751.90 .000                                \n      island    10.22   2     5.11    0.99 .374          .01         [.00, .04]\n         sex   685.30   1   685.30  132.43 .000          .39         [.30, .46]\n     species  3254.78   1  3254.78  628.98 .000          .75         [.71, .78]\n       Error  1081.52 209     5.17                                             \n\nNote: Values in square brackets indicate the bounds of the 90% confidence interval for partial eta-squared \n\n\n\n\n\n\n\n\n\n\n\n\nBesseres VerstÃ¤ndnis dafÃ¼r, welche statistischen Tests in welcher Situation angemessen sind\n\nAntwort: Sprengt hier leider den Rahmen. Wir verweisen hier gerne auf den Statistikbaum der UZH. Jedoch kann auch dieser eine tiefergehende Auseinandersetzung mit der Fragestellung und dem Datenformat nicht ersetzen! FÃ¼r spezifische Fragen zu diesem Thema, kann auch gerne die Methodenberatung genutzt werden!",
    "crumbs": [
      "Muddiest Points",
      "Muddiest Points 3"
    ]
  },
  {
    "objectID": "scripts/04_misc/muddiest_points_3.html#abschlussarbeit",
    "href": "scripts/04_misc/muddiest_points_3.html#abschlussarbeit",
    "title": "Muddiest Points 3",
    "section": "",
    "text": "Ich habe mich gefragt (v.a. auch in Bezug auf unsere spezialisierten Daten), ob man zuerst die einzelnen Dataframes bereinigen muss (v.a. in Bezug auf die duplizierten Zeilen) oder ob mann zuerst einen dat_full erstellen soll und dann diesen bereinigen?\nMir ist nicht ganz klar in welcher Reihenfolge man fehlende Werte, duplizierte Werte und das mergen macht.\nSicherheit im Umgang mit den verschiedenen Schritten der Datenbereinigung\n\nAntwort:\nEinige Schritte der Datenaufbereitung sollten vor dem Mergen durchgefÃ¼hrt werden, da das ZusammenfÃ¼hren der DatensÃ¤tze sonst unnÃ¶tig kompliziert werden kann. Beispielsweise kÃ¶nnen Duplikate oder fehlende Werte (NAs) beim Mergen zu Problemen fÃ¼hren und sollten daher idealerweise bereits vorher behandelt werden. FÃ¼r viele andere Schritte, wie etwa Rekodierungen, spielt es hingegen keine Rolle, ob sie im einzelnen Datensatz oder erst im gemergten Datensatz durchgefÃ¼hrt werden. Es gibt dabei keine festgelegte Reihenfolge, die zwingend eingehalten werden muss. Ob das Vorgehen korrekt war, kann man abschliessend Ã¼berprÃ¼fen, indem man den gemergten Datensatz inspiziert und auf PlausibilitÃ¤t prÃ¼ft (z. B. ob N = 159).\n\n\n\n\n\nCodebook: Muss es fÃ¼r die einzelnen DatensÃ¤tze gemacht werden? Ich habe nÃ¤mlich alles zuerst bereinigt, umgepoolt und dann gemerged und als dat_full.csv abgespeichert. Bedeutet, dass in dat_full keine NAs und revers kodierte Items mehr sind und auch nicht mehr im Codebook wÃ¤ren, sollte dat_full im Codebook verwendet werden mÃ¼ssen (zumind. bei mir). Zudem wurde in dat_full noch mmq_mean hinzugefÃ¼gt, muss das auch ins Codebook?\n\nAntwort:\n\nDas Codebook fÃ¼r den gemergten Datensatz ist ausreichend. Reverse-kodierte Items sollten dennoch angegeben werden, wobei im Codebook vermerkt werden sollte, dass diese bereits rekodiert wurden. Wenn keine NAs vorhanden sind mÃ¼ssen diese auch nicht vermerkt werden. Jede Variable sollte im Codebook enthalten sein, einschliesslich zusammengesetzter Variablen wie mmq_mean.\n\n\n\n\n\nEs steht man soll eine Tabelle/Abbildung nach Wahl erstellen. Heisst, wir mÃ¼ssen nicht alle Plots nachmachen?\n\nAntwort: Eine Tabelle oder eine Abbildung genÃ¼gt. Ihr mÃ¼sst nicht alle Plots des Papers nachmachen!\n\n\n\n\nMÃ¼ssen Resultate interpretiert werden und wenn ja, wie mÃ¼ssen diese verschriftlicht werden?\nAntwort: Es werden keine inhaltlichen Interpretationen der Ergebnisse gefordert. Kurze Zusammenfassungen der Resultate direkt nach den jeweiligen Codechunks kÃ¶nnen jedoch das VerstÃ¤ndnis erleichtern und illustrieren, dass ihr die Analysen richtig lesen kÃ¶nnt.\nZum Beispiel: The one-way ANOVA indicated that there were no significant group differences in this working memory performance measure, F(2, 156) = 0.07, p = 0.929, Î·Â² &lt; 0.01.\n\n\n\n\n\nWenn man etwas umkodiert (z.B. umgekehrt kodierte Items) und es eine ungerade Anzahl hat, muss man dann das mittlere Item bei der Umkodierung auch angeben (z.B. bei fÃ¼nf Stufen wÃ¤re es die 3, die gleich bleibt - mÃ¼sste ich das bei der Umkodierung dennoch notieren?)\n\nAntwort: Nein, solange die Rekodierung klar nachvollziehbar ist ist es nicht zwingend nÃ¶tig (aber schadet auch nicht).\n\n\n\n\nOrdner- und Pfadstruktur: Wo genau sollten die Quartoskripte relativ zu den eingelesenen Daten abgespeichert werden? -&gt; Wenn man die Quartoskripte im Ordner Grinschgl2020 abspeichert geht das zwar gut, jedoch sind dann die Quartoskripte nicht in einem eignen Ordner. Wenn ich sie in einen eignen Ordner lege, dann stimmt der Pfad aber nicht mehr. Gibt es hier eine gute LÃ¶sung?\nAntwort: Ã–ffne die Skripte innerhalb des Projekts. Dann wird der Dateipfad automatisch relativ zum Projektverzeichnis ausgewertet, auch wenn sich die Skripte nicht im gleichen Ordner befinden. Falls dies nicht funktioniert, Ã¼berprÃ¼fe in den Einstellungen, ob die Option â€Evaluate chunks in directoryâ€œ auf â€Projectâ€œ gesetzt ist.",
    "crumbs": [
      "Muddiest Points",
      "Muddiest Points 3"
    ]
  },
  {
    "objectID": "scripts/04_misc/muddiest_points_3.html#statistik",
    "href": "scripts/04_misc/muddiest_points_3.html#statistik",
    "title": "Muddiest Points 3",
    "section": "",
    "text": "Bitte nochmals die Logik der ANOVA sowohl fÃ¼r One-way ANOVA wie v.a. auch 2x3 mixed ANOVA erklÃ¤ren. Welcher Output liefert nun welche Inhalte? Und welche Codes sind alle wichtig?\nIch finde es schwierig, die Outputs der verschiedenen Anovas und t-tests zu verstehen.\nIch wÃ¼rde gerne die Mixed Anovas und t-Tests noch einmal anschauen, vielleicht einfach noch einmal kurz repetieren, worauf man da bei den Codes und der Interpretation achten muss.\n\nAntwort:\nğŸŒErklÃ¤rvideo ANOVA\nğŸŒErklÃ¤rvideo ANOVA + t-Test\nğŸŒErklÃ¤rvideo: Using Linear Models for t tests and ANOVA, Clearly Explained!!!\n\n\nDie ANOVA prÃ¼ft generell die Frage, ob die beobachtete Variation in den Daten grÃ¶ÃŸer ist, als man sie durch Zufall erwarten wÃ¼rde. Der zentrale Gedanke der ANOVA ist, dass Unterschiede zwischen Gruppen dann als bedeutsam gelten, wenn die Gruppenmittelwerte stark voneinander abweichen, wÃ¤hrend die Streuung innerhalb der Gruppen gering ist, sodass es unwahrscheinlich ist, dass diese Unterschiede nur durch Zufall entstanden sind.\nDieses VerhÃ¤ltnis wird durch den F-Wert ausgedrÃ¼ckt:\n\\(F = \\frac{\\text{Varianz zwischen den Gruppen}}{\\text{Varianz innerhalb der Gruppen}}\\).\nDie One-Way ANOVA beantwortet die Frage:\n\nUnterscheiden sich mehr als zwei Gruppen in einer abhÃ¤ngigen Variable?\n\nBeispiel:\nBeispielsweise wird untersucht, ob sich Pinguine in ihrer SchnabellÃ¤nge zwischen mehreren Gruppen (z. B. Inseln) unterscheiden. Da mehr als zwei Gruppen verglichen werden, ist eine One-Way ANOVA angemessen.\nDa der p-Wert &lt; 0.05 ist, ist die ANOVA signifikant. Das bedeutet, dass sich mindestens zwei der Gruppen signifikant voneinander unterscheiden. Welche Gruppen sich konkret unterscheiden, kann jedoch erst mit Post-hoc-t-Tests Ã¼berprÃ¼ft werden.\nDas generalized Î·Â² (ges) gibt an, wie viel Varianz der abhÃ¤ngigen Variable durch den Faktor erklÃ¤rt wird. In diesem Fall erklÃ¤rt die GruppenzugehÃ¶rigkeit (z. B. Spezies) ca. 70 % der Varianz der SchnabellÃ¤nge.\n\nmodel_1 &lt;- aov_4(bill_length_mm ~ species + (1 |id), data = penguins)\n\nWarning: Missing values for 2 ID(s), which were removed before analysis:\n272, 4\nBelow the first few rows (in wide format) of the removed cases with missing data.\n       id species  .\n# 193 272  Gentoo NA\n# 279   4  Adelie NA\n\n\nContrasts set to contr.sum for the following variables: species\n\nsummary(model_1)\n\nAnova Table (Type 3 tests)\n\nResponse: bill_length_mm\n        num Df den Df    MSE     F     ges                Pr(&gt;F)    \nspecies      2    339 8.7607 410.6 0.70781 &lt; 0.00000000000000022 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\nDer Post-hoc t-Test hier ist die logische Konsequenz aus der signifikanten ANOVA.\nDa es drei Spezies (Gentoo, Chinstrap, Adelie) gibt kÃ¶nnen wir drei verschiedene Gruppenvergleiche berechnen. Hier zeigen wir ein Beispiel.\nDer t-Test prÃ¼ft, ob sich die Mittelwerte zweier Gruppen in der abhÃ¤ngigen Variable (SchnabellÃ¤nge) unterscheiden. Auf Basis von Stichprobendaten wird untersucht, ob sich Pinguine der Spezies Adelie und Chinstrap in ihrer SchnabellÃ¤nge (bill_length_mm) unterscheiden. Das signifikante Ergebnis (p &lt; 0.05) spricht dafÃ¼r, dass sich die mittlere SchnabellÃ¤nge dieser beiden Gruppen auf Populationsebene unterscheidet.\n\npenguins_filtered &lt;- penguins |&gt;\n  filter(species != \"Gentoo\")\n\nt.test(bill_length_mm ~ species, data = penguins_filtered)\n\n\n    Welch Two Sample t-test\n\ndata:  bill_length_mm by species\nt = -21.865, df = 106.97, p-value &lt; 0.00000000000000022\nalternative hypothesis: true difference in means between group Adelie and group Chinstrap is not equal to 0\n95 percent confidence interval:\n -10.952948  -9.131917\nsample estimates:\n   mean in group Adelie mean in group Chinstrap \n               38.79139                48.83382 \n\n\n\n\n\n\nWieso braucht man bei t.test() â€œ~â€ und nicht â€œ,â€ bzw. wovon hÃ¤ngt dies ab?\n\nAntwort: Bei t.test() wird das ~ verwendet, wenn der Test in der Formel-Schreibweise durchgefÃ¼hrt wird. Diese Schreibweise trennt die abhÃ¤ngige Variable (links vom ~) von der Gruppierungsvariable (rechts vom ~) und ist typisch fÃ¼r viele statistische Funktionen in R. Sie wird vor allem dann genutzt, wenn die Daten in einem Dataframe vorliegen.\nEin Komma wird hingegen verwendet, wenn man die beiden Gruppen direkt als separate Vektoren Ã¼bergibt. Welche Schreibweise man verwendet, hÃ¤ngt also davon ab, wie die Daten strukturiert sind (Dataframe vs.Â einzelne Vektoren) und welche Schnittstelle die Funktion anbietet.\nBeispiele mit Formelschreibweise:\n\n# Datensatz auf zwei Arten beschrÃ¤nken\npenguins_2 &lt;- subset(\n  penguins,\n  species %in% c(\"Adelie\", \"Chinstrap\")\n)\n\n# t-Test mit Formel-Schreibweise\nt.test(flipper_length_mm ~ species, data = penguins_2)\n\n\n    Welch Two Sample t-test\n\ndata:  flipper_length_mm by species\nt = -5.7804, df = 119.68, p-value = 0.00000006049\nalternative hypothesis: true difference in means between group Adelie and group Chinstrap is not equal to 0\n95 percent confidence interval:\n -7.880530 -3.859244\nsample estimates:\n   mean in group Adelie mean in group Chinstrap \n               189.9536                195.8235 \n\n\nMit Komma:\n\n# Vektoren fÃ¼r die zwei Gruppen\nadelie_flipper &lt;- penguins$flipper_length_mm[\n  penguins$species == \"Adelie\"\n]\n\nchinstrap_flipper &lt;- penguins$flipper_length_mm[\n  penguins$species == \"Chinstrap\"\n]\n\n# t-Test mit Vektoren\nt.test(adelie_flipper, chinstrap_flipper)\n\n\n    Welch Two Sample t-test\n\ndata:  adelie_flipper and chinstrap_flipper\nt = -5.7804, df = 119.68, p-value = 0.00000006049\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -7.880530 -3.859244\nsample estimates:\nmean of x mean of y \n 189.9536  195.8235 \n\n\n\n\n\n\nDie 2Ã—3 ANOVA im Grinschgl et al.Â (2021) Paper beantwortet die folgenden Fragen:\nGibt es Unterschiede zwischen den Feedbackgruppen, gibt es VerÃ¤nderungen Ã¼ber die Zeit (Pre1 vs.Â Pre4), und unterscheiden sich diese zeitlichen VerÃ¤nderungen zwischen den Gruppen (above vs.Â control vs.Â below)?\n\nmixed_anova &lt;- aov_4(rating ~ group_all + (time_rating | code), data = dat_long)\n\nConverting to factor: group_all\n\n\nContrasts set to contr.sum for the following variables: group_all\n\nsummary(mixed_anova)\n\n\nUnivariate Type III Repeated-Measures ANOVA Assuming Sphericity\n\n                      Sum Sq num Df Error SS den Df  F value\n(Intercept)           8198.9      1   500.58    156 2555.113\ngroup_all              126.7      2   500.58    156   19.736\ntime_rating             42.0      1   288.70    156   22.668\ngroup_all:time_rating   74.4      2   288.70    156   20.090\n                                     Pr(&gt;F)    \n(Intercept)           &lt; 0.00000000000000022 ***\ngroup_all                     0.00000002286 ***\ntime_rating                   0.00000436406 ***\ngroup_all:time_rating         0.00000001724 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nDer signifikante Haupteffekt der Feedbackgruppe (group_all) zeigt, dass sich die mittleren Ratings zwischen den Gruppen unterscheiden, unabhÃ¤ngig vom Zeitpunkt der Messung.\nDer signifikante Haupteffekt der Feedbackgruppe (group_all) zeigt, dass sich die mittleren Ratings zwischen den Gruppen unterscheiden, unabhÃ¤ngig vom Zeitpunkt der Messung.\nDer signifikante Interaktionseffekt zeigt, dass sich die VerÃ¤nderung der Ratings Ã¼ber die Zeit zwischen den Feedbackgruppen unterscheidet. ğŸ‘‰Der Effekt der Zeit ist nicht fÃ¼r alle Gruppen gleich.\n\n\n\n\n\n\nbitte Berechnung von Cohens d erneut fÃ¼r spezifisch 2x3 mixed ANOVA erklÃ¤ren. Hier sehe ich weder in den Hands On noch in den FoliensÃ¤tze einen passenden Code, der bei mir funktioniert.\n\nAntwort: Cohenâ€™s d wird fÃ¼r die Post-hoc-t-Tests berechnet, nicht fÃ¼r die 2Ã—3-ANOVA selbst. (FÃ¼r die ANOVA selbst berechnen wir Eta2). Cohenâ€™s d ist ein EffektstÃ¤rkenmaÃŸ, das angibt, wie groÃŸ der Unterschied zwischen zwei Gruppen ist, unabhÃ¤ngig von der StichprobengrÃ¶ÃŸe. Hier ein Beispiel aus den Hands On Ãœbungen. â€‹â€‹\n\ndat_full_below_above &lt;- dat_full |&gt; \n  filter(group_all != \"control\")\n\ndat_full_below_above$group_all &lt;- as.factor(dat_full_below_above$group_all)\n\nt.test(pre4 ~ group_all, data = dat_full_below_above, var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  pre4 by group_all\nt = 7.9845, df = 104, p-value = 0.000000000001991\nalternative hypothesis: true difference in means between group above and group below is not equal to 0\n95 percent confidence interval:\n 2.025170 3.363509\nsample estimates:\nmean in group above mean in group below \n           5.966038            3.271698 \n\neffsize::cohen.d(pre4 ~ group_all, data = dat_full_below_above)\n\n\nCohen's d\n\nd estimate: 1.551045 (large)\n95 percent confidence interval:\n   lower    upper \n1.111706 1.990383 \n\n\n\n\n\n\n\nWas macht es aus, dass man explizit na.rm = TRUE bei mean() und sd() angibt\n\nAntwort: Mittelwerte und Standardabweichungen kÃ¶nnen nicht korrekt berechnet werden, wenn sich fehlende Werte (NAs) in den Daten befinden. Mit na.rm = TRUE werden diese fehlenden Werte bei der Berechnung ausgeschlossen. Wurden die NAs bereits zuvor bereinigt, ist dieser Befehl zwar redundant, schadet jedoch nicht.\n\nx &lt;- c(1,2,3,4,5,6,NA)\n\nmean(x)\n\n[1] NA\n\nmean(x, na.rm = TRUE)\n\n[1] 3.5\n\n\n\n\n\n\n\nWoher weiss man, ob man rowMeans() und(/oder) mean() anwenden soll?\n\nrowMeans(df) berechnet die Zeilenmittelwerte, also den Mittelwert pro Zeile Ã¼ber alle Spalten hinweg.\nIn einem Wide-Datensatz entspricht das typischerweise dem Mittelwert pro Person Ã¼ber mehrere Variablen / Messungen.\nmean(df$V1) berechnet den Mittelwert einer einzelnen Spalte (V1) Ã¼ber alle Zeilen hinweg.\nDas entspricht dem Mittelwert einer Variable Ã¼ber alle Personen\nrowMeans bietet sich also dafÃ¼r an z.B. Skalenwerte zu berechnen (z.B. Durschnitt mehrerer Skalenitems) zu berechnen, wÃ¤hrend mean besser fÃ¼r Durschnittswerte Ã¼ber das gesamte Sample geeignet ist.\n\n\n\nV1\nV2\nV3\n\n\n\n\n1\n2\n3\n\n\n4\n5\n6\n\n\n7\n8\n9\n\n\n\n\ndf &lt;- data.frame(\n  V1 = c(1, 4, 7),\n  V2 = c(2, 5, 8),\n  V3 = c(3, 6, 9)\n)\n\n# Zeilenmittelwerte (Mittelwert pro Zeile Ã¼ber V1â€“V3)\nrowMeans(df)\n\n[1] 2 5 8\n\n# Mittelwert Ã¼ber Variable\nmean((df$V1))\n\n[1] 4\n\n\n\n\n\n\n\nMir ist noch nicht richtig klar, wie man APA konforme ANOVA Tabellen erzeugt, die man gerade abspeichern kann und dann in eine Word Datei einfÃ¼gen kann. Z.B fÃ¼r eine dreifaktorielle ANOVA?\n\nAntwort: Tabellen fÃ¼r ANOVAs haben wir nicht behandelt. In der Praxis werden ANOVAs meist auch nicht in Tabellenform berichtet, sondern direkt im Text. Es ist jedoch mÃ¶glich, APA-konforme ANOVA-Tabellen mit Packages apaTables wie Papaja zu erstellen.\nBeispiel aus Grinschgl et al. (2021)\n\nlibrary(apaTables)\n\nmodel_1 &lt;- aov(bill_length_mm ~ island + sex + species, data = penguins_filtered)\n\napa.aov.table(\n  lm_output = model_1,\n  filename  = \"anova_table.doc\"\n)\n\n\n\nANOVA results using bill_length_mm as the dependent variable\n \n\n   Predictor       SS  df       MS       F    p partial_eta2 CI_90_partial_eta2\n (Intercept) 50463.39   1 50463.39 9751.90 .000                                \n      island    10.22   2     5.11    0.99 .374          .01         [.00, .04]\n         sex   685.30   1   685.30  132.43 .000          .39         [.30, .46]\n     species  3254.78   1  3254.78  628.98 .000          .75         [.71, .78]\n       Error  1081.52 209     5.17                                             \n\nNote: Values in square brackets indicate the bounds of the 90% confidence interval for partial eta-squared \n\n\n\n\n\n\n\n\n\n\n\n\nBesseres VerstÃ¤ndnis dafÃ¼r, welche statistischen Tests in welcher Situation angemessen sind\n\nAntwort: Sprengt hier leider den Rahmen. Wir verweisen hier gerne auf den Statistikbaum der UZH. Jedoch kann auch dieser eine tiefergehende Auseinandersetzung mit der Fragestellung und dem Datenformat nicht ersetzen! FÃ¼r spezifische Fragen zu diesem Thema, kann auch gerne die Methodenberatung genutzt werden!",
    "crumbs": [
      "Muddiest Points",
      "Muddiest Points 3"
    ]
  }
]