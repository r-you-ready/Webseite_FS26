[
  {
    "objectID": "scripts/02_excercises/loesung_7.html",
    "href": "scripts/02_excercises/loesung_7.html",
    "title": "Hands On ‚Äì Analyze (Einheiten 11 und 12)",
    "section": "",
    "text": "Bei Bedarf findest du hier nochmals die Slides zu Einheit 13:",
    "crumbs": [
      "√úbungen zu den Einheiten",
      "Hands on - Block 7 (Woche 13)"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_7.html#einfaktorielle-anova",
    "href": "scripts/02_excercises/loesung_7.html#einfaktorielle-anova",
    "title": "Hands On ‚Äì Analyze (Einheiten 11 und 12)",
    "section": "Einfaktorielle ANOVA",
    "text": "Einfaktorielle ANOVA\n\nBerechne eine einfaktorielle ANOVA mit aov_4 (aus dem Paket ‚Äúafex‚Äù) f√ºr die Offloading-Variable mean_rl_all (√ñffnungen des Modelfensters).\nBerechnet daf√ºr zuerst den Levene-Test um die Varianzhomogenit√§t des between-Faktors zu √ºberpr√ºfen.\n\n::: {.callout-note collapse=‚Äútrue‚Äù title = ‚ÄúL√∂sung‚Äù}\n\nleveneTest(mean_rl_all ~ group_all, data= dat_full)\n\nWarning in leveneTest.default(y = y, group = group, ...): group coerced to\nfactor.\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value Pr(&gt;F)\ngroup   2  0.6889 0.5036\n      156               \n\n\nDer Levene-Test ist nicht signifikant (p &gt; 0.05). Somit ist die Varianzhomogenit√§t, als eine der Vorausetzungen zur Berechnung der ANOVA, gegeben.\n:::\n\nDefiniere die ANOVA nach der folgenden Vorlage\n\n\nmodel_1 &lt;- aov_4(AV ~ Faktor_1 + (1 | ID), data = data)\n\nsummary(model_1)\n\n::: {.callout-note collapse=‚Äútrue‚Äù title = ‚ÄúL√∂sung‚Äù}\n\nmodel_1 &lt;- aov_4(mean_rl_all ~ group_all + (1 | code), data = dat_full)\n\nConverting to factor: group_all\n\n\nContrasts set to contr.sum for the following variables: group_all\n\nsummary(model_1)\n\nAnova Table (Type 3 tests)\n\nResponse: mean_rl_all\n          num Df den Df    MSE      F      ges Pr(&gt;F)\ngroup_all      2    156 1.2602 1.0448 0.013218 0.3542\n\n\n:::\n\nVersuche das Ergbenis zu interpretieren und mit dem Grinschgl et al. (2021) Paper zu vergleichen. üëâ Und schon haben wir ein ANOVAs f√ºr die Offloading Variablen berechnet.\n\n::: {.callout-note collapse=‚Äútrue‚Äù title = ‚ÄúL√∂sung‚Äù}\nDie ANOVA ist nicht signifikant (p &gt; 0.05) ‚Äì es gibt also keine Unterschiede in den Offloadingh√§ufigkeiten zwischen den Gruppen.\n:::\n\nBerechne die Effektst√§rken partielles Œ∑¬≤ und generalisiertes Œ∑¬≤ . Erg√§nze daf√ºr die aov_4 Funktion um anova_table = list(es = c(\"ges\" ,\"pes\")) . Lasse dir das Ergebnis mit model$anova_table ausgeben. Bei einfaktoriellen ANOVAs sind die partiellen und generalisierten Œ∑¬≤ identisch.\n\n::: {.callout-note collapse=‚Äútrue‚Äù title = ‚ÄúL√∂sung‚Äù}\n\nmodel_1 &lt;- aov_4(mean_rl_all ~ group_all + (1 | code), data = dat_full, anova_table = list(es = c(\"ges\" ,\"pes\")))\n\nConverting to factor: group_all\n\n\nContrasts set to contr.sum for the following variables: group_all\n\nmodel_1$anova_table\n\nAnova Table (Type 3 tests)\n\nResponse: mean_rl_all\n          num Df den Df    MSE      F      pes      ges Pr(&gt;F)\ngroup_all      2    156 1.2602 1.0448 0.013218 0.013218 0.3542\n\n\nDas partielle Eta¬≤ und das generalisierte Eta¬≤ sind identisch und betragen 0.01, was auf einen sehr kleinen Effekt hinweist. Die Gruppenzugeh√∂rigkeit kann also nur wenig Varianz des Offloadingverhalten erkl√§ren. Dies hat sich auch in der ANOVA gezeigt, bei welcher die Gruppierungsvariable aufgrund geringer Varianzerkl√§rung nicht signifikant wurde.\n:::",
    "crumbs": [
      "√úbungen zu den Einheiten",
      "Hands on - Block 7 (Woche 13)"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_7.html#post-hoc-t-tests",
    "href": "scripts/02_excercises/loesung_7.html#post-hoc-t-tests",
    "title": "Hands On ‚Äì Analyze (Einheiten 11 und 12)",
    "section": "Post-hoc t-Tests",
    "text": "Post-hoc t-Tests\nZu √úbungszwecken, inhaltlich nicht notwendig wenn die ANOVA nicht signifikant ist.\n\nLade das Package emmeans\n\n\n\nSpeichere mit new_object &lt;- emmeans(object = model, specs = ~group_all) die Mittelwerte und Standardfehler in einem neuen Objekt.\n\n::: {.callout-note collapse=‚Äútrue‚Äù title = ‚ÄúL√∂sung‚Äù}\n\nnew_object &lt;- emmeans(object = model_1, specs = ~ group_all)\nnew_object\n\n group_all emmean    SE  df lower.CL upper.CL\n above       5.10 0.154 156     4.79     5.40\n below       5.39 0.154 156     5.09     5.69\n control     5.14 0.154 156     4.84     5.45\n\nConfidence level used: 0.95 \n\n\n:::\n\nBerechne mit pairs(new_object) multiple t-Tests als Post-Hoc Tests. Diese werden als default-Einstellung mit der Tukey-Methodekorrigiert. Das ist eine Alternative zu einzelnen t-Tests in Grinschgl et al. (2021) so wie in EH12 berechnet - ergibt leicht andere Werte wegen Tukey-Korrektur f√ºr multiples Testen. (F√ºr das Abschlussprojekt sind Post-Hoc Tests in beiden Varianten okay ‚Äì entweder mit emmeans() oder mit t.test() ).\n\n::: {.callout-note collapse=‚Äútrue‚Äù title = ‚ÄúL√∂sung‚Äù}\n\npairs(new_object)\n\n contrast        estimate    SE  df t.ratio p.value\n above - below    -0.2925 0.218 156  -1.341  0.3747\n above - control  -0.0443 0.218 156  -0.203  0.9775\n below - control   0.2481 0.218 156   1.138  0.4924\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\nDie einzelnen post-hoc Tests zeigen keine signifikanten Unterschiede zwischen den jeweiligen Gruppen (alle p-Werte &gt; 0.05). Auch dieses Resultat war zu erwarten, da ja schon der globale Test mit der ANOVA keinerlei Unterschiede zwischen irgendwelchen Gruppen signalisiert hat.\n:::\n\n\n\n\n\n\nTukey-Korrektur\n\n\n\n\n\nDie Tukey-Korrektur ist ein simultanes Verfahren f√ºr Post-hoc-Gruppenvergleiche, das verhindert, dass sich der Alpha-Fehler durch viele t-Tests (familywise error rate) aufsummiert. Sie wird bevorzugt eingesetzt, wenn alle Gruppen miteinander verglichen werden sollen.\n::: {.callout-note collapse=‚Äútrue‚Äù title = ‚ÄúL√∂sung‚Äù}\n\npairs(new_object)\n\n contrast        estimate    SE  df t.ratio p.value\n above - below    -0.2925 0.218 156  -1.341  0.3747\n above - control  -0.0443 0.218 156  -0.203  0.9775\n below - control   0.2481 0.218 156   1.138  0.4924\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\nAuch hier zeigen die post-hoc Tests keine signifikanten Unterschiede zwischen den jeweiligen Gruppen (alle p-Werte &gt; 0.05).\n\n\n\n:::\n\n\n\n\n\n\nFortgeschritten - Effektst√§rken mit pairs()\n\n\n\n\n\nDer Befehl pairs() berechnet nicht automatisch die gew√ºnschten Effektst√§rken (zum Beispiel Cohen‚Äôs d). Die Effektst√§rken k√∂nnen entweder einzeln wie in den √úbungen zu EH 12 berechnet werden, etwa mit cohens_d(). Wenn man jedoch die Effektst√§rken aller Paarvergleiche simultan berechnen m√∂chte, kann man dies mit eff_size() tun. Daf√ºr greift man auf die Residualvarianzen und Freiheitsgrade des ANOVA-Modells zu. Diese Informationen sind im lm-Objekt des Modells gespeichert. Unten siehst du ein Codebeispiel:\n\nposthoc_tests &lt;- emmeans(object = model_1, specs = ~ group_all)\n\neff_size(\n  posthoc_tests,\n  sigma = sigma(model_1$lm),\n  edf   = df.residual(model_1$lm)\n)\n\n contrast        effect.size    SE  df lower.CL upper.CL\n above - below       -0.2605 0.195 156   -0.645    0.124\n above - control     -0.0395 0.194 156   -0.423    0.344\n below - control      0.2210 0.195 156   -0.163    0.606\n\nsigma used for effect sizes: 1.123 \nConfidence level used: 0.95 \n\n\nZum Vergleich: Mit cohens_d()\n\ndat_full_above_below &lt;- dat_full |&gt;\n  filter(group_all != \"control\")\n\ndat_full_above_below$group_all &lt;- factor(dat_full_above_below$group_all )\n\ncohens_d(mean_rl_all ~ group_all, data = dat_full_above_below)\n\nCohen's d |        95% CI\n-------------------------\n-0.25     | [-0.63, 0.13]\n\n- Estimated using pooled SD.\n\n\nDie Effektst√§rken unterscheiden sich hier leicht da nicht mit den exakt gleichen Varianzen gerechnet wird, effsize() verwendet hierf√ºr die die modellbasierten SDs, w√§hrend cohens_d() die gepoolte Standardabweichung aus den Rohdaten verwendet. Dieser Unterschied kann jedoch vernachl√§ssigt werden.",
    "crumbs": [
      "√úbungen zu den Einheiten",
      "Hands on - Block 7 (Woche 13)"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_7.html#x3-mixed-anova-mit-messwiederholung",
    "href": "scripts/02_excercises/loesung_7.html#x3-mixed-anova-mit-messwiederholung",
    "title": "Hands On ‚Äì Analyze (Einheiten 11 und 12)",
    "section": "2x3 Mixed ANOVA mit Messwiederholung",
    "text": "2x3 Mixed ANOVA mit Messwiederholung\n\nDefiniere das 2x3 ANOVA Model aus Grinschgl et al. (2021), nach folgendem Muster - hierf√ºr ben√∂tigen wir den Long Datensatz!\n\n\nmixed_anova &lt;- aov_4(AV ~ between_factor + (messwiederholter_faktor | ID) data = df_long)\n\n::: {.callout-note collapse=‚Äútrue‚Äù title = ‚ÄúL√∂sung‚Äù}\n\nmixed_anova &lt;- aov_4(rating ~ group_all + (time_rating | code), data = dat_long)\n\nConverting to factor: group_all\n\n\nContrasts set to contr.sum for the following variables: group_all\n\nsummary(mixed_anova)\n\n\nUnivariate Type III Repeated-Measures ANOVA Assuming Sphericity\n\n                      Sum Sq num Df Error SS den Df  F value    Pr(&gt;F)    \n(Intercept)           8198.9      1   500.58    156 2555.113 &lt; 2.2e-16 ***\ngroup_all              126.7      2   500.58    156   19.736 2.286e-08 ***\ntime_rating             42.0      1   288.70    156   22.668 4.364e-06 ***\ngroup_all:time_rating   74.4      2   288.70    156   20.090 1.724e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n:::\n\nErg√§nze den Code wie vorher um anova_table um dir die Effektst√§rken partielles Œ∑¬≤ und generalisiertes Œ∑¬≤ ausgeben zu lassen.\n\n::: {.callout-note collapse=‚Äútrue‚Äù title = ‚ÄúL√∂sung‚Äù}\n\nmixed_anova &lt;- aov_4(rating ~ group_all + (time_rating | code), data = dat_long, anova_table = list(es = c(\"ges\" ,\"pes\")))\n\nConverting to factor: group_all\n\n\nContrasts set to contr.sum for the following variables: group_all\n\nsummary(mixed_anova)\n\n\nUnivariate Type III Repeated-Measures ANOVA Assuming Sphericity\n\n                      Sum Sq num Df Error SS den Df  F value    Pr(&gt;F)    \n(Intercept)           8198.9      1   500.58    156 2555.113 &lt; 2.2e-16 ***\ngroup_all              126.7      2   500.58    156   19.736 2.286e-08 ***\ntime_rating             42.0      1   288.70    156   22.668 4.364e-06 ***\ngroup_all:time_rating   74.4      2   288.70    156   20.090 1.724e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmixed_anova$anova_table\n\nAnova Table (Type 3 tests)\n\nResponse: rating\n                      num Df den Df    MSE      F     pes      ges    Pr(&gt;F)\ngroup_all                  2    156 3.2088 19.736 0.20193 0.138283 2.286e-08\ntime_rating                1    156 1.8507 22.668 0.12687 0.050468 4.364e-06\ngroup_all:time_rating      2    156 1.8507 20.090 0.20481 0.086102 1.724e-08\n                         \ngroup_all             ***\ntime_rating           ***\ngroup_all:time_rating ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n:::\n\nIn Grinschgl et al. (2021) wird jedoch nur das reine Œ∑¬≤ berichtet (weder generalisiert noch partiell). Wende eta_squared() auf dem package effectsize auf dein ANOVA Model an und setze partial = FALSE.\n\n::: {.callout-note collapse=‚Äútrue‚Äù title = ‚ÄúL√∂sung‚Äù}\n\nmixed_anova &lt;- aov_4(rating ~ group_all + (time_rating | code), data = dat_long, anova_table = list(es = c(\"ges\" ,\"pes\")))\n\nConverting to factor: group_all\n\n\nContrasts set to contr.sum for the following variables: group_all\n\neta_squared(mixed_anova, partial = FALSE)\n\n# Effect Size for ANOVA (Type III)\n\nParameter             | Eta2 |       95% CI\n-------------------------------------------\ngroup_all             | 0.12 | [0.05, 1.00]\ntime_rating           | 0.04 | [0.01, 1.00]\ngroup_all:time_rating | 0.07 | [0.02, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].\n\n\n:::\n\nVersuche das Ergebnis dieser ANOVA zu interpretieren und mit Grinschgl et al. (2021) zu vergleichen.\n\n::: {.callout-note collapse=‚Äútrue‚Äù title = ‚ÄúL√∂sung‚Äù}\nDie Resultate der von uns gerechneten ANOVA und der in Grinschgl et al. (2021) berichteten ANOVA stimmen √ºberein. Es gibt signifikante Haupteffekte f√ºr den Between-Faktor group_all (p &lt; 0.05, Œ∑¬≤ = 0.12), den Within-Faktor time_rating (p &lt; 0.05, Œ∑¬≤ = 0.04) und die Interaktion beider Variablen group_all:time_rating (p &lt; 0.05, Œ∑¬≤ = 0.07). Es gibt somit Unterschiede im rating zwischen Gruppen, Unterschiede √ºber die Gruppen hinweg zwischen verschiedenen Zeitpunkten, und diese Unterschiede zwischen Gruppen entwickeln sich im Verlaufe der Zeit auch noch unterschiedlich. Die Effektst√§rken deuten auf kleine bis mittlere Effekte hin.\n:::",
    "crumbs": [
      "√úbungen zu den Einheiten",
      "Hands on - Block 7 (Woche 13)"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_7.html#x3-mixed-anova---post-hoc-t-tests",
    "href": "scripts/02_excercises/loesung_7.html#x3-mixed-anova---post-hoc-t-tests",
    "title": "Hands On ‚Äì Analyze (Einheiten 11 und 12)",
    "section": "2x3 Mixed ANOVA - Post-Hoc t-Tests",
    "text": "2x3 Mixed ANOVA - Post-Hoc t-Tests\n\n2 x 3 mixed ANOVA mit Messwiederholung Post-Hoc Tests: emmeans() Objekt erstellen nach folgender Vorlage:\n\n\nresults &lt;- emmeans(object = my_anova, specs = ~ within_factor * between_factor)\n\n::: {.callout-note collapse=‚Äútrue‚Äù title = ‚ÄúL√∂sung‚Äù}\n\nresults &lt;- emmeans(object = mixed_anova, specs = ~ time_rating * group_all)\n\n:::\n\npairs() darauf anwenden ‚Äì hier wollen wir mit simple = ‚Äûgroup_all‚Äú Post-Hoc Tests f√ºr die Gruppenvergleiche zu den beiden Zeitpunkten berechnen. üëâ Berechnung von bedingten Mittelwertsunterschieden so wie im Grinschgl et al. (2021) Paper (aber dort leicht andere Werte wegen anderer Berechnungsfunktion)\n\n::: {.callout-note collapse=‚Äútrue‚Äù title = ‚ÄúL√∂sung‚Äù}\n\npairs(results, simple = \"group_all\")\n\ntime_rating = pre1:\n contrast        estimate    SE  df t.ratio p.value\n above - below     0.3962 0.270 156   1.466  0.3103\n above - control   0.4094 0.270 156   1.514  0.2869\n below - control   0.0132 0.270 156   0.049  0.9987\n\ntime_rating = pre4:\n contrast        estimate    SE  df t.ratio p.value\n above - below     2.6943 0.343 156   7.849  &lt;.0001\n above - control   1.0604 0.343 156   3.089  0.0067\n below - control  -1.6340 0.343 156  -4.760  &lt;.0001\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\n:::\n\n√Ñndere es nun auf simple = time_rating ab und schaue dir den Unterschied zum vorherigen Ergebnis an.\n\n::: {.callout-note collapse=‚Äútrue‚Äù title = ‚ÄúL√∂sung‚Äù}\n\npairs(results, simple = \"time_rating\")\n\ngroup_all = above:\n contrast    estimate    SE  df t.ratio p.value\n pre1 - pre4   -0.257 0.264 156  -0.971  0.3330\n\ngroup_all = below:\n contrast    estimate    SE  df t.ratio p.value\n pre1 - pre4    2.042 0.264 156   7.725  &lt;.0001\n\ngroup_all = control:\n contrast    estimate    SE  df t.ratio p.value\n pre1 - pre4    0.394 0.264 156   1.492  0.1377\n\n\nHier werden die Mittelwertsunterschiede f√ºr die Messzeitpunkte innerhalb der jeweiligen Gruppen berechnet. In der control Gruppe gibt es keinen signifikanten Unterschiede zwischen den Zeitpunkten (p &gt; 0.05). In der above Gruppe gibt es ebenfalls keinen signifikanten Unterschied zwischen den Zeitpunkten (p &gt; 0.05), Innerhalb der Gruppe below gibt es allerdings einen signifikanten Unterschied zwischen den beiden Messzeitpunkten (p &lt; 0.05). Die Gruppen entwickeln sich also √ºber die Messzeitpunkte hinweg unterschiedlich. Dies entspricht der oben gefundenen Interaktion zwischen group_all:time_rating. Die Resultate m√ºssen allerdings mit Vorsicht interpretiert werden, da diese noch nicht f√ºr das multiple testen angepasst wurden und die p-Werte sich im Anschluss noch (signifikant) ver√§ndern k√∂nnten.\n:::\n\nErg√§nze nun die Bonferroni Korrektur f√ºr multiples Testen mit adjust = ‚Äûbonferroni‚Äú\n\n::: {.callout-note collapse=‚Äútrue‚Äù title = ‚ÄúL√∂sung‚Äù}\n\npairs(results, simple = \"group_all\", adjust = \"bonferroni\")\n\ntime_rating = pre1:\n contrast        estimate    SE  df t.ratio p.value\n above - below     0.3962 0.270 156   1.466  0.4343\n above - control   0.4094 0.270 156   1.514  0.3958\n below - control   0.0132 0.270 156   0.049  1.0000\n\ntime_rating = pre4:\n contrast        estimate    SE  df t.ratio p.value\n above - below     2.6943 0.343 156   7.849  &lt;.0001\n above - control   1.0604 0.343 156   3.089  0.0071\n below - control  -1.6340 0.343 156  -4.760  &lt;.0001\n\nP value adjustment: bonferroni method for 3 tests \n\n\nDie paarweisen Vergleiche gelten jeweils f√ºr alle m√∂glichen Gruppenpaare f√ºr die beiden Zeitpunkte time_rating = pre1 und time_rating = pre4. Zum Zeitpunkt pre1 gibt es noch keinerlei signifikante Gruppenunterschiede (alle p-Werte &gt; 0.05). Zum Zeitpunkt pre4 unterscheiden sich dann allerdings alle Gruppen voneinander (alle p-Werte &lt; 0.05). Dies entspricht dem zuvor gefundenen Haupteffekt des Faktors time_rating.\n:::\n\n\n\n\n\n\nImportant\n\n\n\nAchtung: Die pairs() Funktion gibt keine Effektst√§rken aus. Diese m√ºssen f√ºr die 2x3 ANOVA mit der cohens_d() Funktion berechnet werden wie wir das bereits in Hands On 6 ge√ºbt haben.",
    "crumbs": [
      "√úbungen zu den Einheiten",
      "Hands on - Block 7 (Woche 13)"
    ]
  }
]