[
  {
    "objectID": "scripts/03_faq/rstudio.html",
    "href": "scripts/03_faq/rstudio.html",
    "title": "1 RStudio",
    "section": "",
    "text": "Fragen zu RStudio\nUnabhängig von konkreten Fragen zu RStudio kannst du hier noch mal das Skript zur Einführung in R Studio von Andrew Ellis und Boris Mayer abrufen.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#was-gibt-es-alles-für-funktionen-zum-einlesen-der-daten-und-welche-davon-ist-am-besten-geeignet",
    "href": "scripts/03_faq/rstudio.html#was-gibt-es-alles-für-funktionen-zum-einlesen-der-daten-und-welche-davon-ist-am-besten-geeignet",
    "title": "1 RStudio",
    "section": "Was gibt es alles für Funktionen zum Einlesen der Daten und welche davon ist am besten geeignet?",
    "text": "Was gibt es alles für Funktionen zum Einlesen der Daten und welche davon ist am besten geeignet?\nDer einfachste Weg die Daten zu laden, geht über das Environment oben rechts in RStudio. Welche Funktion benötigt wird bzw. welche Funktion verwenden werden kann hängt vom Dateiformat der zu ladende Datei ab. Häufig verwendete Dateiformate sind .xlsx, .csv und .sav. Bei .csv handelt es sich um eine Textdatei, bei welcher die Spalten durch Kommas (csv = Comma-separated values) oder Semikolons getrennt sind. .sav ist die Dateiendung für eine SPSS-Datei und .xlsx ist die Dateiendung für eine Excel-Datei.\n\n\n\n\n\n\nNote\n\n\n\nWeiterführende Informationen und Beispiele können hier nachgelesen werden.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wofür-stehen-die-zusätzlichen-argumente-wie-escape_double-oder-trim_ws-beim-einlesen-von-dateien",
    "href": "scripts/03_faq/rstudio.html#wofür-stehen-die-zusätzlichen-argumente-wie-escape_double-oder-trim_ws-beim-einlesen-von-dateien",
    "title": "1 RStudio",
    "section": "Wofür stehen die zusätzlichen Argumente wie escape_double oder trim_ws beim Einlesen von Dateien?",
    "text": "Wofür stehen die zusätzlichen Argumente wie escape_double oder trim_ws beim Einlesen von Dateien?\n\n\n\n\n\n\nImportant\n\n\n\nDu kannst anhand der Syntax ?Funktionsname()die Dokumentation einer Funktion aufrufen. Hier wird beschrieben, welche Argumente die Funktion erwartet, was die Default-Einstellungen sind und was die Funktion ausgibt.\n\n\nWenn man mit read_delim() aus dem readr Paket die Daten einliest, interpretiert das Argument escape_double = TRUE doppelte Anführungsstriche als einfache Anführungsstriche (““ = “). Mit dem Argument trim_ws = TRUE werden Leerzeichen vor oder nach einer Zeichenkette gelöscht („ Vor dem „V“ befindet sich ein Leerzeichen = „Vor dem „V“ befindet sich ein Leerzeichen). Beide Optionen sind per Default auf TRUE gesetzt. Die folgenden beiden Varianten sind somit identisch:\n\ndata &lt;- readr::read_delim(\"data.csv\", delim = \";\", escape_double = TRUE, trim_ws = TRUE)\n\ndata &lt;- readr::read_delim(\"data.csv\", delim = \";\")",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#was-ist-der-unterschied-zwischen-cbind-und-den-xy_join-funktionen",
    "href": "scripts/03_faq/rstudio.html#was-ist-der-unterschied-zwischen-cbind-und-den-xy_join-funktionen",
    "title": "1 RStudio",
    "section": "Was ist der Unterschied zwischen cbind() und den xy_join()-Funktionen?",
    "text": "Was ist der Unterschied zwischen cbind() und den xy_join()-Funktionen?\nDie Funktion cbind() kann man sich wie „Kleber“ vorstellen. Die Datensätze werden ohne Berücksichtigung der Reihenfolgen der Zeilen aneinandergeklebt. Hierdurch könnten im zusammengefügten Datensatz Werte derselben Zeile von verschiedenen Versuchspersonen stammen. Mit der Funktion xy_join() wird vor dem Zusammenfügen der beiden Datensätze die Reihenfolge der Zeilen über beide Datensätze hinweg kontrolliert und angeglichen. Hierfür wird jene Spalte verwendet, die im Argument xy_join(data, by = „…“) genannt wurde. Damit wird sichergestellt, dass im resultierenden Datensatz Werte derselben Zeile auch von einer einzelnen Versuchsperson stammen.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#was-ist-der-unterschied-zwischen-inner_join-left_join-right_join-full_join",
    "href": "scripts/03_faq/rstudio.html#was-ist-der-unterschied-zwischen-inner_join-left_join-right_join-full_join",
    "title": "1 RStudio",
    "section": "Was ist der Unterschied zwischen inner_join(), left_join(), right_join(), full_join()?",
    "text": "Was ist der Unterschied zwischen inner_join(), left_join(), right_join(), full_join()?\nDie Funktionen unterscheiden sich dahingehend, was von den beiden Datensätzen nach der Zusammenfügung erhalten bleiben soll. inner_join() übernimmt nur Zeilen, welche in beiden Datensätzen vorhanden sind. full_join() übernimmt alle Zeilen, auch wenn sie nur in einen der beiden Datensätze auftaucht. Der Eintrag in der Spalte des anderen Datensatzes wird einfach mit NA ergänzt. Die verbleibenden beiden Funktionen “bevorzugen” sozusagen ihren entsprechenden Datensatz, übernehmen von diesem alle Zeilen und vom anderen Datensatz lediglich die damit übereinstimmenden.\n\n\n\n\n\n\nNote\n\n\n\nEine ausführlichere Beschreibung zu dem Thema findet sich auch noch mal hier unter Kapitel 19.4. Hier sind animierte Abbildungen zu den Funktionsweisen.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wann-verwendet-man-welche-der-xy_join-funktionen-und-anhand-welcher-variable-sollen-die-datensätze-zusammengefügt-werden",
    "href": "scripts/03_faq/rstudio.html#wann-verwendet-man-welche-der-xy_join-funktionen-und-anhand-welcher-variable-sollen-die-datensätze-zusammengefügt-werden",
    "title": "1 RStudio",
    "section": "Wann verwendet man welche der xy_join()-Funktionen und anhand welcher Variable sollen die Datensätze zusammengefügt werden?",
    "text": "Wann verwendet man welche der xy_join()-Funktionen und anhand welcher Variable sollen die Datensätze zusammengefügt werden?\nWelche der xy_join()-Funktionen man am sinnvollsten nutzen sollte hängt von der Datenstruktur ab und was man mit den Daten im Folgenden noch machen möchte. Ein Datensatz mit full_join() erstellt würde beispielsweise die meisten Einträge (inkl. NAs) aufweisen, andererseits wäre dieser Datensatz aber auch vermutlich am unübersichtlichsten. Ob man right_join() oder left_join() verwendet kann beispielsweise einfach nur davon abhängen, welchen Datensatz man als links (bzw. zuerst) vorliegend oder als rechts (bzw. als zweites) vorliegend definiert. Das hängt von den Argumenten in der Funktion ab. Kurzum: Welche Funktion am passendsten ist hängt von der spezifischen Fragestellung ab und davon, in welcher Reihenfolge man die Datensätze betrachtet und der Funktion übergeben möchte. Anhand welcher Variable die Zusammenfügung der Datensätze erfolgen soll lässt sich ebenfalls nicht pauschal sagen. Jeder Datensatz kann andere Spaltennamen oder Strukturen aufweisen. In der Psychologie ist es allerdings üblich, dass man jeder Versuchsperson über Datenerhebungen hinweg einen individuellen Code zuweist. Dieser wird dann zum Zusammenfügen verwendet. Oft heisst diese Variable Code oder ID – sie kann aber auch komplett anders heissen. Unabhängig vom konkreten Namen sollte das Codebook anzeigen, ob es eine solche Variable gibt und um welche es sich handelt.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wie-kann-man-ein-bereits-gesetztes-working-directory-also-den-arbeitsspeicher-des-skriptes-verschieben-idealerweise-sogar-von-ausserhalb-eines-projektes-in-ein-projekt-hinein",
    "href": "scripts/03_faq/rstudio.html#wie-kann-man-ein-bereits-gesetztes-working-directory-also-den-arbeitsspeicher-des-skriptes-verschieben-idealerweise-sogar-von-ausserhalb-eines-projektes-in-ein-projekt-hinein",
    "title": "1 RStudio",
    "section": "Wie kann man ein bereits gesetztes working directory (also den Arbeitsspeicher des Skriptes) verschieben, idealerweise sogar von ausserhalb eines Projektes in ein Projekt hinein?",
    "text": "Wie kann man ein bereits gesetztes working directory (also den Arbeitsspeicher des Skriptes) verschieben, idealerweise sogar von ausserhalb eines Projektes in ein Projekt hinein?\nAm einfachsten schliesst man das Skript und verschiebt es innerhalb deines Ordnersystems in das Projekt. Dann öffnet man RStudio (aber nicht das Skript, sondern nur das Programm) und wählt im gestarteten RStudio über File – Open File… das Skript aus und speichert es ab. Das working directory sollte nun innerhalb des Projektes liegen.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#was-ist-der-unterschied-zwischen-der-funktion-mutate-und-der-funktion-summarize-wie-kombiniert-man-diese-funktionen-am-besten-mit-group_by",
    "href": "scripts/03_faq/rstudio.html#was-ist-der-unterschied-zwischen-der-funktion-mutate-und-der-funktion-summarize-wie-kombiniert-man-diese-funktionen-am-besten-mit-group_by",
    "title": "1 RStudio",
    "section": "Was ist der Unterschied zwischen der Funktion mutate() und der Funktion summarize()? Wie kombiniert man diese Funktionen am besten mit group_by()?",
    "text": "Was ist der Unterschied zwischen der Funktion mutate() und der Funktion summarize()? Wie kombiniert man diese Funktionen am besten mit group_by()?\n\n\n\n\n\n\nImportant\n\n\n\nVorweg: Du kannst anhand der Syntax ?Funktionsname()die Dokumentation einer Funktion aufrufen. Hier wird beschrieben, welche Argumente die Funktion erwartet, was die Default-Einstellungen sind und was die Funktion ausgibt.\n\n\nMit mutate() fügst du Spalten hinzu oder änderst sie, während alle Zeilen erhalten bleiben; summarise() verdichtet hingegen die Zeilen zu Aggregaten – ohne Gruppierung zu einer Zeile für den gesamten Datensatz und mit group_by() zu einer Zeile pro Gruppe – und gibt dabei nur die Gruppenvariablen sowie die neu berechneten Kennwerte zurück.\n\n\n\n\n\n\nNote\n\n\n\nVisualisierungen finden sich hier.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wie-funktioniert-die-umwandlung-eines-wide-datensatzes-hin-zu-einem-long-datensatz-und-welche-argumente-beinhaltet-die-hierfür-angewendete-funktion-pivot_longer",
    "href": "scripts/03_faq/rstudio.html#wie-funktioniert-die-umwandlung-eines-wide-datensatzes-hin-zu-einem-long-datensatz-und-welche-argumente-beinhaltet-die-hierfür-angewendete-funktion-pivot_longer",
    "title": "1 RStudio",
    "section": "Wie funktioniert die Umwandlung eines wide-Datensatzes hin zu einem long-Datensatz und welche Argumente beinhaltet die hierfür angewendete Funktion pivot_longer()?",
    "text": "Wie funktioniert die Umwandlung eines wide-Datensatzes hin zu einem long-Datensatz und welche Argumente beinhaltet die hierfür angewendete Funktion pivot_longer()?\n\n\n\n\n\n\nImportant\n\n\n\nDu kannst anhand der Syntax ?Funktionsname()die Dokumentation einer Funktion aufrufen. Hier wird beschrieben, welche Argumente die Funktion erwartet, was die Default-Einstellungen sind und was die Funktion ausgibt.\n\n\nWie schon in der Frage erwähnt, die passende Funktion zur Umwandlung eines Datensatzes vom wide-Format in das long-Format erfolgt anhand der Funktion pivot_longer(). Die Funktion nimmt als die ersten beiden Argumente den Datensatz (data) und die Spalten, welche transformiert werden sollen (cols). Mit den anderen beiden Argumenten werden die Namen bestimmt, welche die Spalten haben sollen, in welcher die früheren Spaltenüberschriften (names_to = \"name\") und die Werte (values_to = \"value\") eingetragen werden.\n\ndata_long &lt;- data_wide |&gt; \n  pivot_longer(\n    cols = c(Spalte1, Spalte2, Spalte3), \n    names_to = \"Hier kommt der Name der Spalte rein, in welcher die früheren Spaltenüberschriften abgelegt sind\", \n    values_to = \"Hier kommt der Name der Spalte rein, in welcher die Werte der entsprechenden früheren Spalten abgelegt sind\"\n  )\n\n\n\n\n\n\n\nNote\n\n\n\nWeitere Informationen und Beispiele finden sich hier.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wie-funktioniert-der-pipe-operator-bzw.-und-was-ist-der-unterschied-zwischen-den-beiden",
    "href": "scripts/03_faq/rstudio.html#wie-funktioniert-der-pipe-operator-bzw.-und-was-ist-der-unterschied-zwischen-den-beiden",
    "title": "1 RStudio",
    "section": "Wie funktioniert der Pipe Operator |> bzw. %>% und was ist der Unterschied zwischen den beiden?",
    "text": "Wie funktioniert der Pipe Operator |&gt; bzw. %&gt;% und was ist der Unterschied zwischen den beiden?\nDer Pipe Operator nimmt das Resultat von oben bzw. links und übergibt dieses Zwischenergebnis nach unten bzw. rechts. Was helfen könnte: Die Syntax erst ohne Pipe aufschreiben und dann die Klammern nach und nach auflösen und mit der Pipe ersetzen. Die folgenden Code-Snippets sind äquivalent:\n\nsummarize(\n  filter(data, Variable == \"A\"),\n  mean = mean(Wert, na.rm = TRUE),\n  sd = sd(Wert, na.rm = TRUE)\n)\n\ndata %&gt;%\n  filter(Variable == \"A\") %&gt;%\n  summarize(mean = mean(Wert, na.rm = TRUE), sd = sd(Wert, na.rm = TRUE))\n\ndata |&gt; \n  filter(Variable == \"A\") |&gt; \n  summarize(mean = mean(Wert, na.rm = TRUE), sd = sd(Wert, na.rm = TRUE))\n\n\n\n\n\n\n\nNote\n\n\n\nDie Pipe Operatoren unterscheiden sich nur geringfügig und die Unterschiede sind für den Rahmen des Seminars nicht relevant, können jedoch hier nachgelesen werden.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wie-funktioniert-die-t.test-funktion",
    "href": "scripts/03_faq/rstudio.html#wie-funktioniert-die-t.test-funktion",
    "title": "1 RStudio",
    "section": "Wie funktioniert die t.test()-Funktion?",
    "text": "Wie funktioniert die t.test()-Funktion?\n\n\n\n\n\n\nImportant\n\n\n\nDu kannst anhand der Syntax ?Funktionsname()die Dokumentation einer Funktion aufrufen. Hier wird beschrieben, welche Argumente die Funktion erwartet, was die Default-Einstellungen sind und was die Funktion ausgibt.\n\n\nBei der t.test()-Funktion werden die Mittelwerte von Gruppen verglichen. Das Argument x ist verpflichtend und erwartet einen nummerischen Vektor (üblicherweise der Wert von Versuchspersonen auf der relevanten Variable). Das Argument y ist ein optionaler weiterer nummerischer Vektor, falls es sich um einen Zwei-Stichproben-Tests handelt. Das Argument alternative spezifiziert wie der t-Test ausgerichtet ist (≤, ≥ oder ≠). Das Argument mu gibt den erwarteten Mittelwert unter H0 an (Default = 0). Das Argument var.equal bestimmt, ob der Test unter der Annahme von Varianzhomogenität durch wird. Sprich, ob zwischen den beiden Gruppen die Varianzen gleich sind. Ist diese Annahme erfüllt, so wird ein students t-Test gerechnet. Ansonsten wird ein Welch t-Test gerechnet. Mit conf.level kann das Konfidenzintervall beliebig angepasst werden (Default = 0.95). Hier ein Beispiel Code-Snippet:\n\nt.test(x = data$Wert[data$Gruppe == \"A\"], \n       y = data$Wert[data$Gruppe == \"B\"], \n       alternative = \"two.sided\", # in diesem Fall ist der Test ungerichtet\n       mu = 0, # H0: Mittelwertunterschied = 0 (Default)\n       var.equal = FALSE, # Ablehnung der Varianzhomogenität (Defualt) und damit ein Welch`s t-Test\n       conf.level = 0.95) # Default",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#was-ist-der-unterschied-zwischen-as_factor-und-as.factor",
    "href": "scripts/03_faq/rstudio.html#was-ist-der-unterschied-zwischen-as_factor-und-as.factor",
    "title": "1 RStudio",
    "section": "Was ist der Unterschied zwischen as_factor() und as.factor()?",
    "text": "Was ist der Unterschied zwischen as_factor() und as.factor()?\n\n\n\n\n\n\nImportant\n\n\n\nDu kannst anhand der Syntax ?Funktionsname()die Dokumentation einer Funktion aufrufen. Hier wird beschrieben, welche Argumente die Funktion erwartet, was die Default-Einstellungen sind und was die Funktion ausgibt. Hierüber lassen sich auch Unterschiede zwischen ähnlichen Funktionen feststellen.\n\n\nBeide Funktionen formatieren Werte einer Spalte hin zu Faktoren. as.factor() ist in Base R vorhanden und erstellt die Faktoren anhand des Alphabets. as_factor() stammt aus dem Tidyverse, kann bereits in SPSS-Dateien enthaltene Faktorisierungen auslesen und erstellt neue Faktoren anhand der Auftrittsreihenfolge im Vektor.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#was-gibt-es-bei-ggplot-alles-für-visualisierungsmöglichkeiten",
    "href": "scripts/03_faq/rstudio.html#was-gibt-es-bei-ggplot-alles-für-visualisierungsmöglichkeiten",
    "title": "1 RStudio",
    "section": "Was gibt es bei ggplot alles für Visualisierungsmöglichkeiten?",
    "text": "Was gibt es bei ggplot alles für Visualisierungsmöglichkeiten?\nMit ggplot kann eine ganze Reihe an Visualisierungen manuell festgelegt werden, von der Art des Graphen, mehrdimensionale Darstellungen, Formatierung wie Farben, Grössen uvm. Eine grobe Übersicht gibt es hier.\n\n\n\n\n\n\nNote\n\n\n\nBeispiele und Übungen finden sich hier.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wie-kann-man-sicherstellen-dass-bei-der-visualisierung-von-graphen-die-apa-guidelines-eingehalten-werden",
    "href": "scripts/03_faq/rstudio.html#wie-kann-man-sicherstellen-dass-bei-der-visualisierung-von-graphen-die-apa-guidelines-eingehalten-werden",
    "title": "1 RStudio",
    "section": "Wie kann man sicherstellen, dass bei der Visualisierung von Graphen die APA-Guidelines eingehalten werden?",
    "text": "Wie kann man sicherstellen, dass bei der Visualisierung von Graphen die APA-Guidelines eingehalten werden?\nHierfür gibt es ein extra [theme_apa()](https://rdrr.io/cran/jtools/man/theme_apa.html). Dieses nimmt einem viele der Formatierungen ab. Einzelheiten muss man trotzdem noch prüfen bzw. je nach Abbildung müssen manche Formatierungen auch noch selbst ergänzt werden. Die genaueren APA-Guidelines sind auch noch mal hier zu finden.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wann-wird-ein-element-mit-und-wann-wird-ein-element-ohne-anführungszeichen-angesprochen",
    "href": "scripts/03_faq/rstudio.html#wann-wird-ein-element-mit-und-wann-wird-ein-element-ohne-anführungszeichen-angesprochen",
    "title": "1 RStudio",
    "section": "Wann wird ein Element mit und wann wird ein Element ohne Anführungszeichen angesprochen?",
    "text": "Wann wird ein Element mit und wann wird ein Element ohne Anführungszeichen angesprochen?\nAls Regel: Spricht man ein Objekt aus der Environment an, dann werden keine Anführungszeichen verwendet. Spricht man numerische Elemente aus einer Spalte an, dann werden ebenfalls keine Anführungszeichen verwendet. Spricht man Spaltenelemente an, welche als Faktor oder als Character formatiert sind, dann werden auch Anführungszeichen verwendet.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wie-funktionieren-die-relativen-pfade-und-wie-stellt-man-sicher-dass-diese-auch-bei-fremden-personen-funktionieren",
    "href": "scripts/03_faq/rstudio.html#wie-funktionieren-die-relativen-pfade-und-wie-stellt-man-sicher-dass-diese-auch-bei-fremden-personen-funktionieren",
    "title": "1 RStudio",
    "section": "Wie funktionieren die relativen Pfade und wie stellt man sicher, dass diese auch bei fremden Personen funktionieren?",
    "text": "Wie funktionieren die relativen Pfade und wie stellt man sicher, dass diese auch bei fremden Personen funktionieren?\nRelative Pfade gehen immer vom working directory (Arbeitsspeicher des Skripts) aus. Wenn man also Daten laden möchtest, dann muss man immer schauen, wo sich – ausgehend vom working directory – die Datenfiles befindet. Bei der Syntax des dann angegebenen Pfades gilt folgendes: 1. “Datensatz.Dateiendung” bildet ausnahmslos das Ende des Pfades. 2. “/” bilden den nächsten Step, also den Übergang von einem Ordner zum nächsten oder vom finalen Ordner zur Datei. 3. Soll im Ordnersystem in einen Ordner auf einer Ebene weiter oben gewechselt werden, dann kann ein “.” zusätzlich verwendet werden. Hier ein beispielhaftes Code-Snipet:\n\ndata &lt;- readr::read_csv(\"../data/Datensatz.Dateiendung\") # Starte im working directory (deswegen der erste \".\") und gehe eine Ordnerebene hoch (deswegen der zweite \".\"). Von dort aus gehe in den Ordner \"data\" und wähle dort die Datei \"Datensatz\" aus, welche dem Format \"Dateiendung\" entspricht.\n\nWird einer fremden Person nun das gesamte Ordnersystem mit all seinen Inhalten unverändert übergeben, so kann der Dateipfad innerhalb dieses Ordnersystems immer auch den Datensatz einlesen.\n\n\n\nAbb. 2.: Dateipfade",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wann-wird-die-tilde-und-das-dollarzeichen-verwendet",
    "href": "scripts/03_faq/rstudio.html#wann-wird-die-tilde-und-das-dollarzeichen-verwendet",
    "title": "1 RStudio",
    "section": "Wann wird die Tilde (~) und das Dollarzeichen ($) verwendet?",
    "text": "Wann wird die Tilde (~) und das Dollarzeichen ($) verwendet?\nDie Tilde bedeutet, was links von ihr steht, wird von dem, was rechts von ihr steht, vorhergesagt. Beispielsweise wird die Tilde üblicherweise bei Regressionen verwendet: lm(AV ~ UV). Das Dollarzeichen dient vor allem, um Spalten anhand ihrer Namen anzusprechen: data$Spaltenname. Manche Funktionen arbeiten mit beiden Schreibweisen. Beispielsweise sind die folgenden Schreibweisen äquivalent:\n\nt.test(data$variable1, data$variable2)\n      \nt.test(data, formula = variable ~ group)\n\nAllerdings müssen bei letzterer Schreibweise die Werte beider Gruppen zwingend im selben Datensatz vorliegen.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wann-wird-die-tilde-verwendet-und-wann-wird-ein-komma-verwendet",
    "href": "scripts/03_faq/rstudio.html#wann-wird-die-tilde-verwendet-und-wann-wird-ein-komma-verwendet",
    "title": "1 RStudio",
    "section": "Wann wird die Tilde (~) verwendet und wann wird ein Komma (,) verwendet?",
    "text": "Wann wird die Tilde (~) verwendet und wann wird ein Komma (,) verwendet?\nDie Tilde bedeutet, was links von ihr steht, wird von dem, was rechts von ihr steht, vorhergesagt. Beispielsweise wird die Tilde üblicherweise bei Regressionen verwendet: lm(AV ~ UV). Das Komma wird verwendet, um Argumente in einer Funktion zu trennen. Beispiel:\n\nresult &lt;- lm(AV ~ UV, data = datensatz)\n\nresult &lt;- t.test(x = datensatz$variable1, y = datensatz$variable2)\n\n\n\n\n\n\n\nWarning\n\n\n\nDas Komma sollte nicht verwendet werden um Dezimalzahlen zu definieren! Dies führt zu einer Fehlermeldung. Für Dezimalzahlen wird immer der Punkt verwendet (z.B. 3.14).",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wie-berechnet-man-das-generalisierte-η²",
    "href": "scripts/03_faq/rstudio.html#wie-berechnet-man-das-generalisierte-η²",
    "title": "1 RStudio",
    "section": "Wie berechnet man das generalisierte η²?",
    "text": "Wie berechnet man das generalisierte η²?\nMan erhält das generalisierte η² indem man erst eine ANOVA berechnet, abspeichert und dann über summary(anova_ergebnis, es = ges) ausgeben lässt.\n\nanova_ergebnis &lt;- afex::aov_car(value ~ treatment, data = example_data)\n\nsummary(anova_ergebnis, es = ges)",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wie-bereitet-man-die-daten-für-eine-mixed-anova-vor",
    "href": "scripts/03_faq/rstudio.html#wie-bereitet-man-die-daten-für-eine-mixed-anova-vor",
    "title": "1 RStudio",
    "section": "Wie bereitet man die Daten für eine mixed-ANOVA vor?",
    "text": "Wie bereitet man die Daten für eine mixed-ANOVA vor?\nEine mixed-ANOVA besteht aus der Varianzerklärung aufgrund unterschiedlicher Gruppenzugehörigkeiten (bspw. Kontrollgruppe und Experimentalgruppe) und einer Messwiederholung (mehrerer Messwerte pro Person, unabhängig von der Gruppenzugehörigkeit). Beides muss auch bereits in den Daten erkennbar sein. Sprich, pro Versuchsperson muss anhand einer Variable codiert sein, zu welcher Gruppe diese Versuchsperson gehört. Darüber hinaus muss es für jede Versuchsperson zu jedem Messzeitpunkt einen Wert geben. Angenommen die Daten liegen ursprünglich im wide-Format vor, dann müssen diese erst ins long-Format übertragen werden (siehe auch Fragen zum long-Format). Erst dann können die entsprechenden ANOVA-Funktionen die Daten entsprechend interpretieren.\n\n\n\n\n\n\nNote\n\n\n\nInhalte zu ANOVAs mit Messwiederholung oder mixed-ANOVAs könnt ihr auch noch mal über die Inhalte aus Statistik IV von Boris Mayer und Stefan Thoma wiederholen",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wofür-gibt-es-bei-der-funktion-aov_4-das-argument-1-personenidentifikationscode.-bzw.-das-argument-wiederholungsfaktor-personenidentifikationscode",
    "href": "scripts/03_faq/rstudio.html#wofür-gibt-es-bei-der-funktion-aov_4-das-argument-1-personenidentifikationscode.-bzw.-das-argument-wiederholungsfaktor-personenidentifikationscode",
    "title": "1 RStudio",
    "section": "Wofür gibt es bei der Funktion aov_4() das Argument (1 | Personenidentifikationscode). bzw. das Argument (Wiederholungsfaktor | Personenidentifikationscode)?",
    "text": "Wofür gibt es bei der Funktion aov_4() das Argument (1 | Personenidentifikationscode). bzw. das Argument (Wiederholungsfaktor | Personenidentifikationscode)?\n\n\n\n\n\n\nImportant\n\n\n\nDu kannst anhand der Syntax ?Funktionsname()die Dokumentation einer Funktion aufrufen. Hier wird beschrieben, welche Argumente die Funktion erwartet, was die Default-Einstellungen sind und was die Funktion ausgibt.\n\n\nDie Funktion aov_4() ist auf ANOVAs mit Messwiederholung ausgelegt und erwartet die zusätzliche Syntax (x | y). Die genaue Formulierung dieses Arguments hängt dann davon ab, ob es keine Messwiederholung gibt (1 | Personenidentifikationscode) oder ob es eine Messwiederholung gibt (Wiederholungsfaktor | Personenidentifikationscode).\n\nafex::aov_4(value ~ treatment + (1 | Personenidentifikationscode), data = example_data) # Beispiel ohne(!) Messwiederholung\n\nafex::aov_4(value ~ treatment + (time | Personenidentifikationscode), data = example_data) # Beispiel mit(!) Messwiederholung\n\n\n\n\n\n\n\nNote\n\n\n\nFür die Funktion aov_4() gibt es aus Statistik-IV von Boris Mayer und Stefan Thoma noch tiefere und beispielhafte Ausführungen.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wie-stellt-man-ein-dass-in-markdown-oder-quarto-der-output-meines-codes-unterbunden-wird",
    "href": "scripts/03_faq/rstudio.html#wie-stellt-man-ein-dass-in-markdown-oder-quarto-der-output-meines-codes-unterbunden-wird",
    "title": "1 RStudio",
    "section": "Wie stellt man ein, dass in Markdown oder Quarto der Output meines Codes unterbunden wird?",
    "text": "Wie stellt man ein, dass in Markdown oder Quarto der Output meines Codes unterbunden wird?\nEs kann entweder im ersten Chunk des Dokuments als globale Einstellung knitr::opts_chunk$set(output = FALSE) oder im entsprechend gewünschten Chunk einzeln die Option {r, output = FALSE} gesetzt werden den Output zu unterdrücken. Mittlerweile können solche Optionen auch über die Schreibweise #| explizit innerhalb des Chunks geschrieben werden. Ähnliche Befehle existieren auch, wenn man stattdessen oder zusätzlich Warnmeldungen oder den Code unterbinden möchte. Stellt bei der Endabgabe aber bitte sicher, dass der Code und mögliche Warnmeldungen sichtbar sind!\n\n# Hierdurch würde der Code zwar angezeigt, aber nicht mehr durchgeführt werden\n# #| eval: FALSE\n# Hierdurch würde der Code dann zusätzlich auch nicht mehr angezeigt werden\n# #| echo: FALSE",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#was-bedeutet-die-meldung-summarise-has-grouped-output-by-group.-you-can-override-using-the-.groups-argument.-und-was-muss-ich-dabei-beachten",
    "href": "scripts/03_faq/rstudio.html#was-bedeutet-die-meldung-summarise-has-grouped-output-by-group.-you-can-override-using-the-.groups-argument.-und-was-muss-ich-dabei-beachten",
    "title": "1 RStudio",
    "section": "Was bedeutet die Meldung „summarise() has grouped output by ‘group’. You can override using the .groups argument.“ und was muss ich dabei beachten?",
    "text": "Was bedeutet die Meldung „summarise() has grouped output by ‘group’. You can override using the .groups argument.“ und was muss ich dabei beachten?\nÜblicherweise werden deskriptive Werte (auch) für Subgruppen der Gesamtstichprobe angegeben (beispielsweise getrennt für Männer und Frauen, für die Kontrollgruppe oder die Experimentalgruppe etc.). Um entsprechende Änderungen vorzunehmen, wird daher vor der Anwendung von summarise() noch die Funktion group_by() verwendet. Nach der Berechnung der Deskriptivstatistik wird die Gruppierung nicht aufgehoben. Sie bleibt im Hintergrund, nicht direkt sichtbar, erhalten. Die Warnmeldung weisst genau darauf hin. Möchte man die Gruppierung aufheben, dann kann entweder die Funktion ungroup() verwendet werden oder summarise() wird um das Argument summarise(.group = „drop) ergänzt. Gruppierungen aufzulösen kann für manche Vorgänge, wie beispielsweise das Löschen von noch gruppierten Spalten relevant sein.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wann-soll-eine-neue-variable-bzw.-ein-neuer-datensatz-erstellt-werden-und-wann-soll-die-alte-variable-bzw.-der-neue-datensatz-überspeichert-werden",
    "href": "scripts/03_faq/rstudio.html#wann-soll-eine-neue-variable-bzw.-ein-neuer-datensatz-erstellt-werden-und-wann-soll-die-alte-variable-bzw.-der-neue-datensatz-überspeichert-werden",
    "title": "1 RStudio",
    "section": "Wann soll eine neue Variable bzw. ein neuer Datensatz erstellt werden und wann soll die alte Variable bzw. der neue Datensatz überspeichert werden?",
    "text": "Wann soll eine neue Variable bzw. ein neuer Datensatz erstellt werden und wann soll die alte Variable bzw. der neue Datensatz überspeichert werden?\nGrundsätzlich ist es vorzuziehen neue Variablen oder Datensätze zu erstellen. Zum einen kann so bei Bedarf noch auf die ursprünglichen Variablen oder Datensätze zugegriffen werden. Zum anderen ist die Analyse so für aussenstehende leichter nachzuvollziehen. Ausnahmen sind ästhetische Änderungen oder wiederholte Berechnungen, welche für die weitere Analyse nicht weiter relevant sind.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wann-eignet-es-sich-ein-projekt-anzulegen",
    "href": "scripts/03_faq/rstudio.html#wann-eignet-es-sich-ein-projekt-anzulegen",
    "title": "1 RStudio",
    "section": "Wann eignet es sich ein Projekt anzulegen?",
    "text": "Wann eignet es sich ein Projekt anzulegen?\nEin Projekt anzulegen, lohnt sich vor allem dann, wenn in mehreren Skripten gearbeitet wird. Dann muss nicht in jedem Skript einzeln das working directory (Arbeitsspeicher des Skripts) gesetzt werden. Wird in nur einem Skript gearbeitet, dann macht das Anlegen des Projekts keinen Unterschied.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/rstudio.html#wenn-ich-mein-quarto-dokument-zu-einer-pdf-datei-rendern-möchte-erhalte-ich-die-fehlermeldung-dass-latex-nicht-installiert-ist.-wie-kann-ich-latex-installieren",
    "href": "scripts/03_faq/rstudio.html#wenn-ich-mein-quarto-dokument-zu-einer-pdf-datei-rendern-möchte-erhalte-ich-die-fehlermeldung-dass-latex-nicht-installiert-ist.-wie-kann-ich-latex-installieren",
    "title": "1 RStudio",
    "section": "Wenn ich mein Quarto-Dokument zu einer PDF-Datei rendern möchte, erhalte ich die Fehlermeldung, dass LaTeX nicht installiert ist. Wie kann ich LaTeX installieren?",
    "text": "Wenn ich mein Quarto-Dokument zu einer PDF-Datei rendern möchte, erhalte ich die Fehlermeldung, dass LaTeX nicht installiert ist. Wie kann ich LaTeX installieren?\nLaTeX ist eine Software um individuelle, professionelle Formatierungen für PDFs oder andere Dateien zu erstellen. Was für unsere Zwecke bereits ausreichen sollte ist die Installation von tinytex. tinytex ist keine eigenständige Software, sondern schlichtweg um ein Paket von vielen in R.\n\n#install.packages(\"tinytex\")\n\nNach der Installation des Pakets ruft ihr dann folgendene Funktion auf:\n\n#tinytex::install_tinytex() \n#tinytex:: stellt sicher, dass die Funktion aus dem entsprechenden Paket aufgerufen wird\n\nHierdurch wird temporär die eigentliche Software installiert, mit welcher aus eurem Quarto-Dokument eine PDF erstellt werden kann. Dies kann einige Minuten dauern. Im Anschluss sollte das Rendern hin zu einer PDF funktionieren.",
    "crumbs": [
      "FAQ",
      "1  RStudio"
    ]
  },
  {
    "objectID": "scripts/03_faq/fehlermeldungen.html",
    "href": "scripts/03_faq/fehlermeldungen.html",
    "title": "Fehlermeldungen",
    "section": "",
    "text": "Rendering in Quarto zu einer PDF funktioniert nicht\nIn der Vergangenheit gab es öfter Probleme mit der Installation von tinytex. Eine beispielhafte Fehlermeldung hierfür sah folgendermassen aus:\nprocessing file: skript.qmd\n|…………………………………. | x% [unnamed-chunk-x]\nError in contrib.url():\n! trying to use CRAN without setting a mirror\nBacktrace:\nx\n-utils::install.packages(“tinytex”) -utils::contrib.url(repos, “source”)\nQuitting from skript.qmd:Zeile-Zeile [unnamed-chunk-x]\nExecution halted\nDer Kern der Fehlermeldung lautet: “! trying ot use CRAN without setting a mirror”. CRAN ist die Plattform, von welcher standardmässig Pakete heruntergeladen werden. Die URL, also die Internetadressse von CRAN, ist dafür im Hintergrund in R eingestellt. Hier scheint es nun aber so, dass es unter der gesetzten URL kein Paket tinytex gibt. Dieses Problem lässt sich temporär (also einmalig für eure laufende Sitzung in RStudio) oder dauerhaft (also auch, wenn ihr RStudio schliesst und wieder neu startet) beheben. Um das Problem temporär zu lösen kann man einfach die URL zu CRAN explizit in der Console angeben:\n\n #| eval: false\n #| echo: true\n\noptions(repos = c(CRAN = \"https://cloud.r-project.org\"))\n\nMöchte man die Einstellung dauerhaft behalten braucht es einen weiteren Schritt. Erst wird über die Console eine globale Einstellungsdatei von RStudio geöffnet:\nIn diese Datei kann dann der Befehl zur expliziten Setzung der URL platziert werden. Diese Datei abspeichern und RStudio neu starten. Jetzt sollte tinytex von der korrekten URL abgerufen, gefunden und schlussendlich auch erfolgreich installiert werden können.\n\n\nDas Objekt mit dem ich etwas machen möchte kann nicht gefunden werden\n“==&gt; quarto preview Hands on - Block 3.qmd –to html –no-watch-inputs –no-browse\nprocessing file: Hands-on—Block-3.rmarkdown |…………………………………………. | 96% [unnamed-chunk-10] Error:! object ‘dat_full’ not foundBacktrace: ▆ 1. └─dplyr::rename(dat_full, cvstm_sum = “csvtm_sum”) Quitting from Hands-on—Block-3.rmarkdown:331-343 [unnamed-chunk-10] Execution halted”\nNetterweise gibt uns die Fehlermeldung die Stelle im Code aus, an welcher das Problem aufrat:\n\ndplyr::rename(dat_full, cvstm_sum = \"csvtm_sum\")\n\n\nDer zentrale Teil der Fehlermeldung ist hierbei “Error:! object dat_full not found”. Der Datensatz dat_full ist vor der Ausführung scheinbar noch nicht vorhanden. Stellt also unbedingt sicher, vor der Ausführung von dplyr::rename(dat_full, cvstm_sum = \"csvtm_sum\")den Datensatz eingelesen und den dafür vorgesehenen Chunk zum Einlesen nicht auf eval = FALSE gesetzt zu haben.\n\n\nBeim Rendern einer html werden noch einige weitere Ordner und Dateien erstellt\nUm zu grosse html-files oder Ladezeiten eines html-files zu vermeiden, weicht Quarto ggf. beim Rendern dazu aus nicht einen einzelnen html-file zu erstellen, sondern einen Ordner mit mehreren Dateien. Der html-file ruft diese dann beim Laden allesamt auf. Wenn das nicht gewünscht ist, dann gibt es mindestens zwei Möglichkeiten Quarto zu zwingen einen einzelnen und unabhängigen html-file zu erstellen. Als erste Variante kann der YAML-Header (der ganz oben im Quarto-file positioniert ist) um die Zeile embed-resources: true ergänzt werden:\n\n# vorher\n  format:\n    html:\n\n# nachher\n  format:\n    html:\n      embed-resources: true\n\nSollte sich auch damit das Problem nicht lösen, dann kann der Quarto-file auch manuell über das Terminal gerendert werden. Das Terminal beachten wir sonst im Seminar nicht, ist hierfür aber ausnahmsweise eine elegante Lösung. Das Terminal befindet sich unten links, wo sich auch die euch bereits vertraute Console und beim Rendern das Fenster Background Jobs befinden. Ist das Terminal noch nicht vorhanden, kann es über Tools –&gt; Terminal –&gt; New Terminal (Alt+ Umschalttaste + R) geöffnet werden. Dort wird dann folgender Befehl eingegeben:\n\nquarto render meinDokument.qmd --embed-resources\n\nHierbei muss natürlich noch der Dateiname des .qmd-file entsprechend angepasst werden. Weitere Informationen gibt es hier (am besten auf der Seite selbst noch nach dem Begriff embed-resources suchen).",
    "crumbs": [
      "FAQ",
      "1  RStudio",
      "1.1  Fehlermeldungen"
    ]
  },
  {
    "objectID": "scripts/03_faq/endabgabe.html",
    "href": "scripts/03_faq/endabgabe.html",
    "title": "5 Abschlussprojekt",
    "section": "",
    "text": "Note\n\n\n\nLies dir neben den folgenden Fragen auch noch mal die allgemeinen Infos zum Abschlussprojekt unter “Leistungsnachweis” durch.",
    "crumbs": [
      "FAQ",
      "5  Abschlussprojekt"
    ]
  },
  {
    "objectID": "scripts/03_faq/endabgabe.html#was-gibt-es-für-formatvorgaben-für-das-skript-schriftgrösse-fettmarkierungen-etc.",
    "href": "scripts/03_faq/endabgabe.html#was-gibt-es-für-formatvorgaben-für-das-skript-schriftgrösse-fettmarkierungen-etc.",
    "title": "5 Abschlussprojekt",
    "section": "Was gibt es für Formatvorgaben für das Skript (Schriftgrösse, Fettmarkierungen etc.)?",
    "text": "Was gibt es für Formatvorgaben für das Skript (Schriftgrösse, Fettmarkierungen etc.)?\nEs gibt keine exakten Formatvorgaben für das Skript. Vielmehr gilt: Das Skript sollte übersichtlich sein und keine ungewöhnlichen Formatierungen enthalten. Mit den Vorgaben von APA 7 ist das Skript sicher passend formatiert.",
    "crumbs": [
      "FAQ",
      "5  Abschlussprojekt"
    ]
  },
  {
    "objectID": "scripts/03_faq/endabgabe.html#welche-stilvorgaben-gibt-es-bei-der-erstellung-des-skripts-zu-beachten",
    "href": "scripts/03_faq/endabgabe.html#welche-stilvorgaben-gibt-es-bei-der-erstellung-des-skripts-zu-beachten",
    "title": "5 Abschlussprojekt",
    "section": "Welche Stilvorgaben gibt es bei der Erstellung des Skripts zu beachten?",
    "text": "Welche Stilvorgaben gibt es bei der Erstellung des Skripts zu beachten?\nDas Skript sollte sinnvolle Überschriften und eine sinnvolle Gliederung enthalten. Der Code sollte kommentiert sein, so dass die Auswahl von Funktionen und das Vorgehen begründet sind. Sofern LLMs oder andere externe Tools zur Hilfe herangezogen worden sind, muss dies angemerkt werden. Hierfür kann ggf. eine getrennte Kopie des Chatverlaufes eingereicht oder ein Link nach APA-Guidelines ergänzt werden.",
    "crumbs": [
      "FAQ",
      "5  Abschlussprojekt"
    ]
  },
  {
    "objectID": "scripts/03_faq/endabgabe.html#in-welcher-sprache-zeitform-perspektive-und-in-welchem-stil-soll-der-datenanalyseplan-geschrieben-werden",
    "href": "scripts/03_faq/endabgabe.html#in-welcher-sprache-zeitform-perspektive-und-in-welchem-stil-soll-der-datenanalyseplan-geschrieben-werden",
    "title": "5 Abschlussprojekt",
    "section": "In welcher Sprache, Zeitform, Perspektive und in welchem Stil soll der Datenanalyseplan geschrieben werden?",
    "text": "In welcher Sprache, Zeitform, Perspektive und in welchem Stil soll der Datenanalyseplan geschrieben werden?\nAlle für die Abgabe relevanten Unterlagen dürfen auf Englisch oder Deutsch eingereicht werden. Wichtig ist lediglich, dass die Unterlagen untereinander einer einheitlichen Sprache folgen. Als Zeitform gilt das Präsens. Bitte schreibe in der Wir-Form und im wissenschaftlichen Stil.",
    "crumbs": [
      "FAQ",
      "5  Abschlussprojekt"
    ]
  },
  {
    "objectID": "scripts/03_faq/endabgabe.html#wie-umfangreich-sollen-die-kommentare-des-codes-im-skript-sein",
    "href": "scripts/03_faq/endabgabe.html#wie-umfangreich-sollen-die-kommentare-des-codes-im-skript-sein",
    "title": "5 Abschlussprojekt",
    "section": "Wie umfangreich sollen die Kommentare des Codes im Skript sein?",
    "text": "Wie umfangreich sollen die Kommentare des Codes im Skript sein?\nDie Funktionsweise von üblicher Syntax (wie beispielsweise dem Pipe Operator) oder einer Funktion muss nicht kommentiert werden. Aber: Das Dokument muss für fremde Wissenschaftler:innen der Psychologie ohne weiteres nachvollziehbar sein. Bedeutet, Kommentare sollten das Vorgehen im Skript ausreichend begründen.",
    "crumbs": [
      "FAQ",
      "5  Abschlussprojekt"
    ]
  },
  {
    "objectID": "scripts/03_faq/endabgabe.html#sollen-im-skript-warn--undoder-fehlermeldungen-unterbunden-werden-oder-sichtbar-sein",
    "href": "scripts/03_faq/endabgabe.html#sollen-im-skript-warn--undoder-fehlermeldungen-unterbunden-werden-oder-sichtbar-sein",
    "title": "5 Abschlussprojekt",
    "section": "Sollen im Skript Warn- und/oder Fehlermeldungen unterbunden werden oder sichtbar sein?",
    "text": "Sollen im Skript Warn- und/oder Fehlermeldungen unterbunden werden oder sichtbar sein?\nDamit wir die Abgabe leichter kontrollieren können sollen die Warn- und Fehlermeldungen bitte sichtbar sein und nicht ausgeschaltet sein. Auch unabhängig von der Abgabe ist zu empfehlen die Meldungen sichtbar zu lassen. Das erleichtert Unbeteiligten die Analyse nachzuvollziehen und sie auf mögliche Fehler zu untersuchen.",
    "crumbs": [
      "FAQ",
      "5  Abschlussprojekt"
    ]
  },
  {
    "objectID": "scripts/03_faq/endabgabe.html#darf-im-skript-auch-noch-code-von-übungsaufgaben-vorhanden-sein",
    "href": "scripts/03_faq/endabgabe.html#darf-im-skript-auch-noch-code-von-übungsaufgaben-vorhanden-sein",
    "title": "5 Abschlussprojekt",
    "section": "Darf im Skript auch noch Code von Übungsaufgaben vorhanden sein?",
    "text": "Darf im Skript auch noch Code von Übungsaufgaben vorhanden sein?\nHier gilt der Grundsatz: Euer Skript, wie auch alle anderen Unterlagen, sollten für fremde Wissenschaftler:innen der Psychologie ohne weiteres nachvollziehbar sein. Code, welcher nicht im Zusammenhang mit der Endabgabe steht - und dementsprechend auch nicht im Datenanalyseplan erwähnt wird – würde nur vom wesentlichen Ablenken und soll daher nicht im Skript vorhanden sein.",
    "crumbs": [
      "FAQ",
      "5  Abschlussprojekt"
    ]
  },
  {
    "objectID": "scripts/03_faq/endabgabe.html#wie-exakt-sollen-die-tabellen-und-abbildungen-denen-aus-dem-paper-von-grinschgl-et-al.-2020-entsprechen",
    "href": "scripts/03_faq/endabgabe.html#wie-exakt-sollen-die-tabellen-und-abbildungen-denen-aus-dem-paper-von-grinschgl-et-al.-2020-entsprechen",
    "title": "5 Abschlussprojekt",
    "section": "Wie exakt sollen die Tabellen und Abbildungen denen aus dem Paper von Grinschgl et al. (2020) entsprechen?",
    "text": "Wie exakt sollen die Tabellen und Abbildungen denen aus dem Paper von Grinschgl et al. (2020) entsprechen?\nDie Tabellen und Abbildungen aus dem Originalpaper von Grinschgl et al. (2020) müssen nicht exakt repliziert werden. Wichtig ist allerdings, dass die Aussage der Abbildung bzw. der Tabelle korrekt ist und keine wichtigen Details ausgelassen werden.",
    "crumbs": [
      "FAQ",
      "5  Abschlussprojekt"
    ]
  },
  {
    "objectID": "scripts/03_faq/endabgabe.html#soll-die-berechnung-von-cronbachs-alpha-aus-dem-paper-von-grinschgl-et-al.-2020-auch-durchgeführt-werden",
    "href": "scripts/03_faq/endabgabe.html#soll-die-berechnung-von-cronbachs-alpha-aus-dem-paper-von-grinschgl-et-al.-2020-auch-durchgeführt-werden",
    "title": "5 Abschlussprojekt",
    "section": "Soll die Berechnung von Cronbachs Alpha aus dem Paper von Grinschgl et al. (2020) auch durchgeführt werden?",
    "text": "Soll die Berechnung von Cronbachs Alpha aus dem Paper von Grinschgl et al. (2020) auch durchgeführt werden?\nNein, die Berechnung von Cronbachs-Alpha aus dem Paper von Grinschgl et al. (2020) ist nicht Teil des Abschlussprojekts.",
    "crumbs": [
      "FAQ",
      "5  Abschlussprojekt"
    ]
  },
  {
    "objectID": "scripts/03_faq/codebook.html",
    "href": "scripts/03_faq/codebook.html",
    "title": "2 Codebook",
    "section": "",
    "text": "Fragen zum Codebook",
    "crumbs": [
      "FAQ",
      "2  Codebook"
    ]
  },
  {
    "objectID": "scripts/03_faq/codebook.html#sollen-im-codebook-alle-variablen-eines-datensatzes-beschrieben-werden-oder-nur-diejenigen-welche-auch-im-rahmen-der-analyse-verwendet-werden",
    "href": "scripts/03_faq/codebook.html#sollen-im-codebook-alle-variablen-eines-datensatzes-beschrieben-werden-oder-nur-diejenigen-welche-auch-im-rahmen-der-analyse-verwendet-werden",
    "title": "2 Codebook",
    "section": "Sollen im Codebook alle Variablen eines Datensatzes beschrieben werden oder nur diejenigen, welche auch im Rahmen der Analyse verwendet werden?",
    "text": "Sollen im Codebook alle Variablen eines Datensatzes beschrieben werden oder nur diejenigen, welche auch im Rahmen der Analyse verwendet werden?\nAls Grundsatz gilt: Das Codebook soll fremden Wissenschaftler:innen aus der Psychologie dabei helfen ohne weiteren Aufwand eure Arbeit zu beurteilen und ggf. zu replizieren. Für eine Replikation würde eine genaue Beschreibung der von euch in der Analyse verwendeten Variablen ausreichend. Eine allgemeine Beurteilung ist aber erst dann vollständig möglich, wenn auch alle anderen Variablen umfangreich beschrieben sind. Deswegen müssen im Codebook alle Variablen eures Datensatzes beschrieben werden, auch jene, die in der Analyse nicht weiter Beachtung finden.",
    "crumbs": [
      "FAQ",
      "2  Codebook"
    ]
  },
  {
    "objectID": "scripts/03_faq/codebook.html#sollten-unter-questionnaire-wirklich-nur-fragebögen-aufgelistet-werden-oder-kann-man-hier-auch-die-namen-möglicher-kognitiver-tests-angeben",
    "href": "scripts/03_faq/codebook.html#sollten-unter-questionnaire-wirklich-nur-fragebögen-aufgelistet-werden-oder-kann-man-hier-auch-die-namen-möglicher-kognitiver-tests-angeben",
    "title": "2 Codebook",
    "section": "Sollten unter „questionnaire“ wirklich nur Fragebögen aufgelistet werden oder kann man hier auch die Namen möglicher kognitiver Tests angeben?",
    "text": "Sollten unter „questionnaire“ wirklich nur Fragebögen aufgelistet werden oder kann man hier auch die Namen möglicher kognitiver Tests angeben?\nBei Angaben im Codebook sollte immer gelten: Sie erklären für unbeteiligte Wissenschaftler:innen aus der Psychologie mehr als das sie Verwirrung stiften. Unter „questionnaire“ auch die Namen von ggf. angewendeten kognitiven Tests anzugeben, unterstützt die Nachvollziehbarkeit und kann daher so gemacht werden.",
    "crumbs": [
      "FAQ",
      "2  Codebook"
    ]
  },
  {
    "objectID": "scripts/03_faq/codebook.html#wo-liegt-der-unterschied-zwischen-description-und-composition-of-item",
    "href": "scripts/03_faq/codebook.html#wo-liegt-der-unterschied-zwischen-description-und-composition-of-item",
    "title": "2 Codebook",
    "section": "Wo liegt der Unterschied zwischen „description“ und „Composition of item…“?",
    "text": "Wo liegt der Unterschied zwischen „description“ und „Composition of item…“?\nBei „description“ geht es um eine kurze inhaltliche Beschreibung der Variable, also was für einen Zweck die Variable in der Studie einnimmt oder mit welchem Konstrukt die Variable im Zusammenhang steht. Bei „composition of item“ geht es um die mathematische Zusammensetzung der Variable (z.B. Mittelwert aus Items XYZ).",
    "crumbs": [
      "FAQ",
      "2  Codebook"
    ]
  },
  {
    "objectID": "scripts/03_faq/codebook.html#wann-sind-response_labels-zu-verwenden-und-wann-nicht",
    "href": "scripts/03_faq/codebook.html#wann-sind-response_labels-zu-verwenden-und-wann-nicht",
    "title": "2 Codebook",
    "section": "Wann sind „response_labels“ zu verwenden und wann nicht?",
    "text": "Wann sind „response_labels“ zu verwenden und wann nicht?\nDie Labels der Antwortmöglichkeiten direkt zu benennen ist dann wichtig, wenn diese nicht logisch erschliessbar sind. Dies ist z.B. bei einer Likert-Skala der Fall, da diese unterschiedlich streng formuliert sein kann. Selbst wenn diese im Datenanalyseplan aufgeführt werden, ist es sicherer diese auch noch mal im Codebook zu erwähnen.",
    "crumbs": [
      "FAQ",
      "2  Codebook"
    ]
  },
  {
    "objectID": "scripts/03_faq/codebook.html#was-ist-mit-der-spalte-dimensions-gemeint",
    "href": "scripts/03_faq/codebook.html#was-ist-mit-der-spalte-dimensions-gemeint",
    "title": "2 Codebook",
    "section": "Was ist mit der Spalte „dimensions“ gemeint?",
    "text": "Was ist mit der Spalte „dimensions“ gemeint?\nUnter „dimensions“ soll das Konstrukt aufgeführt werden, welches sich hinter Items eines Fragebogens verbirgt (z.B. Item XY gehört zur dimension „Extraversion“ in einem Big 5 Fragebogen).",
    "crumbs": [
      "FAQ",
      "2  Codebook"
    ]
  },
  {
    "objectID": "scripts/03_faq/codebook.html#wie-soll-man-vorgehen-wenn-zu-manchen-dimensionen-der-variable-weder-im-paper-noch-in-der-präregistrierung-genaue-angaben-zu-finden-sind",
    "href": "scripts/03_faq/codebook.html#wie-soll-man-vorgehen-wenn-zu-manchen-dimensionen-der-variable-weder-im-paper-noch-in-der-präregistrierung-genaue-angaben-zu-finden-sind",
    "title": "2 Codebook",
    "section": "Wie soll man vorgehen, wenn zu manchen Dimensionen der Variable weder im Paper noch in der Präregistrierung genaue Angaben zu finden sind?",
    "text": "Wie soll man vorgehen, wenn zu manchen Dimensionen der Variable weder im Paper noch in der Präregistrierung genaue Angaben zu finden sind?\nFür den Fall, dass zu einer Angabe genaue Informationen fehlen, gibt es zwei Möglichkeiten. Zum einen kann man „reverse Engineering“ anwenden. Manche Informationen sind nirgendwo explizit angegeben, lassen sich aber beispielsweise anhand der gegebenen Informationen schlussfolgern. Hierzu zählen beispielsweise die minimalen und maximalen Werte einer Skala, welche mit einer hohen Wahrscheinlichkeit aus den Rohdaten ablesbar sind. Hierzu kann aber auch zählen, sich zu überlegen, was logisch oder mögliche Angaben sind. Das bedeutet nicht, dass in der ursprünglichen Studie auch tatsächlich so gearbeitet wurde, gibt aber trotzdem einen guten Anhaltspunkt. Unabhängig davon, wie man vorgeht, müsste dies kenntlich gemacht werden. Nur so können andere Personen mögliche Fehler in den Schlussfolgerungen oder Annahmen finden, anhand welcher die entsprechenden Informationen ergänzt wurden.",
    "crumbs": [
      "FAQ",
      "2  Codebook"
    ]
  },
  {
    "objectID": "scripts/03_faq/codebook.html#welche-informationen-sind-für-das-codebook-relevant-die-studie-von-grinschgl-et-al.-2020-undoder-die-präregistrierung-von-grinschgl-et-al.-2020",
    "href": "scripts/03_faq/codebook.html#welche-informationen-sind-für-das-codebook-relevant-die-studie-von-grinschgl-et-al.-2020-undoder-die-präregistrierung-von-grinschgl-et-al.-2020",
    "title": "2 Codebook",
    "section": "Welche Informationen sind für das Codebook relevant? Die Studie von Grinschgl et al. (2020) und/oder die Präregistrierung von Grinschgl et al. (2020)?",
    "text": "Welche Informationen sind für das Codebook relevant? Die Studie von Grinschgl et al. (2020) und/oder die Präregistrierung von Grinschgl et al. (2020)?\nFür das Ausfüllen des Codebook sind beide Quellen relevant, die Studie von Grinschgl et al. 2020 und die Präregistrierung zu Grinschgl et al. (2020).",
    "crumbs": [
      "FAQ",
      "2  Codebook"
    ]
  },
  {
    "objectID": "scripts/03_faq/codebook.html#sollen-alle-messwiederholungen-im-codebook-einzeln-aufgeführt-werden-oder-soll-es-eine-einzelne-variable-für-die-messwiederholung-im-codebook-geben",
    "href": "scripts/03_faq/codebook.html#sollen-alle-messwiederholungen-im-codebook-einzeln-aufgeführt-werden-oder-soll-es-eine-einzelne-variable-für-die-messwiederholung-im-codebook-geben",
    "title": "2 Codebook",
    "section": "Sollen alle Messwiederholungen im Codebook einzeln aufgeführt werden oder soll es eine einzelne Variable für die Messwiederholung im Codebook geben?",
    "text": "Sollen alle Messwiederholungen im Codebook einzeln aufgeführt werden oder soll es eine einzelne Variable für die Messwiederholung im Codebook geben?\nPrinzipiell gilt: Das Codebook soll es aussenstehenden möglichst einfach machen, sich mit den Daten und der Analyse der Daten vertraut zu machen und diese replizieren zu können. Daher gilt: Angaben sollten vollständig sein und so exakt wie möglich. Abweichungen – wie beispielsweise Zusammenfassungen mehrerer Variablen – sind demnach nur dann möglich und sinnvoll, wenn sich die einzelnen Variablen nicht voneinander unterscheiden und dies so klarer dargestellt werden kann.",
    "crumbs": [
      "FAQ",
      "2  Codebook"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_11.html#r-u-ready-reproduzierbare-datenaufbereitung-und--analyse-mit-r",
    "href": "scripts/01_slides/EH_11.html#r-u-ready-reproduzierbare-datenaufbereitung-und--analyse-mit-r",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 11",
    "section": "R u Ready? Reproduzierbare Datenaufbereitung und -analyse mit R",
    "text": "R u Ready? Reproduzierbare Datenaufbereitung und -analyse mit R\nHS 2025 LV-Leitung: Dr. Sandra Grinschgl / MSc. Aaron Friedli Tutor: BSc. Lars Schilling11. Einheit, 24.11.2025",
    "crumbs": [
      "Präsentationen",
      "Einheit 11 - 26.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_11.html#heute",
    "href": "scripts/01_slides/EH_11.html#heute",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 11",
    "section": "Heute:",
    "text": "Heute:",
    "crumbs": [
      "Präsentationen",
      "Einheit 11 - 26.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_11.html#fragen-hands-on-block-5",
    "href": "scripts/01_slides/EH_11.html#fragen-hands-on-block-5",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 11",
    "section": "Fragen Hands On Block 5?",
    "text": "Fragen Hands On Block 5?",
    "crumbs": [
      "Präsentationen",
      "Einheit 11 - 26.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_11.html#abbildungen-visualize",
    "href": "scripts/01_slides/EH_11.html#abbildungen-visualize",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 11",
    "section": "Abbildungen: Visualize",
    "text": "Abbildungen: Visualize",
    "crumbs": [
      "Präsentationen",
      "Einheit 11 - 26.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_11.html#visualisierungen-reproduktion-der-figures-aus-grinschgl-2021",
    "href": "scripts/01_slides/EH_11.html#visualisierungen-reproduktion-der-figures-aus-grinschgl-2021",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 11",
    "section": "Visualisierungen: Reproduktion der Figures aus Grinschgl 2021",
    "text": "Visualisierungen: Reproduktion der Figures aus Grinschgl 2021",
    "crumbs": [
      "Präsentationen",
      "Einheit 11 - 26.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_11.html#visualisierungen",
    "href": "scripts/01_slides/EH_11.html#visualisierungen",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 11",
    "section": "Visualisierungen",
    "text": "Visualisierungen",
    "crumbs": [
      "Präsentationen",
      "Einheit 11 - 26.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_11.html#ggplot2",
    "href": "scripts/01_slides/EH_11.html#ggplot2",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 11",
    "section": "ggplot2()",
    "text": "ggplot2()\nSehr flexibles Paket.\n\nPlots werden schrittweise “befüllt”\n\n\n\nAlle plots beginnen mit ggplot() und dem verwendeten Datensatz\nMit aes() definieren wir die elemantaren Elemente der Plots - Variablen die geplottet werden sollen\nmit + können wir geoms, layers und weitere Elemente hinzufügen.",
    "crumbs": [
      "Präsentationen",
      "Einheit 11 - 26.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_11.html#ggplot2---cheatsheet",
    "href": "scripts/01_slides/EH_11.html#ggplot2---cheatsheet",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 11",
    "section": "ggplot2() - Cheatsheet",
    "text": "ggplot2() - Cheatsheet\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWith ggplot2, you begin a plot with the function ggplot(), defining a plot object that you then add layers to. The first argument of ggplot() is the dataset to use in the graph and so ggplot(data = penguins) creates an empty graph that is primed to display the penguins data, but since we haven’t told it how to visualize it yet, for now it’s empty. This is not a very exciting plot, but you can think of it like an empty canvas you’ll paint the remaining layers of your plot onto.\nNext, we need to tell ggplot() how the information from our data will be visually represented. The mapping argument of the ggplot() function defines how variables in your dataset are mapped to visual properties (aesthetics) of your plot. The mapping argument is always defined in the aes() function, and the x and y arguments of aes() specify which variables to map to the x and y axes. For now, we will only map flipper length to the x aesthetic and body mass to the y aesthetic. ggplot2 looks for the mapped variables in the data argument, in this case, penguins.\nTo do so, we need to define a geom: the geometrical object that a plot uses to represent data. These geometric objects are made available in ggplot2 with functions that start with geom_. People often describe plots by the type of geom that the plot uses. For example, bar charts use bar geoms (geom_bar()), line charts use line geoms (geom_line()), boxplots use boxplot geoms (geom_boxplot()), scatterplots use point geoms (geom_point()), and so on.\nZusammenhang bedeutet die Verwendung von +, dass wir einzelne Elemente eines Plot-Objektes zusammenfügen.",
    "crumbs": [
      "Präsentationen",
      "Einheit 11 - 26.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_11.html#argumente-von-ggplot",
    "href": "scripts/01_slides/EH_11.html#argumente-von-ggplot",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 11",
    "section": "Argumente von ggplot()",
    "text": "Argumente von ggplot()\n\nVariablen als Aesthetic Mappings definieren\nMapping ist immer das zweite Argument (nach dem Datensatz), “call” kann also auch verkürzt werden.\n\n\np &lt;- penguins |&gt;\n  ggplot( \n       mapping = \n         aes(x = body_mass_g, \n           y = bill_length_mm))\np",
    "crumbs": [
      "Präsentationen",
      "Einheit 11 - 26.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_11.html#ggplot---geoms",
    "href": "scripts/01_slides/EH_11.html#ggplot---geoms",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 11",
    "section": "ggplot() - Geoms",
    "text": "ggplot() - Geoms\n\nLayers Hinzufügen z.B. ein geom mit +\nGeoms = geometrische Objekte, die die Daten darstellen (z.B. Punkte, Linien)\nMuss je nachdem welche Daten man hat und wie man diese darstellen will ausgewählt werden, z.B.\n\nKategoriale Variable: geom_bar()\nKontinuierliche Variable: geom_histogram()\n2 kontinuierliche Variablen: geom_point(), geom_line()\n2 Kategoriale Variablen: geom_count()\nKategorial + Kontinuierlich: geom_boxplot(), geom_violin()",
    "crumbs": [
      "Präsentationen",
      "Einheit 11 - 26.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_11.html#ggplot---geoms-1",
    "href": "scripts/01_slides/EH_11.html#ggplot---geoms-1",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 11",
    "section": "ggplot() - Geoms",
    "text": "ggplot() - Geoms\n\np &lt;- p +\n  geom_point()\n\np",
    "crumbs": [
      "Präsentationen",
      "Einheit 11 - 26.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_11.html#ggplot---layers",
    "href": "scripts/01_slides/EH_11.html#ggplot---layers",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 11",
    "section": "ggplot() - Layers",
    "text": "ggplot() - Layers\n\nMappings können auch in den Layers definiert werden\n\n\np &lt;- p + \n  geom_point(aes(x = body_mass_g, \n           y = bill_length_mm))\n\np",
    "crumbs": [
      "Präsentationen",
      "Einheit 11 - 26.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_11.html#ggplot---layers-1",
    "href": "scripts/01_slides/EH_11.html#ggplot---layers-1",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 11",
    "section": "ggplot() - Layers",
    "text": "ggplot() - Layers\n\nTitel + Achsenbeschriftung (= labs), Regressionslinien, vereinfachtes Design\n\n\np &lt;- p +\n  geom_smooth(aes(group = 1), method = \"lm\") +\n  theme_classic() +\n  labs(\n    title = \"Relationship Between Body Mass and Bill Length\",\n    x = \"Body Mass (g)\",\n    y = \"Bill Length (mm)\"\n  )\n\np\n\n\nmit theme_ können verschiedene Formatierungen gewählt werden. theme_classic wird typischerweise für APA7 passende Formatierungen gewählt.",
    "crumbs": [
      "Präsentationen",
      "Einheit 11 - 26.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_11.html#ggplot---verschiedene-layersgeoms-kombiniert",
    "href": "scripts/01_slides/EH_11.html#ggplot---verschiedene-layersgeoms-kombiniert",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 11",
    "section": "ggplot() - Verschiedene Layers/Geoms kombiniert",
    "text": "ggplot() - Verschiedene Layers/Geoms kombiniert\n\np2 &lt;- penguins |&gt;\n  ggplot(aes(x = island, y = body_mass_g, color = island, shape = sex)) +\n  geom_boxplot() +\n  geom_jitter(alpha = 0.5)+\n  theme_classic()+\n  labs(\n    title = \"Body Mass Per Island and Species\", x = \"Island\", y = \"Body Mass (g)\")\np2\n\n\n\nAchtung: Nicht optimal formatiert, weil sonst der Plot zu klein dargestellt wird.",
    "crumbs": [
      "Präsentationen",
      "Einheit 11 - 26.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_11.html#abbildungen-speichern",
    "href": "scripts/01_slides/EH_11.html#abbildungen-speichern",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 11",
    "section": "Abbildungen speichern",
    "text": "Abbildungen speichern\n\nggsave(filename = \"my_first_plot.png\", plot = p2)",
    "crumbs": [
      "Präsentationen",
      "Einheit 11 - 26.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_11.html#weitere-ressourcen",
    "href": "scripts/01_slides/EH_11.html#weitere-ressourcen",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 11",
    "section": "Weitere Ressourcen:",
    "text": "Weitere Ressourcen:\nViel, viel mehr Möglichkeiten als wir hier besprechen, siehe z.B.:\nAuflistung von Argumenten\nggplot2 Cheatsheet\nR for Data Science – Kapitel 9 & 10:\nKapitel „Layers“\nKapitel „EDA“\nWeitere Textelemente in Abbildungen (Kapitel 11)\nHier findet man auch weitere Visualisierungsmöglichkeiten & Informationen dazu, wie man verschiedene Plots neben/untereinander abbilden kann.\nTop 50 Visualisierungen mit ggplot2\nfür Animationen, Signifikanztests, Wordclouds usw.",
    "crumbs": [
      "Präsentationen",
      "Einheit 11 - 26.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_11.html#erinnerung-statistik",
    "href": "scripts/01_slides/EH_11.html#erinnerung-statistik",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 11",
    "section": "Erinnerung Statistik",
    "text": "Erinnerung Statistik\n\nForschungsfrage/ Hyptothese aufstellen und Auswahl passender Testverfahren 👉 Bereits im Datenanalyseplan gemacht\n\nEntscheidungsbaum statistischer Testverfahren\n\nEntscheidungsbaum UZH",
    "crumbs": [
      "Präsentationen",
      "Einheit 11 - 26.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_11.html#korrelationen",
    "href": "scripts/01_slides/EH_11.html#korrelationen",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 11",
    "section": "Korrelationen",
    "text": "Korrelationen\n\nLinearer Zusammenhang zweier Variablen\nPositive Korrelation = hohe Ausprägungen einer Variable hängen mit hohen Ausprägungen einer anderen Variable zusammen\nNegative Korrelation = Hohe Ausprägungen einer Variable hängen mit niedrigen Ausprägungen einer anderen Variable zusammen\nKorrelationskoeffizient r kann von -1 bis +1 gehen\nVoraussetzung: Normalverteilung der Residuen (siehe EH 10)\nNicht-parametrische Alternative: Spearman Korrelation\n\n\ncor.test(penguins$bill_length_mm, penguins$body_mass_g)\n\n\n    Pearson's product-moment correlation\n\ndata:  penguins$bill_length_mm and penguins$body_mass_g\nt = 13.654, df = 340, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.5220040 0.6595358\nsample estimates:\n      cor \n0.5951098",
    "crumbs": [
      "Präsentationen",
      "Einheit 11 - 26.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_11.html#notation",
    "href": "scripts/01_slides/EH_11.html#notation",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 11",
    "section": "Notation",
    "text": "Notation\n\noptions(scipen = 999)\ncor.test(penguins$bill_length_mm, penguins$body_mass_g)\n\n\n    Pearson's product-moment correlation\n\ndata:  penguins$bill_length_mm and penguins$body_mass_g\nt = 13.654, df = 340, p-value &lt; 0.00000000000000022\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.5220040 0.6595358\nsample estimates:\n      cor \n0.5951098",
    "crumbs": [
      "Präsentationen",
      "Einheit 11 - 26.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_11.html#hinweise-zur-linearen-regression",
    "href": "scripts/01_slides/EH_11.html#hinweise-zur-linearen-regression",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 11",
    "section": "Hinweise zur linearen Regression",
    "text": "Hinweise zur linearen Regression\n\nTestet den Zusammenhang zwischen zwei Variablen\nEinfache lineare Regression = Korrelation\nKeine Kausalaussagen möglich (wie auch bei Korrelationen)\nVoraussetzungen: Normalverteilung der Residuen, Multikollinearität und Homoskedastizität\nNicht-parametrische Alternative: Poisson-Regression\n\n\n\nHomoskedastizität bedeutet, dass die Varianz der Residuen in einer Regressionsanalyse   für alle Werte des Prädiktors konstant ist. Das heißt, die Abweichungen der vorhergesagten Werte von den wahren Werten sind in etwa immer gleich groß – unabhängig wie hoch oder niedrig der Wert des Prädiktors ist. Um deine Regressionsanalyse sinnvoll interpretieren zu können, ist es wichtig, dass Homoskedastizität vorliegt. Homoskedastizität bildet deshalb neben einigen weiteren Aspekten (z.B. Vermeidung von Multikollinearität ) eine wichtige Voraussetzung für die lineare Regression. Heteroskedastizität Das Gegenteil von Homoskedastizität ist Heteroskedastizität. In diesem Fall verändert sich die Varianz der Residuen mit ansteigenden oder abfallenden Werten des Prädiktors. Beispielsweise kannst du bei Heteroskedastizität mit deiner Vorhersage systematisch umso weiter daneben liegen, je größer der Prädiktorwert ist, für den du dein Kriterium schätzen möchtest.",
    "crumbs": [
      "Präsentationen",
      "Einheit 11 - 26.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_11.html#einfache-lineare-regressionen",
    "href": "scripts/01_slides/EH_11.html#einfache-lineare-regressionen",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 11",
    "section": "Einfache lineare Regressionen",
    "text": "Einfache lineare Regressionen\nArgumente\n\nmodel_1 &lt;- lm(mean_rl_all ~ cvstm_propcorrect, data = dat_full)\n\nsummary(model_1)\n\n\nCall:\nlm(formula = mean_rl_all ~ cvstm_propcorrect, data = dat_full)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.1982 -0.6544 -0.1708  0.7555  3.5717 \n\nCoefficients:\n                  Estimate Std. Error t value             Pr(&gt;|t|)    \n(Intercept)         7.6277     0.8257   9.238 &lt; 0.0000000000000002 ***\ncvstm_propcorrect  -3.2993     1.1202  -2.945              0.00372 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.097 on 157 degrees of freedom\nMultiple R-squared:  0.05236,   Adjusted R-squared:  0.04632 \nF-statistic: 8.674 on 1 and 157 DF,  p-value: 0.003719",
    "crumbs": [
      "Präsentationen",
      "Einheit 11 - 26.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_11.html#regression-output",
    "href": "scripts/01_slides/EH_11.html#regression-output",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 11",
    "section": "Regression: Output",
    "text": "Regression: Output\n\n\nHier eine sehr kurze, punktuelle Zusammenfassung:\n\nIntercept (7.63): Ausgangswert von mean_rl_all, wenn cvstm_propcorrect = 0.\nSteigung (-3.30): Hoeherer cvstm_propcorrect sagt niedrigeren mean_rl_all voraus (negativer Zusammenhang\np = .0037: Zusammenhang ist signifikant.\nResiduen: Durchschnittliche Abweichung vom Modell ca. 1.10.\nR² = 0.052: Modell erklaert 5% der Varianz → kleiner Effekt.\nF-Test p = .0037: Das Gesamtmodell ist signifikant.\n\nKurz: Höhere cvstm_propcorrect-Werte gehen mit niedrigeren mean_rl_all-Werten einher, aber das Modell erklaert nur wenig Varianz.",
    "crumbs": [
      "Präsentationen",
      "Einheit 11 - 26.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_11.html#hierarchische-regression",
    "href": "scripts/01_slides/EH_11.html#hierarchische-regression",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 11",
    "section": "Hierarchische Regression",
    "text": "Hierarchische Regression\n\nMan legt zwei oder mehr Regressionsmodelle an mit zunehmenden Prädiktoren\nDann vergleicht man diese Modelle mit anova(model1, model2). Gibt es einen signifikanten Zuwachs an aufgeklärter Varianz (siehe Determinationskoeffizient) von model1 zu model2?\n\nSiehe hier: Lineare Regression mit R (einfach, multiple, hierarchisch)",
    "crumbs": [
      "Präsentationen",
      "Einheit 11 - 26.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_11.html#heute-haben-wir",
    "href": "scripts/01_slides/EH_11.html#heute-haben-wir",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 11",
    "section": "Heute haben wir:",
    "text": "Heute haben wir:\n\nBasics der Datenvisualisierungen kennengelernt\n\nErstellung von Tabellen\nggplot()\n\nKorrelationen und Regressionen in R kennengelernt\n\nReminder: R Übung bis Freitag 28.11, Peer Feedback über Forum bis 03.12.",
    "crumbs": [
      "Präsentationen",
      "Einheit 11 - 26.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_11.html#optionale-slide-korrelation-einfache-lineare-regression",
    "href": "scripts/01_slides/EH_11.html#optionale-slide-korrelation-einfache-lineare-regression",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 11",
    "section": "Optionale Slide Korrelation = Einfache lineare Regression",
    "text": "Optionale Slide Korrelation = Einfache lineare Regression\n\n\n\n    Pearson's product-moment correlation\n\ndata:  penguins$bill_length_mm and penguins$body_mass_g\nt = 13.654, df = 340, p-value &lt; 0.00000000000000022\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.5220040 0.6595358\nsample estimates:\n      cor \n0.5951098 \n\n\n\nCall:\nlm(formula = bill_length_mm ~ body_mass_g, data = penguins)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-10.1251  -3.0434  -0.8089   2.0711  16.1109 \n\nCoefficients:\n              Estimate Std. Error t value            Pr(&gt;|t|)    \n(Intercept) 26.8988724  1.2691478   21.19 &lt;0.0000000000000002 ***\nbody_mass_g  0.0040514  0.0002967   13.65 &lt;0.0000000000000002 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.394 on 340 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.3542,    Adjusted R-squared:  0.3523 \nF-statistic: 186.4 on 1 and 340 DF,  p-value: &lt; 0.00000000000000022\n\n\n\n\n[1] 0.3541557",
    "crumbs": [
      "Präsentationen",
      "Einheit 11 - 26.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_12.html#r-u-ready-reproduzierbare-datenaufbereitung-und--analyse-mit-r",
    "href": "scripts/01_slides/EH_12.html#r-u-ready-reproduzierbare-datenaufbereitung-und--analyse-mit-r",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 12",
    "section": "R u Ready? Reproduzierbare Datenaufbereitung und -analyse mit R",
    "text": "R u Ready? Reproduzierbare Datenaufbereitung und -analyse mit R\nHS 2025 LV-Leitung: Dr. Sandra Grinschgl / MSc. Aaron Friedli Tutor: BSc. Lars Schilling12. Einheit, 03.12.2025",
    "crumbs": [
      "Präsentationen",
      "Einheit 12 - 03.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_12.html#heute",
    "href": "scripts/01_slides/EH_12.html#heute",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 12",
    "section": "Heute:",
    "text": "Heute:",
    "crumbs": [
      "Präsentationen",
      "Einheit 12 - 03.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_12.html#fragen-zur-r-hausübung-2",
    "href": "scripts/01_slides/EH_12.html#fragen-zur-r-hausübung-2",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 12",
    "section": "Fragen zur R Hausübung 2??",
    "text": "Fragen zur R Hausübung 2??",
    "crumbs": [
      "Präsentationen",
      "Einheit 12 - 03.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_12.html#abgabe-simulierte-datensätze",
    "href": "scripts/01_slides/EH_12.html#abgabe-simulierte-datensätze",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 12",
    "section": "Abgabe simulierte Datensätze",
    "text": "Abgabe simulierte Datensätze\nAuf ILIAS findet ihr Ordner mit eurem Namen. Diese sind nach dem PsychDS System strukturiert. In Raw findet ihr dann eure individuellen Datensätze",
    "crumbs": [
      "Präsentationen",
      "Einheit 12 - 03.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_12.html#abschlussarbeit-leistungsnachweis",
    "href": "scripts/01_slides/EH_12.html#abschlussarbeit-leistungsnachweis",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 12",
    "section": "Abschlussarbeit / Leistungsnachweis",
    "text": "Abschlussarbeit / Leistungsnachweis",
    "crumbs": [
      "Präsentationen",
      "Einheit 12 - 03.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_12.html#simulierte-datensätze",
    "href": "scripts/01_slides/EH_12.html#simulierte-datensätze",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 12",
    "section": "Simulierte Datensätze",
    "text": "Simulierte Datensätze\n\nVorgehen: Eine Funktion simuliert Population(en) und zieht daraus zufällig Datenpunkte. Diese Zufälligkeit der Ziehung führt dazu, dass sich eure Datensätze unterscheiden!\n\n\n\nDadurch ergeben sich Unterschiede in den Hypothesentests und deskriptiven Statistiken.\n\n\n\nAber: Die Ergebnisse werden sich dennoch in einer vergleichbaren Range voneinander bewegen.",
    "crumbs": [
      "Präsentationen",
      "Einheit 12 - 03.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_12.html#plausible-ergebnisse",
    "href": "scripts/01_slides/EH_12.html#plausible-ergebnisse",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 12",
    "section": "Plausible Ergebnisse",
    "text": "Plausible Ergebnisse\n\nAngenommen der Effekt der Intervention hat wirklich keine Auswirkung auf das Offloading Verhalten der Personen (H0 ist wahr).\n\n✅H0 = Keine Gruppenunterschiede zwischen above und below gruppen.\n❌H1 = Gruppen unterscheiden sich voneinander im Offlading Verhalten.\n\n\n\n\nHypothesentest: t-Test für unabhängige Stichproben (above vs. below)\n\n\n\nWie hoch ist die Wahrscheinlichkeit das wir trotzdem ein sigifikantes Ergebnis (Fehler 1. Art) erhalten?\n\n\nAlpha-Fehler 0.05. In allen Analysen in denen wir signifikante werte erwarten (2x3 anova und mmq one-way anova) werden auch signifikante werte rauskommen (simulation so eingestellt). In den ANOVAs in denen wir nicht mit signifikanten werten rechnen, kann es sein das es per zufall trotzdem zu signifikanten werten kommt. In diesen fällen wird nicht erwartet das noch posthoc t-tests gerechnet werden.",
    "crumbs": [
      "Präsentationen",
      "Einheit 12 - 03.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_12.html#t-tests",
    "href": "scripts/01_slides/EH_12.html#t-tests",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 12",
    "section": "t-Tests",
    "text": "t-Tests\n\n\n\n\n\n\n\n\nMittelwertvergleiche\n\nFür unabhängige Stichproben: Testet, ob sich die Mittelwerte zweier unabhängiger Gruppen unterscheiden.\nFür abhängige Stichproben: Testet, ob sich die Mittelwerte derselben Personen in zwei Bedingungen (z. B. Messwiederholung) unterscheiden.\nVoraussetzungen: Normalverteilung, Varianzhomogenität\nAlternative: z. B. Welch-t-Test",
    "crumbs": [
      "Präsentationen",
      "Einheit 12 - 03.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_12.html#t-test-voraussetzungsprüfung",
    "href": "scripts/01_slides/EH_12.html#t-test-voraussetzungsprüfung",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 12",
    "section": "t-Test: Voraussetzungsprüfung",
    "text": "t-Test: Voraussetzungsprüfung\nLevene-Test\nDer Levene Test überprüft Varianzhomogenität! Varianzhomogenität bedeutet, dass alle Gruppen in einer Analyse ungeführ die gleiche Streuung aufweisen, bzw. ähnlich um ihren Mittelwert schwanken.\n\ndat_full_below_above &lt;- dat_full |&gt; \n  filter(group_all != \"control\")\n\ndat_full_below_above$group_all &lt;- as.factor(dat_full_below_above$group_all)\n\n\n\nlibrary(car)\n\nleveneTest(dat_full_below_above$pre4, dat_full_below_above$group_all)\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value Pr(&gt;F)  \ngroup   1  2.8442 0.0947 .\n      104                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1",
    "crumbs": [
      "Präsentationen",
      "Einheit 12 - 03.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_12.html#t-test-beispiel",
    "href": "scripts/01_slides/EH_12.html#t-test-beispiel",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 12",
    "section": "t-Test: Beispiel",
    "text": "t-Test: Beispiel\n\nt.test(pre4 ~ group_all, data = dat_full_below_above, var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  pre4 by group_all\nt = 7.9845, df = 104, p-value = 0.000000000001991\nalternative hypothesis: true difference in means between group above and group below is not equal to 0\n95 percent confidence interval:\n 20.25170 33.63509\nsample estimates:\nmean in group above mean in group below \n           59.66038            32.71698 \n\neffsize::cohen.d(pre4 ~ group_all, data = dat_full_below_above)\n\n\nCohen's d\n\nd estimate: 1.551045 (large)\n95 percent confidence interval:\n   lower    upper \n1.111706 1.990383",
    "crumbs": [
      "Präsentationen",
      "Einheit 12 - 03.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_12.html#grundlegende-t-test-funktionen",
    "href": "scripts/01_slides/EH_12.html#grundlegende-t-test-funktionen",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 12",
    "section": "Grundlegende t-Test-Funktionen",
    "text": "Grundlegende t-Test-Funktionen\n\n\n\n\n\n\n\nFunktion\nBeschreibung\n\n\n\n\nt.test\nAllgemeine Funktion für verschiedene t-Tests: Ein-Stichproben-, unabhängige und abhängige Stichproben.\n\n\nt.test(av, mu = x)\nEin-Stichproben-t-Test. av = abhängige Variable, x = Vergleichswert der Population.\n\n\nt.test(av ~ uv)\nWelch-t-Test für unabhängige Stichproben. av = abhängige Variable, uv = Gruppenvariable (Ungleiche Varianzen erlaubt).\n\n\nt.test(av ~ uv, var.equal = TRUE)\nKlassischer t-Test für unabhängige Stichproben (Varianzgleichheit vorausgesetzt).",
    "crumbs": [
      "Präsentationen",
      "Einheit 12 - 03.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_12.html#paired-t-test-varianzhomogenität-und-effektgrössen",
    "href": "scripts/01_slides/EH_12.html#paired-t-test-varianzhomogenität-und-effektgrössen",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 12",
    "section": "Paired t-Test, Varianzhomogenität und Effektgrössen",
    "text": "Paired t-Test, Varianzhomogenität und Effektgrössen\n\n\n\n\n\n\n\nFunktion\nBeschreibung\n\n\n\n\nt.test(av1, av2, paired = TRUE)\nt-Test für abhängige Stichproben (z. B. Prä–Post). av1 und av2 = Messzeitpunkte.\n\n\nleveneTest(av, uv) *\nLevene-Test auf Varianzhomogenität für unabhängige Gruppen. Aus dem car-Paket.\n\n\neffsize::cohen.d() *\nBerechnet Cohen’s d + Konfidenzintervall. Aus dem efffsize-Paket.",
    "crumbs": [
      "Präsentationen",
      "Einheit 12 - 03.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_12.html#heute-haben-wir",
    "href": "scripts/01_slides/EH_12.html#heute-haben-wir",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 12",
    "section": "Heute haben wir…",
    "text": "Heute haben wir…\n… uns die simulierten Datensätze für die Abschlussarbeit angeschaut.\n…Korrelationen, Regressionen und t-Tests gerechnet",
    "crumbs": [
      "Präsentationen",
      "Einheit 12 - 03.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_12.html#hausübung",
    "href": "scripts/01_slides/EH_12.html#hausübung",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 12",
    "section": "Hausübung",
    "text": "Hausübung\nR Übung 3 bis 12.12.25\nNächste Woche: Aaron übernimmt beide Gruppen\n\n\n\nwith ChatGPT",
    "crumbs": [
      "Präsentationen",
      "Einheit 12 - 03.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_14.html#r-u-ready-reproduzierbare-datenaufbereitung-und--analyse-mit-r",
    "href": "scripts/01_slides/EH_14.html#r-u-ready-reproduzierbare-datenaufbereitung-und--analyse-mit-r",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 14",
    "section": "R u Ready? Reproduzierbare Datenaufbereitung und -analyse mit R",
    "text": "R u Ready? Reproduzierbare Datenaufbereitung und -analyse mit R\nHS 2025 LV-Leitung: Dr. Sandra Grinschgl / MSc. Aaron Friedli Tutor: BSc. Lars Schilling14. Einheit, 17.12.2025",
    "crumbs": [
      "Präsentationen",
      "Einheit 14 - 17.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_14.html#heute",
    "href": "scripts/01_slides/EH_14.html#heute",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 14",
    "section": "Heute:",
    "text": "Heute:",
    "crumbs": [
      "Präsentationen",
      "Einheit 14 - 17.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_14.html#congrats",
    "href": "scripts/01_slides/EH_14.html#congrats",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 14",
    "section": "Congrats",
    "text": "Congrats",
    "crumbs": [
      "Präsentationen",
      "Einheit 14 - 17.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_14.html#fragen-zu-hausübung-3---hands-on-7",
    "href": "scripts/01_slides/EH_14.html#fragen-zu-hausübung-3---hands-on-7",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 14",
    "section": "Fragen zu Hausübung 3 - Hands On 7?",
    "text": "Fragen zu Hausübung 3 - Hands On 7?",
    "crumbs": [
      "Präsentationen",
      "Einheit 14 - 17.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_14.html#recap",
    "href": "scripts/01_slides/EH_14.html#recap",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 14",
    "section": "Recap",
    "text": "Recap\nKonzeptionelle Kompetenzen\n\nReplikationskrise und ihre Ursachen\nOpen-Science-Praktiken\nMöglichkeiten zur Steigerung der Transparenz, z. B. durch Datenanalysepläne und Codebooks\nGrundlagen des FAIR Forschungsdatenmanagement – PsychDS",
    "crumbs": [
      "Präsentationen",
      "Einheit 14 - 17.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_14.html#praktische-kompetenzen",
    "href": "scripts/01_slides/EH_14.html#praktische-kompetenzen",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 14",
    "section": "Praktische Kompetenzen",
    "text": "Praktische Kompetenzen\n\nInstallation von RStudio sowie Installation und Laden von Paketen\nAnlegen von Projekten; Einführung in die RStudio- und Quarto-Benutzeroberfläche\nCoding-Basics (z. B. Erstellen und Verändern von Vektoren, mathematische Operatoren, Arbeitsverzeichnis setzen)\nStilregeln und Fehlersuche (Error Detection) in R\nDatenimport und -export\nManipulation von Data Frames, Matrizen und Listen\nUmwandeln von Data Frames zwischen Wide- und Long-Format\nVerwendung des Pipe-Operators %&gt;% oder |&gt;",
    "crumbs": [
      "Präsentationen",
      "Einheit 14 - 17.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_14.html#praktische-kompetenzen-1",
    "href": "scripts/01_slides/EH_14.html#praktische-kompetenzen-1",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 14",
    "section": "Praktische Kompetenzen",
    "text": "Praktische Kompetenzen\n\nUmgang mit fehlenden Werten\nFiltern, Manipulieren und Gruppieren von Datensätzen (Data Wrangling)\nUmkodieren von Variablen\nBerechnen von deskriptiver Statistik (z. B. Mittelwerte, Standardabweichungen, Schiefe, Kurtosis)\nÜberprüfung der Normalverteilung inkl. visueller Darstellung der Residuen\nBerechnung von Skalenreliabilitäten\nDatenvisualisierungen\nKorrelationen und Regressionen\nt-Tests und ANOVAs (inkl. Überprüfung der Voraussetzungen und Berechnung von Effektstärken)",
    "crumbs": [
      "Präsentationen",
      "Einheit 14 - 17.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_14.html#was-wir-nicht-gemacht-haben",
    "href": "scripts/01_slides/EH_14.html#was-wir-nicht-gemacht-haben",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 14",
    "section": "Was wir nicht gemacht haben:",
    "text": "Was wir nicht gemacht haben:\n\nWiederholung/Auffrischung von Statistik\nEin „Kochbuch“ für die Masterarbeit ein Cheatsheet mit „allen Funktionen“ in R\nkomplexe statistische Analysen in R wie etwa Strukturgleichungsmodelle oder Multilevel Models\n\nSiehe weiterführende Methodenseminare der Abteilungen Gesundheitspsychologie und Psychologie der Digitalisierung",
    "crumbs": [
      "Präsentationen",
      "Einheit 14 - 17.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_14.html#errinnerung-leistungsbeurteilung",
    "href": "scripts/01_slides/EH_14.html#errinnerung-leistungsbeurteilung",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 14",
    "section": "Errinnerung Leistungsbeurteilung",
    "text": "Errinnerung Leistungsbeurteilung",
    "crumbs": [
      "Präsentationen",
      "Einheit 14 - 17.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_14.html#mitarbeit",
    "href": "scripts/01_slides/EH_14.html#mitarbeit",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 14",
    "section": "Mitarbeit",
    "text": "Mitarbeit\n\n14 Punkte Insgesamt\n7 Punkte dürft ihr euch selbst vergeben\n\n👉Umfrage auf ILIAS!",
    "crumbs": [
      "Präsentationen",
      "Einheit 14 - 17.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_14.html#mitarbeit-1",
    "href": "scripts/01_slides/EH_14.html#mitarbeit-1",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 14",
    "section": "Mitarbeit",
    "text": "Mitarbeit",
    "crumbs": [
      "Präsentationen",
      "Einheit 14 - 17.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_14.html#abschlussarbeit",
    "href": "scripts/01_slides/EH_14.html#abschlussarbeit",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 14",
    "section": "Abschlussarbeit",
    "text": "Abschlussarbeit\nDeadline 11.1.2026 - 23:55\nCheckliste auf Website",
    "crumbs": [
      "Präsentationen",
      "Einheit 14 - 17.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_14.html#feedback-möglichkeit",
    "href": "scripts/01_slides/EH_14.html#feedback-möglichkeit",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 14",
    "section": "Feedback-Möglichkeit",
    "text": "Feedback-Möglichkeit\n\nWenn du individuelles Feedback zu deiner Abschlussarbeit möchtest\nZur Zusammensetzung deiner Note\nZu anderen Seminar-bezogenen Dingen\n\n👉 Selbstständig bei und (aaron.friedli@unibe.ch / sandra.grinschgl@unibe.ch) melden!\nAaron nur mehr bis Ende Januar erreichbar!",
    "crumbs": [
      "Präsentationen",
      "Einheit 14 - 17.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_14.html#evaluation",
    "href": "scripts/01_slides/EH_14.html#evaluation",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 14",
    "section": "Evaluation",
    "text": "Evaluation\nStandardfragebogen der Uni",
    "crumbs": [
      "Präsentationen",
      "Einheit 14 - 17.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_14.html#section",
    "href": "scripts/01_slides/EH_14.html#section",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 14",
    "section": "10:15",
    "text": "10:15\nhttps://scanserveruls.unibe.ch/evasys/public/online/index/index?online_php=&pswd=F7GK9&ONLINEID=65188644261466756196721217091602273395940",
    "crumbs": [
      "Präsentationen",
      "Einheit 14 - 17.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_14.html#section-1",
    "href": "scripts/01_slides/EH_14.html#section-1",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 14",
    "section": "16:15",
    "text": "16:15\nhttps://scanserveruls.unibe.ch/evasys/public/online/index/index?online_php=&pswd=SFR8Z&ONLINEID=799329654453545430845235731708924671495875",
    "crumbs": [
      "Präsentationen",
      "Einheit 14 - 17.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_14.html#zusatzfragebogen",
    "href": "scripts/01_slides/EH_14.html#zusatzfragebogen",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 14",
    "section": "Zusatzfragebogen",
    "text": "Zusatzfragebogen\nAuf ILIAS in Ordner EH 14",
    "crumbs": [
      "Präsentationen",
      "Einheit 14 - 17.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_14.html#weiterführende-ressourcen",
    "href": "scripts/01_slides/EH_14.html#weiterführende-ressourcen",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 14",
    "section": "Weiterführende Ressourcen!",
    "text": "Weiterführende Ressourcen!",
    "crumbs": [
      "Präsentationen",
      "Einheit 14 - 17.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_14.html#methodenberatung",
    "href": "scripts/01_slides/EH_14.html#methodenberatung",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 14",
    "section": "Methodenberatung",
    "text": "Methodenberatung\nAb Januar/Februrar von Laura Hirt",
    "crumbs": [
      "Präsentationen",
      "Einheit 14 - 17.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_14.html#schöne-ferien",
    "href": "scripts/01_slides/EH_14.html#schöne-ferien",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 14",
    "section": "Schöne Ferien!",
    "text": "Schöne Ferien!",
    "crumbs": [
      "Präsentationen",
      "Einheit 14 - 17.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_5.html#r-u-ready-reproduzierbare-datenaufbereitung-und--analyse-mit-r",
    "href": "scripts/01_slides/EH_5.html#r-u-ready-reproduzierbare-datenaufbereitung-und--analyse-mit-r",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 5",
    "section": "R u Ready? Reproduzierbare Datenaufbereitung und -analyse mit R",
    "text": "R u Ready? Reproduzierbare Datenaufbereitung und -analyse mit R\nHS 2025 LV-Leitung: Dr. Sandra Grinschgl / MSc. Aaron Friedli Tutor: BSc. Lars Schilling5. Einheit, 15.10.2025",
    "crumbs": [
      "Präsentationen",
      "Einheit 5 - 15.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_5.html#heute",
    "href": "scripts/01_slides/EH_5.html#heute",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 5",
    "section": "Heute:",
    "text": "Heute:",
    "crumbs": [
      "Präsentationen",
      "Einheit 5 - 15.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_5.html#muddiest-points-umfrage",
    "href": "scripts/01_slides/EH_5.html#muddiest-points-umfrage",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 5",
    "section": "Muddiest Points Umfrage:",
    "text": "Muddiest Points Umfrage:",
    "crumbs": [
      "Präsentationen",
      "Einheit 5 - 15.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_5.html#muddiest-points-datenanalyseplan",
    "href": "scripts/01_slides/EH_5.html#muddiest-points-datenanalyseplan",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 5",
    "section": "Muddiest Points Datenanalyseplan",
    "text": "Muddiest Points Datenanalyseplan\nResearch Questions: ➡️ Für jede RQ auch ein “Statistical Model”\n\nBeeinflusst Fake-Performance Feedback die metakognitiven Überzeugungen der Versuchspersonen (im Sinne von subj. Leistungseinschätzungen) über ihre Arbeitsgedächtnisleistung? 👉 2x3 ANOVA der subj. Leistungseinschätzungen\nGibt es Unterschiede zwischen den Gruppen bezüglich des Offloading-Verhaltens im Pattern Copy Task? 👉 One-way ANOVA für jede Offloading-Variable (3x)\nExplorativ: Gibt es Unterschiede zwischen den Gruppen bezüglich der Leistung im Pattern Copy Task? 👉 One-way ANOVA für Trial Dauer\nExplorativ: Gibt es Unterschiede zwischen den Gruppen in Bezug auf den Glauben in ihre generellen Gedächtnisfähigkeiten? 👉 One-way ANOVA für MMQ\nGibt es Unterschiede zwischen den Gruppen bezüglich ihrer Gedächtnisleistung im Feature Switch Detection Task? 👉 One-way ANOVA für Arbeitsgedächtnisleistung",
    "crumbs": [
      "Präsentationen",
      "Einheit 5 - 15.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_5.html#muddiest-points-datenanalyseplan-2",
    "href": "scripts/01_slides/EH_5.html#muddiest-points-datenanalyseplan-2",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 5",
    "section": "Muddiest Points Datenanalyseplan (2)",
    "text": "Muddiest Points Datenanalyseplan (2)\nHypothesen\nBasierend auf RQ1: Wir erwarten einen Interaktionseffekt der subjektiven Leistungseinschätzung. Bei der ersten Leistungseinschätzung erwarten wir keine Unterschiede zwischen den Gruppen, während wir unmittelbar vor dem Pattern Copy Task (4te Leistungeinschätzung) Unterschiede zwischen den drei Gruppen erwarten. Die unterdurchschnittliche-Gruppe wird ihre Leistung am niedrigsten bewerten, gefolgt von der Kontrollgruppe und der „überdurchschnittlichen“-Gruppe, von der wir erwarten, dass sie ihre kommende Leistung am höchsten bewertet.\nBasierend auf RQ2: Wir erwarten, dass die Versuchspersonen, die ein unterdurchschnittliches Leistungsfeedback erhalten, sich mehr Offloading-Verhalten zeigen als Versuchspersonen mit überdurchschnittlichem Feedback, während die Kontrollgruppe (ohne Feedback) zwischen den beiden liegt.\nExplorativ: RQ3 und RQ4\nBasierend auf RQ5: Wir erwarten keine Gruppenunterschiede in Bezug auf die Arbeitsgedächtniskapazität",
    "crumbs": [
      "Präsentationen",
      "Einheit 5 - 15.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_5.html#muddiest-points-datenanalyseplan-3",
    "href": "scripts/01_slides/EH_5.html#muddiest-points-datenanalyseplan-3",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 5",
    "section": "Muddiest Points Datenanalyseplan (3)",
    "text": "Muddiest Points Datenanalyseplan (3)\nAbhängige Variablen/Measured Variables:\n\nSubjektive Leistungseinschätzungen: (für RQ1)\n\nVor jedem Task (4x) gaben die Versuchspersonen an, wie gut sie ihre bevorstehende Leistung im Vergleich zu anderen Studierenden einschätzten (0–100 Percentile).\nEin zusätzliches Post-Rating wurde nach dem Pattern Copy Task erhoben, um die eingeschätzte Leistung nach der Aufgabenbearbeitung zu erfassen.\n\nOffloading-Verhalten: (für RQ2)\n\nAnzahl der Öffnungen des Modellfensters (Mittelwert aus 20 Trials)\nAnzahl korrekt kopierter Items nach der ersten Öffnung (Mittelwert aus 20 Trials)\nDauer der ersten Öffnung (Mittelwert aus 20 Trials). \n\nLeistung im Pattern Copy Task:\n\n(für RQ3) - Trial Dauer (Mittelwert aus 20 Trials)\n\nMMQ\n\n(Mittelwert aus 18 Items) (für RQ4)\n\nArbeitsgedächtnisleistung\n\nFeature Switch Detection Task (Proportion richtiger Antworten bei 120 trials) (für RQ5)",
    "crumbs": [
      "Präsentationen",
      "Einheit 5 - 15.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_5.html#muddiest-points-datenanalyseplan-4",
    "href": "scripts/01_slides/EH_5.html#muddiest-points-datenanalyseplan-4",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 5",
    "section": "Muddiest Points Datenanalyseplan (4)",
    "text": "Muddiest Points Datenanalyseplan (4)\nAnalyses - Statistical Models\n\nBeeinflusst Fake-Performance Feedback die metakognitiven Überzeugungen der Versuchspersonen (im Sinne von subj. Leistungseinschätzungen) über ihre Arbeitsgedächtnisleistung? 👉 2x3 mixed ANOVA der «subjective performance ratings» mit post-hoc t-Tests. Unabhängige Variablen: Zeitpunkt der Selbsteinschätzung (1. vs. 4); 3 Gruppen\nGibt es Unterschiede zwischen den Gruppen bezüglich des Offloading-Verhaltens im Pattern Copy Task? 👉 One-way ANOVA für jede Offloading Variable. UV: 3 Gruppen\nExplorativ: Gibt es Unterschiede zwischen den Gruppen bezüglich der Leistung im Pattern Copy Task? 👉 One-way ANOVA für Trial Dauer. UV: 3 Gruppen\nExplorativ: Gibt es Unterschiede zwischen den Gruppen in Bezug auf den Glauben in ihre generellen Gedächtnisfähigkeiten? 👉 One-way ANOVA für MMQ mit post-hoc t-Tests. UV: 3 Gruppen\nGibt es Unterschiede zwischen den Gruppen bezüglich ihrer Gedächtnisleistung im Feature Switch Detection Task? 👉 One-way ANOVA für Arbeitsgedächtnisleistung; UV: 3 Gruppen",
    "crumbs": [
      "Präsentationen",
      "Einheit 5 - 15.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_5.html#fragen-hands-on-block-2",
    "href": "scripts/01_slides/EH_5.html#fragen-hands-on-block-2",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 5",
    "section": "Fragen Hands On Block 2?",
    "text": "Fragen Hands On Block 2?\n\n\nMergen / Full_join\nStyler",
    "crumbs": [
      "Präsentationen",
      "Einheit 5 - 15.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_5.html#reproduzierbare-auswertung-quarto",
    "href": "scripts/01_slides/EH_5.html#reproduzierbare-auswertung-quarto",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 5",
    "section": "Reproduzierbare Auswertung: Quarto",
    "text": "Reproduzierbare Auswertung: Quarto\n\nOpen Source Publishing System: Nachfolger von RMarkdown\nKombination von Text, Code und Resultaten 👉 Hohe Reproduzierbarkeit\nKann für diverse Arten von Dokumenten verwendet werden:\n✏️Dokumente & Projekte\n📊 Analysen und Reports\n🌐Websites & Blogs\n📱Slides und Shinyapps\n\n\nLive vorzeigen wie die Oberfläche von Quarto aussieht.\n\nQuarto erstellen\nNeuen Code-Chunk erstellen\nRendern und Header anpassen\nInline Code",
    "crumbs": [
      "Präsentationen",
      "Einheit 5 - 15.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_5.html#was-haben-wir-heute-gemacht",
    "href": "scripts/01_slides/EH_5.html#was-haben-wir-heute-gemacht",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 5",
    "section": "Was haben wir heute gemacht?",
    "text": "Was haben wir heute gemacht?\n\nOffene Fragen (Muddiest Points) aufgegriffen\nWichtigste Punkte im Datenanalyseplan besprochen\nQuarto kennengelernt",
    "crumbs": [
      "Präsentationen",
      "Einheit 5 - 15.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_5.html#bis-nächstes-mal",
    "href": "scripts/01_slides/EH_5.html#bis-nächstes-mal",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 5",
    "section": "Bis nächstes Mal:",
    "text": "Bis nächstes Mal:\n\nAbgabe Codebook (ILIAS und Peer–Partner:innen) bis zum 22.10.2025\n\nReminder Instruktionen:\n\nNotwendig für „gemergten“ Datensatz „dat_full“ (159 Versuchspersonen & 36 Variablen)\nVorlage ist auf Englisch, kann aber auch auf Deutsch ausgefüllt werden (selbes gilt für Datenanalyseplan)\nBasierend auf Horstmann et al. (2020)",
    "crumbs": [
      "Präsentationen",
      "Einheit 5 - 15.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_6.html#r-u-ready-reproduzierbare-datenaufbereitung-und--analyse-mit-r",
    "href": "scripts/01_slides/EH_6.html#r-u-ready-reproduzierbare-datenaufbereitung-und--analyse-mit-r",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 6",
    "section": "R u Ready? Reproduzierbare Datenaufbereitung und -analyse mit R",
    "text": "R u Ready? Reproduzierbare Datenaufbereitung und -analyse mit R\nHS 2025 LV-Leitung: Dr. Sandra Grinschgl / MSc. Aaron Friedli Tutor: BSc. Lars Schilling6. Einheit, 22.10.2025",
    "crumbs": [
      "Präsentationen",
      "Einheit 6 - 22.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_6.html#heute",
    "href": "scripts/01_slides/EH_6.html#heute",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 6",
    "section": "Heute:",
    "text": "Heute:",
    "crumbs": [
      "Präsentationen",
      "Einheit 6 - 22.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_6.html#quarto",
    "href": "scripts/01_slides/EH_6.html#quarto",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 6",
    "section": "Quarto",
    "text": "Quarto\nWir arbeiten ab jetzt immer in Quarto Dateien!\nFalls das Rendern nicht klappt -&gt; meldet euch!",
    "crumbs": [
      "Präsentationen",
      "Einheit 6 - 22.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_6.html#datentypen-vektoren",
    "href": "scripts/01_slides/EH_6.html#datentypen-vektoren",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 6",
    "section": "Datentypen: Vektoren",
    "text": "Datentypen: Vektoren\n\nVektoren\n\nNumerische Vektoren (umfasst integer und double)\nCharacter Vektoren\nLogische Vektoren\n\n\nVektoren sind eine Menge von Elementen. Vermischung von Elementen nicht möglich.\nErstellung meistens mit “c” (für combine/concatenate)\nBeispiele:\n\nnumeric_vector &lt;- c(5, 4, 5)\ncharacter_vector &lt;- c(\"Frau\", \"Mann\",\"Non-Binär\")\nlogical_vector &lt;- c(TRUE, FALSE, TRUE)\n\nEin Vektor mit nur einem Element nennen wir einen Skalar\n\nx &lt;- 5\n\n\nNumerische Vektoren (umfassen integer und double, R unterscheidet aber intern kaum zwischen „float“ und „double“)\nInteger: ganze zahlen\ndouble: zahlen mit kommastellen –&gt; Steht für double precision (wegen 64bit)",
    "crumbs": [
      "Präsentationen",
      "Einheit 6 - 22.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_6.html#datentypen-vektoren-2",
    "href": "scripts/01_slides/EH_6.html#datentypen-vektoren-2",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 6",
    "section": "Datentypen: Vektoren (2)",
    "text": "Datentypen: Vektoren (2)\nWenn Typen jedoch trotzdem vermischt werden, werden alle Elemente in denselben Typ umgewandelt – auch dann, wenn sie einzeln betrachtet eigentlich nicht zu diesem Typ gehören würden.\nAttribute von Vektoren können zum Beispiel mit typeof(), length() oder attributes() eingesehen werden.\nBeispiel:\n\nvermischter_vektor &lt;- c(2, 1, \"mann\", TRUE)\nclass(vermischter_vektor)\n\n[1] \"character\"\n\nclass(vermischter_vektor[1])\n\n[1] \"character\"",
    "crumbs": [
      "Präsentationen",
      "Einheit 6 - 22.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_6.html#datentypen-faktoren",
    "href": "scripts/01_slides/EH_6.html#datentypen-faktoren",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 6",
    "section": "Datentypen: Faktoren",
    "text": "Datentypen: Faktoren\nKategoriale bzw. nominale Variablen werden in R als Faktoren gespeichert (factor-Datentyp).\nEin Faktor ordnet den Kategorien sogenannte Levels zu, die intern als Zahlen gespeichert werden.\n🎯 Wichtig für statistische Analysen mit kategorialen Daten (z. B. ANOVA)\n\nFaktoren sorgen dafür, dass R Kategorien korrekt interpretiert – also nicht als Text oder numerische Werte.\nSie ermöglichen das Festlegen einer Referenzkategorie, die für Vergleiche in statistischen Modellen relevant ist.\nTypische Beispiele für Faktoren sind Geschlecht oder Versuchsbedingung.\n\n\nDie Referenzkategorie spielt bei der ANOVA keine Rolle für den Gesamttest (F-Test). Bei z.B. einer linearen Regression, legt die Referenzkategorie fest welche Gruppe als Basis für den Vergleich dient.",
    "crumbs": [
      "Präsentationen",
      "Einheit 6 - 22.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_6.html#datentypen-faktoren-2",
    "href": "scripts/01_slides/EH_6.html#datentypen-faktoren-2",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 6",
    "section": "Datentypen: Faktoren (2)",
    "text": "Datentypen: Faktoren (2)\nBeispiel: Geschlecht als Faktorstufen\n\ngeschlecht &lt;- c(\"male\", \"female\", \"nonbinary\", \"female\", \"male\",\"nonbinary\")\n\ngeschlecht_faktor &lt;- factor(geschlecht)\n\nlevels(geschlecht_faktor)\n\n[1] \"female\"    \"male\"      \"nonbinary\"\n\n\nFaktoren können auch numerisch sein, werden dann aber nicht mehr als Zahlen behandelt.\n\nnumerisch &lt;- c(1, 2, 2, 1, 2, 3, 2, 1)\n\nfaktorstufen_numerisch &lt;- factor(numerisch)\n\nlevels(faktorstufen_numerisch)\n\n[1] \"1\" \"2\" \"3\"\n\n\n🤔 Welche Variable(n) sollten in den Daten von Grinschgl et al. (2020) zu Faktoren transformiert werden?\n\nDie Faktorstufen werden standardmässig alphabetisch festgelegt.\nIn Grinschgl2020 werden group_all als Faktor bestimmt, und nach der transformation zu einem Long Datensatz (kommende Wochen) auch noch time_rating.",
    "crumbs": [
      "Präsentationen",
      "Einheit 6 - 22.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_6.html#datentypen-listen-1",
    "href": "scripts/01_slides/EH_6.html#datentypen-listen-1",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 6",
    "section": "Datentypen: Listen (1)",
    "text": "Datentypen: Listen (1)\nEine Liste ist ein flexibles Datenobjekt, das Elemente unterschiedlicher Typen enthalten kann (z. B. Zahlen, Zeichen, Vektoren, Dataframes, andere Listen).\n\nmy_list &lt;- list(\n  name = \"Anna\",\n  age = 27,\n  scores = c(8, 9, 10),\n  info = list(city = \"Bern\", student = TRUE)\n)\n\nmy_list\n\n$name\n[1] \"Anna\"\n\n$age\n[1] 27\n\n$scores\n[1]  8  9 10\n\n$info\n$info$city\n[1] \"Bern\"\n\n$info$student\n[1] TRUE",
    "crumbs": [
      "Präsentationen",
      "Einheit 6 - 22.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_6.html#datentypen-listen-2",
    "href": "scripts/01_slides/EH_6.html#datentypen-listen-2",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 6",
    "section": "— Datentypen: Listen (2)",
    "text": "— Datentypen: Listen (2)\nAuf Listen zugreifen:\nMit [ ] 👉 gibt einen Element der Liste zurück\n\nmy_list[1]\n\n$name\n[1] \"Anna\"\n\n\n\nMit [[ ]]\n\n\nmy_list[[3]]\n\n[1]  8  9 10\n\nmy_list[[3]][2]\n\n[1] 9\n\n\n\nMit $\n\n\nmy_list$info\n\n$city\n[1] \"Bern\"\n\n$student\n[1] TRUE\n\nmy_list$info[2]\n\n$student\n[1] TRUE",
    "crumbs": [
      "Präsentationen",
      "Einheit 6 - 22.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_6.html#datentypen-listen-2-1",
    "href": "scripts/01_slides/EH_6.html#datentypen-listen-2-1",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 6",
    "section": "Datentypen: Listen (2)",
    "text": "Datentypen: Listen (2)\nListen Elemente hinzufügen\n\nmy_list[[5]] &lt;- 42\nmy_list\n\n$name\n[1] \"Anna\"\n\n$age\n[1] 27\n\n$scores\n[1]  8  9 10\n\n$info\n$info$city\n[1] \"Bern\"\n\n$info$student\n[1] TRUE\n\n\n[[5]]\n[1] 42",
    "crumbs": [
      "Präsentationen",
      "Einheit 6 - 22.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_6.html#datentypen-matrizen",
    "href": "scripts/01_slides/EH_6.html#datentypen-matrizen",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 6",
    "section": "Datentypen: Matrizen",
    "text": "Datentypen: Matrizen\nEine Matrix ist eine zweidimensionale Datenstruktur:\n\nSie besteht aus Zeilen und Spalten.\nAlle Elemente müssen vom gleichen Datentyp sein (z. B. nur numerisch).\nEine Matrix kann zum Beispiel aus einem Vektor erstellt werden, dem anschließend Dimensionen (Zeilen und Spalten) zugewiesen werden.\n\nBeispiel:\n\nv &lt;- 1:20\ndim(v) &lt;- c(2, 10) #Argumente: \nv\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n[1,]    1    3    5    7    9   11   13   15   17    19\n[2,]    2    4    6    8   10   12   14   16   18    20\n\n\n\nattributes(v)\n\n$dim\n[1]  2 10\n\n\n\nDim ist hier keine Funktion sondern ein Attribut.",
    "crumbs": [
      "Präsentationen",
      "Einheit 6 - 22.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_6.html#datentypen-matrizen-2",
    "href": "scripts/01_slides/EH_6.html#datentypen-matrizen-2",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 6",
    "section": "Datentypen: Matrizen (2)",
    "text": "Datentypen: Matrizen (2)\nErstellen von Matrizen\nBeispiel:\n\nMatrix mit den Zahlen 1–20, 2 Zeilen und 10 Spalten, die Werte werden spaltenweise eingefügt.\n\n\nm &lt;- matrix(1:20, nrow = 2, ncol = 10, byrow = FALSE)\n\nAuf einzelne Elemente einer Matrix greift man mit eckigen Klammern zu: matrix_name[zeile, spalte]\nWelche Werte sollten hier rauskommen?\n\nm[2, 4]\nm[2, 1:5]\n\n🤔 Ist der Datensatz dat_full eine Matrix?\n\n\nZweite Zeile, 4te Spalte –&gt; 8\n2, 4, 6, 8, 10. -&gt; Zweite Zeile, erste bis 5te spalte.",
    "crumbs": [
      "Präsentationen",
      "Einheit 6 - 22.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_6.html#datentypen-data-frames",
    "href": "scripts/01_slides/EH_6.html#datentypen-data-frames",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 6",
    "section": "Datentypen: Data Frames",
    "text": "Datentypen: Data Frames\n\nSind tabellarisch aufgebaut\nSpalten können unterschiedliche Datentypen enthalten\nJede Spalte gleich lang (ggf, auffüllen mit NAs)\n\n👉 Ist meistens das Format in dem wir Daten speichern und verarbeiten.\nWenn wir Datensätze einlesen, werden diese als Data Frames in R repräsentiert.",
    "crumbs": [
      "Präsentationen",
      "Einheit 6 - 22.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_6.html#datentypen-data-frames-2",
    "href": "scripts/01_slides/EH_6.html#datentypen-data-frames-2",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 6",
    "section": "Datentypen: Data Frames (2)",
    "text": "Datentypen: Data Frames (2)\n\nData Frame erstellen\n\n\nbundesrät_innen &lt;- data.frame(\n  vorname = c(\"Elisabeth\", \"Martin\", \"Ignazio\"),\n  alter = c(62, 63, 65),\n  partei = c(\"SP\", \"Mitte\", \"FDP\"),\n  graue_haare = c(TRUE, TRUE, FALSE)\n)\n\nhead(bundesrät_innen)\n\n    vorname alter partei graue_haare\n1 Elisabeth    62     SP        TRUE\n2    Martin    63  Mitte        TRUE\n3   Ignazio    65    FDP       FALSE\n\nbundesrät_innen$graue_haare\n\n[1]  TRUE  TRUE FALSE",
    "crumbs": [
      "Präsentationen",
      "Einheit 6 - 22.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_6.html#datentypen-dataframes-3",
    "href": "scripts/01_slides/EH_6.html#datentypen-dataframes-3",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 6",
    "section": "Datentypen: Dataframes (3)",
    "text": "Datentypen: Dataframes (3)\n\nAuf Elemente zugreifen\n\n\nbundesrät_innen[3,\"grauhaarig\"]\n\nNULL\n\nbundesrät_innen$alter\n\n[1] 62 63 65\n\n\n\nFiltern / Auswählen\n\n\nlibrary(tidyverse)\nbrs_unter_63 &lt;- filter(bundesrät_innen, alter &lt; 63)\nhead(brs_unter_63)\n\n    vorname alter partei graue_haare\n1 Elisabeth    62     SP        TRUE\n\n\n\nModifizieren\n\n\nbundesrät_innen$alter_in_10_jahren &lt;- bundesrät_innen$alter + 10\nhead(bundesrät_innen)\n\n    vorname alter partei graue_haare alter_in_10_jahren\n1 Elisabeth    62     SP        TRUE                 72\n2    Martin    63  Mitte        TRUE                 73\n3   Ignazio    65    FDP       FALSE                 75",
    "crumbs": [
      "Präsentationen",
      "Einheit 6 - 22.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_6.html#heute-haben-wir",
    "href": "scripts/01_slides/EH_6.html#heute-haben-wir",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 6",
    "section": "Heute haben wir:",
    "text": "Heute haben wir:\n\nVerschiedene Datentypen angeschaut:\n\nVektoren\nFaktoren\nListen\nMatrizen\nDataframes",
    "crumbs": [
      "Präsentationen",
      "Einheit 6 - 22.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_6.html#bis-nächstes-mal",
    "href": "scripts/01_slides/EH_6.html#bis-nächstes-mal",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 6",
    "section": "Bis nächstes Mal:",
    "text": "Bis nächstes Mal:\n\nPeer-Feedback: Codebook\nTo Do‘s: Codebook des Partners/der Partnerin bis EH7 durchschauen und kommentieren (am besten mit Excel Kommentar-Funktion oder Notizen in zusätzlicher Datei) 👉 sind ALLE Variablen mit ausreichens Detail beschrieben?\nUpload auf Ilias mit Kommentaren + Weitergabe an Partner:in Auch persönliches Feedback erwünscht 👉 selbstorganisiert\n\nSelbständigkeit: Wir geben kein Feedback, bei Fragen auf uns zukommen (Forum, Sprechstunde etc. nutzen)\n\nHands On Block 3 abschliessen!",
    "crumbs": [
      "Präsentationen",
      "Einheit 6 - 22.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_3.html#r-u-ready-reproduzierbare-datenaufbereitung-und--analyse-mit-r",
    "href": "scripts/01_slides/EH_3.html#r-u-ready-reproduzierbare-datenaufbereitung-und--analyse-mit-r",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 3",
    "section": "R u Ready? Reproduzierbare Datenaufbereitung und -analyse mit R",
    "text": "R u Ready? Reproduzierbare Datenaufbereitung und -analyse mit R\nHS 2025 LV-Leitung: Dr. Sandra Grinschgl / MSc. Aaron Friedli Tutor: BSc. Lars Schilling3. Einheit, 01.10.2025",
    "crumbs": [
      "Präsentationen",
      "Einheit 3 - 01.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_3.html#achtung",
    "href": "scripts/01_slides/EH_3.html#achtung",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 3",
    "section": "Achtung",
    "text": "Achtung\n❗Neue Website Domain ❗\nhttps://r-you-ready.github.io/HS2025/front_page.html\nLink wurde in Ilias wurde aktualisiert",
    "crumbs": [
      "Präsentationen",
      "Einheit 3 - 01.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_3.html#fragen-zum-datenanalyseplan",
    "href": "scripts/01_slides/EH_3.html#fragen-zum-datenanalyseplan",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 3",
    "section": "Fragen zum Datenanalyseplan:",
    "text": "Fragen zum Datenanalyseplan:",
    "crumbs": [
      "Präsentationen",
      "Einheit 3 - 01.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_3.html#fragen-zu-den-hands-on-übungen-der-ersten-beiden-wochen",
    "href": "scripts/01_slides/EH_3.html#fragen-zu-den-hands-on-übungen-der-ersten-beiden-wochen",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 3",
    "section": "Fragen zu den Hands On Übungen der ersten beiden Wochen?",
    "text": "Fragen zu den Hands On Übungen der ersten beiden Wochen?\n\nWas hat euch Schwierigkeiten bereitet?\nWelche Übungen sollen wir gemeinsam live durchgehen?\nGibt es noch Unklarheiten?\nMusterlösungen ab jetzt online für Block 1!",
    "crumbs": [
      "Präsentationen",
      "Einheit 3 - 01.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_3.html#heute",
    "href": "scripts/01_slides/EH_3.html#heute",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 3",
    "section": "Heute:",
    "text": "Heute:",
    "crumbs": [
      "Präsentationen",
      "Einheit 3 - 01.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_3.html#peer-pairings",
    "href": "scripts/01_slides/EH_3.html#peer-pairings",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 3",
    "section": "Peer-Pairings",
    "text": "Peer-Pairings\nsiehe Liste auf Ilias\n\nListe zeigen, Namen aufrufen und zusammensetzen lassen",
    "crumbs": [
      "Präsentationen",
      "Einheit 3 - 01.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_3.html#forschungsdatenmanagement",
    "href": "scripts/01_slides/EH_3.html#forschungsdatenmanagement",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 3",
    "section": "Forschungsdatenmanagement:",
    "text": "Forschungsdatenmanagement:\nPlanung, Organisation, Speicherung, Dokumentation und Archivierung von Daten während des gesamten Forschungsprozesses\n\n\nWarum Datenmanagement:\n\nDatenflut in der Forschung\nRisiken ohne gutes Management\n\nZiele von Datenmanagement:\n\nQualitätssicherung\nSicherheit/Datenschutz & Ethik\nReproduzierbarkeit\nNachhaltigkeit und Transparenz",
    "crumbs": [
      "Präsentationen",
      "Einheit 3 - 01.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_3.html#forschungsdatenmanagement-2",
    "href": "scripts/01_slides/EH_3.html#forschungsdatenmanagement-2",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 3",
    "section": "Forschungsdatenmanagement (2)",
    "text": "Forschungsdatenmanagement (2)\n\n\nStandards & Vorgaben:\n\nFair Prinzipien\nData Management Plan (SNF)\nFörderorganisationen & Journals\n\nPraktische Umsetzung:\n\nOrdnerstrukturen & Versionierung\nDokumentation (README, Codebooks)\nOffene Dateiformate\n\n\n\n\nF – auffindbar (aus Wikipedia: https://de.wikipedia.org/wiki/FAIR-Prinzipien)\n[Bearbeiten | Quelltext bearbeiten]\n\nF1 (Meta-)Daten sind mit einem weltweit eindeutigen und dauerhaften persistent identifier versehen.\nF2 (Meta-)Daten werden mit umfangreichen Metadaten beschrieben.\nF3 (Meta-)Daten sind in einer durchsuchbaren Ressource registriert oder indiziert.\nF4 (Meta-)Daten enthalten eine klare und eindeutige Identifizierung der Daten, die sie beschreiben.\n\nA – zugänglich\n[Bearbeiten | Quelltext bearbeiten]\n\nA1 (Meta-)Daten können anhand ihrer Identifizierung über ein standardisiertes Kommunikationsprotokoll abgerufen werden.\n\nA1.1 das Protokoll ist offen, frei und universell implementierbar.\nA1.2 das Protokoll ermöglicht bei Bedarf ein Authentifizierungs- und Autorisierungsverfahren.\n\nA2 – (Meta-)Daten sind zugänglich, auch wenn die Daten nicht mehr verfügbar sind.\n\nI – interoperabel\n[Bearbeiten | Quelltext bearbeiten]\n\nI1 (Meta-)Daten verwenden eine formale, zugängliche, gemeinsame und weithin anwendbare Sprache zur Wissensdarstellung.\nI2 (Meta-)Daten verwenden Vokabulare, die den FAIR-Grundsätzen entsprechen.\nI3 (Meta-)Daten enthalten qualifizierte Verweise auf andere (Meta-)Daten.\n\nR – wiederverwendbar\n[Bearbeiten | Quelltext bearbeiten]\n\nR1 (Meta-)Daten haben mehrere genaue und relevante Attribute.\n\nR1.1 (Meta-)Daten werden mit einer klaren und zugänglichen Datennutzungslizenz freigegeben.\nR1.2 (Meta-)Daten sind mit ihrer Herkunft verbunden.\nR1.3 (Meta-)Daten entsprechen den für den Bereich relevanten Gemeinschaftsstandards.",
    "crumbs": [
      "Präsentationen",
      "Einheit 3 - 01.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_3.html#ordnerstrukturen-psych-ds",
    "href": "scripts/01_slides/EH_3.html#ordnerstrukturen-psych-ds",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 3",
    "section": "Ordnerstrukturen: Psych-DS",
    "text": "Ordnerstrukturen: Psych-DS\n\nStandard für die Organisation von Daten, Skripten und weiteren Studiendokumenten\n\n\nEin Standard von vielen Möglichen\nPsych-DS\n\nHier auch Ordner und Files die wir für unsere Zwecke nicht verwenden werden. Z.B. Github Files, sind zwar gut für Version Control und ein wichtiges Tool, aber würde den Rahmen sprengen.",
    "crumbs": [
      "Präsentationen",
      "Einheit 3 - 01.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_3.html#psych-ds-für-unsere-zwecke",
    "href": "scripts/01_slides/EH_3.html#psych-ds-für-unsere-zwecke",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 3",
    "section": "Psych-DS für unsere Zwecke:",
    "text": "Psych-DS für unsere Zwecke:\n\nLeicht Abgeändertes Format für unser Seminar\n\nMacht es leichter für uns die Abgaben zu kontrollieren\n\nHilft euch eine übersichtliche Ordnerstruktur zu behalten",
    "crumbs": [
      "Präsentationen",
      "Einheit 3 - 01.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_3.html#psych-ds-wichtigste-grundsätze",
    "href": "scripts/01_slides/EH_3.html#psych-ds-wichtigste-grundsätze",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 3",
    "section": "Psych-DS: Wichtigste Grundsätze",
    "text": "Psych-DS: Wichtigste Grundsätze\n\nDatensätze nur in “data”.\n\nDie Rohdatenfiles werden nicht bearbeitet!\nDer aufbereitete Datensatz -&gt; data/processed\n\nCodebook in Ordner “data”\nDatenanalyseplan in “preregistration”\nSkripte in “code”\n\nAufbereitungsschritte im Skript “processing”\nAnalyse (mit dem processed datensatz) im Skript “analysis”\n\nKeine Redundanzen!\n\nKeine redundanten Dateien\nKeine redundanten Pakete (Nur Pakete laden, die auch verwendet werden).\n\n\nBewertungsrelevant für die Abschlussarbeit",
    "crumbs": [
      "Präsentationen",
      "Einheit 3 - 01.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_3.html#psychdsish-styler",
    "href": "scripts/01_slides/EH_3.html#psychdsish-styler",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 3",
    "section": "Psychdsish & Styler",
    "text": "Psychdsish & Styler\n\n📦 Packages welche helfen sollen Psych-DS Struktur & Stylevorgaben leichter einzuhalten.\nFür Masterarbeiten: Psychdsish\nFunktionen wie: create_project_skeleton(), check_unused_objects(), validator()\n🥅 Ziel: Einhaltung von Standards erleichtern\n👗Styler: Funktion um “unschön” formatierten Code leserlicher zu machen. 👉 Hands On!",
    "crumbs": [
      "Präsentationen",
      "Einheit 3 - 01.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_3.html#wiederholung-benennung-von-variablen-ect.-in-r",
    "href": "scripts/01_slides/EH_3.html#wiederholung-benennung-von-variablen-ect.-in-r",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 3",
    "section": "Wiederholung: Benennung von Variablen ect. in R",
    "text": "Wiederholung: Benennung von Variablen ect. in R\n\nNamen können aus Buchstaben, Zahlen und Zeichen (_ oder .) bestehen\nEr muss mit Buchstaben begonnen werden und darf keine Leerzeichen beinhalten\nSonderzeichen und Großbuchstaben sollten vermieden werden Keine Namen verwenden, die schon an Funktionen vergeben sind (z.B. mean())\nEmpfehlung für einen leserlichen Code: snake_case\nName soll Variable inhaltlich bestmöglich beschreiben\nReproduzierbarkeit; „clarity instead of brevity“\nBenennung am besten in Englisch um internationalen Standards zu folgen\nKommentierung von R-Code mit #\n\nText nach # wird ignoriert (für 1 Zeile)\nNeue Zeilen müssen wieder mit # beginnen",
    "crumbs": [
      "Präsentationen",
      "Einheit 3 - 01.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_3.html#weitere-style-konventionen",
    "href": "scripts/01_slides/EH_3.html#weitere-style-konventionen",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 3",
    "section": "Weitere Style Konventionen:",
    "text": "Weitere Style Konventionen:\n\nLeerzeichen:\n\nVor und nach mathematischen Operatoren: 2+2 vs 2 + 2\nVor und nach Zuweisungen: x&lt;-sum(1+2) vs x &lt;- sum(1 + 2)\nAber nicht vor und nach sich öffnenden oder schließenden Klammern oder Anführungszeichen\nNach Kommas (aber nicht davor)\nWeitere Leerzeichen erlaubt wenn die Leserlichkeit erhöht wird (z.B. bei Einrückungen)\n\nVerwendung des Pipe Operators (%&gt;% oder |&gt; ) –&gt; Erklärung folgt in kommenden Wochen!\nZeilenumbrüche für langen Code verwenden\n\nthis_is_a_very_long_function_name &lt;- (something = \"this\", requires = \"many\", arguments = \"long words and sentences\") #–&gt; bad\n\nthis_is_a_very_long_function_name &lt;- (something = \"this\", \n                                      requires = \"many\", \n                                      arguments = \"long words and sentences\") #–&gt; good\n\nStyler: Funktion die Code automatisch in dieses Format bringt. 👉 Hands On!",
    "crumbs": [
      "Präsentationen",
      "Einheit 3 - 01.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_3.html#weitere-style-konventionen-1",
    "href": "scripts/01_slides/EH_3.html#weitere-style-konventionen-1",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 3",
    "section": "Weitere Style Konventionen:",
    "text": "Weitere Style Konventionen:\n📖 Lesbarkeit für Menschen und Maschine\n🧑‍💻 Für Menschen: Verwende aussagekräftige Dateinamen, die klar beschreiben, was in der Datei enthalten ist.\n💻 Für Maschinen: Vermeide Leerzeichen, Sonderzeichen und Symbole in Dateinamen – bleibe bei Buchstaben, Zahlen und Unterstrichen.\n🔢 Struktur: Benenne Dateien so, dass sie auch mit der Standard-Sortierung von Ordnern sinnvoll angeordnet werden. Ein bewährter Ansatz ist, mit Zahlen zu beginnen, um eine logische Reihenfolge abzubilden.",
    "crumbs": [
      "Präsentationen",
      "Einheit 3 - 01.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_3.html#codebook",
    "href": "scripts/01_slides/EH_3.html#codebook",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 3",
    "section": "Codebook",
    "text": "Codebook\n\nNaive Personen sollen Datensatz nachvollziehen können (Reproduzierbarkeit & Zusatzanalysen)\nBeinhaltet eine Liste und Beschreibung aller Variablen, z.B.\n\nWie wurde die Variable erhoben (z.B. aus welchem Fragebogen)?\nWie wurde die Variable berechnet (z.B. Summenscore, Mittelwert)?\nWelche Werte kann die Variable annehmen (theoretisches Minimum und Maximum)?",
    "crumbs": [
      "Präsentationen",
      "Einheit 3 - 01.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_3.html#wichtige-grundsätze-für-das-codebook",
    "href": "scripts/01_slides/EH_3.html#wichtige-grundsätze-für-das-codebook",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 3",
    "section": "Wichtige Grundsätze für das Codebook",
    "text": "Wichtige Grundsätze für das Codebook\n\nAm besten für Rohdaten als auch weiter-verarbeitete Daten\n\n\n\nVariablennamen in Codebook sollen identisch zu Variablennamen in Datensatz sein\nVariable muss ausführlich genug beschrieben sein, sodass andere Personen es nachvollziehen können",
    "crumbs": [
      "Präsentationen",
      "Einheit 3 - 01.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_3.html#codebook-vorlage",
    "href": "scripts/01_slides/EH_3.html#codebook-vorlage",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 3",
    "section": "Codebook: Vorlage",
    "text": "Codebook: Vorlage\n\nKann in verschiedenen Formaten erstellt werden (Word, Excel, ect.)\nExcel-Vorlage für das Seminar (siehe ZIP Datei Abschlussprojekt)\nBeispiel: “Example_Codebook” - Ordner\nFür weitere Anleitungen siehe “Guideline Codebook”\n\nSiehe auch: Pennington (2023)\n\nBuch von Pennington kann man bei Bedarf in Bib oder bei Sandra ausborgen",
    "crumbs": [
      "Präsentationen",
      "Einheit 3 - 01.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_3.html#rohdaten-für-grinschgl-et-al.-2020",
    "href": "scripts/01_slides/EH_3.html#rohdaten-für-grinschgl-et-al.-2020",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 3",
    "section": "Rohdaten für Grinschgl et al. (2020)",
    "text": "Rohdaten für Grinschgl et al. (2020)\n\nBereits vorhanden in euren Ordnern (r_you_ready)\nWir mergen diese heute oder in EH4 zu einem vollständigen Datensatz –&gt; dat_full",
    "crumbs": [
      "Präsentationen",
      "Einheit 3 - 01.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_3.html#codebook-1",
    "href": "scripts/01_slides/EH_3.html#codebook-1",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 3",
    "section": "Codebook",
    "text": "Codebook\n\nNotwendig für „gemergten“ Datensatz „dat_full“\nVorlage ist auf Englisch, kann aber auch auf Deutsch ausgefüllt werden (selbes gilt für Datenanalyseplan)\nBasierend auf Horstmann et al. (2020)\nAbgabe bis EH6 (22.10) über ILIAS und via Email an Peer-Partner:in\nDanach Peer Feedback\n\nIdealerweise Codebook auch für Rohdaten, aber für das Seminar nur für dat_full",
    "crumbs": [
      "Präsentationen",
      "Einheit 3 - 01.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_3.html#beispiel-codebook-bfi",
    "href": "scripts/01_slides/EH_3.html#beispiel-codebook-bfi",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 3",
    "section": "Beispiel Codebook BFI",
    "text": "Beispiel Codebook BFI\nDemo Beispiel:\n\nWir fügen nun live einige Variablen in das Codebook ein. Versucht die Schritte nachzuvollziehen und stellt Fragen bei Unklarheiten.",
    "crumbs": [
      "Präsentationen",
      "Einheit 3 - 01.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_3.html#reproduzierbare-auswertung-grundsätze",
    "href": "scripts/01_slides/EH_3.html#reproduzierbare-auswertung-grundsätze",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 3",
    "section": "Reproduzierbare Auswertung: Grundsätze",
    "text": "Reproduzierbare Auswertung: Grundsätze\n\nDigitale Rohdaten\nSkript soll den gesamten Weg von den Rohdaten bis hin zu den Ergebnissen dokumentieren\nWenn man euren Code auf den Rohdaten laufen lässt, sollte man (fehlerfrei) zu den Ergebnissen kommen\nSkript ist kommentiert und sinnvoll gegliedert",
    "crumbs": [
      "Präsentationen",
      "Einheit 3 - 01.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_3.html#hands-on",
    "href": "scripts/01_slides/EH_3.html#hands-on",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 3",
    "section": "Hands on!",
    "text": "Hands on!\n\nProjekte\nDaten einlesen\nDaten speichern\nFortsetzung Coding Basics",
    "crumbs": [
      "Präsentationen",
      "Einheit 3 - 01.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_3.html#heute-haben-wir",
    "href": "scripts/01_slides/EH_3.html#heute-haben-wir",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 3",
    "section": "Heute haben wir…",
    "text": "Heute haben wir…\n… Uns mit den Grundlagen von Forschungsdatenmanagement beschäftigt\n… Psych-DS als einen Standard kennengelernt\n…Style-Empfehlungen für R Code besprochen\n…die Gründe für und den Aufbau von einem Codebook besprochen\n…Datensätze in R importiert\n…diese gemerged und exportiert (Fortsetzung in EH 4)",
    "crumbs": [
      "Präsentationen",
      "Einheit 3 - 01.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_3.html#hausübungen",
    "href": "scripts/01_slides/EH_3.html#hausübungen",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 3",
    "section": "Hausübungen",
    "text": "Hausübungen\n\nCodebook erstellen bis Mi 22.10.2025\nReminder: Datenanalyseplan bis Mi 08.10.2025",
    "crumbs": [
      "Präsentationen",
      "Einheit 3 - 01.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_3.html#literatur",
    "href": "scripts/01_slides/EH_3.html#literatur",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 3",
    "section": "Literatur:",
    "text": "Literatur:\nHorstmann, K. T., Arslan, R. C., & Greiff, S. (2020). Generating Codebooks to Ensure the Independent Use of Research Data: Some Guidelines. European Journal of Psychological Assessment, 36(5), 721–729. https://doi.org/10.1027/1015-5759/a000620\nPennington, C. R. (2023). A student’s guide to open science: Using the replication crisis to reform psychology. McGraw Hill.",
    "crumbs": [
      "Präsentationen",
      "Einheit 3 - 01.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_1.html#r-u-ready-reproduzierbare-datenaufbereitung-und--analyse",
    "href": "scripts/01_slides/EH_1.html#r-u-ready-reproduzierbare-datenaufbereitung-und--analyse",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 1",
    "section": "R u Ready? Reproduzierbare Datenaufbereitung und -analyse",
    "text": "R u Ready? Reproduzierbare Datenaufbereitung und -analyse\nHS 2025 LV-Leitung: Dr. Sandra Grinschgl / MSc. Aaron Friedli Tutor: BSc. Lars Schilling1. Einheit, 17.09.2025",
    "crumbs": [
      "Präsentationen",
      "Einheit 1 - 17.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_1.html#lv-leitung",
    "href": "scripts/01_slides/EH_1.html#lv-leitung",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 1",
    "section": "LV-Leitung",
    "text": "LV-Leitung\n\n\nDr. Sandra Grinschgl (sie/ihr)\n\nDozentur für «Mensch in digitaler Transformation»\n\nArbeitsbereich Psychologie der Digitalisierung\n\nFabrikstrasse 8, Raum D 262\n\nsandra.grinschgl@unibe.ch\n\nSprechstunde nach Vereinbarung\n\nFun Fact: ist fasziniert davon wie sich Schweizer:innen den Zahnarzt leisten können",
    "crumbs": [
      "Präsentationen",
      "Einheit 1 - 17.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_1.html#lv-leitung-2",
    "href": "scripts/01_slides/EH_1.html#lv-leitung-2",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 1",
    "section": "LV-Leitung (2)",
    "text": "LV-Leitung (2)\n\n\nAaron Friedli (er/ihm) (MSc. Psychologie)\n\nLehrassistenz R you Ready / Methodenberatung\n\nFabrikstrasse 8, A263\n\nSprechstunde/Methodenberatung nach Vereinbarung\n\naaron.friedli@unibe.ch\nWeiss nie, ob ich ‘R’ Englisch oder Deutsch aussprechen soll.",
    "crumbs": [
      "Präsentationen",
      "Einheit 1 - 17.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_1.html#lv-leitung-3",
    "href": "scripts/01_slides/EH_1.html#lv-leitung-3",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 1",
    "section": "LV-Leitung (3)",
    "text": "LV-Leitung (3)\n\n\nLars Schilling (er/ihm)(BSc. Psychologie)\n\nTutor R you Ready\n\nFabrikstrasse 8, D266\n\nSprechstunde nach Vereinbarung\n\nlars.schilling@unibe.ch\nWundert sich noch immer über die pünktlichen Züge in der Schweiz",
    "crumbs": [
      "Präsentationen",
      "Einheit 1 - 17.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_1.html#barrierefreiheit",
    "href": "scripts/01_slides/EH_1.html#barrierefreiheit",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 1",
    "section": "Barrierefreiheit!",
    "text": "Barrierefreiheit!\nBitte melde dich auf einem für dich angemessenem Weg bei uns, wenn dir in dieser Lehrveranstaltung Barrieren begegnen, die auszugleichen sind.",
    "crumbs": [
      "Präsentationen",
      "Einheit 1 - 17.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_1.html#pronomennamen",
    "href": "scripts/01_slides/EH_1.html#pronomennamen",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 1",
    "section": "Pronomen/Namen",
    "text": "Pronomen/Namen\nBitte gebt uns auch Bescheid, falls wir euch falsch ansprechen!\n\nIllustration: Freepik",
    "crumbs": [
      "Präsentationen",
      "Einheit 1 - 17.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_1.html#österreichisch-vs.-berndeutsch",
    "href": "scripts/01_slides/EH_1.html#österreichisch-vs.-berndeutsch",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 1",
    "section": "Österreichisch vs. Berndeutsch",
    "text": "Österreichisch vs. Berndeutsch\nBitte gebt mir/uns auch Bescheid solltet ihr etwas nicht verstehen! Seht es uns nach falls wir etwas nicht verstehen und nachfragen!\n\n\n\n\n\nUhrturm Graz: Foto C. Stadler/Bwag\n\n\n\n\n\n\nFoto: https://en.wikipedia.org/wiki/Zytglogge#/media/File:Zytglogge_01.jpg",
    "crumbs": [
      "Präsentationen",
      "Einheit 1 - 17.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_1.html#organisatorisches",
    "href": "scripts/01_slides/EH_1.html#organisatorisches",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 1",
    "section": "Organisatorisches",
    "text": "Organisatorisches\n\n🕝 Immer Mittwochs um 10:15 (Gruppe Aaron) / 16:15 (Gruppe Sandra)\n📍Fabrikstrasse 8, Raum B101\n💻 Eigener Laptop mit R-Studio notwendig\n📁Unterlagen auf ILIAS und Website\n📅 14 Einheiten\n🛫 Maximal 2 unentschuldigte Fehltermine\n\n\nKeine Pause - Selbstständig wenn nötig.",
    "crumbs": [
      "Präsentationen",
      "Einheit 1 - 17.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_1.html#website-navigation-und-inhalte",
    "href": "scripts/01_slides/EH_1.html#website-navigation-und-inhalte",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 1",
    "section": "Website: Navigation und Inhalte",
    "text": "Website: Navigation und Inhalte\n\nAuf Quarto Website:\n\nAlle Präsentationen\n\nAuch als PDF verfügbar (PDF-Mode)\n\nAlle Hands On Übungen\nFAQ\nAdministrative Infos, z. B. Details zum Leistungsnachweis\n\nAuf ILIAS\n\nDownloads:\n\nFiles\n\nUploads (d.h. Abgaben)\nForum für Fragen und Peer Feedback",
    "crumbs": [
      "Präsentationen",
      "Einheit 1 - 17.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_1.html#themen-der-lehrveranstaltung",
    "href": "scripts/01_slides/EH_1.html#themen-der-lehrveranstaltung",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 1",
    "section": "Themen der Lehrveranstaltung",
    "text": "Themen der Lehrveranstaltung\nZiele\n\nMethodenkenntnisse in R auffrischen & festigen\nTransfer von Statistik-Bachelorwissen auf Datenaufbereitung & -analyse\nErwerb konzeptueller & praktischer Kompetenzen\n\nAblauf\n\nDatenanalyseplan & Codebook\nR Basics\nReproduzierbare Datenaufbereitung (u.a. mit tidyverse)\nReproduzierbare Datenanalyse (u.a. mit tidyverse)\n\nFormat\n\nPräsenz: Input & Anwendung\nHausübungen & Abschlussprojekt\n\n\nKontinuierlicher Lernaufwand während dem Semester - Dafür keine Prüfung",
    "crumbs": [
      "Präsentationen",
      "Einheit 1 - 17.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_1.html#lernziele",
    "href": "scripts/01_slides/EH_1.html#lernziele",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 1",
    "section": "Lernziele",
    "text": "Lernziele\n\nKonzeptionell: Schritte der Datenaufbereitung und -analyse im Analyseplan begründen (WAS muss ich tun & WARUM)\nPraktisch: Reproduzierbare Datenaufbereitung (WIE Daten in ein analysierbares Format bringen)\nPraktisch: Reproduzierbare Datenanalyse (WIE Fragestellungen und Hypothesen testen)\n\nNach dem Seminar können Studierende\n\nGrundkenntnisse in R / RStudio anwenden\nNotwendige Schritte für reproduzierbare Datenaufbereitung und -analyse überblicken und praktisch umsetzen\nSelbständig neue Analyse-Herausforderungen bewältigen und passende Ressourcen nutzen",
    "crumbs": [
      "Präsentationen",
      "Einheit 1 - 17.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_1.html#was-das-seminar-nicht-leisten-kann",
    "href": "scripts/01_slides/EH_1.html#was-das-seminar-nicht-leisten-kann",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 1",
    "section": "Was das Seminar nicht leisten kann:",
    "text": "Was das Seminar nicht leisten kann:\n\nKeine Auffrischung der Statistikvorlesungen\nKein “Schritt-für-Schritt Kochbuch” für die Analyse der Masterarbeit\n\n\nMasterarbeit bleibt eine individuelle Leistung, und es gibt keine One-Size-Fits all Lösung. Das Seminar soll helfen die Grundlagen aufzufrischen die ihr für eine erfolgreiche Datenaufbereitung und Auswertung braucht.",
    "crumbs": [
      "Präsentationen",
      "Einheit 1 - 17.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_1.html#leistungsbeurteilung",
    "href": "scripts/01_slides/EH_1.html#leistungsbeurteilung",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 1",
    "section": "Leistungsbeurteilung",
    "text": "Leistungsbeurteilung\n\nMitarbeit: 14 Punkte\nRegelmässige Hausübungen: 7x, gesamt 40 Punkte\nAbschlussprojekt: 46 Punkte\n–&gt; Total 100 Punkte\nGenauere Informationen zum Leistungsnachweis hier: Leistungsnachweis Website\n–&gt; Update im Laufe des Semesters\nKontinuierliche Arbeit während dem Semester!\nAufwand: 5ECTS für erfolgreichen Abschluss des Seminars -&gt; +- 9h pro Woche\n\nECTS &lt;- 25 \n\nWochen_semester &lt;- 14\n\naufwand_semester &lt;- 5*ECTS\n\naufwand_pro_woche &lt;- mean(aufwand_semester/Wochen_semester)\n\naufwand_pro_woche\n\n[1] 8.928571",
    "crumbs": [
      "Präsentationen",
      "Einheit 1 - 17.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_1.html#leistungsnachweis-mitarbeit-14-punkte",
    "href": "scripts/01_slides/EH_1.html#leistungsnachweis-mitarbeit-14-punkte",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 1",
    "section": "Leistungsnachweis: Mitarbeit (14 Punkte)",
    "text": "Leistungsnachweis: Mitarbeit (14 Punkte)\n… kann unterschiedlich ausfallen zum Beispiel:\n\nWortmeldungen im Plenum\nAktive Teilnahme an den Hands On Sessions\nBeteiligung an Online-Foren & Error Hunt\n\nPunktevergabe:\n\n7 Punkte durch LV-Leitung\n7 Punkte durch Selbstevaluation",
    "crumbs": [
      "Präsentationen",
      "Einheit 1 - 17.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_1.html#leistungsnachweis-hausübungen-40-punkte",
    "href": "scripts/01_slides/EH_1.html#leistungsnachweis-hausübungen-40-punkte",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 1",
    "section": "Leistungsnachweis: Hausübungen (40 Punkte)",
    "text": "Leistungsnachweis: Hausübungen (40 Punkte)\n\n7 Hausübungen - 4 oder 8 Punkte pro Hausübung\nBewertungsrelevant: Auseinandersetzung mit dem Stoff/den aufgetragenen Aufgaben.\nKorrektheit zweitrangig!\n\n\nBei Problemen die ihr nicht lösen könnt und keine Ressourcen findet, könnt ihr euch auch ans Forum wenden und eure Frage posten.",
    "crumbs": [
      "Präsentationen",
      "Einheit 1 - 17.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_1.html#leistungsnachweis-abschlussprojekt-46-punkte",
    "href": "scripts/01_slides/EH_1.html#leistungsnachweis-abschlussprojekt-46-punkte",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 1",
    "section": "Leistungsnachweis: Abschlussprojekt (46 Punkte)",
    "text": "Leistungsnachweis: Abschlussprojekt (46 Punkte)\n\nVorgegebenes Paper; Individuelle, simulierte Datensätze\nDatenanalyseplan überarbeiten / ergänzen\nKontinuierliche Führung/Überarbeitung eines Codebooks\nReproduzierbare Datenaufbereitung und Analyse mit Quarto\n\nAbgabe: Datenanalyseplan, Codebook, Datenfiles, Analyseskript(e) nach vorgegebener Ordnerstruktur\nDeadline: 11.01.26\n-&gt; Weitere Informationen im Verlauf des Semesters",
    "crumbs": [
      "Präsentationen",
      "Einheit 1 - 17.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_1.html#fehlerkultur",
    "href": "scripts/01_slides/EH_1.html#fehlerkultur",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 1",
    "section": "Fehlerkultur",
    "text": "Fehlerkultur\n\n“Ich verliere nie. Entweder ich gewinne oder ich lerne” - Nelson Mandela\n\n“Auch Umwege erweitern unseren Horizont” - Ernst Ferstl\n\n“Wege entstehen dadurch dass wir sie gehen” - Franz Kafka\n\n“Failure is not the opposite of Success, its part of it” - Karamo Brown in Queer Eye\n\n“Den grössten Fehler, den man im Leben machen kann, ist, immer Angst zu haben einen Fehler zu machen.” - Dietrich Bonhoeffer\n\nWir sind hier um Fehler zu machen; auch bei uns ist vieles Trial-und-Error. Das darf und soll auch so sein! Bei Hausübungen sind Fehler erlaubt! Es geht ums das Mitarbeiten und sich bemühen, dann kriegt man auch mit Fehlern die Punkte Klar machen, dass man laufend dran sein muss um zu Lernen & HÜs wichtig sind Auch ich selbst weiß vieles nicht auswendig, muss googlen…",
    "crumbs": [
      "Präsentationen",
      "Einheit 1 - 17.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_1.html#syllabus-1",
    "href": "scripts/01_slides/EH_1.html#syllabus-1",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 1",
    "section": "Syllabus (1)",
    "text": "Syllabus (1)",
    "crumbs": [
      "Präsentationen",
      "Einheit 1 - 17.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_1.html#syllabus-2",
    "href": "scripts/01_slides/EH_1.html#syllabus-2",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 1",
    "section": "Syllabus (2)",
    "text": "Syllabus (2)",
    "crumbs": [
      "Präsentationen",
      "Einheit 1 - 17.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_1.html#begleitende-literatur",
    "href": "scripts/01_slides/EH_1.html#begleitende-literatur",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 1",
    "section": "Begleitende Literatur",
    "text": "Begleitende Literatur\n\nWickham, H., Cetinkaya-Rundel, & Grolemund, G., &. (2023). R for Data Science. O’Reilly Media. https://r4ds.hadley.nz/\nEllis, A., & Mayer, B. (2024). Einführung in R. https://methodenlehre.github.io/einfuehrung-in-R/\nWeitere nützliche Ressourcen:\n\nTidyverse cheat sheets https://posit.co/resources/cheatsheets/\nLuhmann, M. (2020). R für Einsteiger. Beltz.\n\nKurswebsite: FAQ und weitere Informationen",
    "crumbs": [
      "Präsentationen",
      "Einheit 1 - 17.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_1.html#unterstützungsangebote",
    "href": "scripts/01_slides/EH_1.html#unterstützungsangebote",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 1",
    "section": "Unterstützungsangebote",
    "text": "Unterstützungsangebote\n\nMit vorhanden Ressourcen arbeiten: Unterlagen aus dem Bachelor + Online-Ressourcen (auch LLMs)\nPeer Pairing für Präsenzeinheiten und Hausübungen\nOnline-Forum für Peer-to-Peer und Peer-to-Teacher Fragen; Mitarbeitspunkte für Code-Error-Hunt\nSprechstunde für «R Troubles» mit Lars –&gt; vor/nach/während den Einheiten + bei Bedarf\nErhebung & Besprechung der «Muddiest Points»\nMusterlösungen zu Übungen werden blockweise im Ebook ergänzt",
    "crumbs": [
      "Präsentationen",
      "Einheit 1 - 17.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_1.html#bedarfsanalyse",
    "href": "scripts/01_slides/EH_1.html#bedarfsanalyse",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 1",
    "section": "Bedarfsanalyse",
    "text": "Bedarfsanalyse\nBitte reflektiere das im Bachelor erworbene Wissen und überlege wo Aufholbedarf im Bezug auf die Datenaufbereitung und -analyse mit R besteht. Du kannst die zentralen Unterlagen des Bachelor-Studiums (z.B. zu den Statistikvorlesungen) im Ilias Kurs “Masterarbeit Psychologie” einsehen.\nAnonyme Umfrage um\n\nPräferenz für das Peer-Pairing zu erfragen\nVorkenntnisse zu erfassen\nBedarf an R-Unterstützung zu erfassen\n\nUmfrage in ILIAS, Deadline Sonntag 21.09., 23:55\n\nFragen zu Peer-Feedback (ob in von uns zugeteilten Gruppen oder ob präferenz für von uns zugteilten gruppen)",
    "crumbs": [
      "Präsentationen",
      "Einheit 1 - 17.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_1.html#anwesenheit-prüfen-kennenlernen",
    "href": "scripts/01_slides/EH_1.html#anwesenheit-prüfen-kennenlernen",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 1",
    "section": "Anwesenheit prüfen / Kennenlernen",
    "text": "Anwesenheit prüfen / Kennenlernen\n\nkurz Namen sagen und wo im Master (z.B. schon an Masterarbeit)\nfalls Zeit: Lebende Statistik, z.B. wie sehr Panik vor R/Datenanalyse (0 - 10), wie viele Kaffee heute schon getrunken",
    "crumbs": [
      "Präsentationen",
      "Einheit 1 - 17.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_1.html#warum-r",
    "href": "scripts/01_slides/EH_1.html#warum-r",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 1",
    "section": "Warum R?",
    "text": "Warum R?\n\nEs gibt viele Gründe die für R sprechen:\n\nR kann mehr\nR ist aktuell\nR ist ansprechbar\nR schläft nicht\nR ist nachgefragt\nR ist Open Source & somit kostenlos\n\nQuelle: Luhmann, 2019.\n\n\n\nR bietet viele funktionen die in programmen nicht vorhanden ist\nR wird auch ständig weiterentwicklet, auch mit funktionen die erst jahre später in andere programme übernommmen werdne\nR die programmierer einzelner packages sind oft erreichbar und antworten auch auf fragen usw.\nR R nutzer auf der ganzen welt, auch in sozialen medien unterwegs (z.B auch R-Ladies https://rladies.org/about-us/mission/)\nR ist nachgefragt, eröffnet jobmöglichkeiten in und ausserhalb der wissenschaft\n\nR erhöhrt auch die transparenz!! –&gt; Open science block nächste woche",
    "crumbs": [
      "Präsentationen",
      "Einheit 1 - 17.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_1.html#jetzt-hands-on",
    "href": "scripts/01_slides/EH_1.html#jetzt-hands-on",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 1",
    "section": "Jetzt: Hands On!",
    "text": "Jetzt: Hands On!\nÜbungen auf der Website!\n\nIn eigenem Tempo arbeiten, nicht stressen lassen!\nHelft euren Sitznachbar:innen\nMeldet euch bei uns!\nFür die sehr schnellen Personen —&gt; Bedarfsanalyse auf ILIAS.\n\n\nMit Block anfangen; Lars und ich gehen rum, und beantworten fragen. Wenn ihr nicht fertig werdet ist das kein Problem.",
    "crumbs": [
      "Präsentationen",
      "Einheit 1 - 17.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_1.html#heute-haben-wir",
    "href": "scripts/01_slides/EH_1.html#heute-haben-wir",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 1",
    "section": "Heute haben wir…",
    "text": "Heute haben wir…\n\nR bzw. RStudio und wichtige Pakte darin installiert\nUns mit der Oberfläche von R-Studio bekannt gemacht\nErste Operationen in R ausgeführt:\n\nEinfache Rechnungen\nErste Zuweisungen mit &lt;-\nVektoren erstellt\nErste Funktionen aufgerufen ( z.b. sum()",
    "crumbs": [
      "Präsentationen",
      "Einheit 1 - 17.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_1.html#methodenberatung",
    "href": "scripts/01_slides/EH_1.html#methodenberatung",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 1",
    "section": "Methodenberatung",
    "text": "Methodenberatung\nMethodenberatung",
    "crumbs": [
      "Präsentationen",
      "Einheit 1 - 17.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_1.html#bis-nächste-woche",
    "href": "scripts/01_slides/EH_1.html#bis-nächste-woche",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 1",
    "section": "Bis nächste Woche!",
    "text": "Bis nächste Woche!\n\nBedarfsanalyse auf ILIAS bis Sonntag ausfüllen!\nANONYM\n\nILIAS - Sitzung 1",
    "crumbs": [
      "Präsentationen",
      "Einheit 1 - 17.09.2025"
    ]
  },
  {
    "objectID": "scripts/04_misc/muddiest_points_3.html",
    "href": "scripts/04_misc/muddiest_points_3.html",
    "title": "Muddiest Points 3",
    "section": "",
    "text": "Ich habe mich gefragt (v.a. auch in Bezug auf unsere spezialisierten Daten), ob man zuerst die einzelnen Dataframes bereinigen muss (v.a. in Bezug auf die duplizierten Zeilen) oder ob mann zuerst einen dat_full erstellen soll und dann diesen bereinigen?\nMir ist nicht ganz klar in welcher Reihenfolge man fehlende Werte, duplizierte Werte und das mergen macht.\nSicherheit im Umgang mit den verschiedenen Schritten der Datenbereinigung\n\nAntwort:\nEinige Schritte der Datenaufbereitung sollten vor dem Mergen durchgeführt werden, da das Zusammenführen der Datensätze sonst unnötig kompliziert werden kann. Beispielsweise können Duplikate oder fehlende Werte (NAs) beim Mergen zu Problemen führen und sollten daher idealerweise bereits vorher behandelt werden. Für viele andere Schritte, wie etwa Rekodierungen, spielt es hingegen keine Rolle, ob sie im einzelnen Datensatz oder erst im gemergten Datensatz durchgeführt werden. Es gibt dabei keine festgelegte Reihenfolge, die zwingend eingehalten werden muss. Ob das Vorgehen korrekt war, kann man abschliessend überprüfen, indem man den gemergten Datensatz inspiziert und auf Plausibilität prüft (z. B. ob N = 159).\n\n\n\n\n\nCodebook: Muss es für die einzelnen Datensätze gemacht werden? Ich habe nämlich alles zuerst bereinigt, umgepoolt und dann gemerged und als dat_full.csv abgespeichert. Bedeutet, dass in dat_full keine NAs und revers kodierte Items mehr sind und auch nicht mehr im Codebook wären, sollte dat_full im Codebook verwendet werden müssen (zumind. bei mir). Zudem wurde in dat_full noch mmq_mean hinzugefügt, muss das auch ins Codebook?\n\nAntwort:\n\nDas Codebook für den gemergten Datensatz ist ausreichend. Reverse-kodierte Items sollten dennoch angegeben werden, wobei im Codebook vermerkt werden sollte, dass diese bereits rekodiert wurden. Wenn keine NAs vorhanden sind müssen diese auch nicht vermerkt werden. Jede Variable sollte im Codebook enthalten sein, einschliesslich zusammengesetzter Variablen wie mmq_mean.\n\n\n\n\n\nEs steht man soll eine Tabelle/Abbildung nach Wahl erstellen. Heisst, wir müssen nicht alle Plots nachmachen?\n\nAntwort: Eine Tabelle oder eine Abbildung genügt. Ihr müsst nicht alle Plots des Papers nachmachen!\n\n\n\n\nMüssen Resultate interpretiert werden und wenn ja, wie müssen diese verschriftlicht werden?\nAntwort: Es werden keine inhaltlichen Interpretationen der Ergebnisse gefordert. Kurze Zusammenfassungen der Resultate direkt nach den jeweiligen Codechunks können jedoch das Verständnis erleichtern und illustrieren, dass ihr die Analysen richtig lesen könnt.\nZum Beispiel: The one-way ANOVA indicated that there were no significant group differences in this working memory performance measure, F(2, 156) = 0.07, p = 0.929, η² &lt; 0.01.\n\n\n\n\n\nWenn man etwas umkodiert (z.B. umgekehrt kodierte Items) und es eine ungerade Anzahl hat, muss man dann das mittlere Item bei der Umkodierung auch angeben (z.B. bei fünf Stufen wäre es die 3, die gleich bleibt - müsste ich das bei der Umkodierung dennoch notieren?)\n\nAntwort: Nein, solange die Rekodierung klar nachvollziehbar ist ist es nicht zwingend nötig (aber schadet auch nicht).\n\n\n\n\nOrdner- und Pfadstruktur: Wo genau sollten die Quartoskripte relativ zu den eingelesenen Daten abgespeichert werden? -&gt; Wenn man die Quartoskripte im Ordner Grinschgl2020 abspeichert geht das zwar gut, jedoch sind dann die Quartoskripte nicht in einem eignen Ordner. Wenn ich sie in einen eignen Ordner lege, dann stimmt der Pfad aber nicht mehr. Gibt es hier eine gute Lösung?\nAntwort: Öffne die Skripte innerhalb des Projekts. Dann wird der Dateipfad automatisch relativ zum Projektverzeichnis ausgewertet, auch wenn sich die Skripte nicht im gleichen Ordner befinden. Falls dies nicht funktioniert, überprüfe in den Einstellungen, ob die Option „Evaluate chunks in directory“ auf „Project“ gesetzt ist.\n\n\n\n\n\n\n\n\n\n\n\n\n\nBitte nochmals die Logik der ANOVA sowohl für One-way ANOVA wie v.a. auch 2x3 mixed ANOVA erklären. Welcher Output liefert nun welche Inhalte? Und welche Codes sind alle wichtig?\nIch finde es schwierig, die Outputs der verschiedenen Anovas und t-tests zu verstehen.\nIch würde gerne die Mixed Anovas und t-Tests noch einmal anschauen, vielleicht einfach noch einmal kurz repetieren, worauf man da bei den Codes und der Interpretation achten muss.\n\nAntwort:\n🌐Erklärvideo ANOVA\n🌐Erklärvideo ANOVA + t-Test\n🌐Erklärvideo: Using Linear Models for t tests and ANOVA, Clearly Explained!!!\n\n\nDie ANOVA prüft generell die Frage, ob die beobachtete Variation in den Daten größer ist, als man sie durch Zufall erwarten würde. Der zentrale Gedanke der ANOVA ist, dass Unterschiede zwischen Gruppen dann als bedeutsam gelten, wenn die Gruppenmittelwerte stark voneinander abweichen, während die Streuung innerhalb der Gruppen gering ist, sodass es unwahrscheinlich ist, dass diese Unterschiede nur durch Zufall entstanden sind.\nDieses Verhältnis wird durch den F-Wert ausgedrückt:\n\\(F = \\frac{\\text{Varianz zwischen den Gruppen}}{\\text{Varianz innerhalb der Gruppen}}\\).\nDie One-Way ANOVA beantwortet die Frage:\n\nUnterscheiden sich mehr als zwei Gruppen in einer abhängigen Variable?\n\nBeispiel:\nBeispielsweise wird untersucht, ob sich Pinguine in ihrer Schnabellänge zwischen mehreren Gruppen (z. B. Inseln) unterscheiden. Da mehr als zwei Gruppen verglichen werden, ist eine One-Way ANOVA angemessen.\nDa der p-Wert &lt; 0.05 ist, ist die ANOVA signifikant. Das bedeutet, dass sich mindestens zwei der Gruppen signifikant voneinander unterscheiden. Welche Gruppen sich konkret unterscheiden, kann jedoch erst mit Post-hoc-t-Tests überprüft werden.\nDas generalized η² (ges) gibt an, wie viel Varianz der abhängigen Variable durch den Faktor erklärt wird. In diesem Fall erklärt die Gruppenzugehörigkeit (z. B. Spezies) ca. 70 % der Varianz der Schnabellänge.\n\nmodel_1 &lt;- aov_4(bill_length_mm ~ species + (1 |id), data = penguins)\n\nsummary(model_1)\n\n\n\n\nDer Post-hoc t-Test hier ist die logische Konsequenz aus der signifikanten ANOVA.\nDa es drei Spezies (Gentoo, Chinstrap, Adelie) gibt können wir drei verschiedene Gruppenvergleiche berechnen. Hier zeigen wir ein Beispiel.\nDer t-Test prüft, ob sich die Mittelwerte zweier Gruppen in der abhängigen Variable (Schnabellänge) unterscheiden. Auf Basis von Stichprobendaten wird untersucht, ob sich Pinguine der Spezies Adelie und Chinstrap in ihrer Schnabellänge (bill_length_mm) unterscheiden. Das signifikante Ergebnis (p &lt; 0.05) spricht dafür, dass sich die mittlere Schnabellänge dieser beiden Gruppen auf Populationsebene unterscheidet.\n\npenguins_filtered &lt;- penguins |&gt;\n  filter(species != \"Gentoo\")\n\nt.test(bill_length_mm ~ species, data = penguins_filtered)\n\n\n\n\n\nWieso braucht man bei t.test() “~” und nicht “,” bzw. wovon hängt dies ab?\n\nAntwort: Bei t.test() wird das ~ verwendet, wenn der Test in der Formel-Schreibweise durchgeführt wird. Diese Schreibweise trennt die abhängige Variable (links vom ~) von der Gruppierungsvariable (rechts vom ~) und ist typisch für viele statistische Funktionen in R. Sie wird vor allem dann genutzt, wenn die Daten in einem Dataframe vorliegen.\nEin Komma wird hingegen verwendet, wenn man die beiden Gruppen direkt als separate Vektoren übergibt. Welche Schreibweise man verwendet, hängt also davon ab, wie die Daten strukturiert sind (Dataframe vs. einzelne Vektoren) und welche Schnittstelle die Funktion anbietet.\nBeispiele mit Formelschreibweise:\n\n# Datensatz auf zwei Arten beschränken\npenguins_2 &lt;- subset(\n  penguins,\n  species %in% c(\"Adelie\", \"Chinstrap\")\n)\n\n# t-Test mit Formel-Schreibweise\nt.test(flipper_length_mm ~ species, data = penguins_2)\n\nMit Komma:\n\n# Vektoren für die zwei Gruppen\nadelie_flipper &lt;- penguins$flipper_length_mm[\n  penguins$species == \"Adelie\"\n]\n\nchinstrap_flipper &lt;- penguins$flipper_length_mm[\n  penguins$species == \"Chinstrap\"\n]\n\n# t-Test mit Vektoren\nt.test(adelie_flipper, chinstrap_flipper)\n\n\n\n\n\nDie 2×3 ANOVA im Grinschgl et al. (2021) Paper beantwortet die folgenden Fragen:\nGibt es Unterschiede zwischen den Feedbackgruppen, gibt es Veränderungen über die Zeit (Pre1 vs. Pre4), und unterscheiden sich diese zeitlichen Veränderungen zwischen den Gruppen (above vs. control vs. below)?\n\nmixed_anova &lt;- aov_4(rating ~ group_all + (time_rating | code), data = dat_long)\n\nsummary(mixed_anova)\n\nDer signifikante Haupteffekt der Feedbackgruppe (group_all) zeigt, dass sich die mittleren Ratings zwischen den Gruppen unterscheiden, unabhängig vom Zeitpunkt der Messung.\nDer signifikante Haupteffekt der Feedbackgruppe (group_all) zeigt, dass sich die mittleren Ratings zwischen den Gruppen unterscheiden, unabhängig vom Zeitpunkt der Messung.\nDer signifikante Interaktionseffekt zeigt, dass sich die Veränderung der Ratings über die Zeit zwischen den Feedbackgruppen unterscheidet. 👉Der Effekt der Zeit ist nicht für alle Gruppen gleich.\n\n\n\n\n\n\nbitte Berechnung von Cohens d erneut für spezifisch 2x3 mixed ANOVA erklären. Hier sehe ich weder in den Hands On noch in den Foliensätze einen passenden Code, der bei mir funktioniert.\n\nAntwort: Cohen’s d wird für die Post-hoc-t-Tests berechnet, nicht für die 2×3-ANOVA selbst. (Für die ANOVA selbst berechnen wir Eta2). Cohen’s d ist ein Effektstärkenmaß, das angibt, wie groß der Unterschied zwischen zwei Gruppen ist, unabhängig von der Stichprobengröße. Hier ein Beispiel aus den Hands On Übungen. ​​\n\ndat_full_below_above &lt;- dat_full |&gt; \n  filter(group_all != \"control\")\n\ndat_full_below_above$group_all &lt;- as.factor(dat_full_below_above$group_all)\n\nt.test(pre4 ~ group_all, data = dat_full_below_above, var.equal = TRUE)\neffsize::cohen.d(pre4 ~ group_all, data = dat_full_below_above)\n\n\n\n\n\n\nWas macht es aus, dass man explizit na.rm = TRUE bei mean() und sd() angibt\n\nAntwort: Mittelwerte und Standardabweichungen können nicht korrekt berechnet werden, wenn sich fehlende Werte (NAs) in den Daten befinden. Mit na.rm = TRUE werden diese fehlenden Werte bei der Berechnung ausgeschlossen. Wurden die NAs bereits zuvor bereinigt, ist dieser Befehl zwar redundant, schadet jedoch nicht.\n\nx &lt;- c(1,2,3,4,5,6,NA)\n\nmean(x)\nmean(x, na.rm = TRUE)\n\n\n\n\n\n\nWoher weiss man, ob man rowMeans() und(/oder) mean() anwenden soll?\n\nrowMeans(df) berechnet die Zeilenmittelwerte, also den Mittelwert pro Zeile über alle Spalten hinweg.\nIn einem Wide-Datensatz entspricht das typischerweise dem Mittelwert pro Person über mehrere Variablen / Messungen.\nmean(df$V1) berechnet den Mittelwert einer einzelnen Spalte (V1) über alle Zeilen hinweg.\nDas entspricht dem Mittelwert einer Variable über alle Personen\nrowMeans bietet sich also dafür an z.B. Skalenwerte zu berechnen (z.B. Durschnitt mehrerer Skalenitems) zu berechnen, während mean besser für Durschnittswerte über das gesamte Sample geeignet ist.\n\n\n\nV1\nV2\nV3\n\n\n\n\n1\n2\n3\n\n\n4\n5\n6\n\n\n7\n8\n9\n\n\n\n\ndf &lt;- data.frame(\n  V1 = c(1, 4, 7),\n  V2 = c(2, 5, 8),\n  V3 = c(3, 6, 9)\n)\n\n# Zeilenmittelwerte (Mittelwert pro Zeile über V1–V3)\nrowMeans(df)\n\n# Mittelwert über Variable\nmean((df$V1))\n\n\n\n\n\n\nMir ist noch nicht richtig klar, wie man APA konforme ANOVA Tabellen erzeugt, die man gerade abspeichern kann und dann in eine Word Datei einfügen kann. Z.B für eine dreifaktorielle ANOVA?\n\nAntwort: Tabellen für ANOVAs haben wir nicht behandelt. In der Praxis werden ANOVAs meist auch nicht in Tabellenform berichtet, sondern direkt im Text. Es ist jedoch möglich, APA-konforme ANOVA-Tabellen mit Packages apaTables wie Papaja zu erstellen.\nBeispiel aus Grinschgl et al. (2021)\n\nlibrary(apaTables)\n\nmodel_1 &lt;- aov(bill_length_mm ~ island + sex + species, data = penguins_filtered)\n\napa.aov.table(\n  lm_output = model_1,\n  filename  = \"anova_table.doc\"\n)\n\n\n\n\n\n\n\n\n\n\n\nBesseres Verständnis dafür, welche statistischen Tests in welcher Situation angemessen sind\n\nAntwort: Sprengt hier leider den Rahmen. Wir verweisen hier gerne auf den Statistikbaum der UZH. Jedoch kann auch dieser eine tiefergehende Auseinandersetzung mit der Fragestellung und dem Datenformat nicht ersetzen! Für spezifische Fragen zu diesem Thema, kann auch gerne die Methodenberatung genutzt werden!",
    "crumbs": [
      "Muddiest Points",
      "Muddiest Points 3"
    ]
  },
  {
    "objectID": "scripts/04_misc/muddiest_points_3.html#abschlussarbeit",
    "href": "scripts/04_misc/muddiest_points_3.html#abschlussarbeit",
    "title": "Muddiest Points 3",
    "section": "",
    "text": "Ich habe mich gefragt (v.a. auch in Bezug auf unsere spezialisierten Daten), ob man zuerst die einzelnen Dataframes bereinigen muss (v.a. in Bezug auf die duplizierten Zeilen) oder ob mann zuerst einen dat_full erstellen soll und dann diesen bereinigen?\nMir ist nicht ganz klar in welcher Reihenfolge man fehlende Werte, duplizierte Werte und das mergen macht.\nSicherheit im Umgang mit den verschiedenen Schritten der Datenbereinigung\n\nAntwort:\nEinige Schritte der Datenaufbereitung sollten vor dem Mergen durchgeführt werden, da das Zusammenführen der Datensätze sonst unnötig kompliziert werden kann. Beispielsweise können Duplikate oder fehlende Werte (NAs) beim Mergen zu Problemen führen und sollten daher idealerweise bereits vorher behandelt werden. Für viele andere Schritte, wie etwa Rekodierungen, spielt es hingegen keine Rolle, ob sie im einzelnen Datensatz oder erst im gemergten Datensatz durchgeführt werden. Es gibt dabei keine festgelegte Reihenfolge, die zwingend eingehalten werden muss. Ob das Vorgehen korrekt war, kann man abschliessend überprüfen, indem man den gemergten Datensatz inspiziert und auf Plausibilität prüft (z. B. ob N = 159).\n\n\n\n\n\nCodebook: Muss es für die einzelnen Datensätze gemacht werden? Ich habe nämlich alles zuerst bereinigt, umgepoolt und dann gemerged und als dat_full.csv abgespeichert. Bedeutet, dass in dat_full keine NAs und revers kodierte Items mehr sind und auch nicht mehr im Codebook wären, sollte dat_full im Codebook verwendet werden müssen (zumind. bei mir). Zudem wurde in dat_full noch mmq_mean hinzugefügt, muss das auch ins Codebook?\n\nAntwort:\n\nDas Codebook für den gemergten Datensatz ist ausreichend. Reverse-kodierte Items sollten dennoch angegeben werden, wobei im Codebook vermerkt werden sollte, dass diese bereits rekodiert wurden. Wenn keine NAs vorhanden sind müssen diese auch nicht vermerkt werden. Jede Variable sollte im Codebook enthalten sein, einschliesslich zusammengesetzter Variablen wie mmq_mean.\n\n\n\n\n\nEs steht man soll eine Tabelle/Abbildung nach Wahl erstellen. Heisst, wir müssen nicht alle Plots nachmachen?\n\nAntwort: Eine Tabelle oder eine Abbildung genügt. Ihr müsst nicht alle Plots des Papers nachmachen!\n\n\n\n\nMüssen Resultate interpretiert werden und wenn ja, wie müssen diese verschriftlicht werden?\nAntwort: Es werden keine inhaltlichen Interpretationen der Ergebnisse gefordert. Kurze Zusammenfassungen der Resultate direkt nach den jeweiligen Codechunks können jedoch das Verständnis erleichtern und illustrieren, dass ihr die Analysen richtig lesen könnt.\nZum Beispiel: The one-way ANOVA indicated that there were no significant group differences in this working memory performance measure, F(2, 156) = 0.07, p = 0.929, η² &lt; 0.01.\n\n\n\n\n\nWenn man etwas umkodiert (z.B. umgekehrt kodierte Items) und es eine ungerade Anzahl hat, muss man dann das mittlere Item bei der Umkodierung auch angeben (z.B. bei fünf Stufen wäre es die 3, die gleich bleibt - müsste ich das bei der Umkodierung dennoch notieren?)\n\nAntwort: Nein, solange die Rekodierung klar nachvollziehbar ist ist es nicht zwingend nötig (aber schadet auch nicht).\n\n\n\n\nOrdner- und Pfadstruktur: Wo genau sollten die Quartoskripte relativ zu den eingelesenen Daten abgespeichert werden? -&gt; Wenn man die Quartoskripte im Ordner Grinschgl2020 abspeichert geht das zwar gut, jedoch sind dann die Quartoskripte nicht in einem eignen Ordner. Wenn ich sie in einen eignen Ordner lege, dann stimmt der Pfad aber nicht mehr. Gibt es hier eine gute Lösung?\nAntwort: Öffne die Skripte innerhalb des Projekts. Dann wird der Dateipfad automatisch relativ zum Projektverzeichnis ausgewertet, auch wenn sich die Skripte nicht im gleichen Ordner befinden. Falls dies nicht funktioniert, überprüfe in den Einstellungen, ob die Option „Evaluate chunks in directory“ auf „Project“ gesetzt ist.",
    "crumbs": [
      "Muddiest Points",
      "Muddiest Points 3"
    ]
  },
  {
    "objectID": "scripts/04_misc/muddiest_points_3.html#statistik",
    "href": "scripts/04_misc/muddiest_points_3.html#statistik",
    "title": "Muddiest Points 3",
    "section": "",
    "text": "Bitte nochmals die Logik der ANOVA sowohl für One-way ANOVA wie v.a. auch 2x3 mixed ANOVA erklären. Welcher Output liefert nun welche Inhalte? Und welche Codes sind alle wichtig?\nIch finde es schwierig, die Outputs der verschiedenen Anovas und t-tests zu verstehen.\nIch würde gerne die Mixed Anovas und t-Tests noch einmal anschauen, vielleicht einfach noch einmal kurz repetieren, worauf man da bei den Codes und der Interpretation achten muss.\n\nAntwort:\n🌐Erklärvideo ANOVA\n🌐Erklärvideo ANOVA + t-Test\n🌐Erklärvideo: Using Linear Models for t tests and ANOVA, Clearly Explained!!!\n\n\nDie ANOVA prüft generell die Frage, ob die beobachtete Variation in den Daten größer ist, als man sie durch Zufall erwarten würde. Der zentrale Gedanke der ANOVA ist, dass Unterschiede zwischen Gruppen dann als bedeutsam gelten, wenn die Gruppenmittelwerte stark voneinander abweichen, während die Streuung innerhalb der Gruppen gering ist, sodass es unwahrscheinlich ist, dass diese Unterschiede nur durch Zufall entstanden sind.\nDieses Verhältnis wird durch den F-Wert ausgedrückt:\n\\(F = \\frac{\\text{Varianz zwischen den Gruppen}}{\\text{Varianz innerhalb der Gruppen}}\\).\nDie One-Way ANOVA beantwortet die Frage:\n\nUnterscheiden sich mehr als zwei Gruppen in einer abhängigen Variable?\n\nBeispiel:\nBeispielsweise wird untersucht, ob sich Pinguine in ihrer Schnabellänge zwischen mehreren Gruppen (z. B. Inseln) unterscheiden. Da mehr als zwei Gruppen verglichen werden, ist eine One-Way ANOVA angemessen.\nDa der p-Wert &lt; 0.05 ist, ist die ANOVA signifikant. Das bedeutet, dass sich mindestens zwei der Gruppen signifikant voneinander unterscheiden. Welche Gruppen sich konkret unterscheiden, kann jedoch erst mit Post-hoc-t-Tests überprüft werden.\nDas generalized η² (ges) gibt an, wie viel Varianz der abhängigen Variable durch den Faktor erklärt wird. In diesem Fall erklärt die Gruppenzugehörigkeit (z. B. Spezies) ca. 70 % der Varianz der Schnabellänge.\n\nmodel_1 &lt;- aov_4(bill_length_mm ~ species + (1 |id), data = penguins)\n\nsummary(model_1)\n\n\n\n\nDer Post-hoc t-Test hier ist die logische Konsequenz aus der signifikanten ANOVA.\nDa es drei Spezies (Gentoo, Chinstrap, Adelie) gibt können wir drei verschiedene Gruppenvergleiche berechnen. Hier zeigen wir ein Beispiel.\nDer t-Test prüft, ob sich die Mittelwerte zweier Gruppen in der abhängigen Variable (Schnabellänge) unterscheiden. Auf Basis von Stichprobendaten wird untersucht, ob sich Pinguine der Spezies Adelie und Chinstrap in ihrer Schnabellänge (bill_length_mm) unterscheiden. Das signifikante Ergebnis (p &lt; 0.05) spricht dafür, dass sich die mittlere Schnabellänge dieser beiden Gruppen auf Populationsebene unterscheidet.\n\npenguins_filtered &lt;- penguins |&gt;\n  filter(species != \"Gentoo\")\n\nt.test(bill_length_mm ~ species, data = penguins_filtered)\n\n\n\n\n\nWieso braucht man bei t.test() “~” und nicht “,” bzw. wovon hängt dies ab?\n\nAntwort: Bei t.test() wird das ~ verwendet, wenn der Test in der Formel-Schreibweise durchgeführt wird. Diese Schreibweise trennt die abhängige Variable (links vom ~) von der Gruppierungsvariable (rechts vom ~) und ist typisch für viele statistische Funktionen in R. Sie wird vor allem dann genutzt, wenn die Daten in einem Dataframe vorliegen.\nEin Komma wird hingegen verwendet, wenn man die beiden Gruppen direkt als separate Vektoren übergibt. Welche Schreibweise man verwendet, hängt also davon ab, wie die Daten strukturiert sind (Dataframe vs. einzelne Vektoren) und welche Schnittstelle die Funktion anbietet.\nBeispiele mit Formelschreibweise:\n\n# Datensatz auf zwei Arten beschränken\npenguins_2 &lt;- subset(\n  penguins,\n  species %in% c(\"Adelie\", \"Chinstrap\")\n)\n\n# t-Test mit Formel-Schreibweise\nt.test(flipper_length_mm ~ species, data = penguins_2)\n\nMit Komma:\n\n# Vektoren für die zwei Gruppen\nadelie_flipper &lt;- penguins$flipper_length_mm[\n  penguins$species == \"Adelie\"\n]\n\nchinstrap_flipper &lt;- penguins$flipper_length_mm[\n  penguins$species == \"Chinstrap\"\n]\n\n# t-Test mit Vektoren\nt.test(adelie_flipper, chinstrap_flipper)\n\n\n\n\n\nDie 2×3 ANOVA im Grinschgl et al. (2021) Paper beantwortet die folgenden Fragen:\nGibt es Unterschiede zwischen den Feedbackgruppen, gibt es Veränderungen über die Zeit (Pre1 vs. Pre4), und unterscheiden sich diese zeitlichen Veränderungen zwischen den Gruppen (above vs. control vs. below)?\n\nmixed_anova &lt;- aov_4(rating ~ group_all + (time_rating | code), data = dat_long)\n\nsummary(mixed_anova)\n\nDer signifikante Haupteffekt der Feedbackgruppe (group_all) zeigt, dass sich die mittleren Ratings zwischen den Gruppen unterscheiden, unabhängig vom Zeitpunkt der Messung.\nDer signifikante Haupteffekt der Feedbackgruppe (group_all) zeigt, dass sich die mittleren Ratings zwischen den Gruppen unterscheiden, unabhängig vom Zeitpunkt der Messung.\nDer signifikante Interaktionseffekt zeigt, dass sich die Veränderung der Ratings über die Zeit zwischen den Feedbackgruppen unterscheidet. 👉Der Effekt der Zeit ist nicht für alle Gruppen gleich.\n\n\n\n\n\n\nbitte Berechnung von Cohens d erneut für spezifisch 2x3 mixed ANOVA erklären. Hier sehe ich weder in den Hands On noch in den Foliensätze einen passenden Code, der bei mir funktioniert.\n\nAntwort: Cohen’s d wird für die Post-hoc-t-Tests berechnet, nicht für die 2×3-ANOVA selbst. (Für die ANOVA selbst berechnen wir Eta2). Cohen’s d ist ein Effektstärkenmaß, das angibt, wie groß der Unterschied zwischen zwei Gruppen ist, unabhängig von der Stichprobengröße. Hier ein Beispiel aus den Hands On Übungen. ​​\n\ndat_full_below_above &lt;- dat_full |&gt; \n  filter(group_all != \"control\")\n\ndat_full_below_above$group_all &lt;- as.factor(dat_full_below_above$group_all)\n\nt.test(pre4 ~ group_all, data = dat_full_below_above, var.equal = TRUE)\neffsize::cohen.d(pre4 ~ group_all, data = dat_full_below_above)\n\n\n\n\n\n\nWas macht es aus, dass man explizit na.rm = TRUE bei mean() und sd() angibt\n\nAntwort: Mittelwerte und Standardabweichungen können nicht korrekt berechnet werden, wenn sich fehlende Werte (NAs) in den Daten befinden. Mit na.rm = TRUE werden diese fehlenden Werte bei der Berechnung ausgeschlossen. Wurden die NAs bereits zuvor bereinigt, ist dieser Befehl zwar redundant, schadet jedoch nicht.\n\nx &lt;- c(1,2,3,4,5,6,NA)\n\nmean(x)\nmean(x, na.rm = TRUE)\n\n\n\n\n\n\nWoher weiss man, ob man rowMeans() und(/oder) mean() anwenden soll?\n\nrowMeans(df) berechnet die Zeilenmittelwerte, also den Mittelwert pro Zeile über alle Spalten hinweg.\nIn einem Wide-Datensatz entspricht das typischerweise dem Mittelwert pro Person über mehrere Variablen / Messungen.\nmean(df$V1) berechnet den Mittelwert einer einzelnen Spalte (V1) über alle Zeilen hinweg.\nDas entspricht dem Mittelwert einer Variable über alle Personen\nrowMeans bietet sich also dafür an z.B. Skalenwerte zu berechnen (z.B. Durschnitt mehrerer Skalenitems) zu berechnen, während mean besser für Durschnittswerte über das gesamte Sample geeignet ist.\n\n\n\nV1\nV2\nV3\n\n\n\n\n1\n2\n3\n\n\n4\n5\n6\n\n\n7\n8\n9\n\n\n\n\ndf &lt;- data.frame(\n  V1 = c(1, 4, 7),\n  V2 = c(2, 5, 8),\n  V3 = c(3, 6, 9)\n)\n\n# Zeilenmittelwerte (Mittelwert pro Zeile über V1–V3)\nrowMeans(df)\n\n# Mittelwert über Variable\nmean((df$V1))\n\n\n\n\n\n\nMir ist noch nicht richtig klar, wie man APA konforme ANOVA Tabellen erzeugt, die man gerade abspeichern kann und dann in eine Word Datei einfügen kann. Z.B für eine dreifaktorielle ANOVA?\n\nAntwort: Tabellen für ANOVAs haben wir nicht behandelt. In der Praxis werden ANOVAs meist auch nicht in Tabellenform berichtet, sondern direkt im Text. Es ist jedoch möglich, APA-konforme ANOVA-Tabellen mit Packages apaTables wie Papaja zu erstellen.\nBeispiel aus Grinschgl et al. (2021)\n\nlibrary(apaTables)\n\nmodel_1 &lt;- aov(bill_length_mm ~ island + sex + species, data = penguins_filtered)\n\napa.aov.table(\n  lm_output = model_1,\n  filename  = \"anova_table.doc\"\n)\n\n\n\n\n\n\n\n\n\n\n\nBesseres Verständnis dafür, welche statistischen Tests in welcher Situation angemessen sind\n\nAntwort: Sprengt hier leider den Rahmen. Wir verweisen hier gerne auf den Statistikbaum der UZH. Jedoch kann auch dieser eine tiefergehende Auseinandersetzung mit der Fragestellung und dem Datenformat nicht ersetzen! Für spezifische Fragen zu diesem Thema, kann auch gerne die Methodenberatung genutzt werden!",
    "crumbs": [
      "Muddiest Points",
      "Muddiest Points 3"
    ]
  },
  {
    "objectID": "scripts/04_misc/about.html",
    "href": "scripts/04_misc/about.html",
    "title": "About",
    "section": "",
    "text": "Diese Website wurde im Rahmen des Seminars “R u Ready” an der Universität Bern erstellt.\nSollte deine Frage nicht beantwortet worden sein, dann wende dich gerne direkt an die Autor:innen:\n\n\n\nlars.schilling@unibe.ch\n\n\naaron.friedli@unibe.ch\n\n\nsandra.grinschgl@unibe.ch\n\n\n\n\nThis work is licensed under CC BY-SA 4.0",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "scripts/04_misc/ChatGPT.html",
    "href": "scripts/04_misc/ChatGPT.html",
    "title": "ChatGPT in RStudio",
    "section": "",
    "text": "Damit ihr ChatGPT in RStudio einbinden könnt ist ein Account bei OpenAI / ChatGPT notwendig (falls ihr ChatGPT bisher ohne Anmeldung genutzt habt): https://chatgpt.com/\nNeben dieser Anleitung gibt es auch noch dieses YouTube-Tutorial [2:36 - 5:08] welches euch bei der Einrichtung behilflich sein könnte.\nRechtliche Informationen zum Umgang mit ChatGPT und anderen generativen KI-Anwendungen findet ihr hier.",
    "crumbs": [
      "Links und Ressourcen",
      "ChatGPT in RStudio"
    ]
  },
  {
    "objectID": "scripts/04_misc/ChatGPT.html#installieren-von-paketen-welche-chattr-im-hintergrund-benötigt",
    "href": "scripts/04_misc/ChatGPT.html#installieren-von-paketen-welche-chattr-im-hintergrund-benötigt",
    "title": "ChatGPT in RStudio",
    "section": "Installieren von Paketen, welche chattr im Hintergrund benötigt",
    "text": "Installieren von Paketen, welche chattr im Hintergrund benötigt\nEventuell habt ihr diese schon installiert und ihr könnt diesen Schritt dann überspringen. Ansonsten müsst ihr diese Pakete, wie auch alle anderen, nur einmalig installieren.\n\ninstall.packages(\"shiny\")\ninstall.packages(\"httr2\")\ninstall.packages(\"jsonlite\")",
    "crumbs": [
      "Links und Ressourcen",
      "ChatGPT in RStudio"
    ]
  },
  {
    "objectID": "scripts/04_misc/ChatGPT.html#installieren-des-chattr-pakets-von-github",
    "href": "scripts/04_misc/ChatGPT.html#installieren-des-chattr-pakets-von-github",
    "title": "ChatGPT in RStudio",
    "section": "Installieren des chattr-Pakets von GitHub",
    "text": "Installieren des chattr-Pakets von GitHub\nAuch hier gilt, die Installation des Paketes müsst ihr nur einmalig vornehmen.\n\ninstall.packages(\"remotes\") # Hier werdet ihr in der Console möglicherweise gefragt, ob ihr das Paket unter dem vorgeschlagenen Dateipfad abspeichern wollt. Sofern dieser für euch passt könnt ihr einfach mit \"Y\" unten in der Console eingeben und mit Enter bestätigen.\n\n\nremotes::install_github(\"mlverse/chattr\") # Hier werdet ihr möglicherweise gefragt, welche der betroffenen Pakete ihr updaten wollt. Es empfehlt sich, alle zu updaten. Ihr könnt dies tun, indem ihr \"1\" in der Console eingebt und mit Enter bestätigt.",
    "crumbs": [
      "Links und Ressourcen",
      "ChatGPT in RStudio"
    ]
  },
  {
    "objectID": "scripts/04_misc/ChatGPT.html#laden-von-chattr",
    "href": "scripts/04_misc/ChatGPT.html#laden-von-chattr",
    "title": "ChatGPT in RStudio",
    "section": "Laden von chattr",
    "text": "Laden von chattr\nDie Schritte ab hier, also das Laden des Paketes und das Starten des Chat-Interface, müsst ihr bei jedem Start von RStudio erneut durchführen.\n\nlibrary(chattr) # So wie ihr es auch bereits von anderen Paketen kennt",
    "crumbs": [
      "Links und Ressourcen",
      "ChatGPT in RStudio"
    ]
  },
  {
    "objectID": "scripts/04_misc/ChatGPT.html#erstellen-des-chat-interface",
    "href": "scripts/04_misc/ChatGPT.html#erstellen-des-chat-interface",
    "title": "ChatGPT in RStudio",
    "section": "Erstellen des Chat-Interface",
    "text": "Erstellen des Chat-Interface\n\nSys.setenv(OPENAI_API_KEY = \"Hier müsst ihr euren eigenen OpenAI API-Key einsetzen\") # Ihr erhaltet euren OpenAI API Key, indem ihr euch bei OpenAI anmeldet und unter https://platform.openai.com/account/api-keys einen neuen Key generiert.\n\nchattr_app() # Hier werdet ihr möglicherweise gefragt, welche Version von ChatGPT ihr verwenden mögt. Mit Eingabe der Nummer wählt ihr das entsprechende Modell aus. Mit Enter bestätigt ihr die Eingabe.",
    "crumbs": [
      "Links und Ressourcen",
      "ChatGPT in RStudio"
    ]
  },
  {
    "objectID": "scripts/04_misc/ChatGPT.html#prompt-beispiel",
    "href": "scripts/04_misc/ChatGPT.html#prompt-beispiel",
    "title": "ChatGPT in RStudio",
    "section": "Prompt-Beispiel",
    "text": "Prompt-Beispiel\nWofür braucht das Paket chattr im Hintergrund noch die Pakete shiny, httr2 und jsonlite?",
    "crumbs": [
      "Links und Ressourcen",
      "ChatGPT in RStudio"
    ]
  },
  {
    "objectID": "scripts/04_misc/checkliste_abschlussarbeit.html",
    "href": "scripts/04_misc/checkliste_abschlussarbeit.html",
    "title": "Checkliste Abschlussarbeit",
    "section": "",
    "text": "Abgabe bis 11.1.2026 - 23:55\nAbgabe als ZIP-File: vorname_nachname_abschlussarbeit.zip\nFür die Abschlussarbeit erhaltet ihr simulierte Daten. Diese werden den Daten des Originalpapers in den meisten Aspekten sehr ähnlich sein. Allerdings müssen einige Teile davon zusätzlich bereinigt werden, bevor sie ausgewertet werden können. Die folgende Checkliste soll euch dabei helfen, an alle relevanten Aspekte der Datenbereinigung zu denken.\nDie Datensatzaufbereitung erfolgt im processing-Skript. Der final aufbereitete Datensatz (dat_full) sowie der Long-Datensatz (dat_long) werden im Ordner data/processed gespeichert.",
    "crumbs": [
      "Checkliste Abschlussarbeit"
    ]
  },
  {
    "objectID": "scripts/04_misc/checkliste_abschlussarbeit.html#aspekte-die-bei-der-bereinigung-processing-beachtet-werden-sollten",
    "href": "scripts/04_misc/checkliste_abschlussarbeit.html#aspekte-die-bei-der-bereinigung-processing-beachtet-werden-sollten",
    "title": "Checkliste Abschlussarbeit",
    "section": "Aspekte, die bei der Bereinigung (processing) beachtet werden sollten",
    "text": "Aspekte, die bei der Bereinigung (processing) beachtet werden sollten\n\nHaben alle Daten die gleiche Anzahl an Beobachtungen?\n\n-   Gibt es Personen mit fehlenden Werten, die ausgeschlossen werden müssen?\n\n-   Gibt es Personen doppelt im Datensatz?\n\nGibt es unmögliche Werte in den Daten, z. B. -999? Wie können diese Daten ersetzt werden z.B aus anderen Variablen berechnet werden?\nGibt es reverse-kodierte Fragebogenvariablen (var_name_r)?\nGibt es Variablen, die nicht den korrekten Datentyp haben, z. B. numerische Variablen, die als Character angezeigt werden? Schaut euch diese Variablen genau an!\n(Beispiel: drei = 3, stimme voll und ganz zu = höchster Wert)",
    "crumbs": [
      "Checkliste Abschlussarbeit"
    ]
  },
  {
    "objectID": "scripts/04_misc/checkliste_abschlussarbeit.html#weitere-vorbereitende-schritte-im-processed-datensatz",
    "href": "scripts/04_misc/checkliste_abschlussarbeit.html#weitere-vorbereitende-schritte-im-processed-datensatz",
    "title": "Checkliste Abschlussarbeit",
    "section": "Weitere vorbereitende Schritte im processed-Datensatz",
    "text": "Weitere vorbereitende Schritte im processed-Datensatz\n\nMergen der 7 Einzeldatensätze\nDroppen von redundanten Variablen\nUmbenennen von Variablen, die nicht im snake_case-Format sind\nBerechnung der mmq_mean Variable\nErstellung Long-Datensatz\nSpeichern der Daten (Wide & Long)!",
    "crumbs": [
      "Checkliste Abschlussarbeit"
    ]
  },
  {
    "objectID": "scripts/04_misc/checkliste_abschlussarbeit.html#im-analyseskript-analysis-werden",
    "href": "scripts/04_misc/checkliste_abschlussarbeit.html#im-analyseskript-analysis-werden",
    "title": "Checkliste Abschlussarbeit",
    "section": "Im Analyseskript (analysis) werden",
    "text": "Im Analyseskript (analysis) werden\n\nNötige Vorbereitungen gemacht, die nicht zum processing gehören (z.B. Faktoren setzen)\nDie Analysen aus dem Datenanlyseplan durchgeführt!\n\nDeskriptive Statistik (M & SD) berechnen so wie in Table 1 (siehe Grinschgl et al., 2021)\n2x3 mixed ANOVA für subj. Leistungseinschätzungen mit post-hoc t-Tests, inkl.Effektstärken (η2 und Cohen’s d)\nOne-Way ANOVA für jede Offloading Variable (3x), inkl. Effektstärke (η2)\nOne-Way ANOVA für Trial Duration in Pattern Copy Task, inkl. Effektstärke (η2)\nOne-Way ANOVA für MMQ mit post-hoc t-Tests, inkl. Effektstärken (η2 und Cohen’sd)\nOne-Way ANOVA für Arbeitsgedächtnisleistung im Feature Switch Detection Task,inkl. Effektstärke (η2)\n1 Tabelle oder 1 Abbildung nach Wahl erstellen\nOptional: Testen der Voraussetzungen bei jeder Analyse – wenn diese gemacht wird, soll es auch im Datenanalyseplan beschrieben werden und die Analysen bei Voraussetzungsverletzungen entsprechend angepasst werden.\n\n\nPost-hoc-t-Tests werden nur für die 2x3-ANOVA und die MMQ-ANOVA erwartet. Sollte eine weitere ANOVA zufällig signifikante Werte aufweisen, werden hierfür keine Post-hoc-t-Tests verlangt.",
    "crumbs": [
      "Checkliste Abschlussarbeit"
    ]
  },
  {
    "objectID": "scripts/04_misc/checkliste_abschlussarbeit.html#dinge-die-im-datenanalyseplan-angepasst-werden-müssen",
    "href": "scripts/04_misc/checkliste_abschlussarbeit.html#dinge-die-im-datenanalyseplan-angepasst-werden-müssen",
    "title": "Checkliste Abschlussarbeit",
    "section": "Dinge, die im Datenanalyseplan angepasst werden müssen:",
    "text": "Dinge, die im Datenanalyseplan angepasst werden müssen:\n\nData Collection Procedures\nMissing Data\nUnit of Analyses/Data Exclusion",
    "crumbs": [
      "Checkliste Abschlussarbeit"
    ]
  },
  {
    "objectID": "scripts/04_misc/checkliste_abschlussarbeit.html#dinge-die-im-codebook-angepasst-werden-müssen",
    "href": "scripts/04_misc/checkliste_abschlussarbeit.html#dinge-die-im-codebook-angepasst-werden-müssen",
    "title": "Checkliste Abschlussarbeit",
    "section": "Dinge, die im Codebook angepasst werden müssen:",
    "text": "Dinge, die im Codebook angepasst werden müssen:\n\nCoding of item → reverse-kodierte Items\nCoding of Missing Data (falls vorhanden)\n1stes Blatt: Data Collection Procedures → Simulierte Daten.",
    "crumbs": [
      "Checkliste Abschlussarbeit"
    ]
  },
  {
    "objectID": "scripts/04_misc/checkliste_abschlussarbeit.html#ordnerstruktur-für-die-abgabe",
    "href": "scripts/04_misc/checkliste_abschlussarbeit.html#ordnerstruktur-für-die-abgabe",
    "title": "Checkliste Abschlussarbeit",
    "section": "Ordnerstruktur für die Abgabe",
    "text": "Ordnerstruktur für die Abgabe\nDie (für unser Seminar leicht abgeänderte) Psych-DS-Struktur wird eingehalten. Das bedeutet:\n\nDaten im Ordner data.\n\n-   Rohdaten in `data/raw` (werden nicht verändert).\n\n-   Aufbereitete Daten (`dat_full`) in `data/processed`\n\nAnalyseskripte (processing und analysis) im Ordner code\nGerenderte Analyseskripte (html) ebenfalls im Ordner code\nDatenanalyseplan im Ordner preregistration\nCodebook im Ordner data",
    "crumbs": [
      "Checkliste Abschlussarbeit"
    ]
  },
  {
    "objectID": "scripts/04_misc/checkliste_abschlussarbeit.html#self-check-wie-sehen-plausible-ergebnisse-aus",
    "href": "scripts/04_misc/checkliste_abschlussarbeit.html#self-check-wie-sehen-plausible-ergebnisse-aus",
    "title": "Checkliste Abschlussarbeit",
    "section": "Self-Check: Wie sehen plausible Ergebnisse aus?",
    "text": "Self-Check: Wie sehen plausible Ergebnisse aus?\nDie grundsätzliche Struktur der Daten sollte sehr ähnlich zu den Originaldaten sein.\n\nBeispiel aus einem simulierten Datensatz vs Originaldaten\n\nDie Ergebnisse bewegen sich alle in einem ähnlichen Rahmen wie die Daten aus der Originalstudie.\nOriginale Ergebnisse\n\n\n\n\n\nSimulierter Datensatz\n\n\n\n\n\nDementsprechend werden auch die Effekte der Analysen ähnlich ausfallen:",
    "crumbs": [
      "Checkliste Abschlussarbeit"
    ]
  },
  {
    "objectID": "scripts/04_misc/checkliste_abschlussarbeit.html#zu-erwartende-abweichungen-der-ergebnisse-von-der-originalstudie",
    "href": "scripts/04_misc/checkliste_abschlussarbeit.html#zu-erwartende-abweichungen-der-ergebnisse-von-der-originalstudie",
    "title": "Checkliste Abschlussarbeit",
    "section": "Zu erwartende Abweichungen der Ergebnisse von der Originalstudie:",
    "text": "Zu erwartende Abweichungen der Ergebnisse von der Originalstudie:\n\nZufällig signifikante Effekte, die in der Originalstudie nicht signifikant waren, sind möglich. In der Originalstudie zeigte diese Variable keinen signifikanten Effekt. Post-hoc-t-Tests werden hierfür jedoch nicht erwartet.\n\n\n\nEinzelne Werte werden sich unterscheiden! Deskriptiva, Effektgrössen usw. werden sich unterscheiden! Eta2 sind hier grösser als in der Originalstudie.\n\n\n\n\n\n\n\nDeskriptiva: Unterschiede in den Means und SDs!\n\n\n\n\n\n\n##Unplausible Resultate\nErgebnisse die ein komplett anderes Gesamtbild hinterlassen sind nicht zu erwarten!",
    "crumbs": [
      "Checkliste Abschlussarbeit"
    ]
  },
  {
    "objectID": "scripts/04_misc/links_und_ressourcen.html",
    "href": "scripts/04_misc/links_und_ressourcen.html",
    "title": "Links und Ressourcen",
    "section": "",
    "text": "Auf dieser Seite finden sich die Links zu den Ressourcen, die wir im Rahmen dieses Seminars empfehlen.",
    "crumbs": [
      "Links und Ressourcen"
    ]
  },
  {
    "objectID": "scripts/04_misc/links_und_ressourcen.html#open-science-und-replikationskrise",
    "href": "scripts/04_misc/links_und_ressourcen.html#open-science-und-replikationskrise",
    "title": "Links und Ressourcen",
    "section": "Open Science und Replikationskrise",
    "text": "Open Science und Replikationskrise\n\n🎥 Is there a reproducibility crisis in science? – Matt Anticole\n📘 The Seven Deadly Sins of Psychology (Chris Chambers, 2017)\n🏛️ Universitätsbibliothek Bern – Open Science\n🌐 Data Colada\n☕ ReproducibiliTea\n🎓 Universität Bern – Lehrveranstaltungen Institut für Psychologie\n🎥 Charlotte Pennington – A Student’s Guide to Open Science",
    "crumbs": [
      "Links und Ressourcen"
    ]
  },
  {
    "objectID": "scripts/04_misc/links_und_ressourcen.html#r-und-r-studio",
    "href": "scripts/04_misc/links_und_ressourcen.html#r-und-r-studio",
    "title": "Links und Ressourcen",
    "section": "R und R-Studio",
    "text": "R und R-Studio\n\n📗 Einführung in R – Methodenlehre Uni Bern (Andrew Ellis & Boris Mayer)\n📘 R for Data Science – Basics wie Import, Aufbereitung, Visualisierung\n📖 R für Einsteiger – Maike Luhmann\n📊 Psychometrics in Exercises using R and RStudio – EFA, CFA, SEM\n📦 Informationen zu R-Paketen (CRAN)\n🤖 Psyteacher AI Tutor\n💡 Learnr Shinyapps\n📋 RStudio Cheatsheets\n💬 Stack Overflow – R Community\n🎓 DataCamp – Interactive R Courses\n📰 Newsletter zu R – Aktuelle News, Pakete und Tutorials aus der R-Community\n📚 Überblick über weitere Ressourcen – Arslan (2025)",
    "crumbs": [
      "Links und Ressourcen"
    ]
  },
  {
    "objectID": "scripts/04_misc/requirements.html",
    "href": "scripts/04_misc/requirements.html",
    "title": "Requirements",
    "section": "",
    "text": "# requirements.R\n\n# Nutze das benutzerdefinierte Library-Verzeichnis, falls gesetzt\nif (!is.na(Sys.getenv(\"R_LIBS_USER\", unset = NA))) {\n  .libPaths(Sys.getenv(\"R_LIBS_USER\"))\n}\n\ninstall_if_missing &lt;- function(pkg) {\n  if (!pkg %in% rownames(installed.packages())) {\n    install.packages(pkg, repos = \"https://cloud.r-project.org\")\n  }\n}\n\n# Liste der benötigten Pakete – hier kannst du jederzeit erweitern\npkgs &lt;- c(\n  \"tidyverse\",\n  \"knitr\",\n  \"rmarkdown\"\n)\n\nsapply(pkgs, install_if_missing)"
  },
  {
    "objectID": "scripts/02_excercises/hausuebung_loesung_3.html",
    "href": "scripts/02_excercises/hausuebung_loesung_3.html",
    "title": "hausuebung_3",
    "section": "",
    "text": "Abgabe bis: Freitag 12.12, 23:55 via ILIAS\nZip-Datei benennen: vorname_nachname.zip\n\nGerendertes Skript: vorname_nachname_hausuebung_3.html\nUngerendertes Quarto-Skript: vorname_nachname_hausuebung_3.qmd\n\nPeer Feedback: Bis 17.12 direkt an die Person und im Forum als Zusammenfassung. Im Forum bitte auch Namen der Person, für die das Feedback bestimmt ist, nennen.\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nStelle deinen YAML-Header so ein, dass ein table of contents erstellt wird, embed-resources: true aktiviert ist und das Ausgabeformat auf html gesetzt wird. Dies verbessert die Leserlichkeit des Dokuments.\n\n\n\n📥 Download therapie_bedingung.csv\n📥 Download therapie_results.csv\n\n\n\n\nIn den folgenden Daten versuchst du herauszufinden, ob sich eine neuartige Therapie von der Kontrollgruppe (Warteliste) unterscheidet. Dafür wurde das Wohlbefinden der Personen über drei Zeitpunkte hinweg gemessen (therapie_results). Zuerst musst du die Daten bereinigen, mergen und visualisieren und zum Schluss mit einem Hypothesentest entscheiden, ob die neue Therapieform besser abschneidet als die Kontrollgruppe.\n\nLies die beiden Datensätze therapie_Bedingung und therapie_results ein.\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\ntherapie_results &lt;- read_delim(\"raw/therapie_results.csv\",  delim = \";\", escape_double = FALSE, trim_ws = TRUE)\n\ntherapie_bedingung &lt;- read_delim(\"raw/therapie_bedingung.csv\",  delim = \";\", escape_double = FALSE, trim_ws = TRUE)\n\n\n\n\n\nBereinge die Datensätze! Gibt es duplizierte Werte? Gibt es Missings? Gibt es unmögliche Werte?\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\nskimr::skim(therapie_bedingung)\n\n\nData summary\n\n\nName\ntherapie_bedingung\n\n\nNumber of rows\n54\n\n\nNumber of columns\n2\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nbedingung\n0\n1\n14\n14\n0\n2\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nid\n0\n1\n25.28\n14.5\n1\n13.25\n24.5\n37.75\n50\n▇▇▇▇▇\n\n\n\n\nskim(therapie_results)\n\n\nData summary\n\n\nName\ntherapie_results\n\n\nNumber of rows\n50\n\n\nNumber of columns\n4\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nid\n0\n1\n25.50\n14.58\n1\n13.25\n25.5\n37.75\n50\n▇▇▇▇▇\n\n\nbeginn\n0\n1\n3.62\n1.34\n1\n2.80\n3.6\n4.60\n6\n▃▇▇▃▆\n\n\nmitte\n0\n1\n3.86\n1.36\n1\n3.00\n3.8\n4.95\n6\n▅▃▇▅▆\n\n\nende\n0\n1\n3.76\n1.39\n1\n3.00\n3.7\n5.00\n6\n▃▅▇▇▅\n\n\n\n\ntherapie_bedingung_clean &lt;- unique(therapie_bedingung)\n\nIm Datensatz therapie_bedingung gab es duplizierte Werte, die mit der Funktion unique() entfernt wurden. In beiden Datensätzen gab es keine Missings oder unmöglichen Werte.\n\n\n\n\nMerge die bereinigten Datensätze!\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\ntherapie &lt;- full_join(therapie_bedingung_clean, therapie_results, by = \"id\")\n\n\n\n\n\nWandle die Variablen id und bedingung in Faktoren um.\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\n# Variablen zu Faktoren umwandeln\ntherapie$id &lt;- as.factor(therapie$id)\ntherapie$bedingung &lt;- as.factor(therapie$bedingung)\n\n\n\n\n\nFühre eine Wide-to-Long-Transformation durch und erstelle damit einen Dataframe therapie_long mit einem messwiederholten Faktor messzeitpunkt und der (Outcome-)Variable wohlbefinden. Diese setzt sich aus den Werten in beginn, mitte und ende zusammen.\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\ntherapie_long &lt;- therapie  |&gt; \n  pivot_longer(\n    cols = c(\"beginn\", \"mitte\", \"ende\"), \n    names_to = \"messzeitpunkt\", \n    values_to = \"wohlbefinden\"\n    )\n\n\n\n\n\nDefiniere die Variable messzeitpunkt als Faktor mit den Faktorstufen beginn, mitte und ende (in genau dieser Reihenfolge).\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\ntherapie_long &lt;-  therapie_long |&gt;  \n    mutate(messzeitpunkt = factor(messzeitpunkt, \n                                  levels = c(\"beginn\", \"mitte\", \"ende\")))\nlevels(therapie_long$messzeitpunkt)\n\n[1] \"beginn\" \"mitte\"  \"ende\"  \n\n\n\n\n\n\n\n\n\n\nBevor wir die Daten mit Hypothesentests analysieren, wollen wir ein Gefühl für die Daten erhalten. Plotte dafür den Mittelwertsverlauf mit Fehlerbalken über die drei Zeitpunkte hinweg. Nutze den zur Verfügung gestellten Code, um ein Summary zu erstellen.\n\n\nsummary_data &lt;- therapie_long |&gt;\n  group_by(bedingung, messzeitpunkt) |&gt;\n  summarise(\n    mean_wb = mean(wohlbefinden),\n    se_wb   = sd(wohlbefinden) / sqrt(n())\n  )\n\n\nPlotte nun die Daten. Färbe die Verlaufslinien nach Versuchsbedingung ein und gruppiere die Daten mit color = bedingung und group = bedingung. Verwende drei Geoms:\n\ngeom_line() für die Verlaufslinien\ngeom_point() für die einzelnen Datenpunkten\ngeom_errorbar() für die Fehlerbalken.\n\nFüge ausserdem angemessene Formatierungen hinzu (Titel, Achsenbeschriftungen, Theme).\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\nggplot(summary_data, aes(x = messzeitpunkt, y = mean_wb,\n                         color = bedingung, group = bedingung)) +\n  geom_line() +\n  geom_point() +\n  geom_errorbar(aes(ymin = mean_wb - se_wb, ymax = mean_wb + se_wb),\n                width = 0.1) +\n  labs(\n    x = \"Messzeitpunkt\",\n    y = \"Wohlbefinden\",\n    color = \"Bedingung\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPrüfe die Daten auf Varianzhomogenität und nutze dafür den Levene-Test. Der Levene-Test wird für die abhängige Variable über den Between-Faktor berechnet (also: Sind die Varianzen der AV über die drei Gruppen hinweg ähnlich verteilt?).\n\nErgänze dafür den Code um die nötigen Variablen. Der Test prüft gegen Varianzhomogenität; daher bedeutet ein nicht signifikantes Ergebnis, dass die Voraussetzung für die ANOVA nicht verletzt ist.\n\n\nleveneTest(AV ~ Gruppen, data = )\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\nleveneTest(wohlbefinden ~ bedingung, data = therapie_long)\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value Pr(&gt;F)\ngroup   1   0.485 0.4873\n      148               \n\n\nDer Levene-Test ist nicht signifikant (p &gt; .05), somit ist die Voraussetzung der Varianzhomogenität über die verschiedenen Gruppen hinweg erfüllt.\n\n\n\n\nFühre eine Mixed-Design-ANOVA mit aov_4() (aus dem Paket “afex”) durch. Die abhängige Variable ist wohlbefinden, der unabhängige Between-Faktor ist bedingung und der unabhängige Within-Faktor ist messzeitpunkt. Die Formel für die ANOVA lautet: AV ~ Between-Faktor + (Within-Faktor). Für den Within-Faktor verwenden wir die folgende Schreibweise: (messzeitpunkt | id), da die Messwiederholungen innerhalb jeder Person verschachtelt sind.\n\nPasse den Code an:\n\nanova_1 &lt;- aov_4(AV ~ between_subjects_faktor + (messzeitpunkt | id) data = ))\n  \nsummary(anova_1)\n\n\n\n\n\n\n\nNote\n\n\n\nSchaue dir die Ergebnisse einschliesslich des Mauchly-Tests auf Sphärizität an – dieser ist relevant bei mindestens drei Within-Faktoren. Der Mauchly-Test sollte nicht signifikant sein, sodass wir Sphärizität annehmen können (ähnlich zum Levene Test). Falls doch: Werte nach Greenhouse-Geisser-Korrektur interpretieren.\n\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\nanova_1 &lt;- aov_4(wohlbefinden ~ bedingung + (messzeitpunkt | id),\n                      data = therapie_long)\n\nsummary(anova_1)\n\n\nUnivariate Type III Repeated-Measures ANOVA Assuming Sphericity\n\n                         Sum Sq num Df Error SS den Df  F value    Pr(&gt;F)    \n(Intercept)             2104.13      1  196.775     48 513.2660 &lt; 2.2e-16 ***\nbedingung                  3.78      1  196.775     48   0.9212     0.342    \nmesszeitpunkt              1.41      2   57.833     96   1.1691     0.315    \nbedingung:messzeitpunkt   15.24      2   57.833     96  12.6481 1.332e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nMauchly Tests for Sphericity\n\n                        Test statistic p-value\nmesszeitpunkt                  0.97258  0.5203\nbedingung:messzeitpunkt        0.97258  0.5203\n\n\nGreenhouse-Geisser and Huynh-Feldt Corrections\n for Departure from Sphericity\n\n                         GG eps Pr(&gt;F[GG])    \nmesszeitpunkt           0.97331     0.3142    \nbedingung:messzeitpunkt 0.97331   1.66e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                          HF eps   Pr(&gt;F[HF])\nmesszeitpunkt           1.013874 3.150422e-01\nbedingung:messzeitpunkt 1.013874 1.331591e-05\n\n\nMit den Messzeitpunkten beginn, mitte und ende liegen drei Within-Faktoren vor. Daher wird der Mauchly-Test notwendig. Dieser ist nicht signifikant (p &gt; .05), sodass wir Sphärizität annehmen können. Die ANOVA zeigt keinen signifikanten Haupteffekt für den Between-Faktor bedingung (p &gt; .05) und keinen signifikanten Haupteffekt für den Within-Faktor messzeitpunkt (p &gt; .05). Signifikant ist allerdings die Interaktion des Between-Faktors bedingung und des Within-Faktor messzeitpunkt. Das bedeutet, abhängig von der Bedingung, zu welcher eine Versuchsperson gehört, verändert sich das Wohlbefinden einer Person unterschiedlich.\n\n\n\n\nBerechne die die ANOVA erneut und inkludiere die Berechnung des partiellen Eta². Nutze dafür als zusätzliches Argument in der aov_4 Funktion anova_table = list(es = c(\"ges\", \"pes\"))) .\nBetrachte die Ergebnisse indem du mit $ auf anova_table des Objekts zugreifst in dem du die ANOVA abgespeichert hast.\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\nanova_2 &lt;- aov_4(wohlbefinden ~ bedingung + (messzeitpunkt | id),\n                      data = therapie_long,\n                anova_table = list(es = c(\"ges\", \"pes\")))\n\n\nanova_2$anova_table\n\nAnova Table (Type 3 tests)\n\nResponse: wohlbefinden\n                        num Df den Df    MSE       F      pes      ges   Pr(&gt;F)\nbedingung               1.0000 48.000 4.0995  0.9212 0.018829 0.014615   0.3420\nmesszeitpunkt           1.9466 93.438 0.6189  1.1691 0.023776 0.005502   0.3142\nbedingung:messzeitpunkt 1.9466 93.438 0.6189 12.6481 0.208548 0.056473 1.66e-05\n                           \nbedingung                  \nmesszeitpunkt              \nbedingung:messzeitpunkt ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nges und pes geben das generelle und partielle Eta² an. Genauere Erläuterungen zum Unterschied zwischen den beiden Massen findest du auch noch mal in unserem FAQ. Das generelle Eta² ist für den Between-Faktor bedingung ges = 0.015 und für den Within-Faktor messzeitpunkt ges = 0.005. Das partielle Eta² ist für den Between-Faktor bedingung pes = 0.019 und für den Within-Faktor messzeitpunkt pes = 0.024.\n\n\n\n\nBerechne nun paarweise Post-hoc-Vergleiche mit Tukey-Korrektur (Korrektur für multiples Testen), indem du zuerst emmeans() (aus dem Paket “emmeans”) speicherst und anschliessend die Funktion pairs() anwendest. Hier ist ein Muster-Code:\n\n\nresult &lt;- emmeans(object = your_anova_model, specs = ~ messwiederholung_faktor * between_factor)\npairs(results, simple = \"mw_factor\", adjust = \"tukey\")\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\nresult_emmeans &lt;- emmeans(object = anova_1, specs = ~ messzeitpunkt * bedingung)\n\npairs(result_emmeans, simple = \"bedingung\", adjust = \"tukey\")\n\nmesszeitpunkt = beginn:\n contrast                        estimate    SE df t.ratio p.value\n Kontrollgruppe - Therapiegruppe    0.584 0.373 48   1.565  0.1241\n\nmesszeitpunkt = mitte:\n contrast                        estimate    SE df t.ratio p.value\n Kontrollgruppe - Therapiegruppe   -0.752 0.374 48  -2.012  0.0498\n\nmesszeitpunkt = ende:\n contrast                        estimate    SE df t.ratio p.value\n Kontrollgruppe - Therapiegruppe   -0.784 0.381 48  -2.056  0.0453\n\npairs(result_emmeans, simple = \"messzeitpunkt\", adjust = \"tukey\")\n\nbedingung = Kontrollgruppe:\n contrast       estimate    SE df t.ratio p.value\n beginn - mitte    0.432 0.201 48   2.151  0.0903\n beginn - ende     0.544 0.231 48   2.357  0.0575\n mitte - ende      0.112 0.226 48   0.496  0.8736\n\nbedingung = Therapiegruppe:\n contrast       estimate    SE df t.ratio p.value\n beginn - mitte   -0.904 0.201 48  -4.502  0.0001\n beginn - ende    -0.824 0.231 48  -3.571  0.0023\n mitte - ende      0.080 0.226 48   0.354  0.9333\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\nDie vorherige globale ANOVA zeigte eine signifikante Interaktion an. Mit emmeans und pairs lässt sich nun herausfinden, zwischen welchen Messzeitpunkten die signifikanten Unterschiede bestehen. Die paarweisen Vergleiche zeigen, dass es signifikante Unterschiede im Wohlbefinden zwischen der Kontrollgruppe und der Therapiegruppe sowohl zur Mitte als auch zum Ende der Therapie gibt (p &lt; .05). Es gibt jedoch keine signifikanten Unterschiede zu Beginn der Therapie (p &gt; .05). Dies spiegelt die eben gefundene Interaktion wieder und deutet darauf hin, dass die neue Therapieform im Vergleich zur Kontrollgruppe hinsichtlich des Wohlbefindens der Personen über die Zeit hinweg zu positiveren Resultaten führt.",
    "crumbs": [
      "Hausübungen",
      "Hausübung 3 - Mit Lösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/hausuebung_loesung_3.html#formalitäten-und-abgabe",
    "href": "scripts/02_excercises/hausuebung_loesung_3.html#formalitäten-und-abgabe",
    "title": "hausuebung_3",
    "section": "",
    "text": "Abgabe bis: Freitag 12.12, 23:55 via ILIAS\nZip-Datei benennen: vorname_nachname.zip\n\nGerendertes Skript: vorname_nachname_hausuebung_3.html\nUngerendertes Quarto-Skript: vorname_nachname_hausuebung_3.qmd\n\nPeer Feedback: Bis 17.12 direkt an die Person und im Forum als Zusammenfassung. Im Forum bitte auch Namen der Person, für die das Feedback bestimmt ist, nennen.\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nStelle deinen YAML-Header so ein, dass ein table of contents erstellt wird, embed-resources: true aktiviert ist und das Ausgabeformat auf html gesetzt wird. Dies verbessert die Leserlichkeit des Dokuments.\n\n\n\n📥 Download therapie_bedingung.csv\n📥 Download therapie_results.csv",
    "crumbs": [
      "Hausübungen",
      "Hausübung 3 - Mit Lösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/hausuebung_loesung_3.html#datensätze-therapie-einlesen-und-bereinigen",
    "href": "scripts/02_excercises/hausuebung_loesung_3.html#datensätze-therapie-einlesen-und-bereinigen",
    "title": "hausuebung_3",
    "section": "",
    "text": "In den folgenden Daten versuchst du herauszufinden, ob sich eine neuartige Therapie von der Kontrollgruppe (Warteliste) unterscheidet. Dafür wurde das Wohlbefinden der Personen über drei Zeitpunkte hinweg gemessen (therapie_results). Zuerst musst du die Daten bereinigen, mergen und visualisieren und zum Schluss mit einem Hypothesentest entscheiden, ob die neue Therapieform besser abschneidet als die Kontrollgruppe.\n\nLies die beiden Datensätze therapie_Bedingung und therapie_results ein.\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\ntherapie_results &lt;- read_delim(\"raw/therapie_results.csv\",  delim = \";\", escape_double = FALSE, trim_ws = TRUE)\n\ntherapie_bedingung &lt;- read_delim(\"raw/therapie_bedingung.csv\",  delim = \";\", escape_double = FALSE, trim_ws = TRUE)\n\n\n\n\n\nBereinge die Datensätze! Gibt es duplizierte Werte? Gibt es Missings? Gibt es unmögliche Werte?\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\nskimr::skim(therapie_bedingung)\n\n\nData summary\n\n\nName\ntherapie_bedingung\n\n\nNumber of rows\n54\n\n\nNumber of columns\n2\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nnumeric\n1\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nbedingung\n0\n1\n14\n14\n0\n2\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nid\n0\n1\n25.28\n14.5\n1\n13.25\n24.5\n37.75\n50\n▇▇▇▇▇\n\n\n\n\nskim(therapie_results)\n\n\nData summary\n\n\nName\ntherapie_results\n\n\nNumber of rows\n50\n\n\nNumber of columns\n4\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nid\n0\n1\n25.50\n14.58\n1\n13.25\n25.5\n37.75\n50\n▇▇▇▇▇\n\n\nbeginn\n0\n1\n3.62\n1.34\n1\n2.80\n3.6\n4.60\n6\n▃▇▇▃▆\n\n\nmitte\n0\n1\n3.86\n1.36\n1\n3.00\n3.8\n4.95\n6\n▅▃▇▅▆\n\n\nende\n0\n1\n3.76\n1.39\n1\n3.00\n3.7\n5.00\n6\n▃▅▇▇▅\n\n\n\n\ntherapie_bedingung_clean &lt;- unique(therapie_bedingung)\n\nIm Datensatz therapie_bedingung gab es duplizierte Werte, die mit der Funktion unique() entfernt wurden. In beiden Datensätzen gab es keine Missings oder unmöglichen Werte.\n\n\n\n\nMerge die bereinigten Datensätze!\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\ntherapie &lt;- full_join(therapie_bedingung_clean, therapie_results, by = \"id\")\n\n\n\n\n\nWandle die Variablen id und bedingung in Faktoren um.\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\n# Variablen zu Faktoren umwandeln\ntherapie$id &lt;- as.factor(therapie$id)\ntherapie$bedingung &lt;- as.factor(therapie$bedingung)\n\n\n\n\n\nFühre eine Wide-to-Long-Transformation durch und erstelle damit einen Dataframe therapie_long mit einem messwiederholten Faktor messzeitpunkt und der (Outcome-)Variable wohlbefinden. Diese setzt sich aus den Werten in beginn, mitte und ende zusammen.\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\ntherapie_long &lt;- therapie  |&gt; \n  pivot_longer(\n    cols = c(\"beginn\", \"mitte\", \"ende\"), \n    names_to = \"messzeitpunkt\", \n    values_to = \"wohlbefinden\"\n    )\n\n\n\n\n\nDefiniere die Variable messzeitpunkt als Faktor mit den Faktorstufen beginn, mitte und ende (in genau dieser Reihenfolge).\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\ntherapie_long &lt;-  therapie_long |&gt;  \n    mutate(messzeitpunkt = factor(messzeitpunkt, \n                                  levels = c(\"beginn\", \"mitte\", \"ende\")))\nlevels(therapie_long$messzeitpunkt)\n\n[1] \"beginn\" \"mitte\"  \"ende\"",
    "crumbs": [
      "Hausübungen",
      "Hausübung 3 - Mit Lösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/hausuebung_loesung_3.html#daten-visualisieren",
    "href": "scripts/02_excercises/hausuebung_loesung_3.html#daten-visualisieren",
    "title": "hausuebung_3",
    "section": "",
    "text": "Bevor wir die Daten mit Hypothesentests analysieren, wollen wir ein Gefühl für die Daten erhalten. Plotte dafür den Mittelwertsverlauf mit Fehlerbalken über die drei Zeitpunkte hinweg. Nutze den zur Verfügung gestellten Code, um ein Summary zu erstellen.\n\n\nsummary_data &lt;- therapie_long |&gt;\n  group_by(bedingung, messzeitpunkt) |&gt;\n  summarise(\n    mean_wb = mean(wohlbefinden),\n    se_wb   = sd(wohlbefinden) / sqrt(n())\n  )\n\n\nPlotte nun die Daten. Färbe die Verlaufslinien nach Versuchsbedingung ein und gruppiere die Daten mit color = bedingung und group = bedingung. Verwende drei Geoms:\n\ngeom_line() für die Verlaufslinien\ngeom_point() für die einzelnen Datenpunkten\ngeom_errorbar() für die Fehlerbalken.\n\nFüge ausserdem angemessene Formatierungen hinzu (Titel, Achsenbeschriftungen, Theme).\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\nggplot(summary_data, aes(x = messzeitpunkt, y = mean_wb,\n                         color = bedingung, group = bedingung)) +\n  geom_line() +\n  geom_point() +\n  geom_errorbar(aes(ymin = mean_wb - se_wb, ymax = mean_wb + se_wb),\n                width = 0.1) +\n  labs(\n    x = \"Messzeitpunkt\",\n    y = \"Wohlbefinden\",\n    color = \"Bedingung\"\n  ) +\n  theme_minimal()",
    "crumbs": [
      "Hausübungen",
      "Hausübung 3 - Mit Lösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/hausuebung_loesung_3.html#anovas-und-post-hoc-t-tests",
    "href": "scripts/02_excercises/hausuebung_loesung_3.html#anovas-und-post-hoc-t-tests",
    "title": "hausuebung_3",
    "section": "",
    "text": "Prüfe die Daten auf Varianzhomogenität und nutze dafür den Levene-Test. Der Levene-Test wird für die abhängige Variable über den Between-Faktor berechnet (also: Sind die Varianzen der AV über die drei Gruppen hinweg ähnlich verteilt?).\n\nErgänze dafür den Code um die nötigen Variablen. Der Test prüft gegen Varianzhomogenität; daher bedeutet ein nicht signifikantes Ergebnis, dass die Voraussetzung für die ANOVA nicht verletzt ist.\n\n\nleveneTest(AV ~ Gruppen, data = )\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\nleveneTest(wohlbefinden ~ bedingung, data = therapie_long)\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value Pr(&gt;F)\ngroup   1   0.485 0.4873\n      148               \n\n\nDer Levene-Test ist nicht signifikant (p &gt; .05), somit ist die Voraussetzung der Varianzhomogenität über die verschiedenen Gruppen hinweg erfüllt.\n\n\n\n\nFühre eine Mixed-Design-ANOVA mit aov_4() (aus dem Paket “afex”) durch. Die abhängige Variable ist wohlbefinden, der unabhängige Between-Faktor ist bedingung und der unabhängige Within-Faktor ist messzeitpunkt. Die Formel für die ANOVA lautet: AV ~ Between-Faktor + (Within-Faktor). Für den Within-Faktor verwenden wir die folgende Schreibweise: (messzeitpunkt | id), da die Messwiederholungen innerhalb jeder Person verschachtelt sind.\n\nPasse den Code an:\n\nanova_1 &lt;- aov_4(AV ~ between_subjects_faktor + (messzeitpunkt | id) data = ))\n  \nsummary(anova_1)\n\n\n\n\n\n\n\nNote\n\n\n\nSchaue dir die Ergebnisse einschliesslich des Mauchly-Tests auf Sphärizität an – dieser ist relevant bei mindestens drei Within-Faktoren. Der Mauchly-Test sollte nicht signifikant sein, sodass wir Sphärizität annehmen können (ähnlich zum Levene Test). Falls doch: Werte nach Greenhouse-Geisser-Korrektur interpretieren.\n\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\nanova_1 &lt;- aov_4(wohlbefinden ~ bedingung + (messzeitpunkt | id),\n                      data = therapie_long)\n\nsummary(anova_1)\n\n\nUnivariate Type III Repeated-Measures ANOVA Assuming Sphericity\n\n                         Sum Sq num Df Error SS den Df  F value    Pr(&gt;F)    \n(Intercept)             2104.13      1  196.775     48 513.2660 &lt; 2.2e-16 ***\nbedingung                  3.78      1  196.775     48   0.9212     0.342    \nmesszeitpunkt              1.41      2   57.833     96   1.1691     0.315    \nbedingung:messzeitpunkt   15.24      2   57.833     96  12.6481 1.332e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nMauchly Tests for Sphericity\n\n                        Test statistic p-value\nmesszeitpunkt                  0.97258  0.5203\nbedingung:messzeitpunkt        0.97258  0.5203\n\n\nGreenhouse-Geisser and Huynh-Feldt Corrections\n for Departure from Sphericity\n\n                         GG eps Pr(&gt;F[GG])    \nmesszeitpunkt           0.97331     0.3142    \nbedingung:messzeitpunkt 0.97331   1.66e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                          HF eps   Pr(&gt;F[HF])\nmesszeitpunkt           1.013874 3.150422e-01\nbedingung:messzeitpunkt 1.013874 1.331591e-05\n\n\nMit den Messzeitpunkten beginn, mitte und ende liegen drei Within-Faktoren vor. Daher wird der Mauchly-Test notwendig. Dieser ist nicht signifikant (p &gt; .05), sodass wir Sphärizität annehmen können. Die ANOVA zeigt keinen signifikanten Haupteffekt für den Between-Faktor bedingung (p &gt; .05) und keinen signifikanten Haupteffekt für den Within-Faktor messzeitpunkt (p &gt; .05). Signifikant ist allerdings die Interaktion des Between-Faktors bedingung und des Within-Faktor messzeitpunkt. Das bedeutet, abhängig von der Bedingung, zu welcher eine Versuchsperson gehört, verändert sich das Wohlbefinden einer Person unterschiedlich.\n\n\n\n\nBerechne die die ANOVA erneut und inkludiere die Berechnung des partiellen Eta². Nutze dafür als zusätzliches Argument in der aov_4 Funktion anova_table = list(es = c(\"ges\", \"pes\"))) .\nBetrachte die Ergebnisse indem du mit $ auf anova_table des Objekts zugreifst in dem du die ANOVA abgespeichert hast.\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\nanova_2 &lt;- aov_4(wohlbefinden ~ bedingung + (messzeitpunkt | id),\n                      data = therapie_long,\n                anova_table = list(es = c(\"ges\", \"pes\")))\n\n\nanova_2$anova_table\n\nAnova Table (Type 3 tests)\n\nResponse: wohlbefinden\n                        num Df den Df    MSE       F      pes      ges   Pr(&gt;F)\nbedingung               1.0000 48.000 4.0995  0.9212 0.018829 0.014615   0.3420\nmesszeitpunkt           1.9466 93.438 0.6189  1.1691 0.023776 0.005502   0.3142\nbedingung:messzeitpunkt 1.9466 93.438 0.6189 12.6481 0.208548 0.056473 1.66e-05\n                           \nbedingung                  \nmesszeitpunkt              \nbedingung:messzeitpunkt ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nges und pes geben das generelle und partielle Eta² an. Genauere Erläuterungen zum Unterschied zwischen den beiden Massen findest du auch noch mal in unserem FAQ. Das generelle Eta² ist für den Between-Faktor bedingung ges = 0.015 und für den Within-Faktor messzeitpunkt ges = 0.005. Das partielle Eta² ist für den Between-Faktor bedingung pes = 0.019 und für den Within-Faktor messzeitpunkt pes = 0.024.\n\n\n\n\nBerechne nun paarweise Post-hoc-Vergleiche mit Tukey-Korrektur (Korrektur für multiples Testen), indem du zuerst emmeans() (aus dem Paket “emmeans”) speicherst und anschliessend die Funktion pairs() anwendest. Hier ist ein Muster-Code:\n\n\nresult &lt;- emmeans(object = your_anova_model, specs = ~ messwiederholung_faktor * between_factor)\npairs(results, simple = \"mw_factor\", adjust = \"tukey\")\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\nresult_emmeans &lt;- emmeans(object = anova_1, specs = ~ messzeitpunkt * bedingung)\n\npairs(result_emmeans, simple = \"bedingung\", adjust = \"tukey\")\n\nmesszeitpunkt = beginn:\n contrast                        estimate    SE df t.ratio p.value\n Kontrollgruppe - Therapiegruppe    0.584 0.373 48   1.565  0.1241\n\nmesszeitpunkt = mitte:\n contrast                        estimate    SE df t.ratio p.value\n Kontrollgruppe - Therapiegruppe   -0.752 0.374 48  -2.012  0.0498\n\nmesszeitpunkt = ende:\n contrast                        estimate    SE df t.ratio p.value\n Kontrollgruppe - Therapiegruppe   -0.784 0.381 48  -2.056  0.0453\n\npairs(result_emmeans, simple = \"messzeitpunkt\", adjust = \"tukey\")\n\nbedingung = Kontrollgruppe:\n contrast       estimate    SE df t.ratio p.value\n beginn - mitte    0.432 0.201 48   2.151  0.0903\n beginn - ende     0.544 0.231 48   2.357  0.0575\n mitte - ende      0.112 0.226 48   0.496  0.8736\n\nbedingung = Therapiegruppe:\n contrast       estimate    SE df t.ratio p.value\n beginn - mitte   -0.904 0.201 48  -4.502  0.0001\n beginn - ende    -0.824 0.231 48  -3.571  0.0023\n mitte - ende      0.080 0.226 48   0.354  0.9333\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\nDie vorherige globale ANOVA zeigte eine signifikante Interaktion an. Mit emmeans und pairs lässt sich nun herausfinden, zwischen welchen Messzeitpunkten die signifikanten Unterschiede bestehen. Die paarweisen Vergleiche zeigen, dass es signifikante Unterschiede im Wohlbefinden zwischen der Kontrollgruppe und der Therapiegruppe sowohl zur Mitte als auch zum Ende der Therapie gibt (p &lt; .05). Es gibt jedoch keine signifikanten Unterschiede zu Beginn der Therapie (p &gt; .05). Dies spiegelt die eben gefundene Interaktion wieder und deutet darauf hin, dass die neue Therapieform im Vergleich zur Kontrollgruppe hinsichtlich des Wohlbefindens der Personen über die Zeit hinweg zu positiveren Resultaten führt.",
    "crumbs": [
      "Hausübungen",
      "Hausübung 3 - Mit Lösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/hausuebung_1.html",
    "href": "scripts/02_excercises/hausuebung_1.html",
    "title": "Hausübung 1",
    "section": "",
    "text": "Aufgabenstellung\n\nAbgabefrist: 7.11.2025\nAbgabe auf ILIAS und Weitergabe an Peerpartner:in\nArbeite für diese Hausübung mit Quarto.\nVersuche beim Lösen der Aufgaben darauf zu achten, dass du sie reproduzierbar gestaltest. Am Ende der Aufgabe renderst du dein Skript.\nDie Abgabe besteht dann aus deinem Skript sowie dem gerenderten Skript als HTML- oder PDF-Datei.\n\n\n\nAufgabe 1: Datensatz aufbereiten und beschreiben\nWir arbeiten für die Übungen mit diesem Datensatz. Dieser wurde simuliert und spiegelt keine echten Daten oder Zusammenhänge wider. Der Datensatz beinhaltet demografische Variablen sowie eine Version des BFI-44-Fragebogens. In den folgenden Aufgaben werden wir diesen mit den bisher kennengelernten tidyverse-Funktionen aufbereiten und analysieren.\n 📥 Download fake_bfi_dataset.csv \nNutze die dplyr-Funktionen, die wir kennengelernt haben, um die folgenden Aufgaben zu bearbeiten.\nTipp: In einigen Variablen gibt es fehlende Werte (missings). Die Bearbeitung dieser Werte erfolgt erst in Aufgabe 2. Verwende, falls nötig, das Argument na.rm = TRUE.\nAufgaben\n\nBenenne die Variable Ort in Postleitzahl um.\n\n\nWelche Spalte scheint doppelt vorhanden zu sein? Lösche sie aus dem Datensatz.\n\n\nPersonen die nicht volljährig sind dürfen nicht an der Studie teilnehmen und müssen ausgeschlossen werden.\n\n\nFüge dem Datensatz die Spalte Alterskohorte hinzu. Wenn eine Person über 60 Jahre alt ist, gilt sie als alt, ansonsten als jung.\n\n\nWelche Variablen sollten Faktoren sein? Wandle sie in Faktoren um\n\n\nErstelle eine Kopie des Datensatzes nur mit den demographischen Variablen.\n\nVerwende die dplyr-Funktionen, um die folgenden Fragen zu beantworten:\n\nWelchen Anteil am Gesamtsample hat jeder Ort bzw. jede Postleitzahl, und wie kann dieser als neue Spalte im Datensatz ergänzt werden?\n\n\nIn welchem Quartier leben proportional am meisten Personen, die sich als weiblich beschreiben?\n\n\nWie hoch ist das durschnittliche Alter pro Quartier?\n\n\nWie alt sind die jüngsten Personen getrennt nach Gender?\n\n\nErstelle eine Rangliste der Quartiere nach durchschnittlichem Alter (vom höchsten zum niedrigsten).\n\n\n\nAufgabe 2: Fehlende Werte\n📖Kapitel 4.3.3 Ellis & Mayer\nFühre die folgenden Schritte durch:\n\nUntersuche den Datensatz auf fehlende Werte. Wie viele fehlende Werte gibt es insgesamt, und in welchen Variablen treten sie auf\n\n\nEinige Personen haben keine Angabe zu ihrer Geschlechtsidentität gemacht. Ersetze diese fehlenden Werte (NAs) durch “Keine Angabe”. Nutze dafür die Funktion mutate() und replace_na(). Beachte: Gender wurde bereits als Faktor definiert, muss aber erneut zu einem Character transformiert werden.\n\n\nZeilen mit fehlenden Werten löschen\nErstelle eine Kopie des Datensatzes und verwende drop_na(),\num alle Zeilen mit fehlenden Werten zu entfernen.\n\n\n\nAufgabe 3: Skalenberechnung\n📖Kapitel 4.4. Ellis & Mayer\nAufgaben:\n\nUmwandlung der BFI-Items in numerische Werte.\n\n„Stimme gar nicht zu“ → 1\n„Stimme voll und ganz zu“ → 5\n\n\nVerwende dafür eine Kombination aus mutate(), across() und case_when() oder recode().\n\nUmpolen der negativ formulierten Items\n\nDie negativ formulierten Items enden alle mit _r (für reverse). Poole diese Items um.\nSuche dir eine dplyr Funktion, welche helfen kann alle Variablen auszuwählen welche mit _r aufhören.\n💡Tipp: Ähnlich wie starts_with\n\nBerechnung der Big-Five-Skalen\n\nErstelle neue Variablen, die den Mittelwert jedes Big-Five-Faktors pro Person enthalten.\nMit welcher Funktion kannst du dir ersparen alle Variablen auszuschreiben?\n\n\n\nZusammenhänge zwischen Skalen testen\n\nTeste mit cor.test() die Korrelation zwischen zwei Big-Five-Faktoren,\nzum Beispiel zwischen Extraversion und Offenheit.\n\n\n\n\nBerechne die Durchschnittswerte, Standardabweichungen und Mediane der Big-Five-Faktoren Extraversion und Offenheit, unterteilt nach der Geschlechtsangabe.\n\n\nRendere dein Skript!\n\nGib dein Skript und deine gerenderte Datei als ZIP (Dateinaname: vorname_nachname_hausübung_1.ZIP) datei auf ILIAS ab und leite es deinem oder deiner Peerpartner:in weiter.\n\n\nInstruktionen Peerfeedback:\n\nKommentiere direkt im Quarto File deiner Peerpartner:in und schicke es ihm/ihr zu.\nSchreibe eine kurzen Kommentar im Forum auf ILIAS (Ordner EH8).\n\nFokussiere dich dabei auf die folgenden Punkte:\n\nFunktioniert der Code?\nIst die Analyse reproduzierbar (z. B. durch relative Pfade, Kommentierung des Codes, Einhaltung von Style-Guidelines)?\nWelche Aspekte wurden gut umgesetzt?\nWelche Punkte lassen sich noch verbessern?"
  },
  {
    "objectID": "scripts/02_excercises/hausuebung_2.html",
    "href": "scripts/02_excercises/hausuebung_2.html",
    "title": "hausuebung_2",
    "section": "",
    "text": "Abgabe bis: Freitag 28.11, 23:55 via ILIAS\nZip-Datei benennen: vorname_nachname.zip\n\nGerendertes Skript: vorname_nachname_hausuebung_2.html\nUngerendertes Quarto-Skript: vorname_nachname_hausuebung_2.qmd\n\nPeer Feedback: Bis 3.12 direkt an die Person und im Forum als Zusammenfassung. Im Forum bitte auch Namen der Person, für die das Feedback bestimmt ist, nennen.\n\n\n\n\n[1] TRUE [1] FALSE\n📥 Download practice_dataset2.csv\n\n\nStelle in deinem Quarto Header die folgenden Dinge ein. Achtung: Achte auf die Einrückung der Einstellungen. Wenn das nicht von Hand klappt kann man sich bei der Einrückung von einem LLM helfen lassen. 😉.\n\nformat: html\nembed-resources: true\ntable of contents (toc) = true\n\nLies den folgenden Datensatz ein: Practice_dataset2\n\n\n\nBerechne den Mittelwert und die Standardabweichung der Variable self_efficacy für jede Gruppe (condition). Runde die Ergebnisse jeweils auf drei Nachkommastellen. Speichere diese deskriptive Statistik in einen neuen Dataframe ab.\n\n\n\nNutze kable um Formatierungen am unter 1.2 erstellten Dataframe durchzuführen (Überschrift ergänzen, Spalten benennen, Nachkommastellen anpassen).\n\n\n\nBerechne zusätzlich die Schiefe (skew) und Kurtosis (kurtosi) der Variable self_efficacy pro Gruppe (condition), mit Funktionen aus dem Paket psych.\n\n\n\n\n\n\nDer Originaldatensatz enthält die Spalten pre_mood, mid_mood, post_mood. Verwandle diese mithilfe von pivot_longer() in einen Long-Datensatz namens mood_long. Die neue Spalte mit den Zeitpunkten soll mood_time heißen, die mit den Werten mood_rating.\n\n\n\n\n\n\nIm nächsten Schritt verwenden wir den LONG-Datensatz (Siehe Aufgabe 2.1), um den Verlauf über die verschiedenen Zeitpunkte darzustellen. Das Ziel ist es, die Stimmung (mood) zu den unterschiedlichen Zeitpunkten, aggregiert nach den Konditionen, als Verlaufsdiagramm abzubilden.\n\nDafür soll mood_time in einen Faktor mit geordneten Faktorstufen (pre, mid und post) umgewandelt werden.\nErstelle einen Summary, welches die für den Plot benötigten Angaben zusammenfasst (Durschschnittlicher Mood gruppiert nach Condition und Zeitpunkt).\n\n\n\n\nPlotte die Elemente mood_time und mean_mood. Gruppiere die conditions nach Farbe.\n💡Tipp: Wenn du den Plot einem Objekt zuweist, kannst du ihn weiterverwenden, indem du das Objekt aufrufst und erweiterst. So musst du den Code nicht jedes Mal neu ausschreiben.\n\n\n\nPasse nun den Plot aus 3.2 so an, dass er eine Farbpalette verwendet, die für farbenblinde Personen geeignet ist: Nutze die folgende Palette.\nTipp: Verwende: scale_color_manual\n\ncb_palette &lt;- c(   \"#000000\", \"#E69F00\", \"#56B4E9\", \"#009E73\",   \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\" )  \n\n\n\n\nFüge mit geom_point() die einzelnen Punkte auf der Linie ein. Stelle die grösse (size() auf 3)\n\n\n\nFüge dem Diagramm Titel sowie Achsenbeschriftungen zu deinem Plot und verwende ein Theme das du passend findest.\n\n\n\n\n\n\n\n\nSpeichere den Plot ab mit ggsave als png ab.\n\n\n\n\nErstelle aus dem ursprünglichen Wide Originaldatensatz einen neuen Datensatz subset_mood, der nur Daten der Gruppe experimental beinhaltet.\n\n\nPrüfe nun (anhand des unter 4. erstellen Datensatzes) mittels eines gepaarten t-Test ob sich pre_mood und post_mood in der Gruppe experimental unterscheiden. Nutze dafür die Funktion t.test(). Lass dir das Ergebnis mit print() ausgeben.\n\n\n\n\n\nRendere dein Skript als HTML\nLade deine Abgabe (Skript + HTML) als ZIP ordner in ILIAS hoch und schicke sie deinem/deiner Peepartner:in."
  },
  {
    "objectID": "scripts/02_excercises/hausuebung_2.html#formalitäten-und-abgabe",
    "href": "scripts/02_excercises/hausuebung_2.html#formalitäten-und-abgabe",
    "title": "hausuebung_2",
    "section": "",
    "text": "Abgabe bis: Freitag 28.11, 23:55 via ILIAS\nZip-Datei benennen: vorname_nachname.zip\n\nGerendertes Skript: vorname_nachname_hausuebung_2.html\nUngerendertes Quarto-Skript: vorname_nachname_hausuebung_2.qmd\n\nPeer Feedback: Bis 3.12 direkt an die Person und im Forum als Zusammenfassung. Im Forum bitte auch Namen der Person, für die das Feedback bestimmt ist, nennen."
  },
  {
    "objectID": "scripts/02_excercises/hausuebung_2.html#aufgabe-1-datensatz-einlesen-und-deskriptive-statistik",
    "href": "scripts/02_excercises/hausuebung_2.html#aufgabe-1-datensatz-einlesen-und-deskriptive-statistik",
    "title": "hausuebung_2",
    "section": "",
    "text": "[1] TRUE [1] FALSE\n📥 Download practice_dataset2.csv\n\n\nStelle in deinem Quarto Header die folgenden Dinge ein. Achtung: Achte auf die Einrückung der Einstellungen. Wenn das nicht von Hand klappt kann man sich bei der Einrückung von einem LLM helfen lassen. 😉.\n\nformat: html\nembed-resources: true\ntable of contents (toc) = true\n\nLies den folgenden Datensatz ein: Practice_dataset2\n\n\n\nBerechne den Mittelwert und die Standardabweichung der Variable self_efficacy für jede Gruppe (condition). Runde die Ergebnisse jeweils auf drei Nachkommastellen. Speichere diese deskriptive Statistik in einen neuen Dataframe ab.\n\n\n\nNutze kable um Formatierungen am unter 1.2 erstellten Dataframe durchzuführen (Überschrift ergänzen, Spalten benennen, Nachkommastellen anpassen).\n\n\n\nBerechne zusätzlich die Schiefe (skew) und Kurtosis (kurtosi) der Variable self_efficacy pro Gruppe (condition), mit Funktionen aus dem Paket psych."
  },
  {
    "objectID": "scripts/02_excercises/hausuebung_2.html#aufgabe-2-wide-to-long-transformation",
    "href": "scripts/02_excercises/hausuebung_2.html#aufgabe-2-wide-to-long-transformation",
    "title": "hausuebung_2",
    "section": "",
    "text": "Der Originaldatensatz enthält die Spalten pre_mood, mid_mood, post_mood. Verwandle diese mithilfe von pivot_longer() in einen Long-Datensatz namens mood_long. Die neue Spalte mit den Zeitpunkten soll mood_time heißen, die mit den Werten mood_rating."
  },
  {
    "objectID": "scripts/02_excercises/hausuebung_2.html#aufgabe-3-plot---verlaufsdiagramm",
    "href": "scripts/02_excercises/hausuebung_2.html#aufgabe-3-plot---verlaufsdiagramm",
    "title": "hausuebung_2",
    "section": "",
    "text": "Im nächsten Schritt verwenden wir den LONG-Datensatz (Siehe Aufgabe 2.1), um den Verlauf über die verschiedenen Zeitpunkte darzustellen. Das Ziel ist es, die Stimmung (mood) zu den unterschiedlichen Zeitpunkten, aggregiert nach den Konditionen, als Verlaufsdiagramm abzubilden.\n\nDafür soll mood_time in einen Faktor mit geordneten Faktorstufen (pre, mid und post) umgewandelt werden.\nErstelle einen Summary, welches die für den Plot benötigten Angaben zusammenfasst (Durschschnittlicher Mood gruppiert nach Condition und Zeitpunkt).\n\n\n\n\nPlotte die Elemente mood_time und mean_mood. Gruppiere die conditions nach Farbe.\n💡Tipp: Wenn du den Plot einem Objekt zuweist, kannst du ihn weiterverwenden, indem du das Objekt aufrufst und erweiterst. So musst du den Code nicht jedes Mal neu ausschreiben.\n\n\n\nPasse nun den Plot aus 3.2 so an, dass er eine Farbpalette verwendet, die für farbenblinde Personen geeignet ist: Nutze die folgende Palette.\nTipp: Verwende: scale_color_manual\n\ncb_palette &lt;- c(   \"#000000\", \"#E69F00\", \"#56B4E9\", \"#009E73\",   \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\" )  \n\n\n\n\nFüge mit geom_point() die einzelnen Punkte auf der Linie ein. Stelle die grösse (size() auf 3)\n\n\n\nFüge dem Diagramm Titel sowie Achsenbeschriftungen zu deinem Plot und verwende ein Theme das du passend findest.\n\n\n\n\n\n\n\n\nSpeichere den Plot ab mit ggsave als png ab."
  },
  {
    "objectID": "scripts/02_excercises/hausuebung_2.html#subsetting-und-t-test",
    "href": "scripts/02_excercises/hausuebung_2.html#subsetting-und-t-test",
    "title": "hausuebung_2",
    "section": "",
    "text": "Erstelle aus dem ursprünglichen Wide Originaldatensatz einen neuen Datensatz subset_mood, der nur Daten der Gruppe experimental beinhaltet.\n\n\nPrüfe nun (anhand des unter 4. erstellen Datensatzes) mittels eines gepaarten t-Test ob sich pre_mood und post_mood in der Gruppe experimental unterscheiden. Nutze dafür die Funktion t.test(). Lass dir das Ergebnis mit print() ausgeben."
  },
  {
    "objectID": "scripts/02_excercises/hausuebung_2.html#rendern-und-hochladen",
    "href": "scripts/02_excercises/hausuebung_2.html#rendern-und-hochladen",
    "title": "hausuebung_2",
    "section": "",
    "text": "Rendere dein Skript als HTML\nLade deine Abgabe (Skript + HTML) als ZIP ordner in ILIAS hoch und schicke sie deinem/deiner Peepartner:in."
  },
  {
    "objectID": "scripts/02_excercises/hands_on_3.html",
    "href": "scripts/02_excercises/hands_on_3.html",
    "title": "Hands On – Coding Basics (Einheiten 5 und 6)",
    "section": "",
    "text": "Bei Bedarf findest du hier nochmals die Slides zu Einheit 5:\nUnd Einheit 6:"
  },
  {
    "objectID": "scripts/02_excercises/hands_on_3.html#übungen",
    "href": "scripts/02_excercises/hands_on_3.html#übungen",
    "title": "Hands On – Coding Basics (Einheiten 5 und 6)",
    "section": "Übungen:",
    "text": "Übungen:\n\nErstelle ein neues Quarto-Skript:\n\n\n\nVersuche dich zu orientieren: Wie wechselst du zwischen dem Visual und Source Editor?\nErstelle eine Überschrift:\n\nSuche zuerst nach der entsprechenden Option im Visual Editor.\nSchau dir anschließend die Überschrift im Source Editor an. Wie unterscheiden sich Überschriften von normalem Text?\nSchreibe einige Dinge in kursiv, fett, unterstrichen, Schaue dir diese im Source Editor an.\nRendere deine Datei indem du den Button “Render” verwendest. Schaue dir das Resultat an."
  },
  {
    "objectID": "scripts/02_excercises/hands_on_3.html#code-chunks",
    "href": "scripts/02_excercises/hands_on_3.html#code-chunks",
    "title": "Hands On – Coding Basics (Einheiten 5 und 6)",
    "section": "Code Chunks",
    "text": "Code Chunks\n📖 R4DS Kapitel 28.5.1\nFür weitere Informationen, konsultiere das Quarto Cheatsheat und die Quarto Website.\n\nErstelle einen neuen Code-Chunk:\n\nVersuche es im Visual Editor, indem du ein „/“ eingibst und im Drop-down-Menü „R-Code Chunk“ auswählst\n\nGib deinem Code-Chunk ein “Label”. Verwende dafür “#|” in deinem Chunk um lokale Einstellungen zu setzen. (📖 R4DS Kapitel 28.5.1).\nManchmal will man nicht alle Teile des Skripts in das gerenderte Dokument übernehmen. Erstelle einen neuen Code-Chunk und stelle eval und include auf TRUE\nKreiere eine neue Variable datum mit dem heutigen Datum. Nutze dafür Sys.Date()."
  },
  {
    "objectID": "scripts/02_excercises/hands_on_3.html#inline-code",
    "href": "scripts/02_excercises/hands_on_3.html#inline-code",
    "title": "Hands On – Coding Basics (Einheiten 5 und 6)",
    "section": "Inline Code",
    "text": "Inline Code\n\nFüge folgenden dynamischen Satz in dein Dokument ein: „Dieses Dokument wurde zum letzten Mal am datum bearbeitet.“\nBenutze dafür die Variable datum die du bereits kreiert hast. Diese kannst du hinzufügen indem du “/” benutzt und “Inline R Code” suchst. Inline Code lässt sich auch mit diesem Sonderzeichen ` kreieren wenn du danach ein “r” eingibst.\nRendere dein erstes Dokument: Stelle ganz oben in deinem Dokument dafür das Format auf docx um. Wenn du das Dokument als PDF rendern willst benötigst du TinyTeX. Das kannst du mit dem Befehl install.packages(\"tinytex\") installieren.\nNutze dafür den Render-Button und schau dir das gerenderte Ergebnis an. Was ist mit deinem dynamischen Satz passiert?\n\nDas Resultat sollte so aussehen (mit dem aktuellen Datum):\nDieses Dokument wurde zum letzten Mal am 2026-01-21 bearbeitet.\n\n\n\n\n\n\nImportant\n\n\n\nQuarto-Dokumente lassen sich nur rendern, wenn das gesamte Skript fehlerfrei durchläuft. Tritt beim Rendern ein Fehler auf, ist es sinnvoll, das gesamte Skript auszuführen und auf Fehlermeldungen zu achten. Auf diese Weise wird die Reproduzierbarkeit sichergestellt.\nMöchte man das Skript trotz eines Fehlers rendern, kann man an den entsprechenden Code-Chunk #| eval: false schreiben - dies verhindert, dass der Code für die gerenderte Datei ausgeführt wird"
  },
  {
    "objectID": "scripts/02_excercises/hands_on_3.html#quarto-header",
    "href": "scripts/02_excercises/hands_on_3.html#quarto-header",
    "title": "Hands On – Coding Basics (Einheiten 5 und 6)",
    "section": "Quarto Header",
    "text": "Quarto Header\nIn den Code Chunks hast du bereits einige Einstellungen kennengelernt. In den Quarto-Headern lassen sich verschiedene Einstellungen vornehmen.\nBeispielsweise kann man den Output des Dokuments anpassen (z. B. format: html format: docx format: pdf).\nManchmal möchte man auch globale Einstellungen vornehmen, die für das gesamte Dokument gelten.\nZum Beispiel kann es sinnvoll sein, Warnmeldungen von R im gerenderten Dokument auszublenden, um die Übersicht zu behalten.\nDies lässt sich mit der Option warning: false einstellen.\n\nVersuche den Quarto Header so zu verändern das du ein Word oder Pdf renderst.\n\nViele weitere Einstellungsmöglichkeiten findest du unter folgendem Link.\n\n\nÜbungen Quarto Header\nStelle in deinem Quarto Header die folgenden Einstellungen ein indem du die Elemente des YAML-Headers überarbeitest. Diesen findest du ganz oben in deinem Dokument. Dafür kannst du den Code-Block unten kopieren und für deinen Header anpassen.\n\nTitel\nAutor:in\nInhaltsverzeichnis (toc) = TRUE\nPosition des Inhaltsverzeichnisses = left\nWarning = FALSE\nMessage = FALSE\n\n\ntitle: 'Gib hier den Namen deines Dokuments ein'\nauthor: 'Dein Name'\ndate: today\nformat:\n  html:\n    theme: flatly\n    toc:   # Inhaltsverzeichnis?\n    toc-location:  # Links oder Rechts?\nexecute:\n  warning:  # TRUE or FALSE\n  message: # TRUE or FALSE\n\n\n\nAufgabe: Rendere das Dokument erneut und überprüfe das gerenderte Ergebnis im Vorschaufenster oder im Ausgabeordner."
  },
  {
    "objectID": "scripts/02_excercises/hands_on_3.html#vektoren",
    "href": "scripts/02_excercises/hands_on_3.html#vektoren",
    "title": "Hands On – Coding Basics (Einheiten 5 und 6)",
    "section": "Vektoren:",
    "text": "Vektoren:\nWir haben in den Hands-On-Übungen Block 1 und 2 bereits einige einfache Vektoren erstellt und damit operiert."
  },
  {
    "objectID": "scripts/02_excercises/hands_on_3.html#matrizen",
    "href": "scripts/02_excercises/hands_on_3.html#matrizen",
    "title": "Hands On – Coding Basics (Einheiten 5 und 6)",
    "section": "Matrizen",
    "text": "Matrizen\nEine Matrix besteht nur aus einem Datentyp (z. B. nur Zahlen).\n\nErstelle eine 3x3-Matrix matrix() mit den Zahlen 1 bis 9.\nWandle einen Vektor 1:12 in eine 3x4-Matrix um. Teste den Unterschied zwischen byrow = TRUE und byrow = FALSE innerhalb von matrix().\nGreife auf das Element in der 2. Zeile, 3. Spalte zu.\nBerechne die Spaltensummen und Zeilensummen.\nSchaue dir an, was passiert wenn du t() auf deine Matrix anwendest.\n\n\n\n\n\n\n\nFreiwillig für Fortgeschrittene:\n\n\n\n\nGeneriere aus den Variablen ID, Initialen und Alter eine Matrize, die so aussieht: “1-RS-44” “2-MM-78” “3-PD-22” “4-PG-34” “5-DK-67” “1-RS-59«\nErstelle einen Vektor mit den Namen mehrerer berühmter Wissenschaftler:innen. Kombiniere die Namen mit paste() und einem zusätzlichen Suffix, z. B. „, PhD“. Prüfe mit grepl(), ob einer der Namen ein bestimmtes Muster enthält (z. B. „stein“)."
  },
  {
    "objectID": "scripts/02_excercises/hands_on_3.html#listen",
    "href": "scripts/02_excercises/hands_on_3.html#listen",
    "title": "Hands On – Coding Basics (Einheiten 5 und 6)",
    "section": "Listen",
    "text": "Listen\nEine Liste kann verschiedene Datentypen enthalten (z. B. Zahlen, Zeichenketten, logische Werte).\n👉 Einführung in R, Kapitel 2.4.5\n\nErstelle eine Liste mit drei Elementen und der Funktion list():\n\neinem Vektor mit den Zahlen 1 bis 5\neinem Character-Vektor mit den Namen deiner Kommiliton:innen\neinem logischen Vektor (TRUE, FALSE)\n\nGreife auf das zweite Element der Liste zu.\nGreife auf den dritten Wert des ersten Elements der Liste zu.\nFüge der Liste ein weiteres Element hinzu (z. B. den Mittelwert der Zahlen)."
  },
  {
    "objectID": "scripts/02_excercises/hands_on_3.html#data-frames",
    "href": "scripts/02_excercises/hands_on_3.html#data-frames",
    "title": "Hands On – Coding Basics (Einheiten 5 und 6)",
    "section": "Data Frames",
    "text": "Data Frames\n👉Einführung in R, Kapitel 2.4.6\nEin Data Frame ist eine tabellarische Struktur mit Spalten, die verschiedene Datentypen enthalten können.\n\nErstelle einen Data Frame data.frame() oder tibble() mit drei Spalten:\n\nname (Character)\nalter (Numeric)\nstudiert (Logical: TRUE/FALSE)\n\nGreife mit datensatz$alter auf die Spalte “alter” zu.\nFiltere alle Zeilen, in denen studiert == TRUE.\nFüge eine neue Spalte hinzu, die “alter” + 10 berechnet.\nBenenne die Spalten in deinem Data Frame mit colnames() oder rename()um, sodass sie internationalen Standards folgen.\nBerechne den Mittelwert und die Standardabweichung der Variable „age”.\nSortiere den Data Frame basierend auf “age” absteigend mit arrange().\n\nWeitere Informationen zum Erstellen von Data Frames findest du hier: Einführung in R, Kapitel 3.1"
  },
  {
    "objectID": "scripts/02_excercises/hands_on_3.html#übungen-mit-dat_full",
    "href": "scripts/02_excercises/hands_on_3.html#übungen-mit-dat_full",
    "title": "Hands On – Coding Basics (Einheiten 5 und 6)",
    "section": "Übungen mit dat_full",
    "text": "Übungen mit dat_full\nNun, da wir einige Operationen mit Data Frames kennengelernt haben, wenden wir diese auf unseren Datensatz dat_full an.\n\nLies dat_full ein. Diesen Datensatz solltest du als .csv-Datei abgespeichert haben.\nSieh dir den Datensatz genau an. Die Variable csvtm_sum scheint einen Tippfehler zu enthalten. Korrigiere diesen zu cvstm_sum mit einer der oben vorgestellten Funktionen.\nÜberlege dir: Welche Variable sollte in einen Faktor umgewandelt werden?\nDefiniere diese Variable(n) als Faktor, z. B. mit as.factor() oder factor().\nZum Schluss speichere den bereinigten Datensatz erneut mit write.csv ab.\n\n\n\n\n\n\n\nNote\n\n\n\nHinweis: R speichert nicht automatisch, dass eine Variable als Faktor definiert wurde. Dieser Code muss daher bei jedem Neustart erneut ausgeführt werden, wenn du wieder mit denselben Faktoren arbeiten möchtest."
  },
  {
    "objectID": "scripts/02_excercises/hands_on_6.html",
    "href": "scripts/02_excercises/hands_on_6.html",
    "title": "Hands On – Analyze (Einheiten 11 und 12)",
    "section": "",
    "text": "Bei Bedarf findest du hier nochmals die Slides zu Einheit 11:\nUnd zu Einheit 12:"
  },
  {
    "objectID": "scripts/02_excercises/hands_on_6.html#visualize---übungen-zu-ggplot2",
    "href": "scripts/02_excercises/hands_on_6.html#visualize---übungen-zu-ggplot2",
    "title": "Hands On – Analyze (Einheiten 11 und 12)",
    "section": "Visualize - Übungen zu ggplot2",
    "text": "Visualize - Übungen zu ggplot2\n📚 Einführung in R - Kapitel 5\n📚 R for Data Science - Kapitel 1\n📚R for Data Science - Kapitel 11\n\n\n\n\n\n\nTabelle mit häufig verwendeten Geoms()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGeom\nFunktion\nEinsatzbereich\nBild / Beispiel\n\n\n\n\ngeom_point()\nStreudiagramm\nZwei numerische Variablen vergleichen (x = Var1, y = Var2)\n\n\n\ngeom_jitter()\nJitter-Plot\nPunkte leicht versetzen, um Überlappung zu vermeiden (v. a. bei kategorialem x)\n\n\n\ngeom_line()\nLiniendiagramm\nWerteverlauf Über kontinuierliche x-Achse darstellen\n\n\n\ngeom_bar()\nBalkendiagramm\nHäufigkeiten oder Aggregationen für Kategorien (x = Gruppe)\n\n\n\ngeom_histogram()\nHistogramm\nVerteilung einer numerischen Variable (x = Wert)\n\n\n\ngeom_boxplot()\nBoxplot\nVerteilungen über Gruppen vergleichen (x = Gruppe, y = Wert)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCheatsheet ggplot2\n\n\n\n\n\n\n\n\n\n\nIm folgenden wollen wir Figure 4 aus Grinschgl et al. (2021) reproduzieren:\n\n\n\n\n\n\n\n\n\n\nVorbereitungen:\nUm die Mittelwerte plotten zu können, müssen wir die Gruppenmittelwerte und Standardfehler berechnen. Passe dafür den Codeblock an:\nIm Hands-on Block 4 haben wir bereits mit dplyr die MMQ-Skalenwerte „mmq_mean“ pro Person berechnet. Nutze nun die dplyr-Funktionen, insbesondere group_by(), um den durchschnittlichen MMQ-Wert pro Gruppe (group_all) sowie den Standardfehler zu berechnen. Die Formel für den Standardfehler lautet: SE = SD / √n und kann z.b so berechnet werden. se_mmq = sd(mmq_mean) / sqrt(n()) . Ergänze den Code unten mit den nötigen Angaben. Lege group_all in deinem summary als Faktor fest mit den Levels in der Reihenfolge: “below”, “control”, “above”.\n\n\n\n\n\n\nStandardfehler\n\n\n\n\n\nDer Standardfehler des Mittelwerts (SEM) beschreibt wie stark der geschätzte Stichprobenmittelwert zufällig vom wahren Populationsmittelwert abweichen kann. Er ist damit ein Mass für die Präzision des Mittelwerts.\n\n\n\n\ndat_full &lt;- dat_full |&gt; \n  mutate(mmq_mean = rowMeans(select(dat_full, starts_with(\"question\")))\n\n\ngroup_summary &lt;- dat_full %&gt;%\n  group_by(XXXXXXX) %&gt;%\n  summarize(\n    group_mean_mmq = mean(XXXXXX),\n    se_mmq = sd(XXXXXX) / sqrt(n())\n  )\n\ngroup_summary$group_all &lt;- factor(group_summary$group_all,\n                                  levels = c(\"XXXXX\", \"XXXXX\", \"XXXXX\"))\n\n\n\n1. Erstelle einen leeren Plot und gib deinen Datensatz an\nBeginne mit:\n\nggplot() und deinem Datensatz\n\n\n\n2. Definiere die Aesthetic Mappings\nLege fest:\n\nwelche Variable auf der x-Achse liegt\nwelche Variable auf der y-Achse liegt\n\n\n\n3. Füge geom_col() dem Plot hinzu\nDamit zeichnest du die Balken für die Gruppenmittelwerte.\n\ncolor = für Konturen\nfill = für die Füllfarben der Balken\n\n\n\n4. Füge Fehlerbalken hinzu\nNutze geom_errorbar() und definiere innerhalb von aes():\n\nymin = mean - se - Füge die passenden Variablen ein.\nymax = mean + se - Füge die passenden Variablen ein.\n\nPasse die Breite der Fehlerbalken mit width = an.\n\n\n5. Füge Titel und Achsenbeschriftungen hinzu\nNutze dafür labs(). Verändere das theme zu theme_classic()\n\n\n6. Stelle sicher, dass der vollständige Wertebereich sichtbar ist\n\nmit ylim(0, 4)\n\n\nNun wollen wir den zweiten Plot aus Grinschgl et al. (2021) reproduzieren.\nErgänze dafür den folgenden Code an den nötigen Stellen mit den passenden Werten und Argumenten.\n\nLade zuerst den in der letzten Woche gespeicherten Long-Datensatz.\nErsetze anschliessend die Platzhalter “XXXXXX” durch die erforderlichen Werte, um den Plot zu reproduzieren.\nSpeichere deinen Plot als PNG Datei ab.\n\n\n\n\n\n\n\n\n\n\n\ndescriptives &lt;- dat_long |&gt; \n  group_by(XXXXXX, XXXXXXX) |&gt; \n  summarize(N = length(rating),\n               mean_d = mean(rating),\n               sd_d   = sd(rating),\n               se_d   = sd_d / sqrt(N)\n)\n\ndescriptives$group_all &lt;- factor(descriptives$group_all, c(\"above\", \"control\", \"below\"))\n\nrate_plot &lt;- descriptives |&gt; \n  ggplot(aes(x = XXXXXX, \n             y = XXXXXX, \n             group = XXXX)) \n\nrate_plot +\n  geom_line(aes(color = group_all, linetype = group_all), size = 1.2) +\n  geom_errorbar(aes(ymin = mean_d - se_d, ymax = mean_d + se_d), width = .1) +\n  scale_color_manual(values = c(\"green4\", \"red\", \"black\")) +\n  theme_classic() +\n  labs(title = \"XXXXXXX\") +\n  ylab(\"XXXXXXXX\") +\n  xlab(\"XXXXXXXXX\") +\n  theme(plot.title = element_text(hjust = 0.5, size = 12, face = \"bold\"), \n        axis.text = element_text(size = 11), axis.title = element_text(size = 14))"
  },
  {
    "objectID": "scripts/02_excercises/hands_on_6.html#korrelationen",
    "href": "scripts/02_excercises/hands_on_6.html#korrelationen",
    "title": "Hands On – Analyze (Einheiten 11 und 12)",
    "section": "Korrelationen:",
    "text": "Korrelationen:\n\nWähle zwei metrische Variablen aus dem Wide Datensatz aus. Berechne die Korrelation mit cor.test() für diese beiden Variablen.\n\n\ncor.test(dat_full$mean_d1_all, dat_full$mean_d_all, method = \"spearman\")\n\n\n\nFinde den Korrelationskoeffizienten r, den p-Wert und die Freiheitsgrade (df). Versuche das Ergebnis zu interpretieren.\n\n\n\nRufe die Hilfefunktion von cor.test() auf. Welche Anpassungen kannst du vornehmen, um die Korrelation einseitig (z.B. nur positiver Zusammenhang) und mit der Spearman-Methode zu berechnen?\n\n\n\n\n\n\n\nKorrelationen\n\n\n\n\n\nLinearer Zusammenhang (Kovarianz) zweier Variablen. Positive Korrelation = hohe Ausprägungen einer Variable hängen mit hohen Ausprägungen einer anderen Variable zusammen. Negative Korrelation = Hohe Ausprägungen einer Variable hängen mit niedrigen Ausprägungen einer anderen Variable zusammen. Korrelationskoeffizient r kann von -1 bis +1 gehen. Der Korrelationstest testet ob r sich signifikant von 0 (kein Zusammenhang unterscheidet). Für Pearson Korrelationen sollte die Normalverteilung der Residuen gegeben sein. Alternative: Spearman Korrelation."
  },
  {
    "objectID": "scripts/02_excercises/hands_on_6.html#regressionen",
    "href": "scripts/02_excercises/hands_on_6.html#regressionen",
    "title": "Hands On – Analyze (Einheiten 11 und 12)",
    "section": "Regressionen",
    "text": "Regressionen\n\n\n\n\n\n\nTabelle: Funktionen für Regressionen und verwandte Analysen in R\n\n\n\n\n\n\n\n\n\n\n\n\nFunktion\nBeschreibung\n\n\n\n\nlm(y ~ x)\nEinfache lineare Regression mit einer abhängigen Variablen y und einem Prädiktor x.\n\n\nlm(y ~ x1 + x2)\nMultiple Regression mit einer abhängigen Variablen y und zwei Prädiktoren x1 und x2.\n\n\nsummary()\nGibt die Ergebnisse der Regressionsanalyse für ein Regressionsmodell aus.\n\n\nconfint()\nKonfidenzintervalle für die Regressionskoeffizienten.\n\n\nfitted()\nVorhergesagte Werte des Regressionsmodells.\n\n\nresid()\nResiduen des Regressionsmodells.\n\n\npredict()\nVorhergesagte Werte für bestimmte Werte der Prädiktorvariablen.\n\n\nanova()\nVergleicht die Determinationskoeffizienten zweier Regressionsmodelle mit einem F-Test.\n\n\nvif() *\nVariance Inflation Factors (VIF) für jeden Prädiktor; aus dem car-Paket.\n\n\n\n* aus zusätzlichen Paketen\n\n\n\n\nPaket „car“ installieren und laden.\nMach aus deiner davor berechneten Korrelation nun ein Regressionsmodel mit der Funktion model &lt;- lm(outcome ~ predictor, data). Schau dir den Output mit summary(model) an und versuche ihn zu interpretieren.\n\n\nmodel_1 &lt;- lm(mean_d1_all ~ mean_d_all, data = dat_full)\n\nsummary(model_1)\n\n\nErgänze das Modell nun um eine weitere Prädiktorvariable (mit + Variable), sodass du eine multiple Regression berechnest. Hier müssen wir auf Multikollinearität testen – mit vif(model) aus dem „car“ Paket (die Werte sollten größer als 0.10 sein, sodass keine Multikollinearität vorliegt). Berechne auch die Konfidenzintervalle der Beta-Koeffizienten mit confint(model).\n\n\nmodel_2 &lt;- lm(mean_d1_all ~ mean_d_all + mean_rl_all, data = dat_full)\n\nsummary(model_2)\n\nconfint(model_2)\n\n\n\n\n\n\n\nFortgeschritten / Freiwillig\n\n\n\n\n\nBerechne eine einfache logistische Regression zwischen Strategien (ohne strategies == 3) und Offloading (mean_rl_all) mit dem Wide Datensatz. Nimm das Statistik III Cheatsheet von Dr. Boris Mayer zur Hand. Tipp: Du musst die Strategien in 0 und 1 umkodieren."
  },
  {
    "objectID": "scripts/02_excercises/hands_on_6.html#t-tests-für-abhängige-stichproben",
    "href": "scripts/02_excercises/hands_on_6.html#t-tests-für-abhängige-stichproben",
    "title": "Hands On – Analyze (Einheiten 11 und 12)",
    "section": "t-Tests für abhängige Stichproben",
    "text": "t-Tests für abhängige Stichproben\n\n\n\n\n\n\nTabelle: Funktionen für t-Tests und verwandte Analysen in R\n\n\n\n\n\n\n\n\n\n\n\n\nFunktion\nBeschreibung\n\n\n\n\nt.test\nAllgemeine Funktion für verschiedene t-Tests: Ein-Stichproben-t-Test, t-Test für unabhängige Stichproben und t-Test für abhängige Stichproben.\n\n\nt.test(av, mu = x)\nEin-Stichproben-t-Test. av = abhängige Variable. x = Vergleichswert der Population.\n\n\nt.test(av ~ uv)\nWelch-t-Test für unabhängige Stichproben. av = abhängige Variable, uv = Gruppenvariable.\n\n\nt.test(av ~ uv, var.equal = TRUE)\nKlassischer t-Test für unabhängige Stichproben (Varianzen vorausgesetzt gleich).\n\n\nt.test(av1, av2, paired = TRUE)\nt-Test für abhängige Stichproben (z. B. Prä–Post). av1 und av2 = gemessene Variablen.\n\n\nleveneTest(av, uv) *\nLevene-Test auf Varianzhomogenität für unabhängige Gruppen. Aus dem car-Paket.\n\n\neffsize::cohen.d() *\nBerechnet die standardisierte Effektgröße Cohen’s d + Konfidenzintervall. Aus dem effsize-Paket.\n\n\n\n* Funktionen aus zusätzlichen Paketen.\n\n\n\n\nPaket „effsize“ installieren und laden.\nWir wollen einen t-Test für unabhängige Stichproben durchführen, um das Pre 4 Rating der „above“ und „below“ Gruppen zu vergleichen. Starte mit einem leveneTest() aus dem „car“ Paket um die Varianzhomogenität zu prüfen. Tipp: Filtere die Daten, sodass nur die beiden Gruppen „above“ und „below“ beinhaltet sind (d.h. ohne die Gruppe „control“).\n\n\nBerechne nun den entsprechenden t-Test mit t.test(). Du kannst auch die Hilfefunktion zu Rate ziehen. Versuche dann den Output zu verstehen bzw. das Ergebnis zu interpretieren. Tipp: Wenn die Varianzhomogenität gegeben ist (d.h. der Levene Test nicht signifikant ist), muss man var.equal = TRUE angeben, ansonsten wird ein Welch t-Test berechnet.\n\n\nt.test(pre4 ~ group_all, data = dat_full_below_above, var.equal = TRUE)\n\n\nNun berechnen wir noch Cohen‘s d als Effektstärken-Maß für den Mittelwertsunterschied. Verwende dafür effsize::cohen.d().  Da es „cohen.D“ auch im Paket „psych“ gibt, ist es wichtig hier „effsize::“ voranzusetzen.\n\n👉 Und schon haben wir einen der Post-Hoc t-Tests für die 2x3 ANOVA aus Grinschgl et al. (2020) berechnet (notwendig für die Abschlussarbeit)"
  },
  {
    "objectID": "scripts/02_excercises/hands_on_6.html#t-tests-für-abhängige-stichproben-1",
    "href": "scripts/02_excercises/hands_on_6.html#t-tests-für-abhängige-stichproben-1",
    "title": "Hands On – Analyze (Einheiten 11 und 12)",
    "section": "t-Tests für abhängige Stichproben",
    "text": "t-Tests für abhängige Stichproben\n\nBerechne einen t-Test für abhängige Stichproben um in der „control“ Gruppe Pre 1 und Pre 4 zu vergleichen. (D.h. filtere zunächst den Datensatz, sodass nur mehr die „control“ Gruppe\n\n\nt.test(datensatz$Variable1, datensatz$Variable2, paired = TRUE) \n\n\nWandle den t-Test nun in einen einseitigen Test mit alternative = „greater“ oder alternative = „less“ um und berechne Cohen‘s d als Effektstärkenmaß (Achtung: paired = True setzen)."
  },
  {
    "objectID": "scripts/02_excercises/hands_on_5.html",
    "href": "scripts/02_excercises/hands_on_5.html",
    "title": "Hands On – Coding Basics (Einheiten 9 und 10)",
    "section": "",
    "text": "Bei Bedarf findest du hier nochmals die Slides zu Einheit 9:"
  },
  {
    "objectID": "scripts/02_excercises/hands_on_5.html#übungen-zur-datenkonversion",
    "href": "scripts/02_excercises/hands_on_5.html#übungen-zur-datenkonversion",
    "title": "Hands On – Coding Basics (Einheiten 9 und 10)",
    "section": "Übungen zur Datenkonversion",
    "text": "Übungen zur Datenkonversion\n📖R4DS - Kapitel 5.3\n📖Einführung in R - Kapitel 3.1.3\nDie folgenden Schritte dienen der Konversion von Daten zwischen dem Wide- und Long-Format unter Verwendung des Tidyverse-Pakets in R.\n\nMit der Funktion pivot_longer() Spalten der Leistungseinschätzung in Long-Format umwandeln und in neuen Datensatz speichern, nur für Übungszwecke.\nWandle den Datensatz noch mal in das Long Format um, aber nur basierend auf den Spalten pre1 und pre4 Long-Format wird für 2x3 ANOVA aus Grinschgl et al. (2020) benötigt; für Vergleich der 2 Messzeitpunkte in dieser Analysen, benötigen wir diese im Long-Format.\nWandle die Spalte time_rating in einen Factor um –&gt; auch notwendig für Analysen.\nSpeichere den Long Datensatz als csv. Datei ab. Den Long Datensatz werden wir in den kommenden Wochen benötigen.\n\n\nVerwende pivot_wider unter Angabe von names_from und values_from um den Datensatz wieder in das Wide-Format zu bringen. –&gt; nur für Übungszwecke."
  },
  {
    "objectID": "scripts/02_excercises/hands_on_5.html#skewness-und-kurtosis",
    "href": "scripts/02_excercises/hands_on_5.html#skewness-und-kurtosis",
    "title": "Hands On – Coding Basics (Einheiten 9 und 10)",
    "section": "Skewness und Kurtosis",
    "text": "Skewness und Kurtosis\nDie folgenden Schritte dienen der Vorbereitung und deskriptiven Analyse von Daten in R.\n\nInstallieren und laden des Pakets {psych}: Stelle sicher, dass das Statis Paket psychfür die weiteren Analysen geladen ist.\n\n\nBerechne die Schiefe und die Kurtosis der Variablen “Öffnungen des Modellfensters” (mean_rl_all) für die drei Gruppen. Verwende hierfür die dplyr-Funktionen group_by() und summarize()."
  },
  {
    "objectID": "scripts/02_excercises/hands_on_5.html#residuen",
    "href": "scripts/02_excercises/hands_on_5.html#residuen",
    "title": "Hands On – Coding Basics (Einheiten 9 und 10)",
    "section": "Residuen",
    "text": "Residuen\n📖Siehe auch: Normalverteilung der Residuen bei der Regression in R testen\nFür die folgenden Schritte berechnen wir zuerst ein Regressionsmodell:\n\nSpezifikation des Regressionsmodells: Verwende die Funktion lm() um ein Regressionsmodell zwischen Cognitive Offloading (mean_rl_all und der Arbeitsgedächtnisleistung (Feature Switch Detection Task - cvstm_propcorrect) zu spezifizieren.\n\n\nreg_fit &lt;- lm(Cognitive_Offloading_Variable ~ Arbeitsgedächtnisleistung, data = dat_ full)\n\n\nSpeichern der Residuen: Speichere die Residuen dieses Regressionsmodells mit der Funktion rstandard()\n\n\nVisualisierung mittels Histogramm: Stelle die die Residuen in einem Histogramm mit der Funktion hist() dar.\nFrage: Ist im Histogramm eine Glockenkurve (Normalverteilung) erkennbar?\nVisualisierung mittels QQ-Plot: Stelledie Residuen in einem QQ-Plot mit der Funktion qqnorm() dar. Ergänze die Regressionsgerade mit qqline().\nFrage: Wie nah sind die Residuen einer perfekten Normalverteilung (d.h. der Geraden)?"
  },
  {
    "objectID": "scripts/02_excercises/hands_on_5.html#skalenreliabilität",
    "href": "scripts/02_excercises/hands_on_5.html#skalenreliabilität",
    "title": "Hands On – Coding Basics (Einheiten 9 und 10)",
    "section": "Skalenreliabilität",
    "text": "Skalenreliabilität\n📖 Psychometrics in R & Björn Walther\nDie folgenden Schritte dienen der Prüfung der internen Konsistenz der Messinstrumente.\n\nDatenvorbereitung für die Analyse: Speichere alle Variablen des MMQs in einem neuen Data Frame ab. Wähle dabei die Spalten mittels select aus.\nBerechnung von Cronbach’s Alpha: Verwende die Funktion alpha() aus dem psych-Paket und wende sie auf das neue Objekt an, um Cronbach’s Alpha (Interne Konsistenz) für diesen Fragebogen zu berechnen. Schau dir die Ergebnisse (insbesondere raw_alpha) an. Dieses sollte mit Werten in Grinschgl et al. (2021) übereinstimmen.\n\n\n\n\n\n\n\nWarning\n\n\n\nAchtung: Wenn du das Package ggplot() geladen hast, kann es sein dass die Funktion alpha()dadurch verdeckt wird. Spezifiziere aus welchem Package du die Funktion verwenden willst mit psych::alpha()\n\n\n\nVerwende die Funktion omega() aus dem psych-Paket und wende sie auf dein Objekt (z. B. den Datensatz mit den relevanten Items) an, um McDonald’s Omega (interne Konsistenz auf Basis eines Faktorenmodells) zu berechnen.\n\n\n\n\n\n\n\n\nPDF Grinschgl2021 –&gt; Seite 7 –&gt; Multifactorial Memory Questionnaire\n\n\n\n\n\n\n\n\n\n\n\nTipp: In der alpha() Funktion werden unter details alle Werte beschrieben. Für weitere Erklärungen siehe auch: Psychometrics in R"
  },
  {
    "objectID": "scripts/02_excercises/hands_on_5.html#streudiagrammescatterplots-weitere-datenverteilungen",
    "href": "scripts/02_excercises/hands_on_5.html#streudiagrammescatterplots-weitere-datenverteilungen",
    "title": "Hands On – Coding Basics (Einheiten 9 und 10)",
    "section": "Streudiagramme/Scatterplots & weitere Datenverteilungen",
    "text": "Streudiagramme/Scatterplots & weitere Datenverteilungen\n📊Auflistung von Argumenten\n📊R4DS - Layers\n📊R4DS - EDA\n\nTabelle mit Geoms()\n\n\n\n\n\n\n\n\n\nGeom\nFunktion\nEinsatzbereich\nBild / Beispiel\n\n\n\n\ngeom_point()\nStreudiagramm\nZwei numerische Variablen vergleichen (x = Var1, y = Var2)\n\n\n\ngeom_jitter()\nJitter-Plot\nPunkte leicht versetzen, um Überlappung zu vermeiden (v. a. bei kategorialem x)\n\n\n\ngeom_line()\nLiniendiagramm\nWerteverlauf Über kontinuierliche x-Achse darstellen\n\n\n\ngeom_bar()\nBalkendiagramm\nHäufigkeiten oder Aggregationen für Kategorien (x = Gruppe)\n\n\n\ngeom_histogram()\nHistogramm\nVerteilung einer numerischen Variable (x = Wert)\n\n\n\ngeom_boxplot()\nBoxplot\nVerteilungen über Gruppen vergleichen (x = Gruppe, y = Wert)\n\n\n\n\n\n\n\n\n\n\nCheatsheet ggplot2\n\n\n\n\n\n\n\n\n\n\nUm Plots zu erstellen gibt es diverse Packages. Für einfache Darstellungen ist die Syntax der Base r plot() Funktion nützlich, bietet jedoch wesentlich weniger Optionen an als ggplot(). Für diese aufgaben sind zwar beide geeignet, jedoch empfehlen wir ggplot()\n\nPlotte den Zusammenhang zwischen Cognitive Offloading (Öffnungen des Modelfensters - mean_rl_all) und der Arbeitsgedächtnisleistung (Feature Switch Detection Task cvstm_propcorrect). Ergänze dafür den Code unten mit den richtigen Variablen. (Wichtig für Ausreißerkontrolle bei Berechnungen von Korrelationen/Regressionen)\n\n\nggplot(data = dat_full, aes(x = XXXXX, y = XXXXXX))+\n  geom_XXXX()\n\n\nAusreißer können auch mit boxplots für einzelne Variablen identifiziert werden 👉 für Öffnungen des Modelfensters anschauen. Nutze das richtige geom() aus der Tabelle.\n\n❗Man sollte schon vor Studienerhebung oder zumindest vor der Datenanalyse festlegen ob bzw. wie man Ausreißer identifiziert und ausschließt (z.B. in Präregistrierungen oder Datenanalyseplänen)\n\nLass dir den boxplot() getrennt für die 3 Experimentalgruppen anzeigen. Setze dafür y = group."
  },
  {
    "objectID": "scripts/02_excercises/hands_on_5.html#fortgeschrittene-freiwillige-übungen",
    "href": "scripts/02_excercises/hands_on_5.html#fortgeschrittene-freiwillige-übungen",
    "title": "Hands On – Coding Basics (Einheiten 9 und 10)",
    "section": "Fortgeschrittene (freiwillige Übungen)",
    "text": "Fortgeschrittene (freiwillige Übungen)\n\nErweitere den Scatterplot deiner beiden Variablen um die folgenden Dinge:\n\nFärbe deine Datenpunkte nach Gruppenzugehörigkeit ein mit color()\nFüge einen titel ein mit labs und title()\nBenne die Achsen mit ylab() und xlab()\nÄnder die Darstellungart zu theme_minimal()\n\n\nWir werden in EH 11 noch vertiefende Übungen zu ggplot durchführen."
  },
  {
    "objectID": "scripts/02_excercises/Übungen.html",
    "href": "scripts/02_excercises/Übungen.html",
    "title": "Übungen",
    "section": "",
    "text": "Hier findest du die Hands on Übungen. Die Musterlösungen werden jeweils vor Beginn des neuen Blocks hochgeladen.",
    "crumbs": [
      "Übungen zu den Einheiten"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_3.html",
    "href": "scripts/02_excercises/loesung_3.html",
    "title": "Lösung 3",
    "section": "",
    "text": "Bei Bedarf findest du hier nochmals die Slides zu Einheit 5:",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 3 (Woche 5 - 6) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_3.html#übungen",
    "href": "scripts/02_excercises/loesung_3.html#übungen",
    "title": "Lösung 3",
    "section": "Übungen:",
    "text": "Übungen:\n\nErstelle ein neues Quarto-Skript:\n\n\n\nVersuche dich zu orientieren: Wie wechselst du zwischen dem Visual und Source Editor?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nOben links unterhalb des Symbols zum Speichern finden sich zwei Buttons, Visual und Source. Mit einem Klick auf einen der beiden Buttons wechselt man die Ansicht. In der Ansicht Source (auch Source Editor genannt) seht ihr immer den grundlegenden Code. In der Ansicht Visual (auch Visual Editor gennant) wird der Code in eine ansprechendere Form gebracht, die dem gerenderten Dokument ähnelt. Bilder und Formatierungen sind hier beispielsweise schon geladen und werden entsprechend angezeigt.\n\n\n\n\nErstelle eine Überschrift:\n\nSuche zuerst nach der entsprechenden Option im Visual Editor.\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nÄhnlich wie ihr es aus Word kennt, könnt ihr oben in einem Menü, neben den Buttons für Source und Visual, in der Ansicht von Visual euren Text formatieren.\n\n\n\n\nSchau dir anschließend die Überschrift im Source Editor an. Wie unterscheiden sich Überschriften von normalem Text?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nÜberschriften werden im Source Editor mit einer Raute (#) am Anfang der Zeile gekennzeichnet. Je mehr Rauten, desto niedriger die Überschriftebene (z. B. # für Ebene 1, ## für Ebene 2, etc.). Normaler Text hat keine Raute davor.\n\n\n\n\nSchreibe einige Dinge in kursiv, fett, unterstrichen, Schaue dir diese im Source Editor an.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nkursiv\nfett\nunterstrichen\n\n\n\n\nRendere deine Datei indem du den Button “Render” verwendest. Schaue dir das Resultat an.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDen Button zum Rendern findet ihr oben direkt über den Formatierungsoptionen unter Render.",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 3 (Woche 5 - 6) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_3.html#code-chunks",
    "href": "scripts/02_excercises/loesung_3.html#code-chunks",
    "title": "Lösung 3",
    "section": "Code Chunks",
    "text": "Code Chunks\n📖 R4DS Kapitel 28.5.1\nFür weitere Informationen, konsultiere das Quarto Cheatsheat und die Quarto Website.\n\nErstelle einen neuen Code-Chunk:\n\nVersuche es im Visual Editor, indem du ein „/“ eingibst und im Drop-down-Menü „R-Code Chunk“ auswählst\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDu kannst einen neuen Code-Chunk erstellen, indem du im Visual Editor ein / eingibst und dann im erscheinenden Menü R-Code Chunk auswählst. Alternativ kannst du auch den Shortcut Ctrl + Alt + I (Windows) oder Cmd + Option + I (Mac) verwenden.\n\n\n\n\nGib deinem Code-Chunk ein “Label” (📖 R4DS Kapitel 28.5.1).\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nIhr könnt den Namen des Chunks über beide Wege angeben, oben innerhalb der {} oder darunter mit der entsprechenden Syntax. Namen von Chunks dürfen keine Leerzeichen oder Sonderzeichen enthalten.\n\n\n\n\nManchmal will man nicht alle Teile des Skripts in das gerenderte Dokument übernehmen. Erstelle einen neuen Code-Chunk und stelle eval und include auf FALSE.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n# #| eval: false\n# #| include: false\n\neval: false verhindert, dass der Code ausgeführt wird. include: false verhindert, dass der Code und dessen Ausgabe im gerenderten Dokument angezeigt werden. Damit in der gerenderten Lösungsdatei der Chunk normal angezeigt wird, habe ich die Optionen auskommentiert.\n\n\n\n\nKreiere eine neue Variable datum mit dem heutigen Datum. Nutze dafür Sys.Date().\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndatum &lt;- Sys.Date()",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 3 (Woche 5 - 6) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_3.html#inline-code",
    "href": "scripts/02_excercises/loesung_3.html#inline-code",
    "title": "Lösung 3",
    "section": "Inline Code",
    "text": "Inline Code\n\nFüge folgenden dynamischen Satz in dein Dokument ein: „Dieses Dokument wurde zum letzten Mal am datum bearbeitet.“\nBenutze dafür die Variable datum die du bereits kreiert hast. Diese kannst du hinzufügen indem du “/” benutzt und “Inline R Code” suchst.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDieses Dokument wurde zum letzten Mal am 2026-01-21 bearbeitet.\n\n\n\n\nRendere dein erstes Dokument: Stelle ganz oben in deinem Dokument dafür das Format um.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nÜbliche Formate sind html, docx oder pdf.\n\n\n\n\nNutze dafür den Render-Button und schau dir das gerenderte Ergebnis an. Was ist mit deinem dynamischen Satz passiert?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nBeim Rendern des Dokumentes wird der Inline-Code ausgeführt und das aktuelle Datum (bzw. grundsätzlich das entsprechend zuvor definierte Objekt) an der entsprechenden Stelle im Satz eingefügt.\n\n\n\nDas Resultat sollte so aussehen (mit dem aktuellen Datum):\nDieses Dokument wurde zum letzten Mal am 2026-01-21 bearbeitet.\n\n\n\n\n\n\nImportant\n\n\n\nQuarto-Dokumente lassen sich nur rendern, wenn das gesamte Skript fehlerfrei durchläuft. Tritt beim Rendern ein Fehler auf, ist es sinnvoll, das gesamte Skript auszuführen und auf Fehlermeldungen zu achten. Auf diese Weise wird die Reproduzierbarkeit sichergestellt.\nMöchte man das Skript trotz eines Fehlers rendern, kann man an den entsprechenden Code-Chunk #| eval: false schreiben - dies verhindert, dass der Code für die gerenderte Datei ausgeführt wird.",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 3 (Woche 5 - 6) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_3.html#quarto-header",
    "href": "scripts/02_excercises/loesung_3.html#quarto-header",
    "title": "Lösung 3",
    "section": "Quarto Header",
    "text": "Quarto Header\nIn den Code Chunks hast du bereits einige Einstellungen kennengelernt. In den Quarto-Headern lassen sich verschiedene Einstellungen vornehmen.\nBeispielsweise kann man den Output des Dokuments anpassen (z. B. format: html format: docx format: pdf).\nManchmal möchte man auch globale Einstellungen vornehmen, die für das gesamte Dokument gelten.\nZum Beispiel kann es sinnvoll sein, Warnmeldungen von R im gerenderten Dokument auszublenden, um die Übersicht zu behalten.\nDies lässt sich mit der Option warning: false einstellen.\n\nVersuche den Quarto Header so zu verändern das du ein Word oder Pdf renderst.\n\nViele weitere Einstellungsmöglichkeiten findest du unter folgendem Link.\n\n\nÜbungen Quarto Header\nStelle in deinem Quarto Header die folgenden Einstellungen ein indem du die Elemente des YAML-Headers überarbeitest. Diesen findest du ganz oben in deinem Dokument. Dafür kannst du den Code-Block unten kopieren und für deinen Header anpassen.\n\nTitel\nAutor:in\nInhaltsverzeichnis (toc) = TRUE\nPosition des Inhaltsverzeichnisses = left\nWarning = FALSE\nMessage = FALSE\n\n\n\n\n\n    title: 'Gib hier den Namen deines Dokuments ein'\n    author: 'Dein Name'\n    date: today\n    format:\n      html:\n        theme: flatly\n        toc:   # Inhaltsverzeichnis?\n        toc-location:  # Links oder Rechts?\n    execute:\n      warning:  # TRUE or FALSE\n      message: # TRUE or FALSE\n\n&lt;/div&gt;\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n    title: 'Hands-on Block 3'\n    author: 'Lars Schilling'\n    date: \"`r Sys.Date()`\"\n    format:\n      html:\n        theme: flatly\n        toc: true\n        toc-location: left\n    execute:\n      warning:  false\n      message: false\n\n\n\n\nAufgabe: Rendere das Dokument erneut und überprüfe das gerenderte Ergebnis im Vorschaufenster oder im Ausgabeordner.",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 3 (Woche 5 - 6) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_3.html#vektoren",
    "href": "scripts/02_excercises/loesung_3.html#vektoren",
    "title": "Lösung 3",
    "section": "Vektoren:",
    "text": "Vektoren:\nWir haben in den Hands-On-Übungen Block 1 und 2 bereits einige einfache Vektoren erstellt und damit operiert.",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 3 (Woche 5 - 6) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_3.html#matrizen",
    "href": "scripts/02_excercises/loesung_3.html#matrizen",
    "title": "Lösung 3",
    "section": "Matrizen",
    "text": "Matrizen\nEine Matrix besteht nur aus einem Datentyp (z. B. nur Zahlen).\n\nErstelle eine 3x3-Matrix matrix() mit den Zahlen 1 bis 9.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nmatrix(1:9, nrow = 3)\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n\nmatrix(1:9, ncol = 3)\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n\n\n\n\n\n\nWandle einen Vektor 1:12 in eine 3x4-Matrix um. Teste den Unterschied zwischen byrow = TRUE und byrow = FALSE innerhalb von matrix().\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nseq_vektor &lt;- c(1:12)\n    \nmatrix_byrow &lt;- matrix(seq_vektor, nrow = 3, ncol = 4, byrow = TRUE)\nmatrix_byrow\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    2    3    4\n[2,]    5    6    7    8\n[3,]    9   10   11   12\n\nmatrix_bycol &lt;- matrix(seq_vektor, nrow = 3, ncol = 4, byrow = FALSE)\nmatrix_bycol\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    4    7   10\n[2,]    2    5    8   11\n[3,]    3    6    9   12\n\n\nIst das Argument byrow auf TRUE gesetzt, werden die Werte zeilenweise in die Matrix eingefügt. Bei FALSE (Standardwert) erfolgt die Befüllung spaltenweise.\n\n\n\n\nGreife auf das Element in der 2. Zeile, 3. Spalte zu.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nmatrix_byrow[2, 3]\n\n[1] 7\n\nmatrix_bycol[2, 3]\n\n[1] 8\n\n\n\n\n\n\nBerechne die Spaltensummen und Zeilensummen.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ncolSums(matrix_byrow) # col = Spalte\n\n[1] 15 18 21 24\n\nrowSums(matrix_byrow) # row = Zeile\n\n[1] 10 26 42\n\ncolSums(matrix_bycol) # col = Spalte\n\n[1]  6 15 24 33\n\nrowSums(matrix_bycol) # row = Zeile\n\n[1] 22 26 30\n\n\n\n\n\n\nSchaue dir an, was passiert wenn du t() auf deine Matrix anwendest.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nt(matrix_byrow)\n\n     [,1] [,2] [,3]\n[1,]    1    5    9\n[2,]    2    6   10\n[3,]    3    7   11\n[4,]    4    8   12\n\nt(matrix_bycol)\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n[3,]    7    8    9\n[4,]   10   11   12\n\n\nDie Funktion t() transponiert die Matrix, d.h. sie vertauscht die Zeilen und Spalten.\n\n\n\n\n\n\n\n\n\nFreiwillig für Fortgeschrittene:\n\n\n\n\nGeneriere aus den Variablen ID, Initialen und Alter eine Matrize, die so aussieht: “1-RS-44” “2-MM-78” “3-PD-22” “4-PG-34” “5-DK-67” “1-RS-59«\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nID &lt;- c(1, 2, 3, 4, 5, 1)\nInitialen &lt;- c(\"RS\", \"MM\", \"PD\", \"PG\", \"DK\", \"RS\")\nAlter &lt;- c(44, 78, 22, 34, 67, 59)\n\nkombiniert &lt;- paste(ID, Initialen, Alter, sep = \"-\")\n\nmatrix_kombiniert &lt;- matrix(kombiniert, ncol = 1, byrow = FALSE)\nmatrix_kombiniert\n\n     [,1]     \n[1,] \"1-RS-44\"\n[2,] \"2-MM-78\"\n[3,] \"3-PD-22\"\n[4,] \"4-PG-34\"\n[5,] \"5-DK-67\"\n[6,] \"1-RS-59\"\n\n\n\n\n\n\nErstelle einen Vektor mit den Namen mehrerer berühmter Wissenschaftler:innen. Kombiniere die Namen mit paste() und einem zusätzlichen Suffix, z. B. „, PhD“. Prüfe mit grepl(), ob einer der Namen ein bestimmtes Muster enthält (z. B. „stein“).\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nwissenschaftler &lt;- c(\"Albert Einstein\", \"Marie Curie\", \"Isaac Newton\", \"Rosalind Franklin\", \"Charles Darwin\")\n\nwissenschaftler_suffix &lt;- paste(wissenschaftler, \"PhD\", sep = \", \")\n\nmuster_vorhanden &lt;- grepl(\"stein\", wissenschaftler_suffix, ignore.case = TRUE)\nmuster_vorhanden\n\n[1]  TRUE FALSE FALSE FALSE FALSE\n\n\nDer Vektor muster_vorhanden gibt euch für die entsprechende Stelle des Vektors wissenschaftler_suffix aus, ob das Muster “stein” (unabhängig von Groß- und Kleinschreibung) im jeweiligen Namen vorkommt (TRUE/FALSE).",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 3 (Woche 5 - 6) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_3.html#listen",
    "href": "scripts/02_excercises/loesung_3.html#listen",
    "title": "Lösung 3",
    "section": "Listen",
    "text": "Listen\nEine Liste kann verschiedene Datentypen enthalten (z. B. Zahlen, Zeichenketten, logische Werte).\n👉 Einführung in R, Kapitel 2.4.5\n\nErstelle eine Liste mit drei Elementen und der Funktion list():\n\neinem Vektor mit den Zahlen 1 bis 5\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nmeine_liste &lt;- list(\n  zahlen = 1:5\n)\nmeine_liste\n\n$zahlen\n[1] 1 2 3 4 5\n\n\n\n\n\n-   einem Character-Vektor mit den Namen deiner Kommiliton:innen\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nmeine_liste &lt;- list(\n  zahlen = 1:5,\n  namen = c(\"Anna\", \"Ben\", \"Clara\", \"David\", \"Eva\") # frei erfundene Namen\n)\nmeine_liste\n\n$zahlen\n[1] 1 2 3 4 5\n\n$namen\n[1] \"Anna\"  \"Ben\"   \"Clara\" \"David\" \"Eva\"  \n\n\n\n\n\n-   einem logischen Vektor (TRUE, FALSE)\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nmeine_liste &lt;- list(\n  zahlen = 1:5,\n  namen = c(\"Anna\", \"Ben\", \"Clara\", \"David\", \"Eva\"), # frei erfundene Namen\n  logisch = c(TRUE, FALSE, TRUE, FALSE, TRUE)\n)\nmeine_liste\n\n$zahlen\n[1] 1 2 3 4 5\n\n$namen\n[1] \"Anna\"  \"Ben\"   \"Clara\" \"David\" \"Eva\"  \n\n$logisch\n[1]  TRUE FALSE  TRUE FALSE  TRUE\n\n\n\n\n\n\nGreife auf das zweite Element der Liste zu.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nmeine_liste[[2]]\n\n[1] \"Anna\"  \"Ben\"   \"Clara\" \"David\" \"Eva\"  \n\n\n\n\n\n\nGreife auf den dritten Wert des ersten Elements der Liste zu.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nmeine_liste[[1]][3]\n\n[1] 3\n\n\n\n\n\n\nFüge der Liste ein weiteres Element hinzu (z. B. den Mittelwert der Zahlen).\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nmeine_liste$mittelwert &lt;- mean(meine_liste$zahlen)\n\nmeine_liste[[4]]\n\n[1] 3\n\nmeine_liste[[\"mittelwert\"]] # auch direkt über den Namen abrufbar\n\n[1] 3",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 3 (Woche 5 - 6) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_3.html#data-frames",
    "href": "scripts/02_excercises/loesung_3.html#data-frames",
    "title": "Lösung 3",
    "section": "Data Frames",
    "text": "Data Frames\n👉Einführung in R, Kapitel 2.4.6\nEin Data Frame ist eine tabellarische Struktur mit Spalten, die verschiedene Datentypen enthalten können.\n\nErstelle einen Data Frame data.frame() oder tibble() mit drei Spalten:\n\nname (Character)\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndatensatz &lt;- data.frame(\n  name = c(\"Anna\", \"Ben\", \"Clara\", \"David\", \"Eva\")\n)\ndatensatz\n\n   name\n1  Anna\n2   Ben\n3 Clara\n4 David\n5   Eva\n\n\n\n\n\n-   alter (Numeric)\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndatensatz &lt;- data.frame(\n  name = c(\"Anna\", \"Ben\", \"Clara\", \"David\", \"Eva\"),\n  alter = c(22, 25, 23, 30, 28)\n)\ndatensatz\n\n   name alter\n1  Anna    22\n2   Ben    25\n3 Clara    23\n4 David    30\n5   Eva    28\n\n\n\n\n\n-   studiert (Logical: TRUE/FALSE)\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndatensatz &lt;- data.frame(\n  name = c(\"Anna\", \"Ben\", \"Clara\", \"David\", \"Eva\"),\n  alter = c(22, 25, 23, 30, 28),\n  studiert = c(TRUE, FALSE, TRUE, TRUE, FALSE)\n)\ndatensatz\n\n   name alter studiert\n1  Anna    22     TRUE\n2   Ben    25    FALSE\n3 Clara    23     TRUE\n4 David    30     TRUE\n5   Eva    28    FALSE\n\n\n\n\n\n\nGreife mit datensatz$alter auf die Spalte “alter” zu.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndatensatz$alter\n\n[1] 22 25 23 30 28\n\n\n\n\n\n\nFiltere alle Zeilen, in denen studiert == TRUE.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndata_studierende_true &lt;- datensatz[datensatz$studiert == TRUE, ] # mit Base R\n\ndata_studierende_true &lt;- datensatz |&gt; # mit der Pipe (dazu kommen wir noch mal)\n  filter(studiert == TRUE)\n\ndata_studierende_true\n\n   name alter studiert\n1  Anna    22     TRUE\n2 Clara    23     TRUE\n3 David    30     TRUE\n\n\n\n\n\n\nFüge eine neue Spalte hinzu, die “alter” + 10 berechnet.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndatensatz$alter_plus_10 &lt;- datensatz$alter + 10 # mit Base R\n\ndatensatz &lt;- datensatz |&gt; # mit der Pipe\n  mutate(alter_plus_10 = alter + 10)\n\ndatensatz\n\n   name alter studiert alter_plus_10\n1  Anna    22     TRUE            32\n2   Ben    25    FALSE            35\n3 Clara    23     TRUE            33\n4 David    30     TRUE            40\n5   Eva    28    FALSE            38\n\n\n\n\n\n\nBenenne die Spalten in deinem Data Frame mit colnames() oder rename()um, sodass sie internationalen Standards folgen.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndatensatz &lt;- datensatz |&gt; # mit der Pipe (dazu kommen wir noch mal)\n  rename(\n    name = name,\n    age = alter,\n    studies = studiert,\n    age_plus_10 = alter_plus_10\n  )\n\ncolnames(datensatz) &lt;- c(\"name\", \"age\", \"studies\", \"age_plus_10\") # mit Base R\ndatensatz\n\n   name age studies age_plus_10\n1  Anna  22    TRUE          32\n2   Ben  25   FALSE          35\n3 Clara  23    TRUE          33\n4 David  30    TRUE          40\n5   Eva  28   FALSE          38\n\n\nDie Schreibweise mit der Pipe bedingt, dass die Spaltennamen zuvor exakt so im data frame vorhanden sind, wie sie rechts vom Gleichzeichen stehen. Deswegen habe ich die Reihenfolge der beiden Schreibweisen hier geändert.\n\n\n\n\nBerechne den Mittelwert und die Standardabweichung der Variable „age”.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nmean_age &lt;- mean(datensatz$age) # mit Base R\nmean_age\n\n[1] 25.6\n\nsd_age &lt;- sd(datensatz$age) # mit Base R\nsd_age\n\n[1] 3.361547\n\nmean_age_and_sd_age &lt;- datensatz |&gt; # mit der Pipe\n  summarize(\n    mean_age = mean(age),\n    sd_age = sd(age)\n  )\nmean_age_and_sd_age\n\n  mean_age   sd_age\n1     25.6 3.361547\n\n\n\n\n\n\nSortiere den Data Frame basierend auf “age” absteigend mit arrange().\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndatensatz_sorted_age &lt;- datensatz[order(datensatz$age, decreasing = TRUE), ]\n\ndatensatz_sorted_age &lt;- datensatz |&gt; # mit der Pipe\n  arrange(desc(age))\n\ndatensatz_sorted_age\n\n   name age studies age_plus_10\n1 David  30    TRUE          40\n2   Eva  28   FALSE          38\n3   Ben  25   FALSE          35\n4 Clara  23    TRUE          33\n5  Anna  22    TRUE          32\n\n\n\n\n\nWeitere Informationen zum Erstellen von Data Frames findest du hier: Einführung in R, Kapitel 3.1\n\n\n\n\n\n\nFür Fortgeschrittene\n\n\n\n\nÖffne den Datensatz “dat_full” und sieh dir die Datentypen an.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndat_full &lt;- read_csv(\"data/raw/dat_full.csv\")\n\nRows: 159 Columns: 36\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): group_all\ndbl (35): code, question1, question2, question3, question4, question5, quest...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nstr(dat_full) # oder eine andere geeignete Übersichtsfunktion\n\nspc_tbl_ [159 × 36] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ code             : num [1:159] 1 2 3 4 5 6 7 8 9 10 ...\n $ question1        : num [1:159] 2 3 2 1 3 1 1 1 2 1 ...\n $ question2        : num [1:159] 3 4 3 2 4 3 3 2 3 4 ...\n $ question3        : num [1:159] 3 3 2 2 4 3 3 3 3 4 ...\n $ question4        : num [1:159] 3 4 1 3 2 4 1 3 3 4 ...\n $ question5        : num [1:159] 2 3 2 1 4 3 2 2 3 3 ...\n $ question6        : num [1:159] 3 3 2 2 4 3 2 1 3 4 ...\n $ question7        : num [1:159] 3 3 2 2 4 3 0 2 3 4 ...\n $ question8        : num [1:159] 3 3 2 0 3 4 1 3 3 3 ...\n $ question9        : num [1:159] 2 3 1 2 1 4 2 1 3 2 ...\n $ question10       : num [1:159] 3 3 1 3 4 4 1 2 3 4 ...\n $ question11       : num [1:159] 3 3 1 1 3 3 1 1 3 3 ...\n $ question12       : num [1:159] 3 3 2 1 3 3 1 2 3 3 ...\n $ question13       : num [1:159] 2 3 1 3 1 2 1 1 2 2 ...\n $ question14       : num [1:159] 2 2 0 2 1 3 0 1 2 3 ...\n $ question15       : num [1:159] 3 4 2 2 4 3 1 4 3 4 ...\n $ question16       : num [1:159] 2 4 1 1 2 3 1 1 2 3 ...\n $ question17       : num [1:159] 3 3 2 1 3 3 1 1 2 3 ...\n $ question18       : num [1:159] 2 3 0 0 4 3 1 1 3 4 ...\n $ vp_sum           : num [1:159] 33 27 33 31 32 24 28 27 28 26 ...\n $ vp_propcorrect   : num [1:159] 0.917 0.75 0.917 0.861 0.889 ...\n $ cb_sum           : num [1:159] 26 27 30 27 25 23 28 27 30 26 ...\n $ cb_propcorrect   : num [1:159] 0.722 0.75 0.833 0.75 0.694 ...\n $ csvtm_sum        : num [1:159] 70 73 93 83 79 72 94 85 72 90 ...\n $ cvstm_propcorrect: num [1:159] 0.583 0.608 0.775 0.692 0.658 ...\n $ strategies       : num [1:159] 1 1 2 2 1 2 2 2 1 2 ...\n $ pre1             : num [1:159] 6.2 5.5 8.7 5.2 8.1 4.9 6.8 6.5 5.2 6.6 ...\n $ pre2             : num [1:159] 7.5 5.5 4.5 0.9 4.6 3.3 4.2 1.8 6.6 1.5 ...\n $ pre3             : num [1:159] 7.4 2.5 2.5 1.1 6.7 2.9 7 1.9 6.3 1.8 ...\n $ pre4             : num [1:159] 6.2 4.4 2.5 0.6 6.2 2.1 2 2.3 6.5 2 ...\n $ post             : num [1:159] 7 2.1 3.2 0.6 6.3 2.2 5.2 2.1 7 1.8 ...\n $ group_all        : chr [1:159] \"above\" \"control\" \"below\" \"below\" ...\n $ mean_rl_all      : num [1:159] 5.95 5.35 4.8 6.55 6.15 6.05 5 5.4 4.5 6 ...\n $ mean_e1_all      : num [1:159] 3.05 3.25 3.25 2.55 2.5 3.05 3.3 3.3 3.45 2.65 ...\n $ mean_d1_all      : num [1:159] 3.9 16.39 5.58 4.74 5.53 ...\n $ mean_d_all       : num [1:159] 32.8 71.2 36.2 44 42.3 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   code = col_double(),\n  ..   question1 = col_double(),\n  ..   question2 = col_double(),\n  ..   question3 = col_double(),\n  ..   question4 = col_double(),\n  ..   question5 = col_double(),\n  ..   question6 = col_double(),\n  ..   question7 = col_double(),\n  ..   question8 = col_double(),\n  ..   question9 = col_double(),\n  ..   question10 = col_double(),\n  ..   question11 = col_double(),\n  ..   question12 = col_double(),\n  ..   question13 = col_double(),\n  ..   question14 = col_double(),\n  ..   question15 = col_double(),\n  ..   question16 = col_double(),\n  ..   question17 = col_double(),\n  ..   question18 = col_double(),\n  ..   vp_sum = col_double(),\n  ..   vp_propcorrect = col_double(),\n  ..   cb_sum = col_double(),\n  ..   cb_propcorrect = col_double(),\n  ..   csvtm_sum = col_double(),\n  ..   cvstm_propcorrect = col_double(),\n  ..   strategies = col_double(),\n  ..   pre1 = col_double(),\n  ..   pre2 = col_double(),\n  ..   pre3 = col_double(),\n  ..   pre4 = col_double(),\n  ..   post = col_double(),\n  ..   group_all = col_character(),\n  ..   mean_rl_all = col_double(),\n  ..   mean_e1_all = col_double(),\n  ..   mean_d1_all = col_double(),\n  ..   mean_d_all = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\n\n\n\n\n\nSieh dir den Datensatz genau an. Die Variable csvtm_sum scheint einen Tippfehler zu enthalten. Korrigiere diesen zu cvstm_sum mit einer der oben vorgestellten Funktionen.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndat_full &lt;- rename(dat_full, cvstm_sum = csvtm_sum)\n\n# dat_full &lt;- dat_full |&gt; # mit der Pipe\n#   rename(\n#     cvstm_sum = csvtm_sum\n#   ) # letzteren habe ich auskommentiert, da es sonst zu einem Fehler kommt. Die Spalte csvtm_sum existiert nach der ersten Umbennung in diesem Chunk ja nicht mehr\n\n\n\n\n\nWelche Variablen sollten Faktoren sein?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nMeist bietet es sich an jene Variablen als Faktoren zu formatieren, wenn diese in eurem Studiendesign per Definition wenige, klare Ausprägungen erhalten können (bspw. die Gruppenzugehörigkeit in einem between-subject Design). In unserem Fall bietet es sich vor allem für die Variablen strategies und group_all an.\n\n\n\n\nDefiniere diese Variablen als Faktor. Nutze dafür z. B. as.factor() oder factor().\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndat_full$strategies &lt;- as.factor(dat_full$strategies)\ndat_full$group_all &lt;- as.factor(dat_full$group_all)\n\n# alternativ mit factor(). Hier können auch die Reihenfolgen der Levels angepasst werden:\ndat_full$strategies &lt;- factor(dat_full$strategies,\n                              levels = c(1, 2, 3) # je nach Wunsch der Reihenfolge der Levels anpassen\n                              )\ndat_full$group_all &lt;- factor(dat_full$group_all,\n                             levels = c(\"control\", \"above\", \"below\") # je nach Wunsch der Reihenfolge der Levels anpassen\n                             )\n\nsummary(dat_full)\n\n      code         question1       question2       question3    \n Min.   :  1.0   Min.   :0.000   Min.   :0.000   Min.   :0.000  \n 1st Qu.: 40.5   1st Qu.:1.500   1st Qu.:3.000   1st Qu.:3.000  \n Median : 80.0   Median :2.000   Median :3.000   Median :3.000  \n Mean   : 80.0   Mean   :2.195   Mean   :3.214   Mean   :3.126  \n 3rd Qu.:119.5   3rd Qu.:3.000   3rd Qu.:4.000   3rd Qu.:4.000  \n Max.   :159.0   Max.   :4.000   Max.   :4.000   Max.   :4.000  \n   question4       question5       question6       question7    \n Min.   :0.000   Min.   :0.000   Min.   :0.000   Min.   :0.000  \n 1st Qu.:2.000   1st Qu.:2.000   1st Qu.:2.000   1st Qu.:2.000  \n Median :3.000   Median :3.000   Median :3.000   Median :3.000  \n Mean   :2.811   Mean   :2.509   Mean   :2.491   Mean   :2.623  \n 3rd Qu.:4.000   3rd Qu.:3.000   3rd Qu.:3.000   3rd Qu.:3.000  \n Max.   :4.000   Max.   :4.000   Max.   :4.000   Max.   :4.000  \n   question8       question9       question10      question11   \n Min.   :0.000   Min.   :0.000   Min.   :0.000   Min.   :0.000  \n 1st Qu.:3.000   1st Qu.:1.000   1st Qu.:2.000   1st Qu.:2.000  \n Median :3.000   Median :2.000   Median :3.000   Median :3.000  \n Mean   :2.943   Mean   :1.994   Mean   :2.843   Mean   :2.692  \n 3rd Qu.:4.000   3rd Qu.:3.000   3rd Qu.:4.000   3rd Qu.:4.000  \n Max.   :4.000   Max.   :4.000   Max.   :4.000   Max.   :4.000  \n   question12      question13      question14      question15   \n Min.   :0.000   Min.   :0.000   Min.   :0.000   Min.   :0.000  \n 1st Qu.:2.000   1st Qu.:1.000   1st Qu.:1.000   1st Qu.:3.000  \n Median :3.000   Median :2.000   Median :2.000   Median :3.000  \n Mean   :2.516   Mean   :1.937   Mean   :1.962   Mean   :3.182  \n 3rd Qu.:3.000   3rd Qu.:3.000   3rd Qu.:3.000   3rd Qu.:4.000  \n Max.   :4.000   Max.   :4.000   Max.   :4.000   Max.   :4.000  \n   question16      question17      question18        vp_sum     \n Min.   :0.000   Min.   :0.000   Min.   :0.000   Min.   :18.00  \n 1st Qu.:1.000   1st Qu.:2.000   1st Qu.:2.000   1st Qu.:28.00  \n Median :1.000   Median :2.000   Median :3.000   Median :31.00  \n Mean   :1.736   Mean   :2.327   Mean   :2.748   Mean   :30.29  \n 3rd Qu.:3.000   3rd Qu.:3.000   3rd Qu.:4.000   3rd Qu.:33.00  \n Max.   :4.000   Max.   :4.000   Max.   :4.000   Max.   :36.00  \n vp_propcorrect       cb_sum      cb_propcorrect     cvstm_sum     \n Min.   :0.5000   Min.   :18.00   Min.   :0.5000   Min.   : 70.00  \n 1st Qu.:0.7778   1st Qu.:26.00   1st Qu.:0.7222   1st Qu.: 81.00  \n Median :0.8611   Median :27.00   Median :0.7500   Median : 88.00  \n Mean   :0.8414   Mean   :27.49   Mean   :0.7636   Mean   : 87.96  \n 3rd Qu.:0.9167   3rd Qu.:30.00   3rd Qu.:0.8333   3rd Qu.: 93.00  \n Max.   :1.0000   Max.   :35.00   Max.   :0.9722   Max.   :113.00  \n cvstm_propcorrect strategies      pre1            pre2            pre3      \n Min.   :0.5833    1:58       Min.   :0.600   Min.   :0.500   Min.   :0.400  \n 1st Qu.:0.6750    2:88       1st Qu.:4.750   1st Qu.:3.350   1st Qu.:2.600  \n Median :0.7333    3:13       Median :5.400   Median :4.800   Median :4.600  \n Mean   :0.7330               Mean   :5.441   Mean   :4.662   Mean   :4.401  \n 3rd Qu.:0.7750               3rd Qu.:6.300   3rd Qu.:5.900   3rd Qu.:6.000  \n Max.   :0.9417               Max.   :9.100   Max.   :8.400   Max.   :8.800  \n      pre4            post         group_all   mean_rl_all     mean_e1_all   \n Min.   :0.500   Min.   :0.400   control:53   Min.   :2.700   Min.   :1.650  \n 1st Qu.:3.150   1st Qu.:3.100   above  :53   1st Qu.:4.475   1st Qu.:2.825  \n Median :4.900   Median :5.000   below  :53   Median :4.950   Median :3.250  \n Mean   :4.714   Mean   :4.727                Mean   :5.209   Mean   :3.261  \n 3rd Qu.:6.200   3rd Qu.:6.200                3rd Qu.:5.975   3rd Qu.:3.600  \n Max.   :9.600   Max.   :9.300                Max.   :8.450   Max.   :5.550  \n  mean_d1_all       mean_d_all   \n Min.   : 1.903   Min.   :27.54  \n 1st Qu.: 4.612   1st Qu.:35.50  \n Median : 5.576   Median :39.88  \n Mean   : 6.903   Mean   :42.20  \n 3rd Qu.: 8.109   3rd Qu.:46.16  \n Max.   :19.526   Max.   :77.57  \n\n\n\n\n\n\nZum Schluss speichere den bereinigten Datensatz erneut mit write.csv ab.\n\n\nwrite.csv(dat_full, \"data/processed/dat_full.csv\")\n\nHinweis: R speichert nicht, dass eine Variable als Faktor definiert wurde! Dieser Code muss bei jedem Neustart erneut ausgeführt werden, wenn wieder mit denselben Faktoren gearbeitet wird.",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 3 (Woche 5 - 6) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_6.html",
    "href": "scripts/02_excercises/loesung_6.html",
    "title": "Hands On – Analyze (Einheiten 11 und 12)",
    "section": "",
    "text": "Bei Bedarf findest du hier nochmals die Slides zu Einheit 10:",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 6 (Woche 11 - 12) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_6.html#visualize---übungen-zu-ggplot2",
    "href": "scripts/02_excercises/loesung_6.html#visualize---übungen-zu-ggplot2",
    "title": "Hands On – Analyze (Einheiten 11 und 12)",
    "section": "Visualize - Übungen zu ggplot2",
    "text": "Visualize - Übungen zu ggplot2\n📚 Einführung in R - Kapitel 5\n📚 R for Data Science - Kapitel 1\n📚R for Data Science - Kapitel 11\n\n\n\n\n\n\nTabelle mit häufig verwendeten Geoms()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGeom\nFunktion\nEinsatzbereich\nBild / Beispiel\n\n\n\n\ngeom_point()\nStreudiagramm\nZwei numerische Variablen vergleichen (x = Var1, y = Var2)\n\n\n\ngeom_jitter()\nJitter-Plot\nPunkte leicht versetzen, um Überlappung zu vermeiden (v. a. bei kategorialem x)\n\n\n\ngeom_line()\nLiniendiagramm\nWerteverlauf Über kontinuierliche x-Achse darstellen\n\n\n\ngeom_bar()\nBalkendiagramm\nHäufigkeiten oder Aggregationen für Kategorien (x = Gruppe)\n\n\n\ngeom_histogram()\nHistogramm\nVerteilung einer numerischen Variable (x = Wert)\n\n\n\ngeom_boxplot()\nBoxplot\nVerteilungen über Gruppen vergleichen (x = Gruppe, y = Wert)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCheatsheet ggplot2\n\n\n\n\n\n\n\n\n\n\nIm folgenden wollen wir Figure 4 aus Grinschgl et al. (2021) reproduzieren:\n\n\n\n\n\n\n\n\n\n\nVorbereitungen:\nUm die Mittelwerte plotten zu können, müssen wir die Gruppenmittelwerte und Standardfehler berechnen. Passe dafür den Codeblock an:\nIm Hands-on Block 4 haben wir bereits mit dplyr die MMQ-Skalenwerte „mmq_mean“ pro Person berechnet. Nutze nun die dplyr-Funktionen, insbesondere group_by(), um den durchschnittlichen MMQ-Wert pro Gruppe (group_all) sowie den Standardfehler zu berechnen. Die Formel für den Standardfehler lautet: SE = SD / √n und kann z.b so berechnet werden. se_mmq = sd(mmq_mean) / sqrt(n()) . Ergänze den Code unten mit den nötigen Angaben. Lege group_all in deinem summary als Faktor fest mit den Levels in der Reihenfolge: “below”, “control”, “above”.\n\n\n\n\n\n\nNote\n\n\n\n\n\nDer Standardfehler des Mittelwerts (SEM) beschreibt wie stark der geschätzte Stichprobenmittelwert zufällig vom wahren Populationsmittelwert abweichen kann. Er ist damit ein Mass für die Präzision des Mittelwerts.\n\n\n\n\ndat_full &lt;- dat_full |&gt; \n  mutate(mmq_mean = rowMeans(select(dat_full, starts_with(\"question\")))\n\n\ngroup_summary &lt;- dat_full %&gt;%\n  group_by(XXXXXXX) %&gt;%\n  summarize(\n    group_mean_mmq = mean(XXXXXX),\n    se_mmq = sd(XXXXXX) / sqrt(n())\n  )\n\ngroup_summary$group_all &lt;- factor(group_summary$group_all,\n                                  levels = c(\"XXXXX\", \"XXXXX\", \"XXXXX\"))\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndat_full &lt;- dat_full |&gt; \n  mutate(mmq_mean = rowMeans(select(dat_full, starts_with(\"question\"))))\n\n\ngroup_summary &lt;- dat_full %&gt;%\n  group_by(group_all) %&gt;%\n  summarize(\n    group_mean_mmq = mean(mmq_mean),\n    se_mmq = sd(mmq_mean) / sqrt(n())\n  )\n\ngroup_summary$group_all &lt;- factor(group_summary$group_all,\n                                  levels = c(\"below\", \"control\", \"above\"))\n\n\n\n\n\n\n1. Erstelle einen leeren Plot und gib deinen Datensatz an\nBeginne mit:\n\nggplot() und deinem Datensatz\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nplot_base &lt;- group_summary |&gt; \n  ggplot()\n\n\n\n\n\n\n2. Definiere die Aesthetic Mappings\nLege fest:\n\nwelche Variable auf der x-Achse liegt\nwelche Variable auf der y-Achse liegt\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nplot_base_updated &lt;- plot_base +\n  aes(x = group_all, y = group_mean_mmq)\n\n\n\n\n\n\n3. Füge geom_col() dem Plot hinzu\nDamit zeichnest du die Balken für die Gruppenmittelwerte.\n\ncolor = für Konturen\nfill = für die Füllfarben der Balken\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nplot_base_updated &lt;- plot_base_updated +\n  geom_col(fill = \"gray\", color = \"black\")\n\n\n\n\n\n\n4. Füge Fehlerbalken hinzu\nNutze geom_errorbar() und definiere innerhalb von aes():\n\nymin = mean - se - Füge die passenden Variablen ein.\nymax = mean + se - Füge die passenden Variablen ein.\n\nPasse die Breite der Fehlerbalken mit width = an.\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nplot_base_updated &lt;- plot_base_updated +\n  geom_errorbar(\n    aes(ymin = group_mean_mmq - se_mmq, ymax = group_mean_mmq + se_mmq),  \n    width = 0.2,\n    color = \"black\"\n  )\n\n\n\n\n\n\n5. Füge Titel und Achsenbeschriftungen hinzu\nNutze dafür labs(). Verändere das theme zu theme_classic()\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nplot_base_updated &lt;- plot_base_updated +\n  labs(\n    x = \"Feedback Group\",\n    y = \"Mean MMQ Ratings\",\n    title = \"Group Means of Mean MMQ with SE Error Bars\"\n  ) +\n  theme_classic()\n\n\n\n\n\n\n6. Stelle sicher, dass der vollständige Wertebereich sichtbar ist\n\nmit ylim(0, 4)\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nplot_final &lt;- plot_base_updated +\n  ylim(0, 4)\nplot_final\n\n\n\n\n\n\n\n\n\n\n\n\nNun wollen wir den zweiten Plot aus Grinschgl et al. (2021) reproduzieren.\nErgänze dafür den folgenden Code an den nötigen Stellen mit den passenden Werten und Argumenten.\n\nLade zuerst den in der letzten Woche gespeicherten Long-Datensatz.\nErsetze anschliessend die Platzhalter “XXXXXX” durch die erforderlichen Werte, um den Plot zu reproduzieren.\n\n\ndescriptives &lt;- dat_long |&gt; \n  group_by(XXXXXX, XXXXXXX) |&gt; \n  summarize(N = length(rating),\n               mean_d = mean(rating),\n               sd_d   = sd(rating),\n               se_d   = sd_d / sqrt(N)\n)\n\ndescriptives$group_all &lt;- factor(descriptives$group_all, c(\"above\", \"control\", \"below\"))\n\nrate_plot &lt;- descriptives |&gt; \n  ggplot(aes(x = XXXXXX, \n             y = XXXXXX, \n             group = XXXX)) \n\nrate_plot +\n  geom_line(aes(color = group_all, linetype = group_all), size = 1.2) +\n  geom_errorbar(aes(ymin = mean_d - se_d, ymax = mean_d + se_d), width = .1) +\n  scale_color_manual(values = c(\"green4\", \"red\", \"black\")) +\n  theme_classic() +\n  labs(title = \"XXXXXXX\") +\n  ylab(\"XXXXXXXX\") +\n  xlab(\"XXXXXXXXX\") +\n  theme(plot.title = element_text(hjust = 0.5, size = 12, face = \"bold\"), \n        axis.text = element_text(size = 11), axis.title = element_text(size = 14))\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndescriptives &lt;- dat_long |&gt; \n  group_by(group_all, time_rating) |&gt; \n  summarize(N = length(rating),\n               mean_d = mean(rating)*10,\n               sd_d   = sd(rating)*10,\n               se_d   = sd_d / sqrt(N)\n)\n\n`summarise()` has grouped output by 'group_all'. You can override using the\n`.groups` argument.\n\ndescriptives$group_all &lt;- factor(descriptives$group_all, c(\"above\", \"control\", \"below\"))\n\nrate_plot &lt;- descriptives |&gt; \n  ggplot(aes(x = time_rating, \n             y = mean_d, \n             group = group_all)) \n\nrate_plot_updated &lt;- rate_plot +\n  geom_line(aes(color = group_all, linetype = group_all), size = 1.2) +\n  geom_errorbar(aes(ymin = mean_d - se_d, ymax = mean_d + se_d), width = .1) +\n  scale_color_manual(values = c(\"green4\", \"red\", \"black\")) +\n  theme_classic() +\n  labs(title = \"Subjective Performance Ratings \") +\n  ylab(\"Percentile Rank\") +\n  xlab(\"Time\") +\n  theme(plot.title = element_text(hjust = 0.5, size = 12, face = \"bold\"), \n        axis.text = element_text(size = 11), axis.title = element_text(size = 14))\nrate_plot_updated\n\n\n\n\n\n\n\n\n\n\n\n\nSpeichere deinen Plot als PNG Datei ab.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nggsave(\n  \"rate_plot.png\",\n  plot = rate_plot_updated,\n  width = 10,\n  height = 6,\n  dpi = 300\n)",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 6 (Woche 11 - 12) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_6.html#korrelationen",
    "href": "scripts/02_excercises/loesung_6.html#korrelationen",
    "title": "Hands On – Analyze (Einheiten 11 und 12)",
    "section": "Korrelationen:",
    "text": "Korrelationen:\n\nWähle zwei metrische Variablen aus dem Wide Datensatz aus. Berechne die Korrelation mit cor.test() für diese beiden Variablen.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ncor.test(dat_full$mean_d1_all, dat_full$mean_d_all)\n\n\n    Pearson's product-moment correlation\n\ndata:  dat_full$mean_d1_all and dat_full$mean_d_all\nt = 16.806, df = 157, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.7381602 0.8511386\nsample estimates:\n      cor \n0.8016982 \n\n\n\n\n\n\n\nFinde den Korrelationskoeffizienten r, den p-Wert und die Freiheitsgrade (df). Versuche das Ergebnis zu interpretieren.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nIn dem von uns gewählten Beispiel wurde die Korrelation von mean_d1_all mit mean_d_all berechnet. Der Korrelationskoeffizient r beträgt r = 0.78, was auf eine starke positive Korrelation hinweist. Der p-Wert ist p &lt; 0.001, was darauf hindeutet, dass die Korrelation statistisch signifikant ist. Die Freiheitsgrade (df) betragen 157, was auf die Anzahl der Beobachtungen minus 2 zurückzuführen ist (n-2). Das die Dauer bis zur ersten Fensteröffnung und die Dauer des gesamten Trials zusammenhängen war inhaltlich zu erwarten.\n\n\n\n\n\nRufe die Hilfefunktion von cor.test() auf. Welche Anpassungen kannst du vornehmen, um die Korrelation einseitig (z.B. nur positiver Zusammenhang) und mit der Spearman-Methode zu berechnen?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n?cor.test\n\n# Für eine einseitige Korrelation kannst du das Argument `alternative` verwenden, z.B. `alternative = \"greater\"` für eine positive Korrelation.\ncor.test(dat_full$mean_d1_all, dat_full$mean_d_all, alternative = \"greater\")\n\n\n    Pearson's product-moment correlation\n\ndata:  dat_full$mean_d1_all and dat_full$mean_d_all\nt = 16.806, df = 157, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is greater than 0\n95 percent confidence interval:\n 0.7494301 1.0000000\nsample estimates:\n      cor \n0.8016982 \n\n# Für die Spearman-Methode kannst du das Argument `method` verwenden, z.B. `method = \"spearman\"`.\ncor.test(dat_full$mean_d1_all, dat_full$mean_d_all, method = \"spearman\")\n\n\n    Spearman's rank correlation rho\n\ndata:  dat_full$mean_d1_all and dat_full$mean_d_all\nS = 159836, p-value &lt; 2.2e-16\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.7614103 \n\n\n\n\n\n\n\n\n\n\n\nKorrelationen\n\n\n\n\n\nLinearer Zusammenhang (Kovarianz) zweier Variablen. Positive Korrelation = hohe Ausprägungen einer Variable hängen mit hohen Ausprägungen einer anderen Variable zusammen. Negative Korrelation = Hohe Ausprägungen einer Variable hängen mit niedrigen Ausprägungen einer anderen Variable zusammen. Korrelationskoeffizient r kann von -1 bis +1 gehen. Der Korrelationstest testet ob r sich signifikant von 0 (kein Zusammenhang unterscheidet). Für Pearson Korrelationen sollte die Normalverteilung der Residuen gegeben sein. Alternative: Spearman Korrelation.",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 6 (Woche 11 - 12) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_6.html#regressionen",
    "href": "scripts/02_excercises/loesung_6.html#regressionen",
    "title": "Hands On – Analyze (Einheiten 11 und 12)",
    "section": "Regressionen",
    "text": "Regressionen\n\n\n\n\n\n\nTabelle: Funktionen für Regressionen und verwandte Analysen in R\n\n\n\n\n\n\n\n\n\n\n\n\nFunktion\nBeschreibung\n\n\n\n\nlm(y ~ x)\nEinfache lineare Regression mit einer abhängigen Variablen y und einem Prädiktor x.\n\n\nlm(y ~ x1 + x2)\nMultiple Regression mit einer abhängigen Variablen y und zwei Prädiktoren x1 und x2.\n\n\nsummary()\nGibt die Ergebnisse der Regressionsanalyse für ein Regressionsmodell aus.\n\n\nconfint()\nKonfidenzintervalle für die Regressionskoeffizienten.\n\n\nfitted()\nVorhergesagte Werte des Regressionsmodells.\n\n\nresid()\nResiduen des Regressionsmodells.\n\n\npredict()\nVorhergesagte Werte für bestimmte Werte der Prädiktorvariablen.\n\n\nanova()\nVergleicht die Determinationskoeffizienten zweier Regressionsmodelle mit einem F-Test.\n\n\nvif() *\nVariance Inflation Factors (VIF) für jeden Prädiktor; aus dem car-Paket.\n\n\n\n* aus zusätzlichen Paketen\n\n\n\n\nPaket „car“ installieren und laden.\n\n\n\nLoading required package: carData\n\n\n\nAttaching package: 'car'\n\n\nThe following object is masked from 'package:dplyr':\n\n    recode\n\n\nThe following object is masked from 'package:purrr':\n\n    some\n\n\n\nMach aus deiner davor berechneten Korrelation nun ein Regressionsmodel mit der Funktion model &lt;- lm(outcome ~ predictor, data). Schau dir den Output mit summary(model) an und versuche ihn zu interpretieren.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nmodel_1 &lt;- lm(mean_d1_all ~ mean_d_all, data = dat_full)\n\nsummary(model_1)\n\n\nCall:\nlm(formula = mean_d1_all ~ mean_d_all, data = dat_full)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-9.5963 -1.2404 -0.1045  1.0541  8.3688 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -6.49579    0.81643  -7.956  3.3e-13 ***\nmean_d_all   0.31750    0.01889  16.806  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.216 on 157 degrees of freedom\nMultiple R-squared:  0.6427,    Adjusted R-squared:  0.6404 \nF-statistic: 282.4 on 1 and 157 DF,  p-value: &lt; 2.2e-16\n\n\nMit summary(model_1) erhalten wir Informationen über das Regressionsmodell. Der Koeffizient für mean_d_all zeigt an, wie stark sich mean_d1_all ändert, wenn mean_d_all um eine Einheit steigt. Der p-Wert für diesen Koeffizienten ist signifikant (p &lt; 0.001), was darauf hinweist, dass mean_d_all Prädiktor signifikant zur Vorhersage der abhängigen Variable mean_d1_all beiträgt. Das R-Quadrat (R²) beträgt 0.64, was bedeutet, dass etwa 64% der Varianz in mean_d1_all durch mean_d_all erklärt wird.\nWie die folgende logische Abfrage zeigt, entspricht die Wurzel von R-Squared der Korrelation zwischen den beiden Variablen.\n\ncor(dat_full$mean_d1_all, dat_full$mean_d_all) == sqrt(summary(model_1)$r.squared)\n\n[1] TRUE\n\n\n\n\n\n\nErgänze das Modell nun um eine weitere Prädiktorvariable (mit + Variable), sodass du eine multiple Regression berechnest. Hier müssen wir auf Multikollinearität testen – mit vif(model) aus dem „car“ Paket (die Werte sollten größer als 0.10 sein, sodass keine Multikollinearität vorliegt). Berechne auch die Konfidenzintervalle der Beta-Koeffizienten mit confint(model).\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nmodel_2 &lt;- lm(mean_d1_all ~ mean_d_all + mean_rl_all, data = dat_full)\n\nsummary(model_2)\n\n\nCall:\nlm(formula = mean_d1_all ~ mean_d_all + mean_rl_all, data = dat_full)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.9478 -1.0924 -0.0321  0.7889  7.6809 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.22170    0.95106   0.233    0.816    \nmean_d_all   0.30716    0.01504  20.429   &lt;2e-16 ***\nmean_rl_all -1.20577    0.12494  -9.651   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.759 on 156 degrees of freedom\nMultiple R-squared:  0.7763,    Adjusted R-squared:  0.7734 \nF-statistic: 270.7 on 2 and 156 DF,  p-value: &lt; 2.2e-16\n\nvif(model_2)\n\n mean_d_all mean_rl_all \n   1.005097    1.005097 \n\nconfint(model_2)\n\n                 2.5 %     97.5 %\n(Intercept) -1.6569151  2.1003152\nmean_d_all   0.2774643  0.3368628\nmean_rl_all -1.4525580 -0.9589823\n\n\nMit summary(model_2) erhalten wir auch Informationen über das neue, multiple Regressionsmodell. Die Koeffizienten für mean_d_all und mean_rl_all zeigen an, wie stark sich mean_d1_all ändert, wenn diese Prädiktoren um eine Einheit steigen. Beide Prädiktoren haben signifikante p-Werte (p &lt; 0.001), was darauf hinweist, dass sie signifikant zur Vorhersage der abhängigen Variable beitragen. Das R-Quadrat (R²) beträgt 0.77, was bedeutet, dass etwa 77% der Varianz in mean_d1_all durch beide Prödiktoren zusammen erklärt wird.\nDie VIF-Werte für beide Prädiktoren sind unter 10, was darauf hinweist, dass keine Multikollinearität vorliegt.\nDie Konfidenzintervalle für die Koeffizienten geben den Bereich an, in dem wir mit 95%iger Sicherheit erwarten können, dass die wahren Koeffizientenwerte liegen. Beinhalten diese Konfidenzintervalle die 0 nicht, dann gelten die Koeffizienten ebenfalls als signifkant (unterschiedlich zu null).\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nFortgeschritten/Freiwillig:\nBerechne eine einfache logistische Regression zwischen Strategien (ohne strategies == 3) und Offloading (mean_rl_all) mit dem Wide Datensatz. Nimm das Statistik III Cheatsheet von Dr. Boris Mayer zur Hand. Tipp: Du musst die Strategien in 0 und 1 umkodieren.\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndat_log &lt;- dat_full |&gt; \n  filter(strategies != 3) |&gt;  # entferne Strategie 3\n  mutate(strategy_bin = if_else(strategies == 1, 0, 1)) # setze alle Strategien 1 auf 0 und 2 auf 1\n\nmodel &lt;- glm(strategy_bin ~ mean_rl_all, # hier soll das Offloading die Vorhersage der Strategiewahl übernehmen\n             data = dat_log,\n             family = binomial)\n\nsummary(model)\n\n\nCall:\nglm(formula = strategy_bin ~ mean_rl_all, family = binomial, \n    data = dat_log)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept)  -1.3090     0.8468  -1.546   0.1221  \nmean_rl_all   0.3325     0.1613   2.062   0.0392 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 196.19  on 145  degrees of freedom\nResidual deviance: 191.69  on 144  degrees of freedom\nAIC: 195.69\n\nNumber of Fisher Scoring iterations: 4\n\n\nEinmal mehr erhalten wir mit summary() informationen über das von uns gerechnete Modell. Der Koeffizient für mean_rl_all zeigt an, wie sich die Wahrscheinlichkeiten (Log-Odds) der Wahl von Strategie 2 (im Vergleich zu Strategie 1) ändern, wenn mean_rl_all um eine Einheit steigt. Der p-Wert für diesen Koeffizienten ist signifikant (p &lt; 0.05), was darauf hinweist, dass mean_rl_all signifikant zur Vorhersage der Strategiewahl beiträgt.",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 6 (Woche 11 - 12) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_6.html#t-tests-für-abhängige-stichproben",
    "href": "scripts/02_excercises/loesung_6.html#t-tests-für-abhängige-stichproben",
    "title": "Hands On – Analyze (Einheiten 11 und 12)",
    "section": "t-Tests für abhängige Stichproben",
    "text": "t-Tests für abhängige Stichproben\n\n\n\n\n\n\nTabelle: Funktionen für t-Tests und verwandte Analysen in R\n\n\n\n\n\n\n\n\n\n\n\n\nFunktion\nBeschreibung\n\n\n\n\nt.test\nAllgemeine Funktion für verschiedene t-Tests: Ein-Stichproben-t-Test, t-Test für unabhängige Stichproben und t-Test für abhängige Stichproben.\n\n\nt.test(av, mu = x)\nEin-Stichproben-t-Test. av = abhängige Variable. x = Vergleichswert der Population.\n\n\nt.test(av ~ uv)\nWelch-t-Test für unabhängige Stichproben. av = abhängige Variable, uv = Gruppenvariable.\n\n\nt.test(av ~ uv, var.equal = TRUE)\nKlassischer t-Test für unabhängige Stichproben (Varianzen vorausgesetzt gleich).\n\n\nt.test(av1, av2, paired = TRUE)\nt-Test für abhängige Stichproben (z. B. Prä–Post). av1 und av2 = gemessene Variablen.\n\n\nleveneTest(av, uv) *\nLevene-Test auf Varianzhomogenität für unabhängige Gruppen. Aus dem car-Paket.\n\n\neffsize::cohen.d() *\nBerechnet die standardisierte Effektgröße Cohen’s d + Konfidenzintervall. Aus dem effsize-Paket.\n\n\n\n* Funktionen aus zusätzlichen Paketen.\n\n\n\n\nPaket „effsize“ installieren und laden.\n\n\nWir wollen einen t-Test für unabhängige Stichproben durchführen, um das Pre 4 Rating der „above“ und „below“ Gruppen zu vergleichen. Starte mit einem leveneTest() aus dem „car“ Paket um die Varianzhomogenität zu prüfen. Tipp: Filtere die Daten, sodass nur die beiden Gruppen „above“ und „below“ beinhaltet sind (d.h. ohne die Gruppe „control“).\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndat_full_below_above &lt;- dat_full |&gt; \n  filter(group_all != \"control\")\n\ndat_full_below_above$group_all &lt;- as.factor(dat_full_below_above$group_all)\n\nleveneTest(dat_full_below_above$pre4, dat_full_below_above$group_all)\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value Pr(&gt;F)  \ngroup   1  2.8442 0.0947 .\n      104                 \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nDer Levene Test prüft die Homogenität der Varianzen zwischen den Gruppen. Ein nicht-signifikanter p-Wert (p &gt; 0.05) deutet darauf hin, dass die Varianzen in den beiden Gruppen als gleich angenommen werden können. Der vorliegende Test ist nicht signifikant (p = 0.09 &gt; 0.05), was darauf hinweist, dass die Varianzen in den Gruppen „above“ und „below“ als homogen betrachtet werden können.\n\n\n\n\nBerechne nun den entsprechenden t-Test mit t.test(). Du kannst auch die Hilfefunktion zu Rate ziehen. Versuche dann den Output zu verstehen bzw. das Ergebnis zu interpretieren. Tipp: Wenn die Varianzhomogenität gegeben ist (d.h. der Levene Test nicht signifikant ist), muss man var.equal = TRUE angeben, ansonsten wird ein Welch t-Test berechnet.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nt.test(pre4 ~ group_all, data = dat_full_below_above, var.equal = TRUE)\n\n\n    Two Sample t-test\n\ndata:  pre4 by group_all\nt = 7.9845, df = 104, p-value = 1.991e-12\nalternative hypothesis: true difference in means between group above and group below is not equal to 0\n95 percent confidence interval:\n 2.025170 3.363509\nsample estimates:\nmean in group above mean in group below \n           5.966038            3.271698 \n\n\nDer students t-Test vergleicht die Mittelwerte der pre4 Ratings zwischen den Gruppen „above“ und „below“. Der p-Wert weisst auf einen statistisch signifikanten Unterschied der beiden Mittelwerte hin (p &lt; 0.05). Das 95%-Konfidenzintervall für den Mittelwertunterschied liegt zwischen 2.03 und 3.36. Das dieser Bereich nicht die 0 beinhaltet spricht ebenfalls für die Signifikanz der Mittelwertsunterschiede. Unter Einbezug der beiden Gruppenmittelwerte (mean in group above = 5.97 und mean in group below 3.27) deutet das Ergebnis darauf hin, dass die „above“ Gruppe signifikant höhere pre4 Ratings aufweist als die „below“ Gruppe.\n\n\n\n\nNun berechnen wir noch Cohen‘s d als Effektstärken-Maß für den Mittelwertsunterschied. Verwende dafür effsize::cohen.d().  Da es „cohen.D“ auch im Paket „psych“ gibt, ist es wichtig hier „effsize::“ voranzusetzen.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\neffsize::cohen.d(pre4 ~ group_all, data = dat_full_below_above)\n\n\nCohen's d\n\nd estimate: 1.551045 (large)\n95 percent confidence interval:\n   lower    upper \n1.111706 1.990383 \n\n\nCohen’s d beträgt 1.55, was auf einen großen Effekt hinweist.\n\n\n\n👉 Und schon haben wir einen der Post-Hoc t-Tests für die 2x3 ANOVA aus Grinschgl et al. (2020) berechnet (notwendig für die Abschlussarbeit)",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 6 (Woche 11 - 12) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_6.html#t-tests-für-abhängige-stichproben-1",
    "href": "scripts/02_excercises/loesung_6.html#t-tests-für-abhängige-stichproben-1",
    "title": "Hands On – Analyze (Einheiten 11 und 12)",
    "section": "t-Tests für abhängige Stichproben",
    "text": "t-Tests für abhängige Stichproben\n\nBerechne einen t-Test für abhängige Stichproben um in der „control“ Gruppe Pre 1 und Pre 4 zu vergleichen. (D.h. filtere zunächst den Datensatz, sodass nur mehr die „control“ Gruppe\n\n\nt.test(datensatz$Variable1, datensatz$Variable2, paired = TRUE) \n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndat_full_control &lt;- dat_full |&gt;\n  filter(group_all == \"control\")\n\nt.test(dat_full$pre1, dat_full$pre4, paired = TRUE)\n\n\n    Paired t-test\n\ndata:  dat_full$pre1 and dat_full$pre4\nt = 4.2727, df = 158, p-value = 3.325e-05\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 0.3906256 1.0622046\nsample estimates:\nmean difference \n      0.7264151 \n\n\nDer t-Test für abhängige Stichproben (paired = TRUE) vergleicht die Mittelwerte von pre1 und pre4 innerhalb der „control“ Gruppe. Der p-Wert weisst auf einen signifikanten Unterschied zwischen den Mittelwerten dieser beiden Messzeitpunkte hin (p &lt; 0.05). Das 95%-Konfidenzintervall für den Mittelwertunterschied liegt zwischen 0.39 und 1.06, umschliesst damit nicht die 0, und zeigt dadurch ebenfalls einen signifikanten Mittelwertsunterschied zwsichen den beiden Messzeitpunkten an. Die Angabe mean_difference zeigt an, wie stark der Mittelwert von pre1 auf pre4angestiegen ist (mean difference = 0.73).\n\n\n\n\nWandle den t-Test nun in einen einseitigen Test mit alternative = „greater“ oder alternative = „less“ um und berechne Cohen‘s d als Effektstärkenmaß (Achtung: paired = True setzen).\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nt.test(dat_full$pre1, dat_full$pre4, paired = TRUE, alternative = \"greater\")\n\n\n    Paired t-test\n\ndata:  dat_full$pre1 and dat_full$pre4\nt = 4.2727, df = 158, p-value = 1.663e-05\nalternative hypothesis: true mean difference is greater than 0\n95 percent confidence interval:\n 0.4451208       Inf\nsample estimates:\nmean difference \n      0.7264151 \n\nlibrary(effectsize)\n\nRegistered S3 methods overwritten by 'parameters':\n  method                           from      \n  display.parameters_distribution  datawizard\n  plot.parameters_distribution     datawizard\n  print_md.parameters_distribution datawizard\n\ncohens_d(\n  dat_full$pre1,\n  dat_full$pre4,\n  paired = TRUE\n)\n\nFor paired samples, 'repeated_measures_d()' provides more options.\n\n\nCohen's d |       95% CI\n------------------------\n0.34      | [0.18, 0.50]\n\n\nWährend der ungerichtete t-test prüft, ob die Mittelwerte von pre1 und pre4 ungleich sind, prüft der gerichtete t-test (alternative = “greater”) spezifischer, ob der Mittelwert von pre4 signifikant größer ist als der Mittelwert von pre1. Dies ist auch am Ergebnis “alternative hypothesis: true mean difference is greather than 0” erkennen. Der Unterschied im mean_difference ist allerdings gleich geblieben, ebenso das Resultat der Signifikanzprüfung.",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 6 (Woche 11 - 12) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_7.html",
    "href": "scripts/02_excercises/loesung_7.html",
    "title": "Hands On – Analyze (Einheiten 11 und 12)",
    "section": "",
    "text": "Bei Bedarf findest du hier nochmals die Slides zu Einheit 13:",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 7 (Woche 13)"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_7.html#einfaktorielle-anova",
    "href": "scripts/02_excercises/loesung_7.html#einfaktorielle-anova",
    "title": "Hands On – Analyze (Einheiten 11 und 12)",
    "section": "Einfaktorielle ANOVA",
    "text": "Einfaktorielle ANOVA\n\nBerechne eine einfaktorielle ANOVA mit aov_4 (aus dem Paket “afex”) für die Offloading-Variable mean_rl_all (Öffnungen des Modelfensters).\nBerechnet dafür zuerst den Levene-Test um die Varianzhomogenität des between-Faktors zu überprüfen.\n\n::: {.callout-note collapse=“true” title = “Lösung”}\n\nleveneTest(mean_rl_all ~ group_all, data= dat_full)\n\nWarning in leveneTest.default(y = y, group = group, ...): group coerced to\nfactor.\n\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value Pr(&gt;F)\ngroup   2  0.6889 0.5036\n      156               \n\n\nDer Levene-Test ist nicht signifikant (p &gt; 0.05). Somit ist die Varianzhomogenität, als eine der Vorausetzungen zur Berechnung der ANOVA, gegeben.\n:::\n\nDefiniere die ANOVA nach der folgenden Vorlage\n\n\nmodel_1 &lt;- aov_4(AV ~ Faktor_1 + (1 | ID), data = data)\n\nsummary(model_1)\n\n::: {.callout-note collapse=“true” title = “Lösung”}\n\nmodel_1 &lt;- aov_4(mean_rl_all ~ group_all + (1 | code), data = dat_full)\n\nConverting to factor: group_all\n\n\nContrasts set to contr.sum for the following variables: group_all\n\nsummary(model_1)\n\nAnova Table (Type 3 tests)\n\nResponse: mean_rl_all\n          num Df den Df    MSE      F      ges Pr(&gt;F)\ngroup_all      2    156 1.2602 1.0448 0.013218 0.3542\n\n\n:::\n\nVersuche das Ergbenis zu interpretieren und mit dem Grinschgl et al. (2021) Paper zu vergleichen. 👉 Und schon haben wir ein ANOVAs für die Offloading Variablen berechnet.\n\n::: {.callout-note collapse=“true” title = “Lösung”}\nDie ANOVA ist nicht signifikant (p &gt; 0.05) – es gibt also keine Unterschiede in den Offloadinghäufigkeiten zwischen den Gruppen.\n:::\n\nBerechne die Effektstärken partielles η² und generalisiertes η² . Ergänze dafür die aov_4 Funktion um anova_table = list(es = c(\"ges\" ,\"pes\")) . Lasse dir das Ergebnis mit model$anova_table ausgeben. Bei einfaktoriellen ANOVAs sind die partiellen und generalisierten η² identisch.\n\n::: {.callout-note collapse=“true” title = “Lösung”}\n\nmodel_1 &lt;- aov_4(mean_rl_all ~ group_all + (1 | code), data = dat_full, anova_table = list(es = c(\"ges\" ,\"pes\")))\n\nConverting to factor: group_all\n\n\nContrasts set to contr.sum for the following variables: group_all\n\nmodel_1$anova_table\n\nAnova Table (Type 3 tests)\n\nResponse: mean_rl_all\n          num Df den Df    MSE      F      pes      ges Pr(&gt;F)\ngroup_all      2    156 1.2602 1.0448 0.013218 0.013218 0.3542\n\n\nDas partielle Eta² und das generalisierte Eta² sind identisch und betragen 0.01, was auf einen sehr kleinen Effekt hinweist. Die Gruppenzugehörigkeit kann also nur wenig Varianz des Offloadingverhalten erklären. Dies hat sich auch in der ANOVA gezeigt, bei welcher die Gruppierungsvariable aufgrund geringer Varianzerklärung nicht signifikant wurde.\n:::",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 7 (Woche 13)"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_7.html#post-hoc-t-tests",
    "href": "scripts/02_excercises/loesung_7.html#post-hoc-t-tests",
    "title": "Hands On – Analyze (Einheiten 11 und 12)",
    "section": "Post-hoc t-Tests",
    "text": "Post-hoc t-Tests\nZu Übungszwecken, inhaltlich nicht notwendig wenn die ANOVA nicht signifikant ist.\n\nLade das Package emmeans\n\n\n\nSpeichere mit new_object &lt;- emmeans(object = model, specs = ~group_all) die Mittelwerte und Standardfehler in einem neuen Objekt.\n\n::: {.callout-note collapse=“true” title = “Lösung”}\n\nnew_object &lt;- emmeans(object = model_1, specs = ~ group_all)\nnew_object\n\n group_all emmean    SE  df lower.CL upper.CL\n above       5.10 0.154 156     4.79     5.40\n below       5.39 0.154 156     5.09     5.69\n control     5.14 0.154 156     4.84     5.45\n\nConfidence level used: 0.95 \n\n\n:::\n\nBerechne mit pairs(new_object) multiple t-Tests als Post-Hoc Tests. Diese werden als default-Einstellung mit der Tukey-Methodekorrigiert. Das ist eine Alternative zu einzelnen t-Tests in Grinschgl et al. (2021) so wie in EH12 berechnet - ergibt leicht andere Werte wegen Tukey-Korrektur für multiples Testen. (Für das Abschlussprojekt sind Post-Hoc Tests in beiden Varianten okay – entweder mit emmeans() oder mit t.test() ).\n\n::: {.callout-note collapse=“true” title = “Lösung”}\n\npairs(new_object)\n\n contrast        estimate    SE  df t.ratio p.value\n above - below    -0.2925 0.218 156  -1.341  0.3747\n above - control  -0.0443 0.218 156  -0.203  0.9775\n below - control   0.2481 0.218 156   1.138  0.4924\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\nDie einzelnen post-hoc Tests zeigen keine signifikanten Unterschiede zwischen den jeweiligen Gruppen (alle p-Werte &gt; 0.05). Auch dieses Resultat war zu erwarten, da ja schon der globale Test mit der ANOVA keinerlei Unterschiede zwischen irgendwelchen Gruppen signalisiert hat.\n:::\n\n\n\n\n\n\nTukey-Korrektur\n\n\n\n\n\nDie Tukey-Korrektur ist ein simultanes Verfahren für Post-hoc-Gruppenvergleiche, das verhindert, dass sich der Alpha-Fehler durch viele t-Tests (familywise error rate) aufsummiert. Sie wird bevorzugt eingesetzt, wenn alle Gruppen miteinander verglichen werden sollen.\n::: {.callout-note collapse=“true” title = “Lösung”}\n\npairs(new_object)\n\n contrast        estimate    SE  df t.ratio p.value\n above - below    -0.2925 0.218 156  -1.341  0.3747\n above - control  -0.0443 0.218 156  -0.203  0.9775\n below - control   0.2481 0.218 156   1.138  0.4924\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\nAuch hier zeigen die post-hoc Tests keine signifikanten Unterschiede zwischen den jeweiligen Gruppen (alle p-Werte &gt; 0.05).\n\n\n\n:::\n\n\n\n\n\n\nFortgeschritten - Effektstärken mit pairs()\n\n\n\n\n\nDer Befehl pairs() berechnet nicht automatisch die gewünschten Effektstärken (zum Beispiel Cohen’s d). Die Effektstärken können entweder einzeln wie in den Übungen zu EH 12 berechnet werden, etwa mit cohens_d(). Wenn man jedoch die Effektstärken aller Paarvergleiche simultan berechnen möchte, kann man dies mit eff_size() tun. Dafür greift man auf die Residualvarianzen und Freiheitsgrade des ANOVA-Modells zu. Diese Informationen sind im lm-Objekt des Modells gespeichert. Unten siehst du ein Codebeispiel:\n\nposthoc_tests &lt;- emmeans(object = model_1, specs = ~ group_all)\n\neff_size(\n  posthoc_tests,\n  sigma = sigma(model_1$lm),\n  edf   = df.residual(model_1$lm)\n)\n\n contrast        effect.size    SE  df lower.CL upper.CL\n above - below       -0.2605 0.195 156   -0.645    0.124\n above - control     -0.0395 0.194 156   -0.423    0.344\n below - control      0.2210 0.195 156   -0.163    0.606\n\nsigma used for effect sizes: 1.123 \nConfidence level used: 0.95 \n\n\nZum Vergleich: Mit cohens_d()\n\ndat_full_above_below &lt;- dat_full |&gt;\n  filter(group_all != \"control\")\n\ndat_full_above_below$group_all &lt;- factor(dat_full_above_below$group_all )\n\ncohens_d(mean_rl_all ~ group_all, data = dat_full_above_below)\n\nCohen's d |        95% CI\n-------------------------\n-0.25     | [-0.63, 0.13]\n\n- Estimated using pooled SD.\n\n\nDie Effektstärken unterscheiden sich hier leicht da nicht mit den exakt gleichen Varianzen gerechnet wird, effsize() verwendet hierfür die die modellbasierten SDs, während cohens_d() die gepoolte Standardabweichung aus den Rohdaten verwendet. Dieser Unterschied kann jedoch vernachlässigt werden.",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 7 (Woche 13)"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_7.html#x3-mixed-anova-mit-messwiederholung",
    "href": "scripts/02_excercises/loesung_7.html#x3-mixed-anova-mit-messwiederholung",
    "title": "Hands On – Analyze (Einheiten 11 und 12)",
    "section": "2x3 Mixed ANOVA mit Messwiederholung",
    "text": "2x3 Mixed ANOVA mit Messwiederholung\n\nDefiniere das 2x3 ANOVA Model aus Grinschgl et al. (2021), nach folgendem Muster - hierfür benötigen wir den Long Datensatz!\n\n\nmixed_anova &lt;- aov_4(AV ~ between_factor + (messwiederholter_faktor | ID) data = df_long)\n\n::: {.callout-note collapse=“true” title = “Lösung”}\n\nmixed_anova &lt;- aov_4(rating ~ group_all + (time_rating | code), data = dat_long)\n\nConverting to factor: group_all\n\n\nContrasts set to contr.sum for the following variables: group_all\n\nsummary(mixed_anova)\n\n\nUnivariate Type III Repeated-Measures ANOVA Assuming Sphericity\n\n                      Sum Sq num Df Error SS den Df  F value    Pr(&gt;F)    \n(Intercept)           8198.9      1   500.58    156 2555.113 &lt; 2.2e-16 ***\ngroup_all              126.7      2   500.58    156   19.736 2.286e-08 ***\ntime_rating             42.0      1   288.70    156   22.668 4.364e-06 ***\ngroup_all:time_rating   74.4      2   288.70    156   20.090 1.724e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n:::\n\nErgänze den Code wie vorher um anova_table um dir die Effektstärken partielles η² und generalisiertes η² ausgeben zu lassen.\n\n::: {.callout-note collapse=“true” title = “Lösung”}\n\nmixed_anova &lt;- aov_4(rating ~ group_all + (time_rating | code), data = dat_long, anova_table = list(es = c(\"ges\" ,\"pes\")))\n\nConverting to factor: group_all\n\n\nContrasts set to contr.sum for the following variables: group_all\n\nsummary(mixed_anova)\n\n\nUnivariate Type III Repeated-Measures ANOVA Assuming Sphericity\n\n                      Sum Sq num Df Error SS den Df  F value    Pr(&gt;F)    \n(Intercept)           8198.9      1   500.58    156 2555.113 &lt; 2.2e-16 ***\ngroup_all              126.7      2   500.58    156   19.736 2.286e-08 ***\ntime_rating             42.0      1   288.70    156   22.668 4.364e-06 ***\ngroup_all:time_rating   74.4      2   288.70    156   20.090 1.724e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmixed_anova$anova_table\n\nAnova Table (Type 3 tests)\n\nResponse: rating\n                      num Df den Df    MSE      F     pes      ges    Pr(&gt;F)\ngroup_all                  2    156 3.2088 19.736 0.20193 0.138283 2.286e-08\ntime_rating                1    156 1.8507 22.668 0.12687 0.050468 4.364e-06\ngroup_all:time_rating      2    156 1.8507 20.090 0.20481 0.086102 1.724e-08\n                         \ngroup_all             ***\ntime_rating           ***\ngroup_all:time_rating ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n:::\n\nIn Grinschgl et al. (2021) wird jedoch nur das reine η² berichtet (weder generalisiert noch partiell). Wende eta_squared() auf dem package effectsize auf dein ANOVA Model an und setze partial = FALSE.\n\n::: {.callout-note collapse=“true” title = “Lösung”}\n\nmixed_anova &lt;- aov_4(rating ~ group_all + (time_rating | code), data = dat_long, anova_table = list(es = c(\"ges\" ,\"pes\")))\n\nConverting to factor: group_all\n\n\nContrasts set to contr.sum for the following variables: group_all\n\neta_squared(mixed_anova, partial = FALSE)\n\n# Effect Size for ANOVA (Type III)\n\nParameter             | Eta2 |       95% CI\n-------------------------------------------\ngroup_all             | 0.12 | [0.05, 1.00]\ntime_rating           | 0.04 | [0.01, 1.00]\ngroup_all:time_rating | 0.07 | [0.02, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].\n\n\n:::\n\nVersuche das Ergebnis dieser ANOVA zu interpretieren und mit Grinschgl et al. (2021) zu vergleichen.\n\n::: {.callout-note collapse=“true” title = “Lösung”}\nDie Resultate der von uns gerechneten ANOVA und der in Grinschgl et al. (2021) berichteten ANOVA stimmen überein. Es gibt signifikante Haupteffekte für den Between-Faktor group_all (p &lt; 0.05, η² = 0.12), den Within-Faktor time_rating (p &lt; 0.05, η² = 0.04) und die Interaktion beider Variablen group_all:time_rating (p &lt; 0.05, η² = 0.07). Es gibt somit Unterschiede im rating zwischen Gruppen, Unterschiede über die Gruppen hinweg zwischen verschiedenen Zeitpunkten, und diese Unterschiede zwischen Gruppen entwickeln sich im Verlaufe der Zeit auch noch unterschiedlich. Die Effektstärken deuten auf kleine bis mittlere Effekte hin.\n:::",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 7 (Woche 13)"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_7.html#x3-mixed-anova---post-hoc-t-tests",
    "href": "scripts/02_excercises/loesung_7.html#x3-mixed-anova---post-hoc-t-tests",
    "title": "Hands On – Analyze (Einheiten 11 und 12)",
    "section": "2x3 Mixed ANOVA - Post-Hoc t-Tests",
    "text": "2x3 Mixed ANOVA - Post-Hoc t-Tests\n\n2 x 3 mixed ANOVA mit Messwiederholung Post-Hoc Tests: emmeans() Objekt erstellen nach folgender Vorlage:\n\n\nresults &lt;- emmeans(object = my_anova, specs = ~ within_factor * between_factor)\n\n::: {.callout-note collapse=“true” title = “Lösung”}\n\nresults &lt;- emmeans(object = mixed_anova, specs = ~ time_rating * group_all)\n\n:::\n\npairs() darauf anwenden – hier wollen wir mit simple = „group_all“ Post-Hoc Tests für die Gruppenvergleiche zu den beiden Zeitpunkten berechnen. 👉 Berechnung von bedingten Mittelwertsunterschieden so wie im Grinschgl et al. (2021) Paper (aber dort leicht andere Werte wegen anderer Berechnungsfunktion)\n\n::: {.callout-note collapse=“true” title = “Lösung”}\n\npairs(results, simple = \"group_all\")\n\ntime_rating = pre1:\n contrast        estimate    SE  df t.ratio p.value\n above - below     0.3962 0.270 156   1.466  0.3103\n above - control   0.4094 0.270 156   1.514  0.2869\n below - control   0.0132 0.270 156   0.049  0.9987\n\ntime_rating = pre4:\n contrast        estimate    SE  df t.ratio p.value\n above - below     2.6943 0.343 156   7.849  &lt;.0001\n above - control   1.0604 0.343 156   3.089  0.0067\n below - control  -1.6340 0.343 156  -4.760  &lt;.0001\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\n:::\n\nÄndere es nun auf simple = time_rating ab und schaue dir den Unterschied zum vorherigen Ergebnis an.\n\n::: {.callout-note collapse=“true” title = “Lösung”}\n\npairs(results, simple = \"time_rating\")\n\ngroup_all = above:\n contrast    estimate    SE  df t.ratio p.value\n pre1 - pre4   -0.257 0.264 156  -0.971  0.3330\n\ngroup_all = below:\n contrast    estimate    SE  df t.ratio p.value\n pre1 - pre4    2.042 0.264 156   7.725  &lt;.0001\n\ngroup_all = control:\n contrast    estimate    SE  df t.ratio p.value\n pre1 - pre4    0.394 0.264 156   1.492  0.1377\n\n\nHier werden die Mittelwertsunterschiede für die Messzeitpunkte innerhalb der jeweiligen Gruppen berechnet. In der control Gruppe gibt es keinen signifikanten Unterschiede zwischen den Zeitpunkten (p &gt; 0.05). In der above Gruppe gibt es ebenfalls keinen signifikanten Unterschied zwischen den Zeitpunkten (p &gt; 0.05), Innerhalb der Gruppe below gibt es allerdings einen signifikanten Unterschied zwischen den beiden Messzeitpunkten (p &lt; 0.05). Die Gruppen entwickeln sich also über die Messzeitpunkte hinweg unterschiedlich. Dies entspricht der oben gefundenen Interaktion zwischen group_all:time_rating. Die Resultate müssen allerdings mit Vorsicht interpretiert werden, da diese noch nicht für das multiple testen angepasst wurden und die p-Werte sich im Anschluss noch (signifikant) verändern könnten.\n:::\n\nErgänze nun die Bonferroni Korrektur für multiples Testen mit adjust = „bonferroni“\n\n::: {.callout-note collapse=“true” title = “Lösung”}\n\npairs(results, simple = \"group_all\", adjust = \"bonferroni\")\n\ntime_rating = pre1:\n contrast        estimate    SE  df t.ratio p.value\n above - below     0.3962 0.270 156   1.466  0.4343\n above - control   0.4094 0.270 156   1.514  0.3958\n below - control   0.0132 0.270 156   0.049  1.0000\n\ntime_rating = pre4:\n contrast        estimate    SE  df t.ratio p.value\n above - below     2.6943 0.343 156   7.849  &lt;.0001\n above - control   1.0604 0.343 156   3.089  0.0071\n below - control  -1.6340 0.343 156  -4.760  &lt;.0001\n\nP value adjustment: bonferroni method for 3 tests \n\n\nDie paarweisen Vergleiche gelten jeweils für alle möglichen Gruppenpaare für die beiden Zeitpunkte time_rating = pre1 und time_rating = pre4. Zum Zeitpunkt pre1 gibt es noch keinerlei signifikante Gruppenunterschiede (alle p-Werte &gt; 0.05). Zum Zeitpunkt pre4 unterscheiden sich dann allerdings alle Gruppen voneinander (alle p-Werte &lt; 0.05). Dies entspricht dem zuvor gefundenen Haupteffekt des Faktors time_rating.\n:::\n\n\n\n\n\n\nImportant\n\n\n\nAchtung: Die pairs() Funktion gibt keine Effektstärken aus. Diese müssen für die 2x3 ANOVA mit der cohens_d() Funktion berechnet werden wie wir das bereits in Hands On 6 geübt haben.",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 7 (Woche 13)"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_4.html",
    "href": "scripts/02_excercises/loesung_4.html",
    "title": "Hands On – Tidy & Transform (Einheiten 7 und 8)",
    "section": "",
    "text": "Bei Bedarf findest du hier nochmals die Slides zu Einheit 7:",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 4 (Woche 7- 8) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_4.html#filter",
    "href": "scripts/02_excercises/loesung_4.html#filter",
    "title": "Hands On – Tidy & Transform (Einheiten 7 und 8)",
    "section": "filter()",
    "text": "filter()\n\nÜbungen zu filter()\nDiese Aufgaben helfen dir, den Umgang mit dplyr-Funktionen wie filter() und select() zu üben.\nDer Datensatz heißt dat_full und enthält 159 Zeilen und 36 Variablen. Stelle sicher, dass du diesen geladen hast.\nReminder: Verwende die logischen Operatoren, die wir in Hands On 1 kennengelernt haben.\n\n\n\nZeichen\nBedeutung\n\n\n\n\n==\ngleich\n\n\n!=\nungleich\n\n\n&gt;\ngrösser\n\n\n&gt;=\ngrösser gleich\n\n\n&lt;\nkleiner\n\n\n&lt;=\nkleiner gleich\n\n\n|\nLogisches Oder\n\n\n&\nLogisches Und\n\n\n\n\nErste Schritte mit Filter\n\nWähle alle Teilnehmenden aus, die in der Gruppe \"above\" sind.\nWähle alle Teilnehmenden aus, die mehr als 0.7 in cvstm_propcorrect erreicht haben.\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndat_full_filtered_above &lt;- dat_full |&gt;  \n  filter(group_all == \"above\")\n\ndat_full_filtered_cvstm_07 &lt;- dat_full |&gt;  \n  filter(cvstm_propcorrect &gt; 0.7)\n\n\n\n\n\nKombinierte Filter: Nutze die Pipe um beide Filter nacheinander auszuführen.\n\nFiltere alle, die gleichzeitig in der Gruppe below sind UND weniger als 0.6 in vp_propcorrect haben.\nWähle alle Fälle aus, deren strategies größer oder gleich 2 sind oder deren Wert in mean_rl_all nicht gleich 4.5 ist.\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndat_full_combined_filters &lt;- dat_full |&gt;  \n  filter(group_all == \"below\", vp_propcorrect &lt; 0.6) |&gt;  \n  filter(strategies &gt;= 2 | mean_rl_all != 4.5)",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 4 (Woche 7- 8) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_4.html#select",
    "href": "scripts/02_excercises/loesung_4.html#select",
    "title": "Hands On – Tidy & Transform (Einheiten 7 und 8)",
    "section": "select()",
    "text": "select()\n\nÜbungen zu select()\n\nWähle die Variablen (bzw. Spalten) code, group_all, vp_sum und cvstm_propcorrect aus dat_full aus\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nselect(dat_full, c(code, group_all, vp_sum, cvstm_propcorrect))\n\n# A tibble: 159 × 4\n    code group_all vp_sum cvstm_propcorrect\n   &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;             &lt;dbl&gt;\n 1     1 above         33             0.583\n 2     2 control       27             0.608\n 3     3 below         33             0.775\n 4     4 below         31             0.692\n 5     5 above         32             0.658\n 6     6 control       24             0.6  \n 7     7 control       28             0.783\n 8     8 below         27             0.708\n 9     9 above         28             0.6  \n10    10 below         26             0.75 \n# ℹ 149 more rows\n\n\n\n\n\n\n\nKombination von filter() und select()\n\nWähle alle Personen aus der Gruppe “above” aus, die mehr als 0.8 in vp_propcorrect haben,\nund zeige nur code, group_all, vp_sum, vp_propcorrect an.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndat_full |&gt;  \n  filter(group_all == \"above\", vp_propcorrect &gt; 0.8) |&gt;  \n  select(code, group_all, vp_sum, vp_propcorrect)\n\n# A tibble: 40 × 4\n    code group_all vp_sum vp_propcorrect\n   &lt;dbl&gt; &lt;chr&gt;      &lt;dbl&gt;          &lt;dbl&gt;\n 1     1 above         33          0.917\n 2     5 above         32          0.889\n 3    15 above         34          0.944\n 4    24 above         31          0.861\n 5    27 above         31          0.861\n 6    30 above         31          0.861\n 7    31 above         35          0.972\n 8    36 above         35          0.972\n 9    39 above         33          0.917\n10    41 above         31          0.861\n# ℹ 30 more rows",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 4 (Woche 7- 8) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_4.html#rename",
    "href": "scripts/02_excercises/loesung_4.html#rename",
    "title": "Hands On – Tidy & Transform (Einheiten 7 und 8)",
    "section": "rename()",
    "text": "rename()\n\nBenenne die Variable group_all in group um, indem du die Funktion rename() verwendest; achte dabei darauf, dass der neue Name zuerst angegeben wird.\nAnmerkung: je nachdem wie du deine Daten gemerged hast, heisst die Variable bereits “group”. Dann ist dieser Schritt nicht notwendig.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndat_full &lt;- rename(dat_full, group = group_all)",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 4 (Woche 7- 8) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_4.html#mutate",
    "href": "scripts/02_excercises/loesung_4.html#mutate",
    "title": "Hands On – Tidy & Transform (Einheiten 7 und 8)",
    "section": "mutate()",
    "text": "mutate()\nNur für Übungszwecke: Erstelle eine neue Spalte aus der Variable group. Aus above soll EG1, aus below EG2 und aus control KG werden. Verwende dafür eine Kombination aus case_when() (oder recode()) und mutate()\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndat_full |&gt; \n  mutate(\n    group_new = case_when(\n      group == \"above\"   ~ \"EG1\",\n      group == \"below\"   ~ \"EG2\",\n      group == \"control\" ~ \"KG\"\n    )\n  )\n\n# A tibble: 159 × 37\n    code question1 question2 question3 question4 question5 question6 question7\n   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1     1         2         3         3         3         2         3         3\n 2     2         3         4         3         4         3         3         3\n 3     3         2         3         2         1         2         2         2\n 4     4         1         2         2         3         1         2         2\n 5     5         3         4         4         2         4         4         4\n 6     6         1         3         3         4         3         3         3\n 7     7         1         3         3         1         2         2         0\n 8     8         1         2         3         3         2         1         2\n 9     9         2         3         3         3         3         3         3\n10    10         1         4         4         4         3         4         4\n# ℹ 149 more rows\n# ℹ 29 more variables: question8 &lt;dbl&gt;, question9 &lt;dbl&gt;, question10 &lt;dbl&gt;,\n#   question11 &lt;dbl&gt;, question12 &lt;dbl&gt;, question13 &lt;dbl&gt;, question14 &lt;dbl&gt;,\n#   question15 &lt;dbl&gt;, question16 &lt;dbl&gt;, question17 &lt;dbl&gt;, question18 &lt;dbl&gt;,\n#   vp_sum &lt;dbl&gt;, vp_propcorrect &lt;dbl&gt;, cb_sum &lt;dbl&gt;, cb_propcorrect &lt;dbl&gt;,\n#   csvtm_sum &lt;dbl&gt;, cvstm_propcorrect &lt;dbl&gt;, strategies &lt;dbl&gt;, pre1 &lt;dbl&gt;,\n#   pre2 &lt;dbl&gt;, pre3 &lt;dbl&gt;, pre4 &lt;dbl&gt;, post &lt;dbl&gt;, group &lt;chr&gt;, …\n\n# oder alternativ mit recode()\ndat_full |&gt;\n  mutate(\n    group_new = recode(\n      group,\n      \"above\"   = \"EG1\",\n      \"below\"   = \"EG2\",\n      \"control\" = \"KG\"\n    )\n  )\n\n# A tibble: 159 × 37\n    code question1 question2 question3 question4 question5 question6 question7\n   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1     1         2         3         3         3         2         3         3\n 2     2         3         4         3         4         3         3         3\n 3     3         2         3         2         1         2         2         2\n 4     4         1         2         2         3         1         2         2\n 5     5         3         4         4         2         4         4         4\n 6     6         1         3         3         4         3         3         3\n 7     7         1         3         3         1         2         2         0\n 8     8         1         2         3         3         2         1         2\n 9     9         2         3         3         3         3         3         3\n10    10         1         4         4         4         3         4         4\n# ℹ 149 more rows\n# ℹ 29 more variables: question8 &lt;dbl&gt;, question9 &lt;dbl&gt;, question10 &lt;dbl&gt;,\n#   question11 &lt;dbl&gt;, question12 &lt;dbl&gt;, question13 &lt;dbl&gt;, question14 &lt;dbl&gt;,\n#   question15 &lt;dbl&gt;, question16 &lt;dbl&gt;, question17 &lt;dbl&gt;, question18 &lt;dbl&gt;,\n#   vp_sum &lt;dbl&gt;, vp_propcorrect &lt;dbl&gt;, cb_sum &lt;dbl&gt;, cb_propcorrect &lt;dbl&gt;,\n#   csvtm_sum &lt;dbl&gt;, cvstm_propcorrect &lt;dbl&gt;, strategies &lt;dbl&gt;, pre1 &lt;dbl&gt;,\n#   pre2 &lt;dbl&gt;, pre3 &lt;dbl&gt;, pre4 &lt;dbl&gt;, post &lt;dbl&gt;, group &lt;chr&gt;, …",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 4 (Woche 7- 8) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_4.html#summarize",
    "href": "scripts/02_excercises/loesung_4.html#summarize",
    "title": "Hands On – Tidy & Transform (Einheiten 7 und 8)",
    "section": "summarize()",
    "text": "summarize()\nDich interessieren der Durchschnitt (mean) und die Standardabweichung (sd) der Variable mean_e1_all. Du möchtest diese Werte jedoch nicht zu dat_full hinzufügen, sondern als Zusammenfassung in einem neuen Objekt speichern.\nNutze dafür die Funktion summarize().\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsummary_e1_all &lt;- dat_full |&gt;\n  summarize(\n    mean_e1 = mean(mean_e1_all, na.rm = TRUE),\n    sd_e1   = sd(mean_e1_all, na.rm = TRUE)\n  )\n\nsummary_e1_all\n\n# A tibble: 1 × 2\n  mean_e1 sd_e1\n    &lt;dbl&gt; &lt;dbl&gt;\n1    3.26 0.687",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 4 (Woche 7- 8) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_4.html#kombination-summarize-und-group_by",
    "href": "scripts/02_excercises/loesung_4.html#kombination-summarize-und-group_by",
    "title": "Hands On – Tidy & Transform (Einheiten 7 und 8)",
    "section": "Kombination summarize() und group_by()",
    "text": "Kombination summarize() und group_by()\nFinde heraus, wie die durchschnittlichen Werte und Standardabweichungen von pre4 in den verschiedenen Gruppen (group) ausfallen.\n\nNutze dafür zuerst group_by()\nPipe das Ergebnis in summarize()\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndat_full |&gt;\n  group_by(group) |&gt;\n  summarise(\n    mean_pre4 = mean(pre4),\n    sd_pre4   = sd(pre4)\n  )\n\n# A tibble: 3 × 3\n  group   mean_pre4 sd_pre4\n  &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;\n1 above        5.97    1.57\n2 below        3.27    1.89\n3 control      4.91    1.83\n\n\n\n\n\nSo kannst du zum Beispiel Tabelle 1 aus Grinschgl et al. (2020) reproduzieren.",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 4 (Woche 7- 8) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_4.html#anwendung-dplyr-funktionen",
    "href": "scripts/02_excercises/loesung_4.html#anwendung-dplyr-funktionen",
    "title": "Hands On – Tidy & Transform (Einheiten 7 und 8)",
    "section": "Anwendung: dplyr-Funktionen",
    "text": "Anwendung: dplyr-Funktionen\nIn der Analyse von Grinschgl et al. (2020), werden die Skalenwerte des MMQ-Fragebogens untersucht.\nUm diese auszuwerten, müssen wir den Skalenwert pro Person berechnen.\n\nBerechnen von mmq_mean\nMit mutate() kannst du einem bestehenden Datensatz eine neue Spalte hinzufügen.\nUm die Daten des MMQ zu analysieren, füge eine Spalte hinzu, die den Durchschnitt (mmq_mean) über alle 18 Items (z. B. question1 bis question18) enthält.\n💡 Tipps:\n\nVerwende rowMeans() statt mean(), um den Mittelwert pro Versuchsperson zeihlenweise zu berechnen.\nDu kannst mit starts_with() alle Spalten auswählen, die mit question beginnen.\nWenn die Items im Datensatz nebeneinanderstehen, kannst du sie auch mit einem Bereich auswählen, z. B. question1:question18.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndat_full &lt;- dat_full |&gt; \n  mutate(mmq_mean = rowMeans(select(dat_full, starts_with(\"question\")), # bedingt, dass neben den 18 Variablen vom mmq sonst keinerlei andere Variablen mit \"question\" starten\n                             na.rm = TRUE))\n\ndat_full &lt;- dat_full |&gt; \n  mutate(mmq_mean = rowMeans(select(dat_full, # bedingt, dass die 18 Variablen vom mmq nebeneinanderstehen\n                                    question1:question18),\n                             na.rm = TRUE))",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 4 (Woche 7- 8) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_4.html#multiplizieren-von-pre-ratings",
    "href": "scripts/02_excercises/loesung_4.html#multiplizieren-von-pre-ratings",
    "title": "Hands On – Tidy & Transform (Einheiten 7 und 8)",
    "section": "Multiplizieren von Pre Ratings",
    "text": "Multiplizieren von Pre Ratings\nDie Variablen pre1–pre4 und post stellen in der Studie die Leistungseinschätzungen auf einer Skala von 1 bis 100 dar. In unserem Datensatz sind sie jedoch nur auf einer Skala von 1 bis 10 abgebildet. Verwende die Funktion mutate, um die Variablen mit 10 zu multiplizieren und so die richtigen Werte zu erhalten.\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndat_full &lt;- dat_full |&gt;\n  mutate(\n    pre1 = pre1 * 10,\n    pre2 = pre2 * 10,\n    pre3 = pre3 * 10,\n    pre4 = pre4 * 10,\n    post = post * 10\n  )\n\n\n\n\nWeitere Informationen zu dplyr findest du auch hier: 📖Kapitel 4.4 Ellis & Mayer",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 4 (Woche 7- 8) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_4.html#häufige-formen-fehlender-werte",
    "href": "scripts/02_excercises/loesung_4.html#häufige-formen-fehlender-werte",
    "title": "Hands On – Tidy & Transform (Einheiten 7 und 8)",
    "section": "Häufige Formen fehlender Werte",
    "text": "Häufige Formen fehlender Werte\n\nNA (R-typische Kennzeichnung für Not Available)\n999 oder -999 (häufig manuell gesetzte Platzhalter)\nleere Zellen (\"\")\nNULL (in manchen Programmiersprachen, aber in R selten in Datensätzen verwendet)",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 4 (Woche 7- 8) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_4.html#umgang-mit-fehlenden-werten",
    "href": "scripts/02_excercises/loesung_4.html#umgang-mit-fehlenden-werten",
    "title": "Hands On – Tidy & Transform (Einheiten 7 und 8)",
    "section": "Umgang mit fehlenden Werten",
    "text": "Umgang mit fehlenden Werten\nIm Umgang mit fehlenden Werten sollten wir:\n\nPrüfen, ob und wie viele Werte fehlen.\nVerstehen, warum sie fehlen (z. B. fehlende Eingabe durch Teilnehmende).\nEntscheiden, wie mit den fehlenden Werten umgegangen werden soll – basierend auf dieser Analyse.",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 4 (Woche 7- 8) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_4.html#aufgabe",
    "href": "scripts/02_excercises/loesung_4.html#aufgabe",
    "title": "Hands On – Tidy & Transform (Einheiten 7 und 8)",
    "section": "Aufgabe:",
    "text": "Aufgabe:\n 📥 Download bfi_10_data.csv \n📖Kapitel 4.3.3 Ellis & Mayer\nFühre die folgenden Schritte durch:\n\nDatensatz downloaden und einlesen\nLade den Übungsdatensatz in R ein. Achte auf den Delimiter/das Trennzeichen (;)\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nbfi_10_data &lt;- read_delim(\"raw/bfi_10_data.csv\", delim = \";\", escape_double = FALSE, trim_ws = TRUE)\n\n\n\n\n\nFehlende Werte prüfen\nTeste mit is.na(), ob der Datensatz fehlende Werte enthält,\nund zähle sie mit table(is.na()). Eine weitere Art und Weise einen Überblick über missings zu erhalten ist mit dem skimr Paket und der skim() Funktion. Teste diese.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nis.na(bfi_10_data)\n\n         id   age gender bfi_extra_1_r bfi_extra_2 bfi_agree_1 bfi_agree_2_r\n [1,] FALSE FALSE  FALSE         FALSE       FALSE       FALSE         FALSE\n [2,] FALSE FALSE  FALSE         FALSE       FALSE       FALSE         FALSE\n [3,] FALSE FALSE  FALSE         FALSE       FALSE       FALSE         FALSE\n [4,] FALSE FALSE  FALSE         FALSE       FALSE       FALSE         FALSE\n [5,] FALSE FALSE  FALSE         FALSE       FALSE       FALSE         FALSE\n [6,] FALSE FALSE  FALSE         FALSE       FALSE        TRUE         FALSE\n [7,] FALSE FALSE  FALSE         FALSE       FALSE       FALSE         FALSE\n [8,] FALSE FALSE  FALSE         FALSE       FALSE       FALSE         FALSE\n [9,] FALSE FALSE  FALSE          TRUE       FALSE       FALSE         FALSE\n[10,] FALSE FALSE  FALSE         FALSE       FALSE       FALSE         FALSE\n[11,] FALSE FALSE  FALSE         FALSE       FALSE       FALSE         FALSE\n[12,] FALSE FALSE  FALSE         FALSE       FALSE       FALSE         FALSE\n[13,] FALSE FALSE  FALSE         FALSE       FALSE       FALSE         FALSE\n[14,] FALSE FALSE  FALSE         FALSE        TRUE       FALSE         FALSE\n[15,] FALSE FALSE  FALSE         FALSE       FALSE       FALSE         FALSE\n[16,] FALSE FALSE  FALSE         FALSE       FALSE       FALSE         FALSE\n[17,] FALSE FALSE  FALSE         FALSE       FALSE       FALSE         FALSE\n[18,] FALSE FALSE  FALSE         FALSE       FALSE       FALSE         FALSE\n[19,] FALSE FALSE  FALSE         FALSE       FALSE       FALSE         FALSE\n[20,] FALSE FALSE  FALSE         FALSE       FALSE       FALSE         FALSE\n[21,] FALSE FALSE  FALSE         FALSE       FALSE       FALSE          TRUE\n[22,] FALSE FALSE  FALSE         FALSE       FALSE       FALSE         FALSE\n[23,] FALSE FALSE  FALSE         FALSE       FALSE       FALSE         FALSE\n[24,] FALSE FALSE  FALSE         FALSE       FALSE       FALSE         FALSE\n[25,] FALSE FALSE  FALSE         FALSE       FALSE       FALSE         FALSE\n[26,] FALSE FALSE  FALSE         FALSE       FALSE       FALSE         FALSE\n[27,] FALSE FALSE  FALSE         FALSE       FALSE       FALSE         FALSE\n[28,] FALSE FALSE  FALSE         FALSE       FALSE       FALSE         FALSE\n[29,] FALSE FALSE  FALSE         FALSE       FALSE       FALSE         FALSE\n[30,] FALSE FALSE  FALSE         FALSE       FALSE       FALSE         FALSE\n      bfi_consc_1 bfi_consc_2_r bfi_neuro_1 bfi_neuro_2_r bfi_open_1\n [1,]       FALSE         FALSE       FALSE         FALSE      FALSE\n [2,]       FALSE         FALSE       FALSE         FALSE      FALSE\n [3,]       FALSE         FALSE       FALSE         FALSE      FALSE\n [4,]       FALSE         FALSE       FALSE         FALSE      FALSE\n [5,]       FALSE         FALSE       FALSE         FALSE      FALSE\n [6,]       FALSE         FALSE       FALSE         FALSE      FALSE\n [7,]       FALSE          TRUE       FALSE         FALSE      FALSE\n [8,]       FALSE         FALSE       FALSE         FALSE      FALSE\n [9,]       FALSE         FALSE       FALSE         FALSE      FALSE\n[10,]       FALSE         FALSE       FALSE         FALSE      FALSE\n[11,]       FALSE         FALSE       FALSE         FALSE      FALSE\n[12,]       FALSE         FALSE       FALSE         FALSE      FALSE\n[13,]       FALSE         FALSE        TRUE          TRUE       TRUE\n[14,]       FALSE         FALSE       FALSE         FALSE      FALSE\n[15,]       FALSE         FALSE       FALSE         FALSE      FALSE\n[16,]       FALSE         FALSE        TRUE         FALSE      FALSE\n[17,]       FALSE         FALSE       FALSE         FALSE      FALSE\n[18,]       FALSE         FALSE       FALSE         FALSE      FALSE\n[19,]       FALSE         FALSE       FALSE         FALSE      FALSE\n[20,]       FALSE         FALSE       FALSE         FALSE      FALSE\n[21,]       FALSE         FALSE       FALSE         FALSE      FALSE\n[22,]       FALSE         FALSE       FALSE         FALSE      FALSE\n[23,]       FALSE         FALSE       FALSE         FALSE      FALSE\n[24,]       FALSE         FALSE       FALSE         FALSE      FALSE\n[25,]       FALSE         FALSE       FALSE          TRUE      FALSE\n[26,]       FALSE         FALSE       FALSE         FALSE      FALSE\n[27,]       FALSE         FALSE       FALSE         FALSE      FALSE\n[28,]       FALSE         FALSE       FALSE         FALSE      FALSE\n[29,]       FALSE         FALSE       FALSE         FALSE      FALSE\n[30,]       FALSE         FALSE       FALSE         FALSE      FALSE\n      bfi_open_2_r\n [1,]        FALSE\n [2,]        FALSE\n [3,]         TRUE\n [4,]        FALSE\n [5,]        FALSE\n [6,]        FALSE\n [7,]        FALSE\n [8,]        FALSE\n [9,]        FALSE\n[10,]         TRUE\n[11,]        FALSE\n[12,]        FALSE\n[13,]         TRUE\n[14,]        FALSE\n[15,]        FALSE\n[16,]        FALSE\n[17,]        FALSE\n[18,]        FALSE\n[19,]        FALSE\n[20,]        FALSE\n[21,]        FALSE\n[22,]        FALSE\n[23,]        FALSE\n[24,]        FALSE\n[25,]        FALSE\n[26,]        FALSE\n[27,]        FALSE\n[28,]        FALSE\n[29,]        FALSE\n[30,]        FALSE\n\ntable(is.na(bfi_10_data))\n\n\nFALSE  TRUE \n  377    13 \n\nlibrary(skimr)\n\nskim(bfi_10_data)\n\n\nData summary\n\n\nName\nbfi_10_data\n\n\nNumber of rows\n30\n\n\nNumber of columns\n13\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n1\n\n\nnumeric\n12\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\ngender\n0\n1\n4\n6\n0\n2\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nid\n0\n1.00\n15.50\n8.80\n1\n8.25\n15.5\n22.75\n30\n▇▇▇▇▇\n\n\nage\n0\n1.00\n32.73\n7.83\n20\n27.00\n33.0\n40.75\n45\n▇▆▃▆▇\n\n\nbfi_extra_1_r\n1\n0.97\n3.00\n1.07\n1\n2.00\n3.0\n4.00\n5\n▁▅▇▃▂\n\n\nbfi_extra_2\n1\n0.97\n3.00\n1.22\n1\n2.00\n3.0\n4.00\n5\n▃▇▇▆▃\n\n\nbfi_agree_1\n1\n0.97\n2.83\n1.39\n1\n2.00\n3.0\n4.00\n5\n▆▇▃▇▃\n\n\nbfi_agree_2_r\n1\n0.97\n2.72\n1.28\n1\n2.00\n3.0\n4.00\n5\n▆▇▅▇▂\n\n\nbfi_consc_1\n0\n1.00\n2.93\n1.28\n1\n2.00\n3.0\n4.00\n5\n▅▆▅▇▂\n\n\nbfi_consc_2_r\n1\n0.97\n3.00\n1.22\n1\n2.00\n3.0\n4.00\n5\n▃▇▇▆▃\n\n\nbfi_neuro_1\n2\n0.93\n3.04\n1.20\n1\n2.00\n3.0\n4.00\n5\n▃▃▇▆▂\n\n\nbfi_neuro_2_r\n2\n0.93\n3.18\n1.39\n1\n2.00\n3.0\n4.00\n5\n▅▇▆▇▇\n\n\nbfi_open_1\n1\n0.97\n2.69\n1.00\n1\n2.00\n3.0\n3.00\n5\n▂▇▇▃▁\n\n\nbfi_open_2_r\n3\n0.90\n2.93\n1.11\n1\n2.00\n3.0\n4.00\n5\n▂▇▆▆▂\n\n\n\n\n\n\n\n\n\nZeilen mit fehlenden Werten löschen\nErstelle eine Kopie des Datensatzes und verwende drop_na(),\num alle Zeilen mit fehlenden Werten zu entfernen.\nZähle anschließend erneut, wie viele fehlende Werte noch vorhanden sind.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nclean_data_bfi_10 &lt;- drop_na(bfi_10_data)\n\n\n\n\n\n\n\n\n\n\nCaution\n\n\n\nAchtung: Ein einziger fehlender Wert reicht aus, damit die gesamte Zeile (also eine Versuchsperson) entfernt wird!",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 4 (Woche 7- 8) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_4.html#umpolen-der-negativ-formulierten-items",
    "href": "scripts/02_excercises/loesung_4.html#umpolen-der-negativ-formulierten-items",
    "title": "Hands On – Tidy & Transform (Einheiten 7 und 8)",
    "section": "Umpolen der negativ formulierten Items",
    "text": "Umpolen der negativ formulierten Items\n\nPole die negativ gepolten (reverse codierten) BFI-Items um. Die reverse kodierten Items enden immer mit _r. Du kannst dafür Base R oder Funktionen aus dem tidyverse verwenden.\n\nVervollständige diesen Code!\n\nNötige Argumente: Datensatz, Variablen, Rekodierungsschema.\n\n\ndata_bfi_recoded &lt;- XXXXX |&gt; \n  mutate(\n    across(\n      c(XXXXXX),\n      ~ case_when(\n        . == 1 ~ 5,\n        XXXXXXXXXX\n      )\n    )\n  )\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndata_bfi_recoded &lt;- clean_data_bfi_10 |&gt; \n  mutate(\n    across(\n      c(bfi_extra_1_r, bfi_agree_2_r, bfi_consc_2_r, bfi_neuro_2_r, bfi_open_2_r),\n      ~ case_when(\n        . == 1 ~ 5,\n        . == 2 ~ 4,\n        . == 3 ~ 3,\n        . == 4 ~ 2,\n        . == 5 ~ 1\n      )\n    )\n  )\n\n#Sparsamere Alternative\n\ndata_bfi_recoded &lt;- clean_data_bfi_10 |&gt;\n  mutate(\n    across(ends_with(\"_r\"), ~ 6 - .)\n  )\n\n\n\n\nErklärungen zu diesem Code findest du hier: Kapitel 4.4.6 Ellis & Mayer und hier: Kapitel 4.4.7 Ellis & Mayer",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 4 (Woche 7- 8) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_4.html#berechnung-der-big-five-skalen",
    "href": "scripts/02_excercises/loesung_4.html#berechnung-der-big-five-skalen",
    "title": "Hands On – Tidy & Transform (Einheiten 7 und 8)",
    "section": "Berechnung der Big-Five-Skalen",
    "text": "Berechnung der Big-Five-Skalen\n\nErstelle neue Variablen, die den Mittelwert jedes Big-Five-Faktors pro Person enthalten.\n\nNutze dafür die Funktionen:\n\nmutate(), row_means() und select()\n\n💡Tipp: Wenn du die select()-Funktion innerhalb von mutate() verwendest und den native pipe (|&gt;) nutzt, musst du angeben, auf welchen Datensatz sich select() bezieht.\nz.B: extraversion = rowMeans(select(data_bfi_recoded, bfi_extra_1_r, bfi_extra_2))\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nfinal_bfi &lt;- data_bfi_recoded |&gt;\n  mutate(\n    extraversion = rowMeans(select(data_bfi_recoded, bfi_extra_1_r, bfi_extra_2)),\n    agreeableness = rowMeans(select(data_bfi_recoded, bfi_agree_1, bfi_agree_2_r)),\n    conscientiousness = rowMeans(select(data_bfi_recoded, bfi_consc_1, bfi_consc_2_r)),\n    neuroticism = rowMeans(select(data_bfi_recoded, bfi_neuro_1, bfi_neuro_2_r)),\n    openness = rowMeans(select(data_bfi_recoded, bfi_open_1, bfi_open_2_r))\n  )\n\n\n\n\nAbschlussübung: Versuche dein Skript dieser Hands on Einheit zu rendern. Wenn es nicht funktioniert, versuche die Fehlermeldungen nachzuvollziehen und zu beheben!",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 4 (Woche 7- 8) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Webseite_FS26",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "scripts/02_excercises/loesung_5.html",
    "href": "scripts/02_excercises/loesung_5.html",
    "title": "Hands On – Tidy & Transform / Analyze (Einheiten 9 und 10)",
    "section": "",
    "text": "library(tidyverse)\nlibrary(here)\n\ndat_full &lt;- read_csv(here(\"data/raw/dat_full.csv\"))\nBei Bedarf findest du hier nochmals die Slides zu Einheit 9:",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 5 (Woche 9 - 10) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_5.html#übungen-zur-datenkonversion",
    "href": "scripts/02_excercises/loesung_5.html#übungen-zur-datenkonversion",
    "title": "Hands On – Tidy & Transform / Analyze (Einheiten 9 und 10)",
    "section": "Übungen zur Datenkonversion",
    "text": "Übungen zur Datenkonversion\n📖R4DS - Kapitel 5.3\n📖Einführung in R - Kapitel 3.1.3\nDie folgenden Schritte dienen der Konversion von Daten zwischen dem Wide- und Long-Format unter Verwendung des Tidyverse-Pakets in R.\n\nMit der Funktion pivot_longer() Spalten der Leistungseinschätzung in Long-Format umwandeln und in neuen Datensatz speichern, nur für Übungszwecke.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndf_long &lt;- dat_full |&gt;\n  pivot_longer(\n    cols = c(pre1, pre2, pre3, pre4, post),\n    names_to = \"time_rating\",\n    values_to = \"rating\"\n  )\n\n\n\n\n\nWandle den Datensatz noch mal in das Long Format um, aber nur basierend auf den Spalten pre1 und pre4 Long-Format wird für 2x3 ANOVA aus Grinschgl et al. (2020) benötigt; für Vergleich der 2 Messzeitpunkte in dieser Analysen, benötigen wir diese im Long-Format.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndf_long &lt;- dat_full |&gt;\n  pivot_longer(\n    cols = c(pre1, pre4),\n    names_to = \"time_rating\",\n    values_to = \"rating\"\n  )\n\n\n\n\n\nWandle die Spalte time_rating in einen Factor um –&gt; auch notwendig für Analysen.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndf_long$time_rating &lt;- factor(df_long$time_rating)\n\n\n\n\n\nSpeichere den Long Datensatz als csv. Datei ab. Achtung: achte auf das row.names() argument, um keine unnötige Spalte zu generieren.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nwrite.csv(df_long, \"processed/data_long.csv\", row.names = FALSE)\n\n\n\n\n\nVerwende pivot_wider unter Angabe von names_from und values_from um den Datensatz wieder in das Wide-Format zu bringen. –&gt; nur für Übungszwecke.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndf_wide &lt;- df_long |&gt; \n  pivot_wider(names_from = time_rating,\n              values_from = rating)",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 5 (Woche 9 - 10) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_5.html#skewness-und-kurtosis",
    "href": "scripts/02_excercises/loesung_5.html#skewness-und-kurtosis",
    "title": "Hands On – Tidy & Transform / Analyze (Einheiten 9 und 10)",
    "section": "Skewness und Kurtosis",
    "text": "Skewness und Kurtosis\nDie folgenden Schritte dienen der Vorbereitung und deskriptiven Analyse von Daten in R.\n\nInstallieren und laden des Pakets {psych}: Stelle sicher, dass das Statis Paket psychfür die weiteren Analysen geladen ist.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n# install.packages(\"psych\")\nlibrary(psych)\n\n\nAttaching package: 'psych'\n\n\nThe following objects are masked from 'package:ggplot2':\n\n    %+%, alpha\n\n\n\n\n\n\nBerechne die Schiefe und die Kurtosis der Variablen “Öffnungen des Modellfensters” (mean_rl_all) für die drei Gruppen. Verwende hierfür die dplyr-Funktionen group_by() und summarize().\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsummary_table &lt;- dat_full |&gt;\n  group_by(group_all) |&gt;\n  summarize(schiefe = skew(mean_rl_all),\n            wölbung = kurtosi(mean_rl_all))\n\nsummary_table\n\n# A tibble: 3 × 3\n  group_all schiefe wölbung\n  &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;\n1 above       0.715 -0.0561\n2 below       0.106 -0.0658\n3 control     0.318 -0.619",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 5 (Woche 9 - 10) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_5.html#residuen",
    "href": "scripts/02_excercises/loesung_5.html#residuen",
    "title": "Hands On – Tidy & Transform / Analyze (Einheiten 9 und 10)",
    "section": "Residuen",
    "text": "Residuen\n📖Siehe auch: Normalverteilung der Residuen bei der Regression in R testen\nFür die folgenden Schritte berechnen wir zuerst ein Regressionsmodell:\n\nSpezifikation des Regressionsmodells: Verwende die Funktion lm() um ein Regressionsmodell zwischen Cognitive Offloading (mean_rl_all und der Arbeitsgedächtnisleistung (Feature Switch Detection Task - cvstm_propcorrect) zu spezifizieren.\n\n\nreg_fit &lt;- lm(Cognitive_Offloading_Variable ~ Arbeitsgedächtnisleistung, data = dat_ full)\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nreg_fit &lt;- lm(mean_rl_all ~ cvstm_propcorrect, data = dat_full)\n\n\n\n\n\nSpeichern der Residuen: Speichere die Residuen dieses Regressionsmodells mit der Funktion rstandard()\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nresiduals &lt;- rstandard(reg_fit)\n\n\n\n\n\nVisualisierung mittels Histogramm: Stelle die die Residuen in einem Histogramm mit der Funktion hist() dar.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nhist(residuals)\n\n\n\n\n\n\n\n\n\n\n\n*Frage:* Ist im Histogramm eine **Glockenkurve** (Normalverteilung) erkennbar?\n\nVisualisierung mittels QQ-Plot: Stelle die Residuen in einem QQ-Plot mit der Funktion qqnorm() dar. Ergänze die Regressionsgerade mit qqline().\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nqqnorm(residuals)\nqqline(residuals)\n\n\n\n\n\n\n\n\n\n\n\n*Frage:* Wie nah sind die Residuen einer **perfekten Normalverteilung** (d.h. der Geraden)?",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 5 (Woche 9 - 10) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_5.html#skalenreliabilität",
    "href": "scripts/02_excercises/loesung_5.html#skalenreliabilität",
    "title": "Hands On – Tidy & Transform / Analyze (Einheiten 9 und 10)",
    "section": "Skalenreliabilität",
    "text": "Skalenreliabilität\n📖 Psychometrics in R & Björn Walther\nDie folgenden Schritte dienen der Prüfung der internen Konsistenz der Messinstrumente.\n\nDatenvorbereitung für die Analyse: Speichere alle Variablen des MMQs in einem neuen Data Frame ab. Wähle dabei die Spalten mittels select aus.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nmmq_vars &lt;- dat_full |&gt;\n  select(starts_with(\"question\"))\n\n\n\n\n\nBerechnung von Cronbach’s Alpha: Verwende die Funktion alpha() aus dem psych-Paket und wende sie auf das neue Objekt an, um Cronbach’s Alpha (Interne Konsistenz) für diesen Fragebogen zu berechnen. Schau dir die Ergebnisse (insbesondere raw_alpha) an. Dieses sollte mit Werten in Grinschgl et al. (2021) übereinstimmen.\n\n\n\n\n\n\n\nWarning\n\n\n\nAchtung: Wenn du das Package ggplot() geladen hast, kann es sein dass die Funktion alpha()dadurch verdeckt wird. Spezifiziere aus welchem Package du die Funktion verwenden willst mit psych::alpha()\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\npsych::alpha(mmq_vars)\n\n\nReliability analysis   \nCall: psych::alpha(x = mmq_vars)\n\n  raw_alpha std.alpha G6(smc) average_r S/N    ase mean   sd median_r\n      0.93      0.93    0.94      0.42  13 0.0082  2.5 0.68     0.44\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.91  0.93  0.94\nDuhachek  0.91  0.93  0.94\n\n Reliability if an item is dropped:\n           raw_alpha std.alpha G6(smc) average_r S/N alpha se var.r med.r\nquestion1       0.92      0.92    0.94      0.42  12   0.0088 0.035  0.44\nquestion2       0.92      0.92    0.94      0.41  12   0.0088 0.035  0.43\nquestion3       0.92      0.93    0.94      0.43  13   0.0085 0.036  0.45\nquestion4       0.92      0.92    0.94      0.42  12   0.0087 0.038  0.44\nquestion5       0.92      0.92    0.94      0.41  12   0.0091 0.033  0.43\nquestion6       0.92      0.92    0.94      0.42  12   0.0086 0.037  0.44\nquestion7       0.92      0.92    0.94      0.41  12   0.0090 0.035  0.43\nquestion8       0.92      0.92    0.94      0.42  12   0.0086 0.037  0.43\nquestion9       0.93      0.94    0.95      0.46  15   0.0074 0.021  0.46\nquestion10      0.92      0.92    0.94      0.41  12   0.0092 0.034  0.43\nquestion11      0.92      0.92    0.94      0.41  12   0.0088 0.037  0.43\nquestion12      0.92      0.92    0.94      0.41  12   0.0089 0.035  0.43\nquestion13      0.93      0.93    0.95      0.44  14   0.0079 0.034  0.46\nquestion14      0.92      0.93    0.94      0.43  13   0.0083 0.038  0.46\nquestion15      0.92      0.92    0.94      0.41  12   0.0089 0.035  0.43\nquestion16      0.93      0.93    0.94      0.43  13   0.0082 0.037  0.46\nquestion17      0.92      0.92    0.94      0.40  12   0.0091 0.033  0.43\nquestion18      0.92      0.92    0.94      0.40  12   0.0093 0.033  0.42\n\n Item statistics \n             n raw.r std.r r.cor r.drop mean   sd\nquestion1  159  0.71  0.71  0.70   0.66  2.2 1.01\nquestion2  159  0.72  0.73  0.72   0.69  3.2 0.86\nquestion3  159  0.58  0.60  0.57   0.54  3.1 0.75\nquestion4  159  0.69  0.68  0.65   0.63  2.8 1.09\nquestion5  159  0.79  0.80  0.80   0.76  2.5 1.04\nquestion6  159  0.66  0.67  0.65   0.61  2.5 0.99\nquestion7  159  0.78  0.78  0.77   0.74  2.6 1.08\nquestion8  159  0.66  0.66  0.64   0.61  2.9 1.02\nquestion9  159  0.19  0.18  0.12   0.11  2.0 1.09\nquestion10 159  0.82  0.82  0.82   0.79  2.8 1.09\nquestion11 159  0.73  0.72  0.71   0.68  2.7 1.10\nquestion12 159  0.75  0.76  0.75   0.72  2.5 0.94\nquestion13 159  0.41  0.41  0.35   0.34  1.9 1.06\nquestion14 159  0.58  0.58  0.54   0.52  2.0 1.09\nquestion15 159  0.77  0.78  0.77   0.74  3.2 0.89\nquestion16 159  0.55  0.54  0.51   0.49  1.7 1.09\nquestion17 159  0.83  0.84  0.84   0.81  2.3 0.91\nquestion18 159  0.84  0.84  0.85   0.81  2.7 1.14\n\nNon missing response frequency for each item\n              0    1    2    3    4 miss\nquestion1  0.06 0.19 0.29 0.41 0.05    0\nquestion2  0.01 0.04 0.11 0.40 0.43    0\nquestion3  0.01 0.03 0.11 0.55 0.31    0\nquestion4  0.03 0.13 0.11 0.44 0.28    0\nquestion5  0.04 0.14 0.26 0.40 0.16    0\nquestion6  0.03 0.15 0.23 0.47 0.12    0\nquestion7  0.03 0.16 0.19 0.40 0.22    0\nquestion8  0.02 0.11 0.09 0.45 0.32    0\nquestion9  0.08 0.30 0.23 0.34 0.06    0\nquestion10 0.02 0.16 0.10 0.41 0.31    0\nquestion11 0.03 0.16 0.18 0.37 0.26    0\nquestion12 0.02 0.17 0.18 0.55 0.09    0\nquestion13 0.06 0.35 0.22 0.31 0.05    0\nquestion14 0.08 0.35 0.16 0.38 0.04    0\nquestion15 0.01 0.06 0.11 0.40 0.43    0\nquestion16 0.09 0.41 0.23 0.21 0.06    0\nquestion17 0.04 0.13 0.37 0.40 0.06    0\nquestion18 0.04 0.16 0.09 0.43 0.28    0\n\n\n\n\n\n\nVerwende die Funktion omega() aus dem psych-Paket und wende sie auf dein Objekt (z. B. den Datensatz mit den relevanten Items) an, um McDonald’s Omega (interne Konsistenz auf Basis eines Faktorenmodells) zu berechnen.\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\npsych::omega(mmq_vars)\n\nLoading required namespace: GPArotation\n\n\nWarning in fa.stats(r = r, f = f, phi = phi, n.obs = n.obs, np.obs = np.obs, :\nThe estimated weights for the factor scores are probably incorrect.  Try a\ndifferent factor score estimation method.\n\n\nWarning in fac(r = r, nfactors = nfactors, n.obs = n.obs, rotate = rotate, : An\nultra-Heywood case was detected.  Examine the results carefully\n\n\nWarning in fa.stats(r = r, f = f, phi = phi, n.obs = n.obs, np.obs = np.obs, :\nThe estimated weights for the factor scores are probably incorrect.  Try a\ndifferent factor score estimation method.\n\n\nWarning in fac(r = r, nfactors = nfactors, n.obs = n.obs, rotate = rotate, : An\nultra-Heywood case was detected.  Examine the results carefully\n\n\nWarning in fa.stats(r = r, f = f, phi = phi, n.obs = n.obs, np.obs = np.obs, :\nThe estimated weights for the factor scores are probably incorrect.  Try a\ndifferent factor score estimation method.\n\n\nWarning in cov2cor(t(w) %*% r %*% w): diag(V) had non-positive or NA entries;\nthe non-finite result may be dubious\n\n\n\n\n\n\n\n\n\nOmega \nCall: omegah(m = m, nfactors = nfactors, fm = fm, key = key, flip = flip, \n    digits = digits, title = title, sl = sl, labels = labels, \n    plot = plot, n.obs = n.obs, rotate = rotate, Phi = Phi, option = option, \n    covar = covar)\nAlpha:                 0.93 \nG.6:                   0.94 \nOmega Hierarchical:    0.88 \nOmega H asymptotic:    0.94 \nOmega Total            0.94 \n\nSchmid Leiman Factor loadings greater than  0.2 \n               g   F1*   F2*   F3*   h2    u2   p2\nquestion1   0.73                   0.54  0.46 0.99\nquestion2   0.75                   0.56  0.44 1.01\nquestion3   0.51              0.87 1.01 -0.01 0.26\nquestion4   0.59        0.39       0.50  0.50 0.69\nquestion5   0.85                   0.73  0.27 0.99\nquestion6   0.60              0.28 0.45  0.55 0.82\nquestion7   0.78                   0.62  0.38 0.99\nquestion8   0.62                   0.41  0.59 0.94\nquestion9               0.26       0.08  0.92 0.06\nquestion10  0.82                   0.70  0.30 0.96\nquestion11  0.67                   0.50  0.50 0.91\nquestion12  0.78                   0.61  0.39 1.01\nquestion13  0.28        0.31       0.18  0.82 0.44\nquestion14  0.43        0.44  0.22 0.42  0.58 0.44\nquestion15  0.78                   0.61  0.39 0.99\nquestion16  0.39        0.63       0.55  0.45 0.28\nquestion17  0.86                   0.74  0.26 1.01\nquestion18  0.84                   0.73  0.27 0.98\n\nWith Sums of squares  of:\n   g  F1*  F2*  F3* \n8.02 0.00 1.03 0.93 \n\ngeneral/max  7.79   max/min =   Inf\nmean percent general =  0.76    with sd =  0.32 and cv of  0.42 \nExplained Common Variance of the general factor =  0.8 \n\nThe degrees of freedom are 102  and the fit is  1.36 \nThe number of observations was  159  with Chi Square =  203.59  with prob &lt;  9.6e-09\nThe root mean square of the residuals is  0.04 \nThe df corrected root mean square of the residuals is  0.05\nRMSEA index =  0.079  and the 10 % confidence intervals are  0.063 0.095\nBIC =  -313.44\n\nCompare this with the adequacy of just a general factor and no group factors\nThe degrees of freedom for just the general factor are 135  and the fit is  2.19 \nThe number of observations was  159  with Chi Square =  329.07  with prob &lt;  3.1e-18\nThe root mean square of the residuals is  0.07 \nThe df corrected root mean square of the residuals is  0.08 \n\nRMSEA index =  0.095  and the 10 % confidence intervals are  0.082 0.109\nBIC =  -355.23 \n\nMeasures of factor score adequacy             \n                                                 g F1*  F2*  F3*\nCorrelation of scores with factors            0.98   0 0.81 1.01\nMultiple R square of scores with factors      0.96   0 0.66 1.03\nMinimum correlation of factor score estimates 0.91  -1 0.32 1.06\n\n Total, General and Subset omega for each subset\n                                                 g F1*  F2*  F3*\nOmega total for total scores and subscales    0.94  NA 0.91 0.90\nOmega general for total scores and subscales  0.88  NA 0.82 0.82\nOmega group for total scores and subscales    0.05  NA 0.09 0.08\n\n\n\n\n\n\n\n\n\n\n\nPDF Grinschgl2021 –&gt; Seite 7 –&gt; Multifactorial Memory Questionnaire\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nalpha(mmq_vars)\n\n\nReliability analysis   \nCall: alpha(x = mmq_vars)\n\n  raw_alpha std.alpha G6(smc) average_r S/N    ase mean   sd median_r\n      0.93      0.93    0.94      0.42  13 0.0082  2.5 0.68     0.44\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt     0.91  0.93  0.94\nDuhachek  0.91  0.93  0.94\n\n Reliability if an item is dropped:\n           raw_alpha std.alpha G6(smc) average_r S/N alpha se var.r med.r\nquestion1       0.92      0.92    0.94      0.42  12   0.0088 0.035  0.44\nquestion2       0.92      0.92    0.94      0.41  12   0.0088 0.035  0.43\nquestion3       0.92      0.93    0.94      0.43  13   0.0085 0.036  0.45\nquestion4       0.92      0.92    0.94      0.42  12   0.0087 0.038  0.44\nquestion5       0.92      0.92    0.94      0.41  12   0.0091 0.033  0.43\nquestion6       0.92      0.92    0.94      0.42  12   0.0086 0.037  0.44\nquestion7       0.92      0.92    0.94      0.41  12   0.0090 0.035  0.43\nquestion8       0.92      0.92    0.94      0.42  12   0.0086 0.037  0.43\nquestion9       0.93      0.94    0.95      0.46  15   0.0074 0.021  0.46\nquestion10      0.92      0.92    0.94      0.41  12   0.0092 0.034  0.43\nquestion11      0.92      0.92    0.94      0.41  12   0.0088 0.037  0.43\nquestion12      0.92      0.92    0.94      0.41  12   0.0089 0.035  0.43\nquestion13      0.93      0.93    0.95      0.44  14   0.0079 0.034  0.46\nquestion14      0.92      0.93    0.94      0.43  13   0.0083 0.038  0.46\nquestion15      0.92      0.92    0.94      0.41  12   0.0089 0.035  0.43\nquestion16      0.93      0.93    0.94      0.43  13   0.0082 0.037  0.46\nquestion17      0.92      0.92    0.94      0.40  12   0.0091 0.033  0.43\nquestion18      0.92      0.92    0.94      0.40  12   0.0093 0.033  0.42\n\n Item statistics \n             n raw.r std.r r.cor r.drop mean   sd\nquestion1  159  0.71  0.71  0.70   0.66  2.2 1.01\nquestion2  159  0.72  0.73  0.72   0.69  3.2 0.86\nquestion3  159  0.58  0.60  0.57   0.54  3.1 0.75\nquestion4  159  0.69  0.68  0.65   0.63  2.8 1.09\nquestion5  159  0.79  0.80  0.80   0.76  2.5 1.04\nquestion6  159  0.66  0.67  0.65   0.61  2.5 0.99\nquestion7  159  0.78  0.78  0.77   0.74  2.6 1.08\nquestion8  159  0.66  0.66  0.64   0.61  2.9 1.02\nquestion9  159  0.19  0.18  0.12   0.11  2.0 1.09\nquestion10 159  0.82  0.82  0.82   0.79  2.8 1.09\nquestion11 159  0.73  0.72  0.71   0.68  2.7 1.10\nquestion12 159  0.75  0.76  0.75   0.72  2.5 0.94\nquestion13 159  0.41  0.41  0.35   0.34  1.9 1.06\nquestion14 159  0.58  0.58  0.54   0.52  2.0 1.09\nquestion15 159  0.77  0.78  0.77   0.74  3.2 0.89\nquestion16 159  0.55  0.54  0.51   0.49  1.7 1.09\nquestion17 159  0.83  0.84  0.84   0.81  2.3 0.91\nquestion18 159  0.84  0.84  0.85   0.81  2.7 1.14\n\nNon missing response frequency for each item\n              0    1    2    3    4 miss\nquestion1  0.06 0.19 0.29 0.41 0.05    0\nquestion2  0.01 0.04 0.11 0.40 0.43    0\nquestion3  0.01 0.03 0.11 0.55 0.31    0\nquestion4  0.03 0.13 0.11 0.44 0.28    0\nquestion5  0.04 0.14 0.26 0.40 0.16    0\nquestion6  0.03 0.15 0.23 0.47 0.12    0\nquestion7  0.03 0.16 0.19 0.40 0.22    0\nquestion8  0.02 0.11 0.09 0.45 0.32    0\nquestion9  0.08 0.30 0.23 0.34 0.06    0\nquestion10 0.02 0.16 0.10 0.41 0.31    0\nquestion11 0.03 0.16 0.18 0.37 0.26    0\nquestion12 0.02 0.17 0.18 0.55 0.09    0\nquestion13 0.06 0.35 0.22 0.31 0.05    0\nquestion14 0.08 0.35 0.16 0.38 0.04    0\nquestion15 0.01 0.06 0.11 0.40 0.43    0\nquestion16 0.09 0.41 0.23 0.21 0.06    0\nquestion17 0.04 0.13 0.37 0.40 0.06    0\nquestion18 0.04 0.16 0.09 0.43 0.28    0\n\n\n\n\n\n\nTipp: In der alpha() Funktion werden unter details alle Werte beschrieben. Für weitere Erklärungen siehe auch: Psychometrics in R",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 5 (Woche 9 - 10) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_5.html#streudiagrammescatterplots-weitere-datenverteilungen",
    "href": "scripts/02_excercises/loesung_5.html#streudiagrammescatterplots-weitere-datenverteilungen",
    "title": "Hands On – Tidy & Transform / Analyze (Einheiten 9 und 10)",
    "section": "Streudiagramme/Scatterplots & weitere Datenverteilungen",
    "text": "Streudiagramme/Scatterplots & weitere Datenverteilungen\n\n\n\n\n\n\n\n\nGeom\nFunktion\nEinsatzbereich\n\n\n\n\ngeom_point()\nStreudiagramm\nZwei numerische Variablen vergleichen (x = Var1, y = Var2)\n\n\ngeom_line()\nLiniendiagramm\nWerteverlauf über kontinuierliche x-Achse darstellen\n\n\ngeom_bar()\nBalkendiagramm\nHäufigkeiten oder Aggregationen für Kategorien (x = Gruppe)\n\n\ngeom_histogram()\nHistogramm\nVerteilung einer numerischen Variable (x = Wert)\n\n\ngeom_boxplot()\nBoxplot\nVerteilungen über Gruppen vergleichen (x = Gruppe, y = Wert)\n\n\n\n\n\n\n\n\n\nCheatsheet ggplot2\n\n\n\n\n\n\n\n\n\n\nUm Plots zu erstellen gibt es diverse Packages. Für einfache Darstellungen ist die Syntax der Base r plot() Funktion nützlich, bietet jedoch wesentlich weniger Optionen an als ggplot(). Für diese aufgaben sind zwar beide geeignet, jedoch empfehlen wir ggplot()\n\nPlotte den Zusammenhang zwischen Cognitive Offloading (Öffnungen des Modelfensters - mean_rl_all) und der Arbeitsgedächtnisleistung (Feature Switch Detection Task cvstm_propcorrect). Ergänze dafür den Code unten mit den richtigen Variablen. (Wichtig für Ausreißerkontrolle bei Berechnungen von Korrelationen/Regressionen)\n\n\nggplot(data = dat_full, aes(x = XXXXX, y = XXXXXX))+\n  geom_XXXX()\n\n\nAusreißer können auch mit boxplots für einzelne Variablen identifiziert werden 👉 für Öffnungen des Modelfensters anschauen. Nutze das richtige geom() aus der Tabelle.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nggplot(data = dat_full, aes(y = mean_rl_all))+\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\n❗Man sollte schon vor Studienerhebung oder zumindest vor der Datenanalyse festlegen ob bzw. wie man Ausreißer identifiziert und ausschließt (z.B. in Präregistrierungen oder Datenanalyseplänen)\n\nLass dir den boxplot() getrennt für die 3 Experimentalgruppen anzeigen. Setze dafür y = group.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nggplot(data = dat_full, aes(x = group_all, y = mean_rl_all)) +\n  geom_boxplot()",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 5 (Woche 9 - 10) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_5.html#fortgeschrittene-freiwillige-übungen",
    "href": "scripts/02_excercises/loesung_5.html#fortgeschrittene-freiwillige-übungen",
    "title": "Hands On – Tidy & Transform / Analyze (Einheiten 9 und 10)",
    "section": "Fortgeschrittene (freiwillige Übungen)",
    "text": "Fortgeschrittene (freiwillige Übungen)\n\nErweitere den Scatterplot deiner beiden Variablen um die folgenden Dinge:\n\nFärbe deine Datenpunkte nach Gruppenzugehörigkeit ein mit color()\nFüge einen titel ein mit ggtitle()\nBenne die Achsen mit ylab() und xlab()\nÄnder die Darstellungart zu theme_minimal()\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nggplot(data = dat_full, aes(x = mean_rl_all, y = cvstm_propcorrect, color = group_all))+\n  geom_point()+\n  theme_minimal()+\n  ggtitle(\"Meine Wunderschöne Darstellung\")+\n  ylab(\"Arbeitsgedächtnisleistung\")+\n  xlab(\"Öffnungen des Modellfensters\")",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 5 (Woche 9 - 10) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/hausuebungen.html",
    "href": "scripts/02_excercises/hausuebungen.html",
    "title": "Hausuebungen",
    "section": "",
    "text": "Hier findest du die Hausübungen."
  },
  {
    "objectID": "scripts/02_excercises/loesung_2.html",
    "href": "scripts/02_excercises/loesung_2.html",
    "title": "Lösung 2",
    "section": "",
    "text": "Bei Bedarf findest du hier nochmals die Slides zu Einheit 3:",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 2 (Woche 3 - 4) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_2.html#import",
    "href": "scripts/02_excercises/loesung_2.html#import",
    "title": "Lösung 2",
    "section": "Import",
    "text": "Import\n👉 Kapitel 3.2\nCheatsheat Datenimport mit readr\n\nEinlesen via Oberfläche\n\nStelle sicher, dass du das Metapaket tidyverse geladen hast (library(tidyverse)) (siehe Hands-On 1).\nWir verwenden Funktionen aus den Packages readr und readxl, die Teil des Tidyverse sind.\n\nIn diesem Seminar arbeiten wir mit csv und xslx Dateien. Wie werden uns mehere Arten und Weisen anschauen wie man diese einlesen kann.\nBeim Einlesen von Daten ist ein wichtiger Faktor, mich welchem Trennzeichen (Delimiter) die Werte von einander getrennt werden.\nAuszug aus Cheatsheet: Die Funktionen read_delim und read_csv:\n\nread_csv() ist eine Spezialisierung von read_delim(), die automatisch Komma als Trennzeichen verwendet, während man bei read_delim() das gewünschte Trennzeichen selbst angeben muss.\n\nImportiere die Datei \"data_mmq.csv\" über die Point & Klick-Oberfläche von RStudio. Verwende dafür “From Text (readr)”\n\n\nTipp: Klicke auf Environment → Import Dataset → wähle die \"readr\"-Funktion.\nSchaue dir den Datensatz an: Mit welchem Trennzeichen sind die Daten getrennt?\n\n\n\n\n\n\n\n\nVertiefung\n\n\n\n\n\nOhne eine Anpassung des Trennzeichens wird als Default das Komma “,” verwendet. Dies liegt am üblichen Trennzeichen des Dateityps des Datensatzes, csv (comma-separated values). In unserem Fall sind die Daten jedoch mit einem Semikolon “;” getrennt. Deswegen werden im vorliegenden Fall die Daten in dem Vorschaufenster in einer einzigen Spalte eingelesen und nicht sauber getrennt.\n\n\n\n-   ![](images/clipboard-4280669528.png)\n    -   Stelle in der Oberfläche `\"Delimiter\"` auf das passende Trennzeichen. Was verändert sich?\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDas passende Trennzeichen ist in unserem Fall das Semikollon “;”. Wenn auf dieses Trennzeichen gewechselt wird, dann werden die Daten in der Ansicht sauber in einzelne Spalten getrennt und die Daten können passend eingelesen werden.\n\n\n\n-   Betrachte den Code, den die Oberfläche generiert. Versuche den Pfad im Kontext von Projekten zu verstehen.\n    -   Wenn du im Projekt gearbeitet hast, sollte bei dir der Code etwa so aussehen: `data_mmq &lt;- read_delim(\"data/raw/data_mmq.csv\", delim = \";\", escape_double = FALSE, trim_ws = TRUE)`\n    -   Wenn du nicht im Projekt gearbeite hättest, wie würde dann der Dateipfad aussehen?\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDer Dateipfad könnte dann etwa so aussehen:\n“data/raw/data_mmq.csv”\nRelevant ist vor allem, dass ein absoluter Dateipfad verwendet wird, der in dieser Form auf dem eigenen Computer funktioniert. Das Einlesen der Daten wäre somit für andere Personen nicht ohne Anpassungen replizierbar. Deswegen achtet darauf beim Einlesen der Datei relative Pfade zu verwenden!\n\n\n\n-   Wenn du den Code via Klick-Oberfläche eingelesen hast, wirst du den ausgeführten Code in der Konsole sehen. Kopiere diesen in dein Skript, so dass du ihn in Zukunft wiederverwenden und anpassen kannst.\n-   Schaue dir die eingelesenen Daten mit `View(data_mmq)` an. Wenn du alles richtig gemacht hast, ist in jeder Zelle nur ein Wert.\n\n\nEinlesen via Code\n\n.CSV Dateien\n\nVersuche, weitere CSV-Datensätze einzulesen: data_cb, data_cvstm, data_pct, data_vp.\nSuche dafür eine geeignete Funktion zum Einlesen von .csv.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nDie Funktion read_csv() aus dem Paket readr ist eine geeignete Funktion zum Einlesen von .csv Dateien. Diese Funktion verwendet automatisch das Komma als Trennzeichen.\n\n# install.packages(\"readr\") # den Code führst du einmalig in deiner Console aus\n# wenn du schon das Tidyverse geladen hast, musst du readr nicht extra laden - dieses ist in Tidyverse beinhaltet \nlibrary(readr)\n\ndata_cb &lt;- read_delim(\"data/raw/data_cb.csv\", delim = \";\")\n\nRows: 159 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\ndbl (3): code, cb_sum, cb_propcorrect\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndata_cvstm &lt;- read_delim(\"data/raw/data_cvstm.csv\", delim = \";\")\n\nRows: 159 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\ndbl (3): code, csvtm_sum, cvstm_propcorrect\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndata_pct &lt;- read_delim(\"data/raw/data_pct.csv\", \";\")\n\nRows: 159 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr (1): group_all\ndbl (5): code_all, mean_rl_all, mean_e1_all, mean_d1_all, mean_d_all\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndata_vp &lt;- read_delim(\"data/raw/data_vp.csv\" , \";\")\n\nRows: 159 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\ndbl (3): code, vp_sum, vp_propcorrect\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nWie in der Aufgabenstellung bereits beschrieben verwendet read_csv() automatisch das Komma als Trennzeichen. Daher werden die Datensätze hier zwar eingelesen, sind dann allerdings nicht korrekt formatiert. Wenn die Daten mit einem anderen Trennzeichen getrennt sind, muss eine andere Funktion verwendet werden, z.B. read_delim(), bei der das Trennzeichen explizit angegeben werden muss.\n\nF\n\n[1] FALSE\n\n\n\n\n\n-   Verwende den von R-Studio generierten Code, und passe ihn an um einen weiteren Datensatz einzulesen (z.B. indem du den Filenamen veränderst).\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndata_mmq &lt;- read_delim(\"data/raw/data_mmq.csv\",\n                      delim = \";\")\n\nRows: 159 Columns: 19\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\ndbl (19): code, question1, question2, question3, question4, question5, quest...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\nKorrigiere diesen Code und lies damit die Datei data_vp ein (überprüfe den Pfad und den Delimiter)\n\n\n# data_vp &lt;- read_delim(\"/raw/data_vp.csv\", \n#     delim = \",\")\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n# Was wir dir vorgegeben hatten:\n# data_vp &lt;- read_delim(\"/raw/data_vp.csv\", \n#    delim = \",\")\n\n# Korrigierter Code:\ndata_vp &lt;- read_delim(\"data/raw/data_vp.csv\",\n                      delim = \";\")\n\n\n\n\n\n\n.XSLX Dateien\n\nEinige Dateien liegen im .xlsx-Format.\n\nVerwende dafür das Paket readxl und die Funktion read_excel(). Tipp: Installiere und lade das Paket zunächst.\nNutze die Hilfefunktion (?read_excel) für Infos zur Funktion oder schaue dir das Cheatsheet an\nVersuche, die Datensätze data_ratings und data_strategies einzulesen.\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n# install.packages(\"readxl\") # den Code führst du einmalig in deiner Console aus\nlibrary(readxl)\n\n?read_excel() # Aufruf der Dokumentation\n\ndata_ratings &lt;- read_excel(\"data/raw/data_ratings.xlsx\") # erstellt über RStudio Environment\n\ndata_strategies &lt;- read_excel(\"data/raw/data_strategies.xlsx\") # kopiert und angepasst\n\n\n\n\n\nAm Ende solltest du die 7 verschiedene Datensätze in deinem Environment sehen.\n\n\n\n\n\n\n\nVertiefung\n\n\n\n\n\n👉Für das Einlesen anderer Arten von Datensätzen (z.B. SPSS Dateien), siehe Kapitel 3.2",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 2 (Woche 3 - 4) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_2.html#aufgaben",
    "href": "scripts/02_excercises/loesung_2.html#aufgaben",
    "title": "Lösung 2",
    "section": "Aufgaben",
    "text": "Aufgaben\n\nFüge alle 7 Datensätze mit cbind() zusammen und schaue dir das Ergebnis an.\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndat_cbind &lt;- cbind(data_mmq, data_cb, data_cvstm, data_pct, data_vp, data_ratings, data_strategies)\n\n\n\n\n\nWas fällt dir auf?\n\nHinweis: Die Datensätze werden einfach nebeneinander „geklebt“, ohne inhaltlich abgeglichen zu werden.\n\nReflektiere: Macht das Sinn? Was sind die Gefahren, Daten auf diese Art zu mergen?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\nSinn ergibt das einfache “kleben” über cbind nicht. Nur für den Fall das alle Datensätze in der entsprechenden Zeile dieselbe Versuchsperson abdecken wäre das einfache zusammenkleben überhaupt zulässig. Andernfalls würden Einträge von Versuchspersonen vermischt werden.\n\n\n\n\n\n\nVersuche es nun mit full_join().\nFull_join verbindet zwei Datensätze anhand einer Schlüsselvariable, so dass alle Zeilen aus beiden Datensätzen erhalten bleiben. Die Schlüsselvariable ist essentiell dafür dass die Datensätze richtig verbunden werden (Anordnung der Variablen), und grenzt sich dadurch von Funktionen wie cbind() ab.\n\n\nLege eine gemeinsame Variable als Schlüssel fest, hier: by = \"code\".\nFüge nun alle 7 Datensätze zu einem zusammen, nenne diesen dat_full\n\nAchtung: full_join() funktioniert immer nur mit 2 Datensätzen gleichzeitig 👉 du musst es also mehrfach anwenden, um alle 7 Datensätze zusammenzuführen.\nHinweis: Im Datensatz data_pct heißt die Code-Variable leicht anders. Verwende deshalb by = c(\"code_all\" = \"code\").\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ purrr     1.0.2\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# Hier werden zu Beginn die beiden Datensätze data_mmq und data_cb zusammengefügt und in dat_step_1 gespeichert (über `code` wird sichergestellt, dass die passenden Zeilen hintereinander stehen)\ndat_step_1 &lt;- full_join(data_mmq, data_cb, by = \"code\")\n\n# Hier wird data_cvstm an dat_step_1 angefügt und in dat_step_2 gespeichert.\ndat_step_2 &lt;- full_join(dat_step_1, data_cvstm, by = \"code\")\n\n# ...\ndat_step_3 &lt;- full_join(dat_step_2, data_pct, by = c(\"code\" = \"code_all\"))\n\ndat_step_4 &lt;- full_join(dat_step_3, data_vp, by = \"code\")\n\ndat_step_5 &lt;- full_join(dat_step_4, data_ratings, by = \"code\")\n\ndat_full &lt;- full_join(dat_step_5, data_strategies, by = \"code\")\n\n# Eine alternative Schreibweise (welche die Pipe verwendet, die wir erst noch näher kennenlernen werden):\n\ndat_full &lt;- data_mmq %&gt;%\n  full_join(data_cb, by = \"code\") %&gt;%\n  full_join(data_cvstm, by = \"code\") %&gt;%\n  full_join(data_pct, by = c(\"code\" = \"code_all\")) %&gt;%\n  full_join(data_vp, by = \"code\") %&gt;%\n  full_join(data_ratings, by = \"code\") %&gt;%\n  full_join(data_strategies, by = \"code\")\n\n\n\n\n\n\n\nInspiziere deinen zusammengefügten Datensatz “dat_full”\n\n🔍Überprüfe: Wie viele Zeilen und Spalten hat dein Datensatz? Verwende: ncol() , nrow(), dim()\n\nStimmt die Anzahl der Zeilen mit der Anzahl der Versuchspersonen aus dem Paper überein?\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nncol(dat_full) # Anzahl der Spalten\n\n[1] 36\n\nnrow(dat_full) # Anzahl der Zeilen\n\n[1] 159\n\ndim(dat_full)  # Anzahl der Zeilen und Spalten\n\n[1] 159  36\n\n\nDer vollständige Datensatz enthält Informationen von 159 Versuchspersonen. Das entspricht der Angabe aus dem Paper von Grinschgl et al., 2020.\n\n\n\n\n👀Verschaffe dir eine Überblick über deinen Datensatz mit den Funktionen, die wir schon im letzten Hands On getestet haben:\n\nLasse dir die Variablenamen ausgeben mit names()\nhead()\nglimpse()\nstr()\ndat_full\nsummary()\n\nGibt es redundante oder doppelte Variablen?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nnames(dat_full)\n\n [1] \"code\"              \"question1\"         \"question2\"        \n [4] \"question3\"         \"question4\"         \"question5\"        \n [7] \"question6\"         \"question7\"         \"question8\"        \n[10] \"question9\"         \"question10\"        \"question11\"       \n[13] \"question12\"        \"question13\"        \"question14\"       \n[16] \"question15\"        \"question16\"        \"question17\"       \n[19] \"question18\"        \"cb_sum\"            \"cb_propcorrect\"   \n[22] \"csvtm_sum\"         \"cvstm_propcorrect\" \"group_all\"        \n[25] \"mean_rl_all\"       \"mean_e1_all\"       \"mean_d1_all\"      \n[28] \"mean_d_all\"        \"vp_sum\"            \"vp_propcorrect\"   \n[31] \"pre1\"              \"pre2\"              \"pre3\"             \n[34] \"pre4\"              \"post\"              \"strategies\"       \n\nhead(dat_full)\n\n# A tibble: 6 × 36\n   code question1 question2 question3 question4 question5 question6 question7\n  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1     1         2         3         3         3         2         3         3\n2     2         3         4         3         4         3         3         3\n3     3         2         3         2         1         2         2         2\n4     4         1         2         2         3         1         2         2\n5     5         3         4         4         2         4         4         4\n6     6         1         3         3         4         3         3         3\n# ℹ 28 more variables: question8 &lt;dbl&gt;, question9 &lt;dbl&gt;, question10 &lt;dbl&gt;,\n#   question11 &lt;dbl&gt;, question12 &lt;dbl&gt;, question13 &lt;dbl&gt;, question14 &lt;dbl&gt;,\n#   question15 &lt;dbl&gt;, question16 &lt;dbl&gt;, question17 &lt;dbl&gt;, question18 &lt;dbl&gt;,\n#   cb_sum &lt;dbl&gt;, cb_propcorrect &lt;dbl&gt;, csvtm_sum &lt;dbl&gt;,\n#   cvstm_propcorrect &lt;dbl&gt;, group_all &lt;chr&gt;, mean_rl_all &lt;dbl&gt;,\n#   mean_e1_all &lt;dbl&gt;, mean_d1_all &lt;dbl&gt;, mean_d_all &lt;dbl&gt;, vp_sum &lt;dbl&gt;,\n#   vp_propcorrect &lt;dbl&gt;, pre1 &lt;dbl&gt;, pre2 &lt;dbl&gt;, pre3 &lt;dbl&gt;, pre4 &lt;dbl&gt;, …\n\nglimpse(dat_full)\n\nRows: 159\nColumns: 36\n$ code              &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 1…\n$ question1         &lt;dbl&gt; 2, 3, 2, 1, 3, 1, 1, 1, 2, 1, 4, 2, 3, 3, 3, 0, 0, 1…\n$ question2         &lt;dbl&gt; 3, 4, 3, 2, 4, 3, 3, 2, 3, 4, 2, 3, 4, 3, 4, 1, 1, 4…\n$ question3         &lt;dbl&gt; 3, 3, 2, 2, 4, 3, 3, 3, 3, 4, 4, 3, 4, 4, 3, 2, 1, 3…\n$ question4         &lt;dbl&gt; 3, 4, 1, 3, 2, 4, 1, 3, 3, 4, 4, 2, 4, 3, 3, 1, 1, 3…\n$ question5         &lt;dbl&gt; 2, 3, 2, 1, 4, 3, 2, 2, 3, 3, 3, 2, 3, 3, 4, 0, 0, 3…\n$ question6         &lt;dbl&gt; 3, 3, 2, 2, 4, 3, 2, 1, 3, 4, 3, 1, 3, 3, 3, 1, 0, 3…\n$ question7         &lt;dbl&gt; 3, 3, 2, 2, 4, 3, 0, 2, 3, 4, 4, 1, 4, 3, 3, 1, 1, 4…\n$ question8         &lt;dbl&gt; 3, 3, 2, 0, 3, 4, 1, 3, 3, 3, 4, 3, 4, 3, 3, 0, 2, 3…\n$ question9         &lt;dbl&gt; 2, 3, 1, 2, 1, 4, 2, 1, 3, 2, 0, 0, 2, 1, 3, 3, 1, 1…\n$ question10        &lt;dbl&gt; 3, 3, 1, 3, 4, 4, 1, 2, 3, 4, 3, 1, 4, 3, 4, 0, 1, 4…\n$ question11        &lt;dbl&gt; 3, 3, 1, 1, 3, 3, 1, 1, 3, 3, 3, 1, 3, 2, 3, 1, 2, 2…\n$ question12        &lt;dbl&gt; 3, 3, 2, 1, 3, 3, 1, 2, 3, 3, 4, 1, 3, 3, 3, 1, 1, 3…\n$ question13        &lt;dbl&gt; 2, 3, 1, 3, 1, 2, 1, 1, 2, 2, 3, 0, 2, 2, 1, 3, 1, 3…\n$ question14        &lt;dbl&gt; 2, 2, 0, 2, 1, 3, 0, 1, 2, 3, 3, 0, 3, 3, 3, 2, 0, 3…\n$ question15        &lt;dbl&gt; 3, 4, 2, 2, 4, 3, 1, 4, 3, 4, 4, 3, 4, 3, 4, 1, 2, 4…\n$ question16        &lt;dbl&gt; 2, 4, 1, 1, 2, 3, 1, 1, 2, 3, 3, 0, 2, 2, 3, 1, 0, 1…\n$ question17        &lt;dbl&gt; 3, 3, 2, 1, 3, 3, 1, 1, 2, 3, 2, 2, 2, 2, 3, 0, 1, 3…\n$ question18        &lt;dbl&gt; 2, 3, 0, 0, 4, 3, 1, 1, 3, 4, 3, 1, 4, 3, 3, 0, 1, 3…\n$ cb_sum            &lt;dbl&gt; 26, 27, 30, 27, 25, 23, 28, 27, 30, 26, 29, 29, 26, …\n$ cb_propcorrect    &lt;dbl&gt; 0.7222222, 0.7500000, 0.8333333, 0.7500000, 0.694444…\n$ csvtm_sum         &lt;dbl&gt; 70, 73, 93, 83, 79, 72, 94, 85, 72, 90, 96, 91, 106,…\n$ cvstm_propcorrect &lt;dbl&gt; 0.5833333, 0.6083333, 0.7750000, 0.6916667, 0.658333…\n$ group_all         &lt;chr&gt; \"above\", \"control\", \"below\", \"below\", \"above\", \"cont…\n$ mean_rl_all       &lt;dbl&gt; 5.95, 5.35, 4.80, 6.55, 6.15, 6.05, 5.00, 5.40, 4.50…\n$ mean_e1_all       &lt;dbl&gt; 3.05, 3.25, 3.25, 2.55, 2.50, 3.05, 3.30, 3.30, 3.45…\n$ mean_d1_all       &lt;dbl&gt; 3.900720, 16.393639, 5.576016, 4.738268, 5.529630, 8…\n$ mean_d_all        &lt;dbl&gt; 32.77313, 71.17568, 36.18764, 44.01890, 42.33930, 45…\n$ vp_sum            &lt;dbl&gt; 33, 27, 33, 31, 32, 24, 28, 27, 28, 26, 34, 18, 32, …\n$ vp_propcorrect    &lt;dbl&gt; 0.9166667, 0.7500000, 0.9166667, 0.8611111, 0.888888…\n$ pre1              &lt;dbl&gt; 6.2, 5.5, 8.7, 5.2, 8.1, 4.9, 6.8, 6.5, 5.2, 6.6, 6.…\n$ pre2              &lt;dbl&gt; 7.5, 5.5, 4.5, 0.9, 4.6, 3.3, 4.2, 1.8, 6.6, 1.5, 7.…\n$ pre3              &lt;dbl&gt; 7.4, 2.5, 2.5, 1.1, 6.7, 2.9, 7.0, 1.9, 6.3, 1.8, 6.…\n$ pre4              &lt;dbl&gt; 6.2, 4.4, 2.5, 0.6, 6.2, 2.1, 2.0, 2.3, 6.5, 2.0, 8.…\n$ post              &lt;dbl&gt; 7.0, 2.1, 3.2, 0.6, 6.3, 2.2, 5.2, 2.1, 7.0, 1.8, 7.…\n$ strategies        &lt;dbl&gt; 1, 1, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 2, 1, 1…\n\nstr(dat_full)\n\nspc_tbl_ [159 × 36] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ code             : num [1:159] 1 2 3 4 5 6 7 8 9 10 ...\n $ question1        : num [1:159] 2 3 2 1 3 1 1 1 2 1 ...\n $ question2        : num [1:159] 3 4 3 2 4 3 3 2 3 4 ...\n $ question3        : num [1:159] 3 3 2 2 4 3 3 3 3 4 ...\n $ question4        : num [1:159] 3 4 1 3 2 4 1 3 3 4 ...\n $ question5        : num [1:159] 2 3 2 1 4 3 2 2 3 3 ...\n $ question6        : num [1:159] 3 3 2 2 4 3 2 1 3 4 ...\n $ question7        : num [1:159] 3 3 2 2 4 3 0 2 3 4 ...\n $ question8        : num [1:159] 3 3 2 0 3 4 1 3 3 3 ...\n $ question9        : num [1:159] 2 3 1 2 1 4 2 1 3 2 ...\n $ question10       : num [1:159] 3 3 1 3 4 4 1 2 3 4 ...\n $ question11       : num [1:159] 3 3 1 1 3 3 1 1 3 3 ...\n $ question12       : num [1:159] 3 3 2 1 3 3 1 2 3 3 ...\n $ question13       : num [1:159] 2 3 1 3 1 2 1 1 2 2 ...\n $ question14       : num [1:159] 2 2 0 2 1 3 0 1 2 3 ...\n $ question15       : num [1:159] 3 4 2 2 4 3 1 4 3 4 ...\n $ question16       : num [1:159] 2 4 1 1 2 3 1 1 2 3 ...\n $ question17       : num [1:159] 3 3 2 1 3 3 1 1 2 3 ...\n $ question18       : num [1:159] 2 3 0 0 4 3 1 1 3 4 ...\n $ cb_sum           : num [1:159] 26 27 30 27 25 23 28 27 30 26 ...\n $ cb_propcorrect   : num [1:159] 0.722 0.75 0.833 0.75 0.694 ...\n $ csvtm_sum        : num [1:159] 70 73 93 83 79 72 94 85 72 90 ...\n $ cvstm_propcorrect: num [1:159] 0.583 0.608 0.775 0.692 0.658 ...\n $ group_all        : chr [1:159] \"above\" \"control\" \"below\" \"below\" ...\n $ mean_rl_all      : num [1:159] 5.95 5.35 4.8 6.55 6.15 6.05 5 5.4 4.5 6 ...\n $ mean_e1_all      : num [1:159] 3.05 3.25 3.25 2.55 2.5 3.05 3.3 3.3 3.45 2.65 ...\n $ mean_d1_all      : num [1:159] 3.9 16.39 5.58 4.74 5.53 ...\n $ mean_d_all       : num [1:159] 32.8 71.2 36.2 44 42.3 ...\n $ vp_sum           : num [1:159] 33 27 33 31 32 24 28 27 28 26 ...\n $ vp_propcorrect   : num [1:159] 0.917 0.75 0.917 0.861 0.889 ...\n $ pre1             : num [1:159] 6.2 5.5 8.7 5.2 8.1 4.9 6.8 6.5 5.2 6.6 ...\n $ pre2             : num [1:159] 7.5 5.5 4.5 0.9 4.6 3.3 4.2 1.8 6.6 1.5 ...\n $ pre3             : num [1:159] 7.4 2.5 2.5 1.1 6.7 2.9 7 1.9 6.3 1.8 ...\n $ pre4             : num [1:159] 6.2 4.4 2.5 0.6 6.2 2.1 2 2.3 6.5 2 ...\n $ post             : num [1:159] 7 2.1 3.2 0.6 6.3 2.2 5.2 2.1 7 1.8 ...\n $ strategies       : num [1:159] 1 1 2 2 1 2 2 2 1 2 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   code = col_double(),\n  ..   question1 = col_double(),\n  ..   question2 = col_double(),\n  ..   question3 = col_double(),\n  ..   question4 = col_double(),\n  ..   question5 = col_double(),\n  ..   question6 = col_double(),\n  ..   question7 = col_double(),\n  ..   question8 = col_double(),\n  ..   question9 = col_double(),\n  ..   question10 = col_double(),\n  ..   question11 = col_double(),\n  ..   question12 = col_double(),\n  ..   question13 = col_double(),\n  ..   question14 = col_double(),\n  ..   question15 = col_double(),\n  ..   question16 = col_double(),\n  ..   question17 = col_double(),\n  ..   question18 = col_double()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt; \n\ndat_full\n\n# A tibble: 159 × 36\n    code question1 question2 question3 question4 question5 question6 question7\n   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1     1         2         3         3         3         2         3         3\n 2     2         3         4         3         4         3         3         3\n 3     3         2         3         2         1         2         2         2\n 4     4         1         2         2         3         1         2         2\n 5     5         3         4         4         2         4         4         4\n 6     6         1         3         3         4         3         3         3\n 7     7         1         3         3         1         2         2         0\n 8     8         1         2         3         3         2         1         2\n 9     9         2         3         3         3         3         3         3\n10    10         1         4         4         4         3         4         4\n# ℹ 149 more rows\n# ℹ 28 more variables: question8 &lt;dbl&gt;, question9 &lt;dbl&gt;, question10 &lt;dbl&gt;,\n#   question11 &lt;dbl&gt;, question12 &lt;dbl&gt;, question13 &lt;dbl&gt;, question14 &lt;dbl&gt;,\n#   question15 &lt;dbl&gt;, question16 &lt;dbl&gt;, question17 &lt;dbl&gt;, question18 &lt;dbl&gt;,\n#   cb_sum &lt;dbl&gt;, cb_propcorrect &lt;dbl&gt;, csvtm_sum &lt;dbl&gt;,\n#   cvstm_propcorrect &lt;dbl&gt;, group_all &lt;chr&gt;, mean_rl_all &lt;dbl&gt;,\n#   mean_e1_all &lt;dbl&gt;, mean_d1_all &lt;dbl&gt;, mean_d_all &lt;dbl&gt;, vp_sum &lt;dbl&gt;, …\n\nsummary(dat_full)\n\n      code         question1       question2       question3    \n Min.   :  1.0   Min.   :0.000   Min.   :0.000   Min.   :0.000  \n 1st Qu.: 40.5   1st Qu.:1.500   1st Qu.:3.000   1st Qu.:3.000  \n Median : 80.0   Median :2.000   Median :3.000   Median :3.000  \n Mean   : 80.0   Mean   :2.195   Mean   :3.214   Mean   :3.126  \n 3rd Qu.:119.5   3rd Qu.:3.000   3rd Qu.:4.000   3rd Qu.:4.000  \n Max.   :159.0   Max.   :4.000   Max.   :4.000   Max.   :4.000  \n   question4       question5       question6       question7    \n Min.   :0.000   Min.   :0.000   Min.   :0.000   Min.   :0.000  \n 1st Qu.:2.000   1st Qu.:2.000   1st Qu.:2.000   1st Qu.:2.000  \n Median :3.000   Median :3.000   Median :3.000   Median :3.000  \n Mean   :2.811   Mean   :2.509   Mean   :2.491   Mean   :2.623  \n 3rd Qu.:4.000   3rd Qu.:3.000   3rd Qu.:3.000   3rd Qu.:3.000  \n Max.   :4.000   Max.   :4.000   Max.   :4.000   Max.   :4.000  \n   question8       question9       question10      question11   \n Min.   :0.000   Min.   :0.000   Min.   :0.000   Min.   :0.000  \n 1st Qu.:3.000   1st Qu.:1.000   1st Qu.:2.000   1st Qu.:2.000  \n Median :3.000   Median :2.000   Median :3.000   Median :3.000  \n Mean   :2.943   Mean   :1.994   Mean   :2.843   Mean   :2.692  \n 3rd Qu.:4.000   3rd Qu.:3.000   3rd Qu.:4.000   3rd Qu.:4.000  \n Max.   :4.000   Max.   :4.000   Max.   :4.000   Max.   :4.000  \n   question12      question13      question14      question15   \n Min.   :0.000   Min.   :0.000   Min.   :0.000   Min.   :0.000  \n 1st Qu.:2.000   1st Qu.:1.000   1st Qu.:1.000   1st Qu.:3.000  \n Median :3.000   Median :2.000   Median :2.000   Median :3.000  \n Mean   :2.516   Mean   :1.937   Mean   :1.962   Mean   :3.182  \n 3rd Qu.:3.000   3rd Qu.:3.000   3rd Qu.:3.000   3rd Qu.:4.000  \n Max.   :4.000   Max.   :4.000   Max.   :4.000   Max.   :4.000  \n   question16      question17      question18        cb_sum     \n Min.   :0.000   Min.   :0.000   Min.   :0.000   Min.   :18.00  \n 1st Qu.:1.000   1st Qu.:2.000   1st Qu.:2.000   1st Qu.:26.00  \n Median :1.000   Median :2.000   Median :3.000   Median :27.00  \n Mean   :1.736   Mean   :2.327   Mean   :2.748   Mean   :27.49  \n 3rd Qu.:3.000   3rd Qu.:3.000   3rd Qu.:4.000   3rd Qu.:30.00  \n Max.   :4.000   Max.   :4.000   Max.   :4.000   Max.   :35.00  \n cb_propcorrect     csvtm_sum      cvstm_propcorrect  group_all        \n Min.   :0.5000   Min.   : 70.00   Min.   :0.5833    Length:159        \n 1st Qu.:0.7222   1st Qu.: 81.00   1st Qu.:0.6750    Class :character  \n Median :0.7500   Median : 88.00   Median :0.7333    Mode  :character  \n Mean   :0.7636   Mean   : 87.96   Mean   :0.7330                      \n 3rd Qu.:0.8333   3rd Qu.: 93.00   3rd Qu.:0.7750                      \n Max.   :0.9722   Max.   :113.00   Max.   :0.9417                      \n  mean_rl_all     mean_e1_all     mean_d1_all       mean_d_all   \n Min.   :2.700   Min.   :1.650   Min.   : 1.903   Min.   :27.54  \n 1st Qu.:4.475   1st Qu.:2.825   1st Qu.: 4.612   1st Qu.:35.50  \n Median :4.950   Median :3.250   Median : 5.576   Median :39.88  \n Mean   :5.209   Mean   :3.261   Mean   : 6.903   Mean   :42.20  \n 3rd Qu.:5.975   3rd Qu.:3.600   3rd Qu.: 8.109   3rd Qu.:46.16  \n Max.   :8.450   Max.   :5.550   Max.   :19.526   Max.   :77.57  \n     vp_sum      vp_propcorrect        pre1            pre2      \n Min.   :18.00   Min.   :0.5000   Min.   :0.600   Min.   :0.500  \n 1st Qu.:28.00   1st Qu.:0.7778   1st Qu.:4.750   1st Qu.:3.350  \n Median :31.00   Median :0.8611   Median :5.400   Median :4.800  \n Mean   :30.29   Mean   :0.8414   Mean   :5.441   Mean   :4.662  \n 3rd Qu.:33.00   3rd Qu.:0.9167   3rd Qu.:6.300   3rd Qu.:5.900  \n Max.   :36.00   Max.   :1.0000   Max.   :9.100   Max.   :8.400  \n      pre3            pre4            post         strategies   \n Min.   :0.400   Min.   :0.500   Min.   :0.400   Min.   :1.000  \n 1st Qu.:2.600   1st Qu.:3.150   1st Qu.:3.100   1st Qu.:1.000  \n Median :4.600   Median :4.900   Median :5.000   Median :2.000  \n Mean   :4.401   Mean   :4.714   Mean   :4.727   Mean   :1.717  \n 3rd Qu.:6.000   3rd Qu.:6.200   3rd Qu.:6.200   3rd Qu.:2.000  \n Max.   :8.800   Max.   :9.600   Max.   :9.300   Max.   :3.000  \n\n\nEs gibt keine redundanten oder doppelten Variablen.\n\n\n\nAuf einzelne Werte zugreiffen:\n\nGreife auf den ersten Wert der ersten Spalte zu: Verwende eckige Klammern. Der erste Wert in der Klammer steht für die Zeile, der zweite für die Spalte.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndat_full[1, 1]\n\n# A tibble: 1 × 1\n   code\n  &lt;dbl&gt;\n1     1\n\n\n\n\n\n\nGreife auf die Werte der Spalten 1–15 in der ersten Zeile zu. Verwende wieder eckige Klammern und den Bereichsoperator 1:15.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndat_full[1, 1:15]\n\n# A tibble: 1 × 15\n   code question1 question2 question3 question4 question5 question6 question7\n  &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1     1         2         3         3         3         2         3         3\n# ℹ 7 more variables: question8 &lt;dbl&gt;, question9 &lt;dbl&gt;, question10 &lt;dbl&gt;,\n#   question11 &lt;dbl&gt;, question12 &lt;dbl&gt;, question13 &lt;dbl&gt;, question14 &lt;dbl&gt;\n\n\n\n\n\n\nLasse dir alle Werte der Variable \"mean_rl_all\" ausgeben. Auf Variablen greifst du mit $ zu.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndat_full$mean_rl_all\n\n  [1] 5.95 5.35 4.80 6.55 6.15 6.05 5.00 5.40 4.50 6.00 4.65 4.60 4.50 5.05 3.95\n [16] 3.20 3.85 3.95 5.05 4.65 4.90 5.90 6.20 3.30 5.55 6.00 4.70 4.25 8.00 3.75\n [31] 3.85 4.60 4.65 7.65 5.45 5.70 6.75 6.45 4.90 7.30 4.45 4.15 4.95 3.75 4.15\n [46] 4.10 4.25 5.55 8.45 6.30 4.60 4.85 5.40 4.30 4.90 6.45 3.70 3.95 4.75 2.90\n [61] 7.50 3.55 6.35 6.60 3.70 6.15 4.00 3.45 6.15 7.35 6.80 4.70 6.70 4.75 5.90\n [76] 4.50 4.40 3.35 4.75 5.60 5.80 7.65 6.00 4.30 4.70 4.95 5.00 5.00 3.85 5.90\n [91] 5.80 6.10 4.65 4.85 4.40 6.10 4.40 4.90 5.90 3.60 4.95 6.75 4.85 4.05 3.20\n[106] 5.95 4.35 4.60 7.75 4.60 7.90 6.95 6.55 2.70 4.75 5.65 7.05 4.80 4.90 6.35\n[121] 4.95 6.00 5.55 7.00 5.15 5.80 5.90 5.30 4.55 5.55 5.75 4.50 5.35 4.25 4.90\n[136] 4.50 4.45 4.20 6.30 6.25 6.80 5.50 5.15 4.50 4.65 4.25 5.45 4.60 6.05 5.45\n[151] 5.10 5.90 5.05 4.45 5.80 3.45 5.30 6.75 4.20\n\n\n\n\n\n\nGreife auf die ersten 10 Werte der Variable \"question1\" zu. Verwende dazu den $-Operator in Kombination mit dem Bereichsoperator 1:10.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndat_full$question1[1:10]\n\n [1] 2 3 2 1 3 1 1 1 2 1",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 2 (Woche 3 - 4) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_2.html#tab-completion",
    "href": "scripts/02_excercises/loesung_2.html#tab-completion",
    "title": "Lösung 2",
    "section": "Tab Completion:",
    "text": "Tab Completion:\nEine nützliche Funktion von RStudio ist die Tab Completion. Wenn du eine Funktion aufrufst und die Tabulator-Taste drückst, erscheint ein Menü mit den möglichen Argumenten, die du angeben kannst. Probiere es mit der Funktion mean(). Das funktioniert auch für Funktionen aus Paketen, wenn du diese mit :: auswählst, zum Beispiel: readr::.\n\n\n\n\n\n\nAnmerkung\n\n\n\n\n\n\n# readr::\n\n# mean(\n\n# Die Lösung hierzu kann ich euch nicht darstellen, da es sich um ein Feature von RStudio handelt, welches nur \"live\" angezeigt wird. Ihr könnt aber den hier auskommentierten Code verwenden und es damit ausprobieren",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 2 (Woche 3 - 4) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_2.html#weitere-tasten-und-tastenkürzel",
    "href": "scripts/02_excercises/loesung_2.html#weitere-tasten-und-tastenkürzel",
    "title": "Lösung 2",
    "section": "Weitere Tasten und Tastenkürzel:",
    "text": "Weitere Tasten und Tastenkürzel:\n👉Kapitel 1.4.6\nIn RStudio benötigen wir häufig Zeichen, die wir im Alltag kaum verwenden. Da wir nicht alle mit dem gleichen Betriebssystem (Mac/Windows) und auch nicht mit identischen Tastaturen arbeiten, können wir keine einheitlichen Angaben machen, wo sich diese Zeichen genau befinden. Versuche daher, die folgenden Zeichen auf deiner eigenen Tastatur zu finden:\n\n[ ] Square brackets (eckige Klammern)\n{ } Curly brackets (geschweifte Klammern)\n$ Dollar sign (Dollarzeichen – wird für das Auswählen von Variablen benötigt)\n# Hash (Rautezeichen – für Kommentare in R-Skripten)\n~ Tilde (für Modellnotationen in R; brauchen wir v.a. am Ende des Semesters bei den Analysen)\n| Vertical bar (senkrechter Strich – als logischer Operator)\n` Backtick (Gravis – vor allem für Code Chunks, selten manuell einzugeben)",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 2 (Woche 3 - 4) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_2.html#verschachtelte-funktionen",
    "href": "scripts/02_excercises/loesung_2.html#verschachtelte-funktionen",
    "title": "Lösung 2",
    "section": "Verschachtelte Funktionen:",
    "text": "Verschachtelte Funktionen:\nℹ️Es ist zwar möglich, mehrere Funktionen ineinander zu verschachteln. Dies kann jedoch schnell zu Verwirrung führen und den Code unnötig unübersichtlich machen. Verschachtelte Funktionen werden von innen nach aussen ausgeführt.\n❓Stelle dir hier die Frage: Was wird genau gerundet? Die einzelnen Elemente des Vektors oder der errechnete Durchschnitt?\n\nprint(mean(round(first_vector)))\n\n[1] 5785.25\n\n\n❗Aufgabe: Zerlege die Verschatelte Funktion in ihre Teilschritte.\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nrounded_values &lt;- round(first_vector)\nmittelwert &lt;- mean(rounded_values)\nprint(mittelwert)\n\n[1] 5785.25",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 2 (Woche 3 - 4) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_1.html",
    "href": "scripts/02_excercises/loesung_1.html",
    "title": "Lösung 1",
    "section": "",
    "text": "Bei Bedarf finden sich hier nochmal die Slides zur EH1: \n\n\nInstalliere R und RStudio:\n\nInstallation von R – neueste Version 4.5.1: https://stat.ethz.ch/CRAN/\nInstallation von Rstudio (Version 2025.05.1): https://posit.co/download/rstudio-desktop/\n\nDu weisst nicht was mit R auf sich hat? Hier ist eine Kurzerklärung: https://methodenlehre.github.io/einfuehrung-in-R/\n\n\n\n\nRStudio öffnen & Einstellungen vornehmen: Unter «tools» –«global options» die unter 1.1. beschriebenen Einstellungen vornehmen: https://methodenlehre.github.io/einfuehrung-in-R/chapters/01-workflow.html\n\n\n\nNeues Skript öffnen & orientieren:\n\n\n\n\nIm folgenden machen wir uns vertraut mit der Oberfläche von R-Studio:\n\n\n\n\n\n\n\nSkript für Code-Eingabe sowie Kommentare\nKonsole für die Ausführung von Code -&gt; Teste einfache mathematische Operation in dieser; reproduziere diese mittels Skript\nRechts oben: Environment & History\nRechts unten: Files, Plots, Packages und Help Viewer\n\n\n\n\nTidyverse ist ein Meta-Paket, das mehrere Pakete umfasst\n\nPakete installieren (nur 1x notwendig) -&gt; führe diesen Code in der Konsole aus\n\ninstall.packages(\"tidyverse\")\n\nPaket laden (innerhalb des Skriptes, bei jedem Neustart von R notwendig)\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\nTipp: Pakete regelmässig updaten mit z.B. update.packages()\n\n\n\na. Nutze R als Taschenrechner\n\n123+456\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n123 + 456\n\n[1] 579\n\n\n\n\n\n2.  `144*112`\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n144*112\n\n[1] 16128\n\n\n\n\n\n3.  `10/3`\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n10/3\n\n[1] 3.333333\n\n\n\n\n\n4.  Quadriere 420\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n420^2\n\n[1] 176400\n\n\n\n\n\n5.  Ziehe die Quadratwurzel aus 146 mit der Funktion `sqrt()`\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsqrt(146)\n\n[1] 12.08305\n\n\n\n\n\n6.  Berechne den Rest der Division 10/3 mit dem Modulo Operator: `%%`\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n10 %% 3\n\n[1] 1\n\n\n\n\n\n\n\n\n\n\nZeichen\nBedeutung\n\n\n\n\n+\nAddition\n\n\n-\nSubstraktion\n\n\n*\nMultiplikation\n\n\n/\nDivision\n\n\nsqrt(x)\nQuadratwurzel\n\n\nabs(x)\nBetrag (absoluter Wert)\n\n\nx %% y\nModulo (x mod y) 5 %% 2 = 1\n\n\n^\nPotenz\n\n\n\n\n\n\n\n\nWeise den Wert 5 der Variable x zu mit dem Operator &lt;-\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nx &lt;- 5\n\n\n\n\n\nWeise eine beliebige Zahl der Variable y hinzu und dividiere dann x durch y. Speichere dieses Ergebnis in der Variable z.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ny &lt;- 10 # hier könntet ihr auch jede andere Ziffer wählen\n\nz &lt;- x / y\n\n\n\n\n\nSchaue dir das Ergebnis in deinem Environment an. Lass dir das Ergebnis auch in der Konsole ausgeben. Das Environment findest du oben rechts, die Konsole ist unter deinem Skript.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n# z (hier über das # auskommentiert, da der Befehl nicht im Skript, sondern unten in der Konsole ausgeführt werden soll)\n\n\n\n\n\nErstelle zwei Variablen: Eine mit deinem Vornamen und eine mit deinem Nachnamen. Solche “character” Variablen musst du in Anführungszeichen setzen \"\"\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nvorname &lt;- \"Lars\"\nnachname &lt;- \"Schilling\"\n\n\n\n\n\nKombiniere deinen Vor- und Nachnamen zu deinem vollen Namen mittels paste . Speichere diese Variable als voller_name.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nvoller_name &lt;- paste(vorname, nachname)\n\n\n\n\n\n\n\n\nDefiniere einen Vektor «first_vector» mit den Zahlen 100, 80, 54, 73. Einen Vektor definiert man so: first_vector &lt;- c(...)\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nfirst_vector &lt;- c(100, 80, 54, 73)\n\n\n\n\n\nWende den Befehl boxplot() auf deinen Vektor an\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nboxplot(first_vector)\n\n\n\n\n\n\n\n\n\n\n\n\nBerechne die Summe sum()und den Mittelwert mean() von deinem Vektor\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsum(first_vector)\n\n[1] 307\n\nmean(first_vector)\n\n[1] 76.75\n\n\n\n\n\n\nMultipliziere deinen Vektor mit *2\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nfirst_vector * 2\n\n[1] 200 160 108 146\n\n\n\n\n\nDie wichtigsten Operatoren und Funktionen in R: https://methodenlehre.github.io/einfuehrung-in-R/chapters/02-R-language.html\n\n\n\n\n\nFunktion\nBedeutung\n\n\n\n\nmean(x, na.rm =FALSE)\nMittelwert\n\n\nsd(x)\nStandardabweichung\n\n\nvar(x)\nVarianz\n\n\nmedian(x)\nMedian\n\n\nsum(x)\nSumme\n\n\nmin(x)\nMinimalwert\n\n\nmax(x)\nMaximalwert\n\n\nrange(x)\nMinimal - und Maximalwert\n\n\n\n\n\n\n\n\nTeste ob die Zahl 5 größer als 2 ist –&gt; TRUE or FALSE?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n5 &gt; 2\n\n[1] TRUE\n\n\nTRUE, 5 ist grösser als 2.\n\n\n\n\nTeste ob 6 ungleich 8 ist –&gt; TRUE or FALSE?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n6 != 8\n\n[1] TRUE\n\n\nTRUE, 6 und 8 sind ungleich.\n\n\n\n\nSubtrahiere 80 von 50 und speichere das Ergebnis in einer Variable namens «diff_score».\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndiff_score &lt;- 80 - 50\n\n\n\n\n\nBerechne mit abs() den absoluten Wert von «diff_score» lassen dir diesen mit print(diff_score) in der Konsole ausgeben.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndiff_score_abs &lt;- abs(diff_score)\n\n# print(diff_score_abs) (hier erneut mit # auskommentiert, da der Befehl nicht im Skript, sondern in der Console ausgeführt werden soll)\n\n\n\n\n\n\n\n\n\nZeichen\nBedeutung\n\n\n\n\n==\ngleich\n\n\n!=\nungleich\n\n\n&gt;\ngrösser\n\n\n&gt;=\ngrösser gleich\n\n\n&lt;\nkleiner\n\n\n&lt;=\nkleiner gleich\n\n\n|\nLogisches Oder\n\n\n&\nLogisches Und\n\n\n\n\n\n\n\n\n\n\nInformative Kommentare im Code sind elementar für die Nachvollziehbarkeit.\n\nSchreibe einen Kommentar indem du ein # verwendest.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n# Hier ein Beipsiel für einen Kommentar, wie auch schon weiter oben mehrmals verwendet um die Lösungen davon zu hindern ausgeführt zu werden.\n\n\n\n\n\nCode der nach einem # steht wird nicht ausgeführt. Setze ein # vor eine Codezeile und führe sie aus und beobachte was passiert.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n# 1 + 2\n\n\n\n\n\n\n\nEs gibt verschiedene Konventionen wie man Variablen bennen kann:\nhttps://methodenlehre.github.io/einfuehrung-in-R/chapters/02-R-language.html#variablennamen\n\nDefiniere eine neue Variable nach snake_case\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nneue_variable &lt;- \"snake_case\"\n\n\n\n\n\nDefiniere eine zweite Variable nach CamelCase\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nneueVariable &lt;- \"CamelCase\"\n\n\n\n\n\n\n\n\n\nSpeichere die beiden höchsten Werte aus «first_vector» in einer neuen Variable ab.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ntop_two &lt;- sort(first_vector, decreasing = TRUE)[1:2]\n\n\n\n\n\nErstelle einen Vektor mit Werten von 0-1000 in 10er Schritten.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nvec_seq &lt;- seq(from = 1, to = 1000, by = 10)\n\n\n\n\n\nZiehe zufällig eine Zahl aus diesem Vektor\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsample(vec_seq, 1)\n\n[1] 181\n\n\n\n\n\n\nGeneriere einen Vektor, der aus 50 Wiederholungen der Zahl 3 besteht.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nmy_vector &lt;- rep(3, times = 50)\n\n\n\n\nTipps zu diesen Aufgaben findest du bei Bedarf hier: https://methodenlehre.github.io/einfuehrung-in-R/chapters/02-R-language.html (Kapitel 2.1)\n\n\n\n\nnumeric vectors: werden in integer (ganze Zahlen) und double (reelle Zahlen) unterteilt, z.B.\nnumerical_vector &lt;- c(1, 2.5, 4)\ncharacter vectors: bestehen aus Zeichen, welche von Anführungszeichen umgeben werden, z.B.\ntext_vector &lt;- c(\"Hello\", \"World\")\nlogical vectors: Elemente dieses Typs können nur 3 Werte annehmen: TRUE, FALSE oder NA\nlog_vector &lt;- c(TRUE, FALSE, TRUE)\n\nVektoren müssen aus denselbsten Elementen bestehen, d.h. z.B. numeric und character können nicht gemischt werden. Vektoren werden meist mit c() erstellt.",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 1 (Woche 1 - 2) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_1.html#installation-r-und-r-studio",
    "href": "scripts/02_excercises/loesung_1.html#installation-r-und-r-studio",
    "title": "Lösung 1",
    "section": "",
    "text": "Installiere R und RStudio:\n\nInstallation von R – neueste Version 4.5.1: https://stat.ethz.ch/CRAN/\nInstallation von Rstudio (Version 2025.05.1): https://posit.co/download/rstudio-desktop/\n\nDu weisst nicht was mit R auf sich hat? Hier ist eine Kurzerklärung: https://methodenlehre.github.io/einfuehrung-in-R/",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 1 (Woche 1 - 2) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_1.html#einstellungen",
    "href": "scripts/02_excercises/loesung_1.html#einstellungen",
    "title": "Lösung 1",
    "section": "",
    "text": "RStudio öffnen & Einstellungen vornehmen: Unter «tools» –«global options» die unter 1.1. beschriebenen Einstellungen vornehmen: https://methodenlehre.github.io/einfuehrung-in-R/chapters/01-workflow.html\n\n\n\nNeues Skript öffnen & orientieren:",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 1 (Woche 1 - 2) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_1.html#hands-on-coding-basics",
    "href": "scripts/02_excercises/loesung_1.html#hands-on-coding-basics",
    "title": "Lösung 1",
    "section": "",
    "text": "Im folgenden machen wir uns vertraut mit der Oberfläche von R-Studio:\n\n\n\n\n\n\n\nSkript für Code-Eingabe sowie Kommentare\nKonsole für die Ausführung von Code -&gt; Teste einfache mathematische Operation in dieser; reproduziere diese mittels Skript\nRechts oben: Environment & History\nRechts unten: Files, Plots, Packages und Help Viewer",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 1 (Woche 1 - 2) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_1.html#pakete-installieren-und-laden",
    "href": "scripts/02_excercises/loesung_1.html#pakete-installieren-und-laden",
    "title": "Lösung 1",
    "section": "",
    "text": "Tidyverse ist ein Meta-Paket, das mehrere Pakete umfasst\n\nPakete installieren (nur 1x notwendig) -&gt; führe diesen Code in der Konsole aus\n\ninstall.packages(\"tidyverse\")\n\nPaket laden (innerhalb des Skriptes, bei jedem Neustart von R notwendig)\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\nTipp: Pakete regelmässig updaten mit z.B. update.packages()\n\n\n\na. Nutze R als Taschenrechner\n\n123+456\n\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n123 + 456\n\n[1] 579\n\n\n\n\n\n2.  `144*112`\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n144*112\n\n[1] 16128\n\n\n\n\n\n3.  `10/3`\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n10/3\n\n[1] 3.333333\n\n\n\n\n\n4.  Quadriere 420\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n420^2\n\n[1] 176400\n\n\n\n\n\n5.  Ziehe die Quadratwurzel aus 146 mit der Funktion `sqrt()`\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsqrt(146)\n\n[1] 12.08305\n\n\n\n\n\n6.  Berechne den Rest der Division 10/3 mit dem Modulo Operator: `%%`\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n10 %% 3\n\n[1] 1\n\n\n\n\n\n\n\n\n\n\nZeichen\nBedeutung\n\n\n\n\n+\nAddition\n\n\n-\nSubstraktion\n\n\n*\nMultiplikation\n\n\n/\nDivision\n\n\nsqrt(x)\nQuadratwurzel\n\n\nabs(x)\nBetrag (absoluter Wert)\n\n\nx %% y\nModulo (x mod y) 5 %% 2 = 1\n\n\n^\nPotenz\n\n\n\n\n\n\n\n\nWeise den Wert 5 der Variable x zu mit dem Operator &lt;-\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nx &lt;- 5\n\n\n\n\n\nWeise eine beliebige Zahl der Variable y hinzu und dividiere dann x durch y. Speichere dieses Ergebnis in der Variable z.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ny &lt;- 10 # hier könntet ihr auch jede andere Ziffer wählen\n\nz &lt;- x / y\n\n\n\n\n\nSchaue dir das Ergebnis in deinem Environment an. Lass dir das Ergebnis auch in der Konsole ausgeben. Das Environment findest du oben rechts, die Konsole ist unter deinem Skript.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n# z (hier über das # auskommentiert, da der Befehl nicht im Skript, sondern unten in der Konsole ausgeführt werden soll)\n\n\n\n\n\nErstelle zwei Variablen: Eine mit deinem Vornamen und eine mit deinem Nachnamen. Solche “character” Variablen musst du in Anführungszeichen setzen \"\"\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nvorname &lt;- \"Lars\"\nnachname &lt;- \"Schilling\"\n\n\n\n\n\nKombiniere deinen Vor- und Nachnamen zu deinem vollen Namen mittels paste . Speichere diese Variable als voller_name.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nvoller_name &lt;- paste(vorname, nachname)\n\n\n\n\n\n\n\n\nDefiniere einen Vektor «first_vector» mit den Zahlen 100, 80, 54, 73. Einen Vektor definiert man so: first_vector &lt;- c(...)\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nfirst_vector &lt;- c(100, 80, 54, 73)\n\n\n\n\n\nWende den Befehl boxplot() auf deinen Vektor an\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nboxplot(first_vector)\n\n\n\n\n\n\n\n\n\n\n\n\nBerechne die Summe sum()und den Mittelwert mean() von deinem Vektor\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsum(first_vector)\n\n[1] 307\n\nmean(first_vector)\n\n[1] 76.75\n\n\n\n\n\n\nMultipliziere deinen Vektor mit *2\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nfirst_vector * 2\n\n[1] 200 160 108 146\n\n\n\n\n\nDie wichtigsten Operatoren und Funktionen in R: https://methodenlehre.github.io/einfuehrung-in-R/chapters/02-R-language.html\n\n\n\n\n\nFunktion\nBedeutung\n\n\n\n\nmean(x, na.rm =FALSE)\nMittelwert\n\n\nsd(x)\nStandardabweichung\n\n\nvar(x)\nVarianz\n\n\nmedian(x)\nMedian\n\n\nsum(x)\nSumme\n\n\nmin(x)\nMinimalwert\n\n\nmax(x)\nMaximalwert\n\n\nrange(x)\nMinimal - und Maximalwert\n\n\n\n\n\n\n\n\nTeste ob die Zahl 5 größer als 2 ist –&gt; TRUE or FALSE?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n5 &gt; 2\n\n[1] TRUE\n\n\nTRUE, 5 ist grösser als 2.\n\n\n\n\nTeste ob 6 ungleich 8 ist –&gt; TRUE or FALSE?\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n6 != 8\n\n[1] TRUE\n\n\nTRUE, 6 und 8 sind ungleich.\n\n\n\n\nSubtrahiere 80 von 50 und speichere das Ergebnis in einer Variable namens «diff_score».\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndiff_score &lt;- 80 - 50\n\n\n\n\n\nBerechne mit abs() den absoluten Wert von «diff_score» lassen dir diesen mit print(diff_score) in der Konsole ausgeben.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ndiff_score_abs &lt;- abs(diff_score)\n\n# print(diff_score_abs) (hier erneut mit # auskommentiert, da der Befehl nicht im Skript, sondern in der Console ausgeführt werden soll)\n\n\n\n\n\n\n\n\n\nZeichen\nBedeutung\n\n\n\n\n==\ngleich\n\n\n!=\nungleich\n\n\n&gt;\ngrösser\n\n\n&gt;=\ngrösser gleich\n\n\n&lt;\nkleiner\n\n\n&lt;=\nkleiner gleich\n\n\n|\nLogisches Oder\n\n\n&\nLogisches Und",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 1 (Woche 1 - 2) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_1.html#nachvollziehbarkeit-von-code",
    "href": "scripts/02_excercises/loesung_1.html#nachvollziehbarkeit-von-code",
    "title": "Lösung 1",
    "section": "",
    "text": "Informative Kommentare im Code sind elementar für die Nachvollziehbarkeit.\n\nSchreibe einen Kommentar indem du ein # verwendest.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n# Hier ein Beipsiel für einen Kommentar, wie auch schon weiter oben mehrmals verwendet um die Lösungen davon zu hindern ausgeführt zu werden.\n\n\n\n\n\nCode der nach einem # steht wird nicht ausgeführt. Setze ein # vor eine Codezeile und führe sie aus und beobachte was passiert.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\n# 1 + 2\n\n\n\n\n\n\n\nEs gibt verschiedene Konventionen wie man Variablen bennen kann:\nhttps://methodenlehre.github.io/einfuehrung-in-R/chapters/02-R-language.html#variablennamen\n\nDefiniere eine neue Variable nach snake_case\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nneue_variable &lt;- \"snake_case\"\n\n\n\n\n\nDefiniere eine zweite Variable nach CamelCase\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nneueVariable &lt;- \"CamelCase\"",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 1 (Woche 1 - 2) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_1.html#für-fortgeschrittene-r-nutzerinnen",
    "href": "scripts/02_excercises/loesung_1.html#für-fortgeschrittene-r-nutzerinnen",
    "title": "Lösung 1",
    "section": "",
    "text": "Speichere die beiden höchsten Werte aus «first_vector» in einer neuen Variable ab.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\ntop_two &lt;- sort(first_vector, decreasing = TRUE)[1:2]\n\n\n\n\n\nErstelle einen Vektor mit Werten von 0-1000 in 10er Schritten.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nvec_seq &lt;- seq(from = 1, to = 1000, by = 10)\n\n\n\n\n\nZiehe zufällig eine Zahl aus diesem Vektor\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nsample(vec_seq, 1)\n\n[1] 181\n\n\n\n\n\n\nGeneriere einen Vektor, der aus 50 Wiederholungen der Zahl 3 besteht.\n\n\n\n\n\n\n\nLösung\n\n\n\n\n\n\nmy_vector &lt;- rep(3, times = 50)\n\n\n\n\nTipps zu diesen Aufgaben findest du bei Bedarf hier: https://methodenlehre.github.io/einfuehrung-in-R/chapters/02-R-language.html (Kapitel 2.1)",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 1 (Woche 1 - 2) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/loesung_1.html#datentypen",
    "href": "scripts/02_excercises/loesung_1.html#datentypen",
    "title": "Lösung 1",
    "section": "",
    "text": "numeric vectors: werden in integer (ganze Zahlen) und double (reelle Zahlen) unterteilt, z.B.\nnumerical_vector &lt;- c(1, 2.5, 4)\ncharacter vectors: bestehen aus Zeichen, welche von Anführungszeichen umgeben werden, z.B.\ntext_vector &lt;- c(\"Hello\", \"World\")\nlogical vectors: Elemente dieses Typs können nur 3 Werte annehmen: TRUE, FALSE oder NA\nlog_vector &lt;- c(TRUE, FALSE, TRUE)\n\nVektoren müssen aus denselbsten Elementen bestehen, d.h. z.B. numeric und character können nicht gemischt werden. Vektoren werden meist mit c() erstellt.",
    "crumbs": [
      "Übungen zu den Einheiten",
      "Hands on - Block 1 (Woche 1 - 2) - Mit Musterlösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/hands_on_4.html",
    "href": "scripts/02_excercises/hands_on_4.html",
    "title": "Hands On – Tidy (Einheiten 7 und 8)",
    "section": "",
    "text": "Bei Bedarf findest du hier nochmals die Slides zu Einheit 7 & 8 :"
  },
  {
    "objectID": "scripts/02_excercises/hands_on_4.html#filter",
    "href": "scripts/02_excercises/hands_on_4.html#filter",
    "title": "Hands On – Tidy (Einheiten 7 und 8)",
    "section": "filter()",
    "text": "filter()\n\nÜbungen zu filter()\nDiese Aufgaben helfen dir, den Umgang mit dplyr-Funktionen wie filter() und select() zu üben.\nDer Datensatz heißt dat_full und enthält 159 Zeilen und 36 Variablen. Stelle sicher, dass du diesen geladen hast.\nReminder: Verwende die logischen Operatoren, die wir in Hands On 1 kennengelernt haben.\n\n\n\nZeichen\nBedeutung\n\n\n\n\n==\ngleich\n\n\n!=\nungleich\n\n\n&gt;\ngrösser\n\n\n&gt;=\ngrösser gleich\n\n\n&lt;\nkleiner\n\n\n&lt;=\nkleiner gleich\n\n\n|\nLogisches Oder\n\n\n&\nLogisches Und\n\n\n\n\nErste Schritte mit Filter\n\nWähle alle Teilnehmenden aus, die in der Gruppe \"above\" sind.\nWähle alle Teilnehmenden aus, die mehr als 0.7 in cvstm_propcorrect erreicht haben.\n\n\n\nKombinierte Filter: Nutze die Pipe um beide Filter nacheinander auszuführen.\n\nFiltere alle, die gleichzeitig in der Gruppe below sind UND weniger als 0.6 in vp_propcorrect haben.\nWähle alle Fälle aus, deren strategies größer oder gleich 2 sind oder deren Wert in mean_rl_all nicht gleich 4.5 ist."
  },
  {
    "objectID": "scripts/02_excercises/hands_on_4.html#select",
    "href": "scripts/02_excercises/hands_on_4.html#select",
    "title": "Hands On – Tidy (Einheiten 7 und 8)",
    "section": "select()",
    "text": "select()\n\nÜbungen zu select()\n\nWähle die Variablen (bzw. Spalten) code, group_all, vp_sum und cvstm_propcorrect aus dat_full aus\n\n\n\nKombination von filter() und select()\n\nWähle alle Personen aus der Gruppe “above” aus, die mehr als 0.8 in vp_propcorrect haben,\nund zeige nur code, group_all, vp_sum, vp_propcorrect an."
  },
  {
    "objectID": "scripts/02_excercises/hands_on_4.html#rename",
    "href": "scripts/02_excercises/hands_on_4.html#rename",
    "title": "Hands On – Tidy (Einheiten 7 und 8)",
    "section": "rename()",
    "text": "rename()\n\nBenenne die Variable group_all in group um, indem du die Funktion rename() verwendest; achte dabei darauf, dass der neue Name zuerst angegeben wird.\nAnmerkung: je nachdem wie du deine Daten gemerged hast, heisst die Variable bereits “group”. Dann ist dieser Schritt nicht notwendig."
  },
  {
    "objectID": "scripts/02_excercises/hands_on_4.html#mutate",
    "href": "scripts/02_excercises/hands_on_4.html#mutate",
    "title": "Hands On – Tidy (Einheiten 7 und 8)",
    "section": "mutate()",
    "text": "mutate()\nNur für Übungszwecke: Erstelle eine neue Spalte aus der Variable group. Aus above soll EG1, aus below EG2 und aus control KG werden. Verwende dafür eine Kombination aus case_when() (oder recode()) und mutate()"
  },
  {
    "objectID": "scripts/02_excercises/hands_on_4.html#summarize",
    "href": "scripts/02_excercises/hands_on_4.html#summarize",
    "title": "Hands On – Tidy (Einheiten 7 und 8)",
    "section": "summarize()",
    "text": "summarize()\nDich interessieren der Durchschnitt (mean) und die Standardabweichung (sd) der Variable mean_e1_all. Du möchtest diese Werte jedoch nicht zu dat_full hinzufügen, sondern als Zusammenfassung in einem neuen Objekt speichern.\nNutze dafür die Funktion summarize()."
  },
  {
    "objectID": "scripts/02_excercises/hands_on_4.html#kombination-summarize-und-group_by",
    "href": "scripts/02_excercises/hands_on_4.html#kombination-summarize-und-group_by",
    "title": "Hands On – Tidy (Einheiten 7 und 8)",
    "section": "Kombination summarize() und group_by()",
    "text": "Kombination summarize() und group_by()\nFinde heraus, wie die durchschnittlichen Werte und Standardabweichungen von pre4 in den verschiedenen Gruppen (group) ausfallen.\n\nNutze dafür zuerst group_by()\nPipe das Ergebnis in summarize()\n\nSo kannst du zum Beispiel Tabelle 1 aus Grinschgl et al. (2020) reproduzieren."
  },
  {
    "objectID": "scripts/02_excercises/hands_on_4.html#anwendung-dplyr-funktionen",
    "href": "scripts/02_excercises/hands_on_4.html#anwendung-dplyr-funktionen",
    "title": "Hands On – Tidy (Einheiten 7 und 8)",
    "section": "Anwendung: dplyr-Funktionen",
    "text": "Anwendung: dplyr-Funktionen\nIn der Analyse von Grinschgl et al. (2020), werden die Skalenwerte des MMQ-Fragebogens untersucht.\nUm diese auszuwerten, müssen wir den Skalenwert pro Person berechnen.\n\nBerechnen von mmq_mean\nMit mutate() kannst du einem bestehenden Datensatz eine neue Spalte hinzufügen.\nUm die Daten des MMQ zu analysieren, füge eine Spalte hinzu, die den Durchschnitt (mmq_mean) über alle 18 Items (z. B. question1 bis question18) enthält.\n💡 Tipps:\n\nVerwende rowMeans() statt mean(), um den Mittelwert pro Versuchsperson zeihlenweise zu berechnen.\nDu kannst mit starts_with() alle Spalten auswählen, die mit question beginnen.\nWenn die Items im Datensatz nebeneinanderstehen, kannst du sie auch mit einem Bereich auswählen, z. B. question1:question18."
  },
  {
    "objectID": "scripts/02_excercises/hands_on_4.html#multiplizieren-von-pre-ratings",
    "href": "scripts/02_excercises/hands_on_4.html#multiplizieren-von-pre-ratings",
    "title": "Hands On – Tidy (Einheiten 7 und 8)",
    "section": "Multiplizieren von Pre Ratings",
    "text": "Multiplizieren von Pre Ratings\nDie Variablen pre1–pre4 und post stellen in der Studie die Leistungseinschätzungen auf einer Skala von 1 bis 100 dar. In unserem Datensatz sind sie jedoch nur auf einer Skala von 1 bis 10 abgebildet. Verwende die Funktion mutate, um die Variablen mit 10 zu multiplizieren und so die richtigen Werte zu erhalten.\nWeitere Informationen zu dplyr findest du auch hier: 📖Kapitel 4.4 Ellis & Mayer"
  },
  {
    "objectID": "scripts/02_excercises/hands_on_4.html#häufige-formen-fehlender-werte",
    "href": "scripts/02_excercises/hands_on_4.html#häufige-formen-fehlender-werte",
    "title": "Hands On – Tidy (Einheiten 7 und 8)",
    "section": "Häufige Formen fehlender Werte",
    "text": "Häufige Formen fehlender Werte\n\nNA (R-typische Kennzeichnung für Not Available)\n999 oder -999 (häufig manuell gesetzte Platzhalter)\nleere Zellen (\"\")\nNULL (in manchen Programmiersprachen, aber in R selten in Datensätzen verwendet)"
  },
  {
    "objectID": "scripts/02_excercises/hands_on_4.html#umgang-mit-fehlenden-werten",
    "href": "scripts/02_excercises/hands_on_4.html#umgang-mit-fehlenden-werten",
    "title": "Hands On – Tidy (Einheiten 7 und 8)",
    "section": "Umgang mit fehlenden Werten",
    "text": "Umgang mit fehlenden Werten\nIm Umgang mit fehlenden Werten sollten wir:\n\nPrüfen, ob und wie viele Werte fehlen.\nVerstehen, warum sie fehlen (z. B. fehlende Eingabe durch Teilnehmende).\nEntscheiden, wie mit den fehlenden Werten umgegangen werden soll – basierend auf dieser Analyse."
  },
  {
    "objectID": "scripts/02_excercises/hands_on_4.html#aufgabe",
    "href": "scripts/02_excercises/hands_on_4.html#aufgabe",
    "title": "Hands On – Tidy (Einheiten 7 und 8)",
    "section": "Aufgabe:",
    "text": "Aufgabe:\n 📥 Download bfi_10_data.csv \n📖Kapitel 4.3.3 Ellis & Mayer\nFühre die folgenden Schritte durch:\n\nDatensatz downloaden und einlesen\nLade den Übungsdatensatz in R ein. Achte auf den Delimiter/das Trennzeichen (;)\n\n\nFehlende Werte prüfen\nTeste mit is.na(), ob der Datensatz fehlende Werte enthält,\nund zähle sie mit table(is.na()). Eine weitere Art und Weise einen Überblick über missings zu erhalten ist mit dem skimr Paket und der skim() Funktion. Teste diese.\n\n\nZeilen mit fehlenden Werten löschen\nErstelle eine Kopie des Datensatzes und verwende drop_na(),\num alle Zeilen mit fehlenden Werten zu entfernen.\nZähle anschließend erneut, wie viele fehlende Werte noch vorhanden sind.\n\n\n\n\n\n\n\nCaution\n\n\n\nAchtung: Ein einziger fehlender Wert reicht aus, damit die gesamte Zeile (also eine Versuchsperson) entfernt wird!"
  },
  {
    "objectID": "scripts/02_excercises/hands_on_4.html#umpolen-der-negativ-formulierten-items",
    "href": "scripts/02_excercises/hands_on_4.html#umpolen-der-negativ-formulierten-items",
    "title": "Hands On – Tidy (Einheiten 7 und 8)",
    "section": "Umpolen der negativ formulierten Items",
    "text": "Umpolen der negativ formulierten Items\n\nPole die negativ gepolten (reverse codierten) BFI-Items um. Die reverse kodierten Items enden immer mit _r. Du kannst dafür Base R oder Funktionen aus dem tidyverse verwenden.\n\nVervollständige diesen Code!\n\nNötige Argumente: Datensatz, Variablen, Rekodierungsschema.\n\n\ndata_bfi_recoded &lt;- XXXXX |&gt; \n  mutate(\n    across(\n      c(XXXXXX),\n      ~ case_when(\n        . == 1 ~ 5,\n        XXXXXXXXXX\n      )\n    )\n  )\n\nErklärungen zu diesem Code findest du hier: Kapitel 4.4.6 Ellis & Mayer und hier: Kapitel 4.4.7 Ellis & Mayer"
  },
  {
    "objectID": "scripts/02_excercises/hands_on_4.html#berechnung-der-big-five-skalen",
    "href": "scripts/02_excercises/hands_on_4.html#berechnung-der-big-five-skalen",
    "title": "Hands On – Tidy (Einheiten 7 und 8)",
    "section": "Berechnung der Big-Five-Skalen",
    "text": "Berechnung der Big-Five-Skalen\n\nErstelle neue Variablen, die den Mittelwert jedes Big-Five-Faktors pro Person enthalten.\n\nNutze dafür die Funktionen:\n\nmutate(), row_means() und select()\n\n💡Tipp: Wenn du die select()-Funktion innerhalb von mutate() verwendest und den native pipe (|&gt;) nutzt, musst du angeben, auf welchen Datensatz sich select() bezieht.\nz.B: extraversion = rowMeans(select(data_bfi_recoded, bfi_extra_1_r, bfi_extra_2))\nAbschlussübung: Versuche dein Skript dieser Hands on Einheit zu rendern. Wenn es nicht funktioniert, versuche die Fehlermeldungen nachzuvollziehen und zu beheben!"
  },
  {
    "objectID": "scripts/02_excercises/hands_on_7.html",
    "href": "scripts/02_excercises/hands_on_7.html",
    "title": "Hands On – Analyze (Einheit 13)",
    "section": "",
    "text": "Bei Bedarf findest du hier nochmals die Slides zu Einheit 13:"
  },
  {
    "objectID": "scripts/02_excercises/hands_on_7.html#einfaktorielle-anova",
    "href": "scripts/02_excercises/hands_on_7.html#einfaktorielle-anova",
    "title": "Hands On – Analyze (Einheit 13)",
    "section": "Einfaktorielle ANOVA",
    "text": "Einfaktorielle ANOVA\n\nBerechne eine einfaktorielle ANOVA mit aov_4 (aus dem Paket “afex”) ür die Offloading-Variable mean_rl_all (Öffnungen des Modelfensters). Nutze hierfür den Wide-Datensatz (dat_full).\nBerechnet dafür zuerst den Levene-Test um die Varianzhomogenität des between-Faktors zu überprüfen.\nDefiniere die ANOVA nach der folgenden Vorlage\n\n\nmodel_1 &lt;- aov_4(AV ~ Faktor_1 + (1 | ID), data = data)\n\nsummary(model_1)\n\n\nVersuche das Ergbenis zu interpretieren und mit dem Grinschgl et al. (2021) Paper zu vergleichen. 👉 Und schon haben wir ein ANOVAs für die Offloading Variablen berechnet.\nBerechne die Effektstärken partielles η² und generalisiertes η² . Ergänze dafür die aov_4 Funktion um anova_table = list(es = c(\"ges\" ,\"pes\")) . Lasse dir das Ergebnis mit model$anova_table ausgeben. Bei einfaktoriellen ANOVAs sind die partiellen und generalisierten η² identisch."
  },
  {
    "objectID": "scripts/02_excercises/hands_on_7.html#post-hoc-t-tests",
    "href": "scripts/02_excercises/hands_on_7.html#post-hoc-t-tests",
    "title": "Hands On – Analyze (Einheit 13)",
    "section": "Post-hoc t-Tests",
    "text": "Post-hoc t-Tests\nZu Übungszwecken, inhaltlich nicht notwendig wenn die ANOVA nicht signifikant ist.\n\nLade das Package emmeans\n\n\n\nSpeichere mit new_object &lt;- emmeans(object = model, specs = ~group_all) die Mittelwerte und Standardfehler in einem neuen Objekt.\n\n\nBerechne mit pairs(new_object) multiple t-Tests als Post-Hoc Tests. Diese werden als default-Einstellung mit der Tukey-Methodekorrigiert. Das ist eine Alternative zu einzelnen t-Tests in Grinschgl et al. (2021) so wie in EH12 berechnet - ergibt leicht andere Werte wegen Tukey-Korrektur für multiples Testen. (Für das Abschlussprojekt sind Post-Hoc Tests in beiden Varianten okay – entweder mit emmeans() oder mit t.test() ).\n\n\n\n\n\n\n\nTukey-Korrektur\n\n\n\n\n\nDie Tukey-Korrektur ist ein simultanes Verfahren für Post-hoc-Gruppenvergleiche, das verhindert, dass sich der Alpha-Fehler durch viele t-Tests (familywise error rate) aufsummiert. Sie wird bevorzugt eingesetzt, wenn alle Gruppen miteinander verglichen werden sollen.\n\n\n\n\n\n\n\n\n\nFortgeschritten - Effektstärken mit pairs()\n\n\n\n\n\nDer Befehl pairs() berechnet nicht automatisch die gewünschten Effektstärken (zum Beispiel Cohen’s d). Die Effektstärken können entweder einzeln wie in den Übungen zu EH 12 berechnet werden, etwa mit cohens_d(). Wenn man jedoch die Effektstärken aller Paarvergleiche simultan berechnen möchte, kann man dies mit eff_size() tun. Dafür greift man auf die Residualvarianzen und Freiheitsgrade des ANOVA-Modells zu. Diese Informationen sind im lm-Objekt des Modells gespeichert. Unten siehst du ein Codebeispiel:\n\nposthoc_tests &lt;- emmeans(object = model_1, specs = ~ group_all)\n\neff_size(\n  posthoc_tests,\n  sigma = sigma(model_1$lm),\n  edf   = df.residual(model_1$lm)\n)\n\n contrast        effect.size    SE  df lower.CL upper.CL\n above - below       -0.2605 0.195 156   -0.645    0.124\n above - control     -0.0395 0.194 156   -0.423    0.344\n below - control      0.2210 0.195 156   -0.163    0.606\n\nsigma used for effect sizes: 1.123 \nConfidence level used: 0.95 \n\n\nZum Vergleich: Mit cohens_d()\n\ndat_full_above_below &lt;- dat_full |&gt;\n  filter(group_all != \"control\")\n\ndat_full_above_below$group_all &lt;- factor(dat_full_above_below$group_all )\n\ncohens_d(mean_rl_all ~ group_all, data = dat_full_above_below)\n\nCohen's d |        95% CI\n-------------------------\n-0.25     | [-0.63, 0.13]\n\n- Estimated using pooled SD.\n\n\nDie Effektstärken unterscheiden sich hier leicht da nicht mit den exakt gleichen Varianzen gerechnet wird, effsize() verwendet hierfür die die modellbasierten SDs, während cohens_d() die gepoolte Standardabweichung aus den Rohdaten verwendet. Dieser Unterschied kann jedoch vernachlässigt werden."
  },
  {
    "objectID": "scripts/02_excercises/hands_on_7.html#x3-mixed-anova-mit-messwiederholung",
    "href": "scripts/02_excercises/hands_on_7.html#x3-mixed-anova-mit-messwiederholung",
    "title": "Hands On – Analyze (Einheit 13)",
    "section": "2x3 Mixed ANOVA mit Messwiederholung",
    "text": "2x3 Mixed ANOVA mit Messwiederholung\n\nDefiniere das 2x3 ANOVA Model aus Grinschgl et al. (2021), nach folgendem Muster - hierfür benötigen wir den Long Datensatz!\n\n\nmixed_anova &lt;- aov_4(AV ~ between_factor + (messwiederholter_faktor | ID), data = df_long)\n\n\nErgänze den Code wie vorher um anova_table um dir die Effektstärken partielles η² und generalisiertes η² ausgeben zu lassen.\nIn Grinschgl et al. (2021) wird jedoch nur das reine η² berichtet (weder generalisiert noch partiell). Wende eta_squared() auf dem package effectsize auf dein ANOVA Model an und setze partial = FALSE.\n\n\nVersuche das Ergebnis dieser ANOVA zu interpretieren und mit Grinschgl et al. (2021) zu vergleichen."
  },
  {
    "objectID": "scripts/02_excercises/hands_on_7.html#x3-mixed-anova---post-hoc-t-tests",
    "href": "scripts/02_excercises/hands_on_7.html#x3-mixed-anova---post-hoc-t-tests",
    "title": "Hands On – Analyze (Einheit 13)",
    "section": "2x3 Mixed ANOVA - Post-Hoc t-Tests",
    "text": "2x3 Mixed ANOVA - Post-Hoc t-Tests\n\n2 x 3 mixed ANOVA mit Messwiederholung Post-Hoc Tests: emmeans() Objekt erstellen nach folgender Vorlage:\n\n\nresults &lt;- emmeans(object = my_anova, specs = ~ within_factor * between_factor)\n\n\npairs() darauf anwenden – hier wollen wir mit simple = „group_all“ Post-Hoc Tests für die Gruppenvergleiche zu den beiden Zeitpunkten berechnen. 👉 Berechnung von bedingten Mittelwertsunterschieden so wie im Grinschgl et al. (2021) Paper (aber dort leicht andere Werte wegen anderer Berechnungsfunktion)\n\n\nÄndere es nun auf simple = time_rating ab und schaue dir den Unterschied zum vorherigen Ergebnis an.\n\n\nErgänze nun die Bonferroni Korrektur für multiples Testen mit adjust = „bonferroni“\n\n\n\n\n\n\n\nImportant\n\n\n\nAchtung: Die pairs() Funktion gibt keine Effektstärken aus. Diese müssen für die 2x3 ANOVA mit der cohens_d() Funktion berechnet werden wie wir das bereits in Hands On 6 geübt haben."
  },
  {
    "objectID": "scripts/02_excercises/hands_on_2.html",
    "href": "scripts/02_excercises/hands_on_2.html",
    "title": "Hands On – Coding Basics (Einheiten 3 und 4)",
    "section": "",
    "text": "Bei Bedarf findest du hier nochmals die Slides zu Einheit 3:\nUnd zu Einheit 4:"
  },
  {
    "objectID": "scripts/02_excercises/hands_on_2.html#import",
    "href": "scripts/02_excercises/hands_on_2.html#import",
    "title": "Hands On – Coding Basics (Einheiten 3 und 4)",
    "section": "Import",
    "text": "Import\n👉 Kapitel 3.2\nCheatsheat Datenimport mit readr\n\nEinlesen via Oberfläche\n\nStelle sicher, dass du das Metapaket tidyverse geladen hast (library(tidyverse)) (siehe Hands-On 1).\nWir verwenden Funktionen aus den Packages readr und readxl, die Teil des Tidyverse sind.\n\nIn diesem Seminar arbeiten wir mit csv und xslx Dateien. Wie werden uns mehere Arten und Weisen anschauen wie man diese einlesen kann.\nBeim Einlesen von Daten ist ein wichtiger Faktor, mich welchem Trennzeichen (Delimiter) die Werte von einander getrennt werden.\nAuszug aus Cheatsheet: Die Funktionen read_delim und read_csv:\n\nread_csv() ist eine Spezialisierung von read_delim(), die automatisch Komma als Trennzeichen verwendet, während man bei read_delim() das gewünschte Trennzeichen selbst angeben muss.\n\nImportiere die Datei \"data_mmq.csv\" über die Point & Klick-Oberfläche von RStudio. Verwende dafür “From Text (readr)”\n\n\nTipp: Klicke auf Environment → Import Dataset → wähle die \"readr\"-Funktion.\nSchaue dir den Datensatz an: Mit welchem Trennzeichen sind die Daten getrennt?\n\n\nStelle in der Oberfläche \"Delimiter\" auf das passende Trennzeichen. Was verändert sich?\n\nBetrachte den Code, den die Oberfläche generiert. Versuche den Pfad im Kontext von Projekten zu verstehen.\n\nWenn du im Projekt gearbeitet hast, sollte bei dir der Code etwa so aussehen: data_mmq &lt;- read_delim(\"data/raw/data_mmq.csv\", delim = \";\", escape_double = FALSE, trim_ws = TRUE)\nWenn du nicht im Projekt gearbeite hättest, wie würde dann der Dateipfad aussehen?\n\nWenn du den Code via Klick-Oberfläche eingelesen hast, wirst du den ausgeführten Code in der Konsole sehen. Kopiere diesen in dein Skript, so dass du ihn in Zukunft wiederverwenden und anpassen kannst.\nSchaue dir die eingelesenen Daten mit View(data_mmq) an. Wenn du alles richtig gemacht hast, ist in jeder Zelle nur ein Wert.\n\n\n\n\nEinlesen via Code\n\n.CSV Dateien\n\nVersuche, weitere CSV-Datensätze einzulesen: data_cb, data_cvstm, data_pct, data_vp.\nSuche dafür eine geeignete Funktion zum Einlesen von .csv.\n\nVerwende den von R-Studio generierten Code, und passe ihn an um einen weiteren Datensatz einzulesen (z.B. indem du den Filenamen veränderst).\n\nKorrigiere diesen Code und lies damit die Datei data_vp ein (überprüfe den Pfad und den Delimiter)\n\n\ndata_vp &lt;- read_delim(\"/raw/data_vp.csv\", \n    delim = \",\")\n\n\n\n.XSLX Dateien\n\nEinige Dateien liegen im .xlsx-Format.\n\nVerwende dafür das Paket readxl und die Funktion read_excel(). Tipp: Installiere und lade das Paket zunächst.\nNutze die Hilfefunktion (?read_excel) für Infos zur Funktion oder schaue dir das Cheatsheet an\nVersuche, die Datensätze data_ratings und data_strategies einzulesen.\n\nAm Ende solltest du die 7 verschiedene Datensätze in deinem Environment sehen.\n\n\n\n\n\n\n\nVertiefung\n\n\n\n\n\n👉Für das Einlesen anderer Arten von Datensätzen (z.B. SPSS Dateien), siehe Kapitel 3.2"
  },
  {
    "objectID": "scripts/02_excercises/hands_on_2.html#aufgaben",
    "href": "scripts/02_excercises/hands_on_2.html#aufgaben",
    "title": "Hands On – Coding Basics (Einheiten 3 und 4)",
    "section": "Aufgaben",
    "text": "Aufgaben\n\nFüge alle 7 Datensätze mit cbind() zusammen und schaue dir das Ergebnis an.\n\nWas fällt dir auf?\n\nHinweis: Die Datensätze werden einfach nebeneinander „geklebt“, ohne inhaltlich abgeglichen zu werden.\n\nReflektiere: Macht das Sinn? Was sind die Gefahren, Daten auf diese Art zu mergen?\n\n\n\n\nVersuche es nun mit full_join().\nFull_join verbindet zwei Datensätze anhand einer Schlüsselvariable, so dass alle Zeilen aus beiden Datensätzen erhalten bleiben. Die Schlüsselvariable ist essentiell dafür dass die Datensätze richtig verbunden werden (Anordnung der Variablen), und grenzt sich dadurch von Funktionen wie cbind() ab.\n\n\nLege eine gemeinsame Variable als Schlüssel fest, hier: by = \"code\".\nFüge nun alle 7 Datensätze zu einem zusammen, nenne diesen dat_full\n\nAchtung: full_join() funktioniert immer nur mit 2 Datensätzen gleichzeitig 👉 du musst es also mehrfach anwenden, um alle 7 Datensätze zusammenzuführen.\nHinweis: Im Datensatz data_pct heißt die Code-Variable leicht anders. Verwende deshalb by = c(\"code_all\" = \"code\").\n\n\n\n\n\nInspiziere deinen zusammengefügten Datensatz “dat_full”\n\n🔍Überprüfe: Wie viele Zeilen und Spalten hat dein Datensatz? Verwende: ncol() , nrow(), dim()\n\nStimmt die Anzahl der Zeilen mit der Anzahl der Versuchspersonen aus dem Paper überein?\n\n👀Verschaffe dir eine Überblick über deinen Datensatz mit den Funktionen, die wir schon im letzten Hands On getestet haben:\n\nLasse dir die Variablenamen ausgeben mit names()\nhead()\nglimpse()\nstr()\ndat_full\nsummary()\n\nGibt es redundante oder doppelte Variablen?\n\nAuf einzelne Werte zugreiffen:\n\nGreife auf den ersten Wert der ersten Spalte zu: Verwende eckige Klammern. Der erste Wert in der Klammer steht für die Zeile, der zweite für die Spalte.\nGreife auf die Werte der Spalten 1–15 in der ersten Zeile zu. Verwende wieder eckige Klammern und den Bereichsoperator 1:15.\nLasse dir alle Werte der Variable \"mean_rl_all\" ausgeben. Auf Variablen greifst du mit $ zu.\nGreife auf die ersten 10 Werte der Variable \"question1\" zu. Verwende dazu den $-Operator in Kombination mit dem Bereichsoperator 1:10."
  },
  {
    "objectID": "scripts/02_excercises/hands_on_2.html#tab-completion",
    "href": "scripts/02_excercises/hands_on_2.html#tab-completion",
    "title": "Hands On – Coding Basics (Einheiten 3 und 4)",
    "section": "Tab Completion:",
    "text": "Tab Completion:\nEine nützliche Funktion von RStudio ist die Tab Completion. Wenn du eine Funktion aufrufst und die Tabulator-Taste drückst, erscheint ein Menü mit den möglichen Argumenten, die du angeben kannst. Probiere es mit der Funktion mean(). Das funktioniert auch für Funktionen aus Paketen, wenn du diese mit :: auswählst, zum Beispiel: readr::."
  },
  {
    "objectID": "scripts/02_excercises/hands_on_2.html#weitere-tasten-und-tastenkürzel",
    "href": "scripts/02_excercises/hands_on_2.html#weitere-tasten-und-tastenkürzel",
    "title": "Hands On – Coding Basics (Einheiten 3 und 4)",
    "section": "Weitere Tasten und Tastenkürzel:",
    "text": "Weitere Tasten und Tastenkürzel:\n👉Kapitel 1.4.6\nIn RStudio benötigen wir häufig Zeichen, die wir im Alltag kaum verwenden. Da wir nicht alle mit dem gleichen Betriebssystem (Mac/Windows) und auch nicht mit identischen Tastaturen arbeiten, können wir keine einheitlichen Angaben machen, wo sich diese Zeichen genau befinden. Versuche daher, die folgenden Zeichen auf deiner eigenen Tastatur zu finden:\n\n[ ] Square brackets (eckige Klammern)\n{ } Curly brackets (geschweifte Klammern)\n$ Dollar sign (Dollarzeichen – wird für das Auswählen von Variablen benötigt)\n# Hash (Rautezeichen – für Kommentare in R-Skripten)\n~ Tilde (für Modellnotationen in R; brauchen wir v.a. am Ende des Semesters bei den Analysen)\n| Vertical bar (senkrechter Strich – als logischer Operator)\n` Backtick (Gravis – vor allem für Code Chunks, selten manuell einzugeben)"
  },
  {
    "objectID": "scripts/02_excercises/hands_on_2.html#verschachtelte-funktionen",
    "href": "scripts/02_excercises/hands_on_2.html#verschachtelte-funktionen",
    "title": "Hands On – Coding Basics (Einheiten 3 und 4)",
    "section": "Verschachtelte Funktionen:",
    "text": "Verschachtelte Funktionen:\nℹ️Es ist zwar möglich, mehrere Funktionen ineinander zu verschachteln. Dies kann jedoch schnell zu Verwirrung führen und den Code unnötig unübersichtlich machen. Verschachtelte Funktionen werden von innen nach aussen ausgeführt.\n❓Stelle dir hier die Frage: Was wird genau gerundet? Die einzelnen Elemente des Vektors oder der errechnet Durchschnitt?\n\nprint(mean(round(first_vector)))\n\n[1] 5785.25\n\n\n❗Aufgabe: Zerlege die Verschatelte Funktion in ihre Teilschritte."
  },
  {
    "objectID": "scripts/02_excercises/hands_on_1.html",
    "href": "scripts/02_excercises/hands_on_1.html",
    "title": "Hands On 1",
    "section": "",
    "text": "Bei Bedarf finden sich hier nochmal die Slides zur EH1: \nUnd EH2\n\n\n\n\nInstalliere R und RStudio:\n\nInstallation von R – neueste Version 4.5.1: https://stat.ethz.ch/CRAN/\nInstallation von RStudio (Version 2025.09.0): https://posit.co/download/rstudio-desktop/\n\nDu weisst nicht was mit R auf sich hat? Hier ist eine Kurzerklärung: https://methodenlehre.github.io/einfuehrung-in-R/\n\n\n\n\nRStudio öffnen & Einstellungen vornehmen: Unter «tools» –«global options» die unter 1.1. beschriebenen Einstellungen vornehmen:\nhttps://methodenlehre.github.io/einfuehrung-in-R/chapters/01-workflow.html\n\n\n\nNeues Skript öffnen & orientieren\n\n\n\n\nIm folgenden machen wir uns vertraut mit der Oberfläche von RStudio:\n\n\n\n\n\n\n\nSkript für Code-Eingabe sowie Kommentare\nKonsole für die Ausführung von Code -&gt; Teste einfache mathematische Operation in dieser; reproduziere diese mittels Skript\nRechts oben: Environment & History\nRechts unten: Files, Plots, Packages und Help Viewer\n\n\n\n\nTidyverse ist ein Meta-Paket, das mehrere Pakete umfasst\n\nPakete installieren (nur 1x notwendig) -&gt; führe diesen Code in der Konsole aus\n\ninstall.packages(\"tidyverse\")\n\nPaket laden (innerhalb des Skriptes, bei jedem Neustart von R notwendig)\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\nTipp: Pakete regelmässig updaten mit z.B. update.packages()\n\n\n\n\na. Nutze R als Taschenrechner\n\n123+456\n144*112\n10/3\nQuadriere 420\nZiehe die Quadratwurzel aus 146 mit der Funktion sqrt()\nBerechne den Rest der Division 10/3 mit dem Modulo Operator: %%\n\n\n\n\n\n\n\nZeichen\nBedeutung\n\n\n\n\n+\nAddition\n\n\n-\nSubstraktion\n\n\n*\nMultiplikation\n\n\n/\nDivision\n\n\nsqrt(x)\nQuadratwurzel\n\n\nabs(x)\nBetrag (absoluter Wert)\n\n\nx %% y\nModulo (x mod y) 5 %% 2 = 1\n\n\n^\nPotenz\n\n\n\n\n\n\n\n\nWeise den Wert 5 der Variable x zu mit dem Operator &lt;-\nWeise eine beliebige Zahl der Variable y zu und dividiere dann x durch y. Speichere dieses Ergebnis in der Variable z.\nSchaue dir das Ergebnis in deinem Environment an. Lass dir das Ergebnis auch in der Konsole ausgeben. Das Environment findest du oben rechts, die Konsole ist unter deinem Skript.\nErstelle zwei Variablen: Eine mit deinem Vornamen und eine mit deinem Nachnamen. Solche “character” Variablen musst du in Anführungszeichen setzen \"\"\nKombiniere deinen Vor- und Nachnamen zu deinem vollen Namen mittels paste . Speichere diese Variable als voller_name.\n\n\n\n\n\nDefiniere einen Vektor «first_vector» mit den Zahlen 100, 80, 54, 73. Einen Vektor definiert man so: first_vector &lt;- c(...)\nWende den Befehl boxplot() auf deinen Vektor an\nBerechne die Summe sum()und den Mittelwert mean() von deinem Vektor\nMultipliziere deinen Vektor mit *2 und schaue dir das Ergebnis an.\n\nDie wichtigsten Operatoren und Funktionen in R: https://methodenlehre.github.io/einfuehrung-in-R/chapters/02-R-language.html\n\n\n\n\n\nFunktion\nBedeutung\n\n\n\n\nmean(x, na.rm =FALSE)\nMittelwert\n\n\nsd(x)\nStandardabweichung\n\n\nvar(x)\nVarianz\n\n\nmedian(x)\nMedian\n\n\nsum(x)\nSumme\n\n\nmin(x)\nMinimalwert\n\n\nmax(x)\nMaximalwert\n\n\nrange(x)\nMinimal - und Maximalwert\n\n\n\n\n\n\n\n\nTeste ob die Zahl 5 größer als 2 ist –&gt; TRUE or FALSE?\nTeste ob 6 ungleich 8 ist –&gt; TRUE or FALSE?\nSubtrahiere 80 von 50 und speichere das Ergebnis in einer Variable namens «diff_score».\nBerechne mit abs() den absoluten Wert von «diff_score» lasse dir diesen mit print(diff_score) in der Konsole ausgeben.\n\n\n\n\n\n\nZeichen\nBedeutung\n\n\n\n\n==\ngleich\n\n\n!=\nungleich\n\n\n&gt;\ngrösser\n\n\n&gt;=\ngrösser gleich\n\n\n&lt;\nkleiner\n\n\n&lt;=\nkleiner gleich\n\n\n|\nLogisches Oder\n\n\n&\nLogisches Und\n\n\n\n\n\n\n\n\n\nInformative Kommentare im Code sind elementar für die Nachvollziehbarkeit.\n\nSchreibe einen Kommentar indem du ein # verwendest.\nCode der nach einem # steht wird nicht ausgeführt. Setze ein # vor eine Codezeile und führe sie aus und beobachte was passiert.\n\n\n\n\nEs gibt verschiedene Konventionen, wie man Variablen benennen kann.\nEinige wichtige Grundsätze dafür sind:\n\nNamen können aus Buchstaben, Zahlen sowie den Zeichen _ oder . bestehen.\nSie müssen mit einem Buchstaben beginnen und dürfen keine Leerzeichen enthalten.\nSonderzeichen und Großbuchstaben sollten vermieden werden.\nKeine Namen verwenden, die bereits für Funktionen reserviert sind (z. B. mean()).\nDer Name sollte den Inhalt der Variablen möglichst gut beschreiben → Reproduzierbarkeit; clarity instead of brevity.\nAm besten englische Bezeichnungen verwenden, um internationalen Standards zu folgen.\n\n👉 Mehr dazu\nÜbung:\n\nDefiniere eine neue Variable nach snake_case.\nDefiniere eine zweite Variable nach CamelCase.\n\nIn unserem Seminar verwenden wir den snake_case.\n\n\n\n\n\nSpeichere die beiden höchsten Werte aus «first_vector» in einer neuen Variable ab (Tipp: verwende sort() )\nErstelle einen Vektor mit Werten von 0-1000 in 10er Schritten (Tipp: suche nach der Funktion seq()\nZiehe zufällig eine Zahl aus diesem Vektor\nGeneriere einen Vektor, der aus 50 Wiederholungen der Zahl 3 besteht\n\nTipps zu diesen Aufgaben findest du bei Bedarf hier: https://methodenlehre.github.io/einfuehrung-in-R/chapters/02-R-language.html (Kapitel 2.1)\nTipp: Suche nach der Dokumentation der folgenden Funktionen: sort(), seq(), sample, rep().\nDie Dokumentation kannst du mittels ?Funktionsname aufrufen.\n\n\n\n\nnumeric vectors: werden in integer (ganze Zahlen) und double (reelle Zahlen) unterteilt, z.B.\nnumerical_vector &lt;- c(1, 2.5, 4)\ncharacter vectors: bestehen aus Zeichen, welche von Anführungszeichen umgeben werden, z.B.\ntext_vector &lt;- c(\"Hello\", \"World\")\nlogical vectors: Elemente dieses Typs können nur 3 Werte annehmen: TRUE, FALSE oder NA\nlog_vector &lt;- c(TRUE, FALSE, TRUE)\n\nVektoren müssen aus denselbsten Elementen bestehen, d.h. z.B. numeric und character können nicht gemischt werden. Vektoren werden meist mit c() erstellt."
  },
  {
    "objectID": "scripts/02_excercises/hands_on_1.html#installation-r-und-r-studio",
    "href": "scripts/02_excercises/hands_on_1.html#installation-r-und-r-studio",
    "title": "Hands On 1",
    "section": "",
    "text": "Installiere R und RStudio:\n\nInstallation von R – neueste Version 4.5.1: https://stat.ethz.ch/CRAN/\nInstallation von RStudio (Version 2025.09.0): https://posit.co/download/rstudio-desktop/\n\nDu weisst nicht was mit R auf sich hat? Hier ist eine Kurzerklärung: https://methodenlehre.github.io/einfuehrung-in-R/"
  },
  {
    "objectID": "scripts/02_excercises/hands_on_1.html#einstellungen",
    "href": "scripts/02_excercises/hands_on_1.html#einstellungen",
    "title": "Hands On 1",
    "section": "",
    "text": "RStudio öffnen & Einstellungen vornehmen: Unter «tools» –«global options» die unter 1.1. beschriebenen Einstellungen vornehmen:\nhttps://methodenlehre.github.io/einfuehrung-in-R/chapters/01-workflow.html\n\n\n\nNeues Skript öffnen & orientieren"
  },
  {
    "objectID": "scripts/02_excercises/hands_on_1.html#rstudio-oberfläche",
    "href": "scripts/02_excercises/hands_on_1.html#rstudio-oberfläche",
    "title": "Hands On 1",
    "section": "",
    "text": "Im folgenden machen wir uns vertraut mit der Oberfläche von RStudio:\n\n\n\n\n\n\n\nSkript für Code-Eingabe sowie Kommentare\nKonsole für die Ausführung von Code -&gt; Teste einfache mathematische Operation in dieser; reproduziere diese mittels Skript\nRechts oben: Environment & History\nRechts unten: Files, Plots, Packages und Help Viewer"
  },
  {
    "objectID": "scripts/02_excercises/hands_on_1.html#pakete-installieren-und-laden",
    "href": "scripts/02_excercises/hands_on_1.html#pakete-installieren-und-laden",
    "title": "Hands On 1",
    "section": "",
    "text": "Tidyverse ist ein Meta-Paket, das mehrere Pakete umfasst\n\nPakete installieren (nur 1x notwendig) -&gt; führe diesen Code in der Konsole aus\n\ninstall.packages(\"tidyverse\")\n\nPaket laden (innerhalb des Skriptes, bei jedem Neustart von R notwendig)\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\nTipp: Pakete regelmässig updaten mit z.B. update.packages()"
  },
  {
    "objectID": "scripts/02_excercises/hands_on_1.html#operatoren-kennenlernen",
    "href": "scripts/02_excercises/hands_on_1.html#operatoren-kennenlernen",
    "title": "Hands On 1",
    "section": "",
    "text": "a. Nutze R als Taschenrechner\n\n123+456\n144*112\n10/3\nQuadriere 420\nZiehe die Quadratwurzel aus 146 mit der Funktion sqrt()\nBerechne den Rest der Division 10/3 mit dem Modulo Operator: %%\n\n\n\n\n\n\n\nZeichen\nBedeutung\n\n\n\n\n+\nAddition\n\n\n-\nSubstraktion\n\n\n*\nMultiplikation\n\n\n/\nDivision\n\n\nsqrt(x)\nQuadratwurzel\n\n\nabs(x)\nBetrag (absoluter Wert)\n\n\nx %% y\nModulo (x mod y) 5 %% 2 = 1\n\n\n^\nPotenz"
  },
  {
    "objectID": "scripts/02_excercises/hands_on_1.html#erste-zuweisungenvariablen-definieren",
    "href": "scripts/02_excercises/hands_on_1.html#erste-zuweisungenvariablen-definieren",
    "title": "Hands On 1",
    "section": "",
    "text": "Weise den Wert 5 der Variable x zu mit dem Operator &lt;-\nWeise eine beliebige Zahl der Variable y zu und dividiere dann x durch y. Speichere dieses Ergebnis in der Variable z.\nSchaue dir das Ergebnis in deinem Environment an. Lass dir das Ergebnis auch in der Konsole ausgeben. Das Environment findest du oben rechts, die Konsole ist unter deinem Skript.\nErstelle zwei Variablen: Eine mit deinem Vornamen und eine mit deinem Nachnamen. Solche “character” Variablen musst du in Anführungszeichen setzen \"\"\nKombiniere deinen Vor- und Nachnamen zu deinem vollen Namen mittels paste . Speichere diese Variable als voller_name."
  },
  {
    "objectID": "scripts/02_excercises/hands_on_1.html#vektoren-definieren",
    "href": "scripts/02_excercises/hands_on_1.html#vektoren-definieren",
    "title": "Hands On 1",
    "section": "",
    "text": "Definiere einen Vektor «first_vector» mit den Zahlen 100, 80, 54, 73. Einen Vektor definiert man so: first_vector &lt;- c(...)\nWende den Befehl boxplot() auf deinen Vektor an\nBerechne die Summe sum()und den Mittelwert mean() von deinem Vektor\nMultipliziere deinen Vektor mit *2 und schaue dir das Ergebnis an.\n\nDie wichtigsten Operatoren und Funktionen in R: https://methodenlehre.github.io/einfuehrung-in-R/chapters/02-R-language.html\n\n\n\n\n\nFunktion\nBedeutung\n\n\n\n\nmean(x, na.rm =FALSE)\nMittelwert\n\n\nsd(x)\nStandardabweichung\n\n\nvar(x)\nVarianz\n\n\nmedian(x)\nMedian\n\n\nsum(x)\nSumme\n\n\nmin(x)\nMinimalwert\n\n\nmax(x)\nMaximalwert\n\n\nrange(x)\nMinimal - und Maximalwert"
  },
  {
    "objectID": "scripts/02_excercises/hands_on_1.html#logische-operatoren",
    "href": "scripts/02_excercises/hands_on_1.html#logische-operatoren",
    "title": "Hands On 1",
    "section": "",
    "text": "Teste ob die Zahl 5 größer als 2 ist –&gt; TRUE or FALSE?\nTeste ob 6 ungleich 8 ist –&gt; TRUE or FALSE?\nSubtrahiere 80 von 50 und speichere das Ergebnis in einer Variable namens «diff_score».\nBerechne mit abs() den absoluten Wert von «diff_score» lasse dir diesen mit print(diff_score) in der Konsole ausgeben.\n\n\n\n\n\n\nZeichen\nBedeutung\n\n\n\n\n==\ngleich\n\n\n!=\nungleich\n\n\n&gt;\ngrösser\n\n\n&gt;=\ngrösser gleich\n\n\n&lt;\nkleiner\n\n\n&lt;=\nkleiner gleich\n\n\n|\nLogisches Oder\n\n\n&\nLogisches Und"
  },
  {
    "objectID": "scripts/02_excercises/hands_on_1.html#nachvollziehbarkeit-von-code",
    "href": "scripts/02_excercises/hands_on_1.html#nachvollziehbarkeit-von-code",
    "title": "Hands On 1",
    "section": "",
    "text": "Informative Kommentare im Code sind elementar für die Nachvollziehbarkeit.\n\nSchreibe einen Kommentar indem du ein # verwendest.\nCode der nach einem # steht wird nicht ausgeführt. Setze ein # vor eine Codezeile und führe sie aus und beobachte was passiert.\n\n\n\n\nEs gibt verschiedene Konventionen, wie man Variablen benennen kann.\nEinige wichtige Grundsätze dafür sind:\n\nNamen können aus Buchstaben, Zahlen sowie den Zeichen _ oder . bestehen.\nSie müssen mit einem Buchstaben beginnen und dürfen keine Leerzeichen enthalten.\nSonderzeichen und Großbuchstaben sollten vermieden werden.\nKeine Namen verwenden, die bereits für Funktionen reserviert sind (z. B. mean()).\nDer Name sollte den Inhalt der Variablen möglichst gut beschreiben → Reproduzierbarkeit; clarity instead of brevity.\nAm besten englische Bezeichnungen verwenden, um internationalen Standards zu folgen.\n\n👉 Mehr dazu\nÜbung:\n\nDefiniere eine neue Variable nach snake_case.\nDefiniere eine zweite Variable nach CamelCase.\n\nIn unserem Seminar verwenden wir den snake_case."
  },
  {
    "objectID": "scripts/02_excercises/hands_on_1.html#für-fortgeschrittene-r-nutzerinnen",
    "href": "scripts/02_excercises/hands_on_1.html#für-fortgeschrittene-r-nutzerinnen",
    "title": "Hands On 1",
    "section": "",
    "text": "Speichere die beiden höchsten Werte aus «first_vector» in einer neuen Variable ab (Tipp: verwende sort() )\nErstelle einen Vektor mit Werten von 0-1000 in 10er Schritten (Tipp: suche nach der Funktion seq()\nZiehe zufällig eine Zahl aus diesem Vektor\nGeneriere einen Vektor, der aus 50 Wiederholungen der Zahl 3 besteht\n\nTipps zu diesen Aufgaben findest du bei Bedarf hier: https://methodenlehre.github.io/einfuehrung-in-R/chapters/02-R-language.html (Kapitel 2.1)\nTipp: Suche nach der Dokumentation der folgenden Funktionen: sort(), seq(), sample, rep().\nDie Dokumentation kannst du mittels ?Funktionsname aufrufen."
  },
  {
    "objectID": "scripts/02_excercises/hands_on_1.html#datentypen",
    "href": "scripts/02_excercises/hands_on_1.html#datentypen",
    "title": "Hands On 1",
    "section": "",
    "text": "numeric vectors: werden in integer (ganze Zahlen) und double (reelle Zahlen) unterteilt, z.B.\nnumerical_vector &lt;- c(1, 2.5, 4)\ncharacter vectors: bestehen aus Zeichen, welche von Anführungszeichen umgeben werden, z.B.\ntext_vector &lt;- c(\"Hello\", \"World\")\nlogical vectors: Elemente dieses Typs können nur 3 Werte annehmen: TRUE, FALSE oder NA\nlog_vector &lt;- c(TRUE, FALSE, TRUE)\n\nVektoren müssen aus denselbsten Elementen bestehen, d.h. z.B. numeric und character können nicht gemischt werden. Vektoren werden meist mit c() erstellt."
  },
  {
    "objectID": "scripts/02_excercises/hausuebung_3.html",
    "href": "scripts/02_excercises/hausuebung_3.html",
    "title": "hausuebung_3",
    "section": "",
    "text": "Abgabe bis: Freitag 12.12, 23:55 via ILIAS\nZip-Datei benennen: vorname_nachname.zip\n\nGerendertes Skript: vorname_nachname_hausuebung_3.html\nUngerendertes Quarto-Skript: vorname_nachname_hausuebung_3.qmd\n\nPeer Feedback: Bis 17.12 direkt an die Person und im Forum als Zusammenfassung. Im Forum bitte auch Namen der Person, für die das Feedback bestimmt ist, nennen.\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nStelle deinen YAML-Header so ein, dass ein table of contents erstellt wird, embed-resources: true aktiviert ist und das Ausgabeformat auf html gesetzt wird. Dies verbessert die Leserlichkeit des Dokuments.\n\n\n\n📥 Download therapie_bedingung.csv\n📥 Download therapie_results.csv\n\n\n\n\nIn den folgenden Daten versuchst du herauszufinden, ob sich eine neuartige Therapie von der Kontrollgruppe (Warteliste) unterscheidet. Dafür wurde das Wohlbefinden der Personen über drei Zeitpunkte hinweg gemessen (therapie_results). Zuerst musst du die Daten bereinigen, mergen und visualisieren und zum Schluss mit einem Hypothesentest entscheiden, ob die neue Therapieform besser abschneidet als die Kontrollgruppe.\n\nLies die beiden Datensätze therapie_Bedingung und therapie_results ein.\nBereinge die Datensätze! Gibt es duplizierte Werte? Gibt es Missings? Gibt es unmögliche Werte?\n\n\nMerge die bereinigten Datensätze!\n\n\nWandle die Variablen id und bedingung in Faktoren um.\n\n\nFühre eine Wide-to-Long-Transformation durch und erstelle damit einen Dataframe therapie_long mit einem messwiederholten Faktor messzeitpunkt und der (Outcome-)Variable wohlbefinden. Diese setzt sich aus den Werten in beginn, mitte und ende zusammen.\n\n\nDefiniere die Variable messzeitpunkt als Faktor mit den Faktorstufen beginn, mitte und ende (in genau dieser Reihenfolge).\n\n\n\n\n\n\nBevor wir die Daten mit Hypothesentests analysieren, wollen wir ein Gefühl für die Daten erhalten. Plotte dafür den Mittelwertsverlauf mit Fehlerbalken über die drei Zeitpunkte hinweg. Nutze den zur Verfügung gestellten Code, um ein Summary zu erstellen.\n\n\nsummary_data &lt;- therapie_long |&gt;\n  group_by(bedingung, messzeitpunkt) |&gt;\n  summarise(\n    mean_wb = mean(wohlbefinden),\n    se_wb   = sd(wohlbefinden) / sqrt(n())\n  )\n\n\nPlotte nun die Daten. Färbe die Verlaufslinien nach Versuchsbedingung ein und gruppiere die Daten mit color = bedingung und group = bedingung. Verwende drei Geoms:\n\ngeom_line() für die Verlaufslinien\ngeom_point() für die einzelnen Datenpunkten\ngeom_errorbar() für die Fehlerbalken.\n\nFüge ausserdem angemessene Formatierungen hinzu (Titel, Achsenbeschriftungen, Theme).\n\n\n\n\n\n\n\n\n\n\n\nBenötigte Packages\n\n\n\n\nFür die folgenden Aufgaben benötigst du afex und car und emmeans\n\n\n\n\n\n\n\n\n\nCheatsheet Statistik 2\n\n\n\n\n\n\n\n\n\n\nPrüfe die Daten auf Varianzhomogenität und nutze dafür den Levene-Test. Der Levene-Test wird für die abhängige Variable über den Between-Faktor berechnet (also: Sind die Varianzen der AV über die drei Gruppen hinweg ähnlich verteilt?).\n\nErgänze dafür den Code um die nötigen Variablen. Der Test prüft gegen Varianzhomogenität; daher bedeutet ein nicht signifikantes Ergebnis, dass die Voraussetzung für die ANOVA nicht verletzt ist.\n\n\nleveneTest(AV ~ Gruppen, data = )\n\n\nFühre eine Mixed-Design-ANOVA mit aov_4() (aus dem Paket afex) durch. Die abhängige Variable ist wohlbefinden, der unabhängige Between-Faktor ist bedingung und der unabhängige Within-Faktor ist messzeitpunkt. Die Formel für die ANOVA lautet: AV ~ Between-Faktor + (Within-Faktor). Für den Within-Faktor verwenden wir die folgende Schreibweise: (messzeitpunkt | id), da die Messwiederholungen innerhalb jeder Person verschachtelt sind.\n\nPasse den Code an:\n\nanova_1 &lt;- aov_4(AV ~ between_subjects_faktor + (messzeitpunkt | id), data = xx)\n  \nsummary(anova_1)\n\n\n\n\n\n\n\nNote\n\n\n\nSchaue dir die Ergebnisse einschliesslich des Mauchly-Tests auf Sphärizität an – dieser ist relevant bei mindestens drei Within-Faktoren. Der Mauchly-Test sollte nicht signifikant sein, sodass wir Sphärizität annehmen können (ähnlich zum Levene Test). Falls doch: Werte nach Greenhouse-Geisser-Korrektur interpretieren.\n\n\n\nBerechne die die ANOVA erneut und inkludiere die Berechnung des partiellen Eta². Nutze dafür als zusätzliches Argument in der aov_4 Funktion anova_table = list(es = c(\"ges\", \"pes\"))) .\nBetrachte die Ergebnisse indem du mit $ auf anova_table des Objekts zugreifst in dem du die ANOVA abgespeichert hast.\n\n\nBerechne nun paarweise Post-hoc-Vergleiche mit Tukey-Korrektur (Korrektur für multiples Testen), indem du zuerst emmeans() (aus dem Paket “emmeans”) speicherst und anschliessend die Funktion pairs() anwendest. Hier ist ein Muster-Code:\n\n\nresult &lt;- emmeans(object = your_anova_model, specs = ~ messwiederholung_faktor * between_factor)\npairs(results, simple = \"mw_factor\", adjust = \"tukey\")"
  },
  {
    "objectID": "scripts/02_excercises/hausuebung_3.html#formalitäten-und-abgabe",
    "href": "scripts/02_excercises/hausuebung_3.html#formalitäten-und-abgabe",
    "title": "hausuebung_3",
    "section": "",
    "text": "Abgabe bis: Freitag 12.12, 23:55 via ILIAS\nZip-Datei benennen: vorname_nachname.zip\n\nGerendertes Skript: vorname_nachname_hausuebung_3.html\nUngerendertes Quarto-Skript: vorname_nachname_hausuebung_3.qmd\n\nPeer Feedback: Bis 17.12 direkt an die Person und im Forum als Zusammenfassung. Im Forum bitte auch Namen der Person, für die das Feedback bestimmt ist, nennen.\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nStelle deinen YAML-Header so ein, dass ein table of contents erstellt wird, embed-resources: true aktiviert ist und das Ausgabeformat auf html gesetzt wird. Dies verbessert die Leserlichkeit des Dokuments.\n\n\n\n📥 Download therapie_bedingung.csv\n📥 Download therapie_results.csv"
  },
  {
    "objectID": "scripts/02_excercises/hausuebung_3.html#datensätze-therapie-einlesen-und-bereinigen",
    "href": "scripts/02_excercises/hausuebung_3.html#datensätze-therapie-einlesen-und-bereinigen",
    "title": "hausuebung_3",
    "section": "",
    "text": "In den folgenden Daten versuchst du herauszufinden, ob sich eine neuartige Therapie von der Kontrollgruppe (Warteliste) unterscheidet. Dafür wurde das Wohlbefinden der Personen über drei Zeitpunkte hinweg gemessen (therapie_results). Zuerst musst du die Daten bereinigen, mergen und visualisieren und zum Schluss mit einem Hypothesentest entscheiden, ob die neue Therapieform besser abschneidet als die Kontrollgruppe.\n\nLies die beiden Datensätze therapie_Bedingung und therapie_results ein.\nBereinge die Datensätze! Gibt es duplizierte Werte? Gibt es Missings? Gibt es unmögliche Werte?\n\n\nMerge die bereinigten Datensätze!\n\n\nWandle die Variablen id und bedingung in Faktoren um.\n\n\nFühre eine Wide-to-Long-Transformation durch und erstelle damit einen Dataframe therapie_long mit einem messwiederholten Faktor messzeitpunkt und der (Outcome-)Variable wohlbefinden. Diese setzt sich aus den Werten in beginn, mitte und ende zusammen.\n\n\nDefiniere die Variable messzeitpunkt als Faktor mit den Faktorstufen beginn, mitte und ende (in genau dieser Reihenfolge)."
  },
  {
    "objectID": "scripts/02_excercises/hausuebung_3.html#daten-visualisieren",
    "href": "scripts/02_excercises/hausuebung_3.html#daten-visualisieren",
    "title": "hausuebung_3",
    "section": "",
    "text": "Bevor wir die Daten mit Hypothesentests analysieren, wollen wir ein Gefühl für die Daten erhalten. Plotte dafür den Mittelwertsverlauf mit Fehlerbalken über die drei Zeitpunkte hinweg. Nutze den zur Verfügung gestellten Code, um ein Summary zu erstellen.\n\n\nsummary_data &lt;- therapie_long |&gt;\n  group_by(bedingung, messzeitpunkt) |&gt;\n  summarise(\n    mean_wb = mean(wohlbefinden),\n    se_wb   = sd(wohlbefinden) / sqrt(n())\n  )\n\n\nPlotte nun die Daten. Färbe die Verlaufslinien nach Versuchsbedingung ein und gruppiere die Daten mit color = bedingung und group = bedingung. Verwende drei Geoms:\n\ngeom_line() für die Verlaufslinien\ngeom_point() für die einzelnen Datenpunkten\ngeom_errorbar() für die Fehlerbalken.\n\nFüge ausserdem angemessene Formatierungen hinzu (Titel, Achsenbeschriftungen, Theme)."
  },
  {
    "objectID": "scripts/02_excercises/hausuebung_3.html#anovas-und-post-hoc-t-tests",
    "href": "scripts/02_excercises/hausuebung_3.html#anovas-und-post-hoc-t-tests",
    "title": "hausuebung_3",
    "section": "",
    "text": "Benötigte Packages\n\n\n\n\nFür die folgenden Aufgaben benötigst du afex und car und emmeans\n\n\n\n\n\n\n\n\n\nCheatsheet Statistik 2\n\n\n\n\n\n\n\n\n\n\nPrüfe die Daten auf Varianzhomogenität und nutze dafür den Levene-Test. Der Levene-Test wird für die abhängige Variable über den Between-Faktor berechnet (also: Sind die Varianzen der AV über die drei Gruppen hinweg ähnlich verteilt?).\n\nErgänze dafür den Code um die nötigen Variablen. Der Test prüft gegen Varianzhomogenität; daher bedeutet ein nicht signifikantes Ergebnis, dass die Voraussetzung für die ANOVA nicht verletzt ist.\n\n\nleveneTest(AV ~ Gruppen, data = )\n\n\nFühre eine Mixed-Design-ANOVA mit aov_4() (aus dem Paket afex) durch. Die abhängige Variable ist wohlbefinden, der unabhängige Between-Faktor ist bedingung und der unabhängige Within-Faktor ist messzeitpunkt. Die Formel für die ANOVA lautet: AV ~ Between-Faktor + (Within-Faktor). Für den Within-Faktor verwenden wir die folgende Schreibweise: (messzeitpunkt | id), da die Messwiederholungen innerhalb jeder Person verschachtelt sind.\n\nPasse den Code an:\n\nanova_1 &lt;- aov_4(AV ~ between_subjects_faktor + (messzeitpunkt | id), data = xx)\n  \nsummary(anova_1)\n\n\n\n\n\n\n\nNote\n\n\n\nSchaue dir die Ergebnisse einschliesslich des Mauchly-Tests auf Sphärizität an – dieser ist relevant bei mindestens drei Within-Faktoren. Der Mauchly-Test sollte nicht signifikant sein, sodass wir Sphärizität annehmen können (ähnlich zum Levene Test). Falls doch: Werte nach Greenhouse-Geisser-Korrektur interpretieren.\n\n\n\nBerechne die die ANOVA erneut und inkludiere die Berechnung des partiellen Eta². Nutze dafür als zusätzliches Argument in der aov_4 Funktion anova_table = list(es = c(\"ges\", \"pes\"))) .\nBetrachte die Ergebnisse indem du mit $ auf anova_table des Objekts zugreifst in dem du die ANOVA abgespeichert hast.\n\n\nBerechne nun paarweise Post-hoc-Vergleiche mit Tukey-Korrektur (Korrektur für multiples Testen), indem du zuerst emmeans() (aus dem Paket “emmeans”) speicherst und anschliessend die Funktion pairs() anwendest. Hier ist ein Muster-Code:\n\n\nresult &lt;- emmeans(object = your_anova_model, specs = ~ messwiederholung_faktor * between_factor)\npairs(results, simple = \"mw_factor\", adjust = \"tukey\")"
  },
  {
    "objectID": "scripts/02_excercises/hausuebung_loesung_1.html",
    "href": "scripts/02_excercises/hausuebung_loesung_1.html",
    "title": "Hausübung 1 Lösung",
    "section": "",
    "text": "Aufgabe 1: Datensatz aufbereiten und beschreiben\nWir arbeiten für die Übungen mit diesem Datensatz. Dieser wurde simuliert und spiegelt keine echten Daten oder Zusammenhänge wider. Der Datensatz beinhaltet demografische Variablen sowie eine Version des BFI-44-Fragebogens. In den folgenden Aufgaben werden wir diesen mit den bisher kennengelernten tidyverse-Funktionen aufbereiten und analysieren.\n 📥 Download fake_bfi_dataset.csv \nNutze die dplyr-Funktionen, die wir kennengelernt haben, um die folgenden Aufgaben zu bearbeiten.\nTipp: In einigen Variablen gibt es fehlende Werte (missings). Die Bearbeitung dieser Werte erfolgt erst in Aufgabe 2. Verwende, falls nötig, das Argument na.rm = TRUE.\nAufgaben\n\nBenenne die Variable Ort in Postleitzahl um.\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\ndata &lt;- read_delim(\"raw/fake_bfi_dataset.csv\", delim = \";\", escape_double = FALSE, trim_ws = TRUE)\n\n\ndata &lt;- data |&gt; \n  rename(Postleitzahl = Ort)\n\n\n\n\n\nWelche Spalte scheint doppelt vorhanden zu sein? Lösche sie aus dem Datensatz.\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\ndata &lt;- select(data, - Ort_2)\n\n\n\n\n\nPersonen die nicht volljährig sind dürfen nicht an der Studie teilnehmen und müssen ausgeschlossen werden.\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\ndata &lt;- filter(data, Age &gt;= 18)\n\n\n\n\n\nFüge dem Datensatz die Spalte Alterskohorte hinzu. Wenn eine Person über 60 Jahre alt ist, gilt sie als alt, ansonsten als jung.\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\ndata &lt;- data |&gt;\n  mutate(Alterskohorte = ifelse(Age &gt; 60, \"alt\", \"jung\"))\n\n\n\n\n\nWelche Variablen sollten Faktoren sein? Wandle sie in Faktoren um\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\ndata$Gender &lt;- as.factor(data$Gender)\ndata$Alterskohorte &lt;- as.factor(data$Alterskohorte)\n\n\n\n\n\nErstelle eine Kopie des Datensatzes nur mit den demographischen Variablen.\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\ndata_demographic &lt;- data |&gt; \n  select(Age, Gender, Postleitzahl, Alterskohorte)\n\n\n\n\nVerwende die dplyr-Funktionen, um die folgenden Fragen zu beantworten:\n\nWelchen Anteil am Gesamtsample hat jeder Ort bzw. jede Postleitzahl, und wie kann dieser als neue Spalte im Datensatz ergänzt werden?\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\ndata &lt;- data |&gt;\n  group_by(Postleitzahl) |&gt;\n  mutate(proportion = n() / nrow(data)) |&gt;\n  ungroup()\n\n\n\n\n\nIn welchem Quartier leben proportional am meisten Personen, die sich als weiblich beschreiben?\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\ndata_demographic |&gt;\n  group_by(Postleitzahl) |&gt;\n  summarise(\n    n_female = sum(Gender == \"female\", na.rm = TRUE),\n    n_total = n(),\n    proportion_weiblich = n_female / n_total\n  ) |&gt;\n  arrange(desc(proportion_weiblich))\n\n# A tibble: 4 × 4\n  Postleitzahl n_female n_total proportion_weiblich\n         &lt;dbl&gt;    &lt;int&gt;   &lt;int&gt;               &lt;dbl&gt;\n1         3005        6      10               0.6  \n2         3014        2       8               0.25 \n3         3012        5      21               0.238\n4         3001        0       3               0    \n\n\n\n\n\n\nWie hoch ist das durschnittliche Alter pro Quartier?\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\ndata_demographic |&gt;\n  group_by(Postleitzahl) |&gt; \n  summarize(durschnittsalter = mean(Age))\n\n# A tibble: 4 × 2\n  Postleitzahl durschnittsalter\n         &lt;dbl&gt;            &lt;dbl&gt;\n1         3001             54.7\n2         3005             46.9\n3         3012             40  \n4         3014             46.8\n\n\n\n\n\n\nWie alt sind die jüngsten Personen getrennt nach Gender?\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\ndata_demographic |&gt;\n  group_by(Gender) |&gt; \n  summarize(min_age = min(Age))\n\n# A tibble: 5 × 2\n  Gender     min_age\n  &lt;fct&gt;        &lt;dbl&gt;\n1 female          19\n2 male            19\n3 non-binary      24\n4 other           21\n5 &lt;NA&gt;            26\n\n\n\n\n\n\nErstelle eine Rangliste der Quartiere nach durchschnittlichem Alter (vom höchsten zum niedrigsten).\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\nrangliste &lt;- data_demographic |&gt;\n  group_by(Postleitzahl) |&gt; \n  summarise(mean_age = mean(Age)) |&gt; \n  arrange(desc(mean_age))\n\nrangliste\n\n# A tibble: 4 × 2\n  Postleitzahl mean_age\n         &lt;dbl&gt;    &lt;dbl&gt;\n1         3001     54.7\n2         3005     46.9\n3         3014     46.8\n4         3012     40  \n\n\n\n\n\n\n\nAufgabe 2: Fehlende Werte\n📖Kapitel 4.3.3 Ellis & Mayer\nFühre die folgenden Schritte durch:\n\nUntersuche den Datensatz auf fehlende Werte. Wie viele fehlende Werte gibt es insgesamt, und in welchen Variablen treten sie auf\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\nskim(data)\n\n\nData summary\n\n\nName\ndata\n\n\nNumber of rows\n42\n\n\nNumber of columns\n49\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n44\n\n\nfactor\n2\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nextra_1\n0\n1.00\n7\n23\n0\n5\n0\n\n\nagree_1_r\n0\n1.00\n7\n23\n0\n5\n0\n\n\nconsc_1\n0\n1.00\n7\n23\n0\n5\n0\n\n\nneuro_1\n1\n0.98\n7\n23\n0\n5\n0\n\n\nopen_1_r\n0\n1.00\n7\n23\n0\n5\n0\n\n\nextra_2\n0\n1.00\n7\n23\n0\n5\n0\n\n\nagree_2\n0\n1.00\n7\n23\n0\n5\n0\n\n\nconsc_2\n1\n0.98\n7\n23\n0\n5\n0\n\n\nneuro_2_r\n0\n1.00\n7\n23\n0\n5\n0\n\n\nopen_2\n0\n1.00\n7\n23\n0\n5\n0\n\n\nextra_3\n0\n1.00\n7\n23\n0\n5\n0\n\n\nagree_3\n0\n1.00\n7\n23\n0\n5\n0\n\n\nconsc_3_r\n2\n0.95\n7\n23\n0\n5\n0\n\n\nneuro_3\n0\n1.00\n7\n23\n0\n5\n0\n\n\nopen_3\n0\n1.00\n7\n23\n0\n5\n0\n\n\nextra_4_r\n0\n1.00\n7\n23\n0\n5\n0\n\n\nagree_4\n0\n1.00\n7\n23\n0\n5\n0\n\n\nconsc_4\n0\n1.00\n7\n23\n0\n5\n0\n\n\nneuro_4\n0\n1.00\n7\n23\n0\n5\n0\n\n\nopen_4\n0\n1.00\n7\n23\n0\n5\n0\n\n\nextra_5_r\n0\n1.00\n7\n23\n0\n5\n0\n\n\nagree_5\n1\n0.98\n7\n23\n0\n5\n0\n\n\nconsc_5\n0\n1.00\n7\n23\n0\n5\n0\n\n\nneuro_5\n0\n1.00\n7\n23\n0\n5\n0\n\n\nopen_5\n0\n1.00\n7\n23\n0\n5\n0\n\n\nextra_6\n2\n0.95\n7\n23\n0\n5\n0\n\n\nagree_6\n0\n1.00\n7\n23\n0\n5\n0\n\n\nconsc_6_r\n2\n0.95\n7\n23\n0\n5\n0\n\n\nneuro_6\n1\n0.98\n7\n23\n0\n5\n0\n\n\nopen_6\n0\n1.00\n7\n23\n0\n5\n0\n\n\nextra_7\n0\n1.00\n7\n23\n0\n5\n0\n\n\nagree_7\n2\n0.95\n7\n23\n0\n5\n0\n\n\nconsc_7\n1\n0.98\n7\n23\n0\n5\n0\n\n\nneuro_7_r\n1\n0.98\n7\n23\n0\n5\n0\n\n\nopen_7\n0\n1.00\n7\n23\n0\n5\n0\n\n\nextra_8\n0\n1.00\n7\n23\n0\n5\n0\n\n\nagree_8_r\n0\n1.00\n7\n23\n0\n5\n0\n\n\nconsc_8\n0\n1.00\n7\n23\n0\n5\n0\n\n\nneuro_8\n0\n1.00\n7\n23\n0\n5\n0\n\n\nopen_8_r\n0\n1.00\n7\n23\n0\n5\n0\n\n\nextra_9\n2\n0.95\n7\n23\n0\n5\n0\n\n\nagree_9\n1\n0.98\n7\n23\n0\n5\n0\n\n\nconsc_9\n0\n1.00\n7\n23\n0\n5\n0\n\n\nneuro_9_r\n1\n0.98\n7\n23\n0\n5\n0\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nGender\n3\n0.93\nFALSE\n4\nmal: 14, fem: 13, non: 9, oth: 3\n\n\nAlterskohorte\n0\n1.00\nFALSE\n2\njun: 31, alt: 11\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nAge\n0\n1\n43.98\n16.99\n19.00\n31.0\n42.00\n60.5\n69.0\n▇▇▃▅▇\n\n\nPostleitzahl\n0\n1\n3009.93\n4.15\n3001.00\n3005.0\n3012.00\n3012.0\n3014.0\n▁▃▁▁▇\n\n\nproportion\n0\n1\n0.35\n0.16\n0.07\n0.2\n0.37\n0.5\n0.5\n▁▇▁▁▇\n\n\n\n\ntable(is.na(data))\n\n\nFALSE  TRUE \n 2037    21 \n\n\n\n\n\n\nEinige Personen haben keine Angabe zu ihrer Geschlechtsidentität gemacht. Ersetze diese fehlenden Werte (NAs) durch “Keine Angabe”. Nutze dafür die Funktion mutate() und replace_na(). Beachte: Gender wurde bereits als Faktor definiert, muss aber erneut zu einem Character transformiert werden.\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\nlibrary(dplyr)\nlibrary(tidyr)\n\ndata &lt;- data |&gt;\n  mutate(\n    Gender = as.character(Gender),\n    Gender = replace_na(Gender, \"Keine Angabe\")\n  )\n\n\n\n\n\nZeilen mit fehlenden Werten löschen\nErstelle eine Kopie des Datensatzes und verwende drop_na(),\num alle Zeilen mit fehlenden Werten zu entfernen.\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\ndata_drop_na &lt;- drop_na(data) \n\n\n\n\n\n\nAufgabe 3: Skalenberechnung\n📖Kapitel 4.4. Ellis & Mayer\nAufgaben:\n\nUmwandlung der BFI-Items in numerische Werte.\n\n„Stimme gar nicht zu“ → 1\n„Stimme voll und ganz zu“ → 5\n\n\nVerwende dafür eine Kombination aus mutate(), across() und case_when() oder recode().\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\ndata_numeric &lt;- data_drop_na |&gt;\n  mutate(\n    across(\n      extra_1:neuro_9_r,   # selects all columns in that range\n      ~ case_when(\n        . == \"Stimme gar nicht zu\" ~ 1,\n        . == \"Stimme eher nicht zu\" ~ 2,\n        . == \"Neutral\" ~ 3,\n        . == \"Stimme eher zu\" ~ 4,\n        . == \"Stimme voll und ganz zu\" ~ 5\n      )\n    )\n  )\n\n# Alternative mit recode\ndata_numeric &lt;- data_drop_na |&gt;\n  mutate(\n    across(\n      extra_1:neuro_9_r,\n      ~ recode(\n        .,\n        \"Stimme gar nicht zu\" = 1,\n        \"Stimme eher nicht zu\" = 2,\n        \"Neutral\" = 3,\n        \"Stimme eher zu\" = 4,\n        \"Stimme voll und ganz zu\" = 5\n      )\n    )\n  )\n\n\n\n\n\nUmpolen der negativ formulierten Items\n\nDie negativ formulierten Items enden alle mit _r (für reverse). Poole diese Items um.\nSuche dir eine dplyr Funktion, welche helfen kann alle Variablen auszuwählen welche mit _r aufhören.\n💡Tipp: Ähnlich wie starts_with\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\nlibrary(dplyr)\n\ndata_reversed &lt;- data_numeric |&gt;\n  mutate(\n    across(\n      ends_with(\"_r\"),\n      ~ case_when(\n        . == 1 ~ 5,\n        . == 2 ~ 4,\n        . == 3 ~ 3,\n        . == 4 ~ 2,\n        . == 5 ~ 1\n      )\n    )\n  )\n\n\n#Oder Effizienter\n\ndata_reversed &lt;- data_numeric |&gt;\n  mutate(\n    across(ends_with(\"_r\"), ~ 6 - .) #~ 6 - . --&gt; Für jede wert der col -6 \n  )\n\n\n\n\n\n\nBerechnung der Big-Five-Skalen\n\nErstelle neue Variablen, die den Mittelwert jedes Big-Five-Faktors pro Person enthalten.\nMit welcher Funktion kannst du dir ersparen alle Variablen auszuschreiben?\n\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\n# Berechnung der Mittelwerte ohne na.rm\ndata_bfi_scores &lt;- data_reversed |&gt;\n  mutate(\n    extraversion = rowMeans(select(data_reversed, starts_with(\"extra\"))),\n    agreeableness = rowMeans(select(data_reversed, starts_with(\"agree\"))),\n    conscientiousness = rowMeans(select(data_reversed, starts_with(\"consc\"))),\n    neuroticism = rowMeans(select(data_reversed, starts_with(\"neuro\"))),\n    openness = rowMeans(select(data_reversed, starts_with(\"open\")))\n  )\n\n\n\n\n\nZusammenhänge zwischen Skalen testen\n\nTeste mit cor.test() die Korrelation zwischen zwei Big-Five-Faktoren,\nzum Beispiel zwischen Extraversion und Offenheit.\n\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\n# Korrelation zwischen Extraversion und Offenheit testen\ncor.test(\n  data_bfi_scores$extraversion,\n  data_bfi_scores$openness\n)\n\n\n    Pearson's product-moment correlation\n\ndata:  data_bfi_scores$extraversion and data_bfi_scores$openness\nt = 1.4255, df = 25, p-value = 0.1664\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n -0.1181582  0.5924542\nsample estimates:\n      cor \n0.2741663 \n\n\n\n\n\n\n\nBerechne die Durchschnittswerte, Standardabweichungen und Mediane der Big-Five-Faktoren Extraversion und Offenheit, unterteilt nach der Geschlechtsangabe.\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\ndata_summary &lt;- data_bfi_scores |&gt;\n  group_by(Gender) |&gt;\n  summarise(\n    across(\n      c(extraversion, openness),\n      list(\n        Mittelwert = mean,\n        SD = sd,\n        Median = median\n      ),\n      na.rm = TRUE\n    )\n  )\n\nWarning: There was 1 warning in `summarise()`.\nℹ In argument: `across(...)`.\nℹ In group 1: `Gender = \"Keine Angabe\"`.\nCaused by warning:\n! The `...` argument of `across()` is deprecated as of dplyr 1.1.0.\nSupply arguments directly to `.fns` through an anonymous function instead.\n\n  # Previously\n  across(a:b, mean, na.rm = TRUE)\n\n  # Now\n  across(a:b, \\(x) mean(x, na.rm = TRUE))\n\ndata_summary\n\n# A tibble: 5 × 7\n  Gender       extraversion_Mittelwert extraversion_SD extraversion_Median\n  &lt;chr&gt;                          &lt;dbl&gt;           &lt;dbl&gt;               &lt;dbl&gt;\n1 Keine Angabe                    3.11           0.157                3.11\n2 female                          3.26           0.448                3.33\n3 male                            2.97           0.772                2.72\n4 non-binary                      2.94           0.551                2.89\n5 other                           2.5            0.393                2.5 \n# ℹ 3 more variables: openness_Mittelwert &lt;dbl&gt;, openness_SD &lt;dbl&gt;,\n#   openness_Median &lt;dbl&gt;",
    "crumbs": [
      "Hausübungen",
      "Hausübung 1 - Mit Lösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/hausuebung_loesung_2.html",
    "href": "scripts/02_excercises/hausuebung_loesung_2.html",
    "title": "Hausübung 2 Lösung",
    "section": "",
    "text": "Abgabe bis: Freitag 28.11, 23:55 via ILIAS\nZip-Datei benennen: vorname_nachname.zip\n\nGerendertes Skript: vorname_nachname_hausuebung_2.html\nUngerendertes Quarto-Skript: vorname_nachname_hausuebung_2.qmd\n\nPeer Feedback: Bis 3.12 direkt an die Person und im Forum als Zusammenfassung. Im Forum bitte auch Namen der Person, für die das Feedback bestimmt ist, nennen.\n\n\n\n\n📥 Download practice_dataset2.csv\n\n\nStelle in deinem Quarto Header die folgenden Dinge ein. Achtung: Achte auf die Einrückung der Einstellungen. Wenn das nicht von Hand klappt kann man sich bei der Einrückung von einem LLM helfen lassen. 😉.\n\nformat: html\nembed-resources: true\ntable of contents (toc) = true\n\nLies den folgenden Datensatz ein: Practice_dataset2\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\npractice_dataset2 &lt;- read_delim(\"raw/practice_dataset2.csv\", delim = \";\", escape_double = FALSE, trim_ws = TRUE)\n\n\n\n\n\n\n\nBerechne den Mittelwert und die Standardabweichung der Variable self_efficacy für jede Gruppe (condition). Runde die Ergebnisse jeweils auf drei Nachkommastellen. Speichere diese deskriptive Statistik in einen neuen Dataframe ab.\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\npractice_dataset_sum &lt;- practice_dataset2 |&gt; \n  group_by(condition) |&gt; \n  summarize(\n    mean_selfeff = round(mean(self_efficacy, na.rm = TRUE), 3),\n    sd_selfeff = round(sd(self_efficacy, na.rm = TRUE), 3) #mit einem \",\" getrennt, koennt ihr beliebig viele zusammenfassende Berechnungen hintereinander in einem Call durchfuehren\n  )\n\n\n\n\n\n\n\nNutze kable um Formatierungen am unter 1.2 erstellten Dataframe durchzuführen (Überschrift ergänzen, Spalten benennen, Nachkommastellen anpassen).\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\nkable(practice_dataset_sum,   caption = \"Zusammenfassung der Self-Efficacy nach Bedingung\",   col.names = c(\"Bedingung\", \"Mittelwert Self-Efficacy\", \"SD Self-Efficacy\"),   digits = 3 ) \n\n\nZusammenfassung der Self-Efficacy nach Bedingung\n\n\nBedingung\nMittelwert Self-Efficacy\nSD Self-Efficacy\n\n\n\n\ncontrol\n68.993\n10.21\n\n\nexperimental\n70.596\n8.25\n\n\n\n\n\n\n\n\n\n\n\nBerechne zusätzlich die Schiefe (skew) und Kurtosis (kurtosi) der Variable self_efficacy pro Gruppe (condition), mit Funktionen aus dem Paket psych.\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\npractice_dataset_dis &lt;- practice_dataset2 |&gt;    \n  group_by(condition) |&gt;   \n  summarize(     \n    skew = round(psych::skew(self_efficacy), 3), \n    kurtosis = round(psych::kurtosi(self_efficacy), 3))  #Die Ergebnisse werden auf 3 Nachkommastellen gerundet\n\nprint(practice_dataset_dis) \n\n# A tibble: 2 × 3\n  condition     skew kurtosis\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 control      0.11    -0.217\n2 experimental 0.025    0.22 \n\n\n\n\n\n\n\n\n\n\n\nDer Originaldatensatz enthält die Spalten pre_mood, mid_mood, post_mood. Verwandle diese mithilfe von pivot_longer() in einen Long-Datensatz namens mood_long. Die neue Spalte mit den Zeitpunkten soll mood_time heißen, die mit den Werten mood_rating.\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\nmood_long &lt;- practice_dataset2 |&gt;\n  pivot_longer(\n    cols = starts_with(\"pre_mood\"):post_mood, #hier waehlt ihr die Spalten aus, welche vom breiten (wide) Datensatz in einen laengeren (long) Datensatz ueberfuehrt werden sollen\n    names_to = \"mood_time\", #hier benennt ihr die Spalte, in welcher die alten Spaltennamen abgelegt werden\n    values_to = \"mood_rating\" #hier benennt ihr die Spalte, in welcher die alten Spaltenwerte abgelegt werden\n  )\n\n#alternativen\nmood_long &lt;- practice_dataset2 |&gt;\n  pivot_longer(\n    cols = c(\"pre_mood\", \"mid_mood\", \"post_mood\"), #hier mit der expliziten Nennung aller entsprechenden Spalten\n    names_to = \"mood_time\",\n    values_to = \"mood_rating\"\n  )\n\nmood_long &lt;- practice_dataset2 |&gt;\n  pivot_longer(\n    cols = ends_with(\"mood\"), #hier anhand dessen, womit der Spaltenname endet\n    names_to = \"mood_time\",\n    values_to = \"mood_rating\"\n  )\n\n\n\n\n\n\n\n\n\n\nIm nächsten Schritt verwenden wir den LONG-Datensatz (Siehe Aufgabe 2.1), um den Verlauf über die verschiedenen Zeitpunkte darzustellen. Das Ziel ist es, die Stimmung (mood) zu den unterschiedlichen Zeitpunkten, aggregiert nach den Konditionen, als Verlaufsdiagramm abzubilden.\n\nDafür soll mood_time in einen Faktor mit geordneten Faktorstufen (pre, mid und post) umgewandelt werden.\nErstelle einen Summary, welches die für den Plot benötigten Angaben zusammenfasst (Durschschnittlicher Mood gruppiert nach Condition und Zeitpunkt).\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\nmood_long$mood_time &lt;- factor(\n  mood_long$mood_time,\n  levels = c(\"pre_mood\", \"mid_mood\", \"post_mood\")\n)\n\nlevels(mood_long$mood_time)\n\n[1] \"pre_mood\"  \"mid_mood\"  \"post_mood\"\n\ndata_plot &lt;- mood_long |&gt;\n  group_by(mood_time, condition) |&gt; \n  summarise(mean_mood = mean(mood_rating))\n\n\n\n\n\n\n\nPlotte die Elemente mood_time und mean_mood. Gruppiere die conditions nach Farbe.\n💡Tipp: Wenn du den Plot einem Objekt zuweist, kannst du ihn weiterverwenden, indem du das Objekt aufrufst und erweiterst. So musst du den Code nicht jedes Mal neu ausschreiben.\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNormalerweise würde das Argument color = condition ausreichen, damit ggplot implizit eine Gruppierung der Daten nach der Variable condition vornimmt und die Datenpunkte innerhalb des Plots verbindet. Da wir vorher aber auch die Variable mood_time explizit als Faktor gesetzt hatten, wird nun jede Kombination aus beiden Variablen implizit als Gruppierung angesehen. Daher gibt es ohne das von uns explizite Argument group = condition für jede Zeile eine eigene Gruppe und die Datenpunkte würden nicht verbunden werden. Probiere den ggplot-call gerne ohne das entsprechende Argument aus und schaue, was passiert!\n\n\n\n\n\n\nPasse nun den Plot aus 3.2 so an, dass er eine Farbpalette verwendet, die für farbenblinde Personen geeignet ist: Nutze die folgende Palette.\nTipp: Verwende: scale_color_manual\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\ncb_palette &lt;- c(   \"#000000\", \"#E69F00\", \"#56B4E9\", \"#009E73\",   \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\" )  \n\n\n\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\nplot_farbe &lt;- plot +   \n  scale_color_manual(values = cb_palette)  \n\nplot_farbe\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFüge mit geom_point() die einzelnen Punkte auf der Linie ein. Stelle die grösse (size() auf 3)\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\nplot_2 &lt;- plot_farbe +   \n geom_point(alpha = 0.5, size = 3)\n\nplot_2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFüge dem Diagramm Titel sowie Achsenbeschriftungen zu deinem Plot und verwende ein Theme das du passend findest.\n\n\n\n\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\nplot_3 &lt;- plot_2 +    \n  labs(     \n    title = \"Zeitlicher Verlauf Mood\",\n    y = \"Mood\",    \n    x = \"Messzeitpunkt\",    \n    color = \"Bedingung\"   ) +  \n  theme_classic()  \nprint(plot_3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpeichere den Plot ab mit ggsave als png ab.\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\nggsave(\"mein_plot.png\", plot = plot_3)\n\n\n\n\n\n\n\n\nErstelle aus dem ursprünglichen Wide Originaldatensatz einen neuen Datensatz subset_mood, der nur Daten der Gruppe experimental beinhaltet.\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\nsubset_mood &lt;- practice_dataset2 |&gt;   filter(condition == \"experimental\") \n\n\n\n\n\n\nPrüfe nun (anhand des unter 4. erstellen Datensatzes) mittels eines gepaarten t-Test ob sich pre_mood und post_mood in der Gruppe experimental unterscheiden. Nutze dafür die Funktion t.test(). Lass dir das Ergebnis mit print() ausgeben.\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\nt_test_result &lt;- t.test(subset_mood$pre_mood, subset_mood$post_mood, paired = TRUE) \n\nprint(t_test_result)\n\n\n    Paired t-test\n\ndata:  subset_mood$pre_mood and subset_mood$post_mood\nt = -0.42731, df = 43, p-value = 0.6713\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -1.0399187  0.6762823\nsample estimates:\nmean difference \n     -0.1818182 \n\n# hier gilt paired = TRUE, da sich die beiden Messungen bedingen (sie sind beide von der selben Person, lediglich zu unterschiedlichen Zeitpunkten aufgenommen worden) = within-subjects Vergleich \n\n\n\n\n\n\n\n\n\nRendere dein Skript als HTML\nLade deine Abgabe (Skript + HTML) als ZIP ordner in ILIAS hoch und schicke sie deinem/deiner Peepartner:in.",
    "crumbs": [
      "Hausübungen",
      "Hausübung 2 - Mit Lösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/hausuebung_loesung_2.html#formalitäten-und-abgabe",
    "href": "scripts/02_excercises/hausuebung_loesung_2.html#formalitäten-und-abgabe",
    "title": "Hausübung 2 Lösung",
    "section": "",
    "text": "Abgabe bis: Freitag 28.11, 23:55 via ILIAS\nZip-Datei benennen: vorname_nachname.zip\n\nGerendertes Skript: vorname_nachname_hausuebung_2.html\nUngerendertes Quarto-Skript: vorname_nachname_hausuebung_2.qmd\n\nPeer Feedback: Bis 3.12 direkt an die Person und im Forum als Zusammenfassung. Im Forum bitte auch Namen der Person, für die das Feedback bestimmt ist, nennen.",
    "crumbs": [
      "Hausübungen",
      "Hausübung 2 - Mit Lösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/hausuebung_loesung_2.html#aufgabe-1-datensatz-einlesen-und-deskriptive-statistik",
    "href": "scripts/02_excercises/hausuebung_loesung_2.html#aufgabe-1-datensatz-einlesen-und-deskriptive-statistik",
    "title": "Hausübung 2 Lösung",
    "section": "",
    "text": "📥 Download practice_dataset2.csv\n\n\nStelle in deinem Quarto Header die folgenden Dinge ein. Achtung: Achte auf die Einrückung der Einstellungen. Wenn das nicht von Hand klappt kann man sich bei der Einrückung von einem LLM helfen lassen. 😉.\n\nformat: html\nembed-resources: true\ntable of contents (toc) = true\n\nLies den folgenden Datensatz ein: Practice_dataset2\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\npractice_dataset2 &lt;- read_delim(\"raw/practice_dataset2.csv\", delim = \";\", escape_double = FALSE, trim_ws = TRUE)\n\n\n\n\n\n\n\nBerechne den Mittelwert und die Standardabweichung der Variable self_efficacy für jede Gruppe (condition). Runde die Ergebnisse jeweils auf drei Nachkommastellen. Speichere diese deskriptive Statistik in einen neuen Dataframe ab.\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\npractice_dataset_sum &lt;- practice_dataset2 |&gt; \n  group_by(condition) |&gt; \n  summarize(\n    mean_selfeff = round(mean(self_efficacy, na.rm = TRUE), 3),\n    sd_selfeff = round(sd(self_efficacy, na.rm = TRUE), 3) #mit einem \",\" getrennt, koennt ihr beliebig viele zusammenfassende Berechnungen hintereinander in einem Call durchfuehren\n  )\n\n\n\n\n\n\n\nNutze kable um Formatierungen am unter 1.2 erstellten Dataframe durchzuführen (Überschrift ergänzen, Spalten benennen, Nachkommastellen anpassen).\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\nkable(practice_dataset_sum,   caption = \"Zusammenfassung der Self-Efficacy nach Bedingung\",   col.names = c(\"Bedingung\", \"Mittelwert Self-Efficacy\", \"SD Self-Efficacy\"),   digits = 3 ) \n\n\nZusammenfassung der Self-Efficacy nach Bedingung\n\n\nBedingung\nMittelwert Self-Efficacy\nSD Self-Efficacy\n\n\n\n\ncontrol\n68.993\n10.21\n\n\nexperimental\n70.596\n8.25\n\n\n\n\n\n\n\n\n\n\n\nBerechne zusätzlich die Schiefe (skew) und Kurtosis (kurtosi) der Variable self_efficacy pro Gruppe (condition), mit Funktionen aus dem Paket psych.\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\npractice_dataset_dis &lt;- practice_dataset2 |&gt;    \n  group_by(condition) |&gt;   \n  summarize(     \n    skew = round(psych::skew(self_efficacy), 3), \n    kurtosis = round(psych::kurtosi(self_efficacy), 3))  #Die Ergebnisse werden auf 3 Nachkommastellen gerundet\n\nprint(practice_dataset_dis) \n\n# A tibble: 2 × 3\n  condition     skew kurtosis\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n1 control      0.11    -0.217\n2 experimental 0.025    0.22",
    "crumbs": [
      "Hausübungen",
      "Hausübung 2 - Mit Lösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/hausuebung_loesung_2.html#aufgabe-2-wide-to-long-transformation",
    "href": "scripts/02_excercises/hausuebung_loesung_2.html#aufgabe-2-wide-to-long-transformation",
    "title": "Hausübung 2 Lösung",
    "section": "",
    "text": "Der Originaldatensatz enthält die Spalten pre_mood, mid_mood, post_mood. Verwandle diese mithilfe von pivot_longer() in einen Long-Datensatz namens mood_long. Die neue Spalte mit den Zeitpunkten soll mood_time heißen, die mit den Werten mood_rating.\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\nmood_long &lt;- practice_dataset2 |&gt;\n  pivot_longer(\n    cols = starts_with(\"pre_mood\"):post_mood, #hier waehlt ihr die Spalten aus, welche vom breiten (wide) Datensatz in einen laengeren (long) Datensatz ueberfuehrt werden sollen\n    names_to = \"mood_time\", #hier benennt ihr die Spalte, in welcher die alten Spaltennamen abgelegt werden\n    values_to = \"mood_rating\" #hier benennt ihr die Spalte, in welcher die alten Spaltenwerte abgelegt werden\n  )\n\n#alternativen\nmood_long &lt;- practice_dataset2 |&gt;\n  pivot_longer(\n    cols = c(\"pre_mood\", \"mid_mood\", \"post_mood\"), #hier mit der expliziten Nennung aller entsprechenden Spalten\n    names_to = \"mood_time\",\n    values_to = \"mood_rating\"\n  )\n\nmood_long &lt;- practice_dataset2 |&gt;\n  pivot_longer(\n    cols = ends_with(\"mood\"), #hier anhand dessen, womit der Spaltenname endet\n    names_to = \"mood_time\",\n    values_to = \"mood_rating\"\n  )",
    "crumbs": [
      "Hausübungen",
      "Hausübung 2 - Mit Lösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/hausuebung_loesung_2.html#aufgabe-3-plot---verlaufsdiagramm",
    "href": "scripts/02_excercises/hausuebung_loesung_2.html#aufgabe-3-plot---verlaufsdiagramm",
    "title": "Hausübung 2 Lösung",
    "section": "",
    "text": "Im nächsten Schritt verwenden wir den LONG-Datensatz (Siehe Aufgabe 2.1), um den Verlauf über die verschiedenen Zeitpunkte darzustellen. Das Ziel ist es, die Stimmung (mood) zu den unterschiedlichen Zeitpunkten, aggregiert nach den Konditionen, als Verlaufsdiagramm abzubilden.\n\nDafür soll mood_time in einen Faktor mit geordneten Faktorstufen (pre, mid und post) umgewandelt werden.\nErstelle einen Summary, welches die für den Plot benötigten Angaben zusammenfasst (Durschschnittlicher Mood gruppiert nach Condition und Zeitpunkt).\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\nmood_long$mood_time &lt;- factor(\n  mood_long$mood_time,\n  levels = c(\"pre_mood\", \"mid_mood\", \"post_mood\")\n)\n\nlevels(mood_long$mood_time)\n\n[1] \"pre_mood\"  \"mid_mood\"  \"post_mood\"\n\ndata_plot &lt;- mood_long |&gt;\n  group_by(mood_time, condition) |&gt; \n  summarise(mean_mood = mean(mood_rating))\n\n\n\n\n\n\n\nPlotte die Elemente mood_time und mean_mood. Gruppiere die conditions nach Farbe.\n💡Tipp: Wenn du den Plot einem Objekt zuweist, kannst du ihn weiterverwenden, indem du das Objekt aufrufst und erweiterst. So musst du den Code nicht jedes Mal neu ausschreiben.\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNormalerweise würde das Argument color = condition ausreichen, damit ggplot implizit eine Gruppierung der Daten nach der Variable condition vornimmt und die Datenpunkte innerhalb des Plots verbindet. Da wir vorher aber auch die Variable mood_time explizit als Faktor gesetzt hatten, wird nun jede Kombination aus beiden Variablen implizit als Gruppierung angesehen. Daher gibt es ohne das von uns explizite Argument group = condition für jede Zeile eine eigene Gruppe und die Datenpunkte würden nicht verbunden werden. Probiere den ggplot-call gerne ohne das entsprechende Argument aus und schaue, was passiert!\n\n\n\n\n\n\nPasse nun den Plot aus 3.2 so an, dass er eine Farbpalette verwendet, die für farbenblinde Personen geeignet ist: Nutze die folgende Palette.\nTipp: Verwende: scale_color_manual\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\ncb_palette &lt;- c(   \"#000000\", \"#E69F00\", \"#56B4E9\", \"#009E73\",   \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\" )  \n\n\n\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\nplot_farbe &lt;- plot +   \n  scale_color_manual(values = cb_palette)  \n\nplot_farbe\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFüge mit geom_point() die einzelnen Punkte auf der Linie ein. Stelle die grösse (size() auf 3)\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\nplot_2 &lt;- plot_farbe +   \n geom_point(alpha = 0.5, size = 3)\n\nplot_2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFüge dem Diagramm Titel sowie Achsenbeschriftungen zu deinem Plot und verwende ein Theme das du passend findest.\n\n\n\n\n\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\nplot_3 &lt;- plot_2 +    \n  labs(     \n    title = \"Zeitlicher Verlauf Mood\",\n    y = \"Mood\",    \n    x = \"Messzeitpunkt\",    \n    color = \"Bedingung\"   ) +  \n  theme_classic()  \nprint(plot_3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSpeichere den Plot ab mit ggsave als png ab.\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\nggsave(\"mein_plot.png\", plot = plot_3)",
    "crumbs": [
      "Hausübungen",
      "Hausübung 2 - Mit Lösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/hausuebung_loesung_2.html#subsetting-und-t-test",
    "href": "scripts/02_excercises/hausuebung_loesung_2.html#subsetting-und-t-test",
    "title": "Hausübung 2 Lösung",
    "section": "",
    "text": "Erstelle aus dem ursprünglichen Wide Originaldatensatz einen neuen Datensatz subset_mood, der nur Daten der Gruppe experimental beinhaltet.\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\nsubset_mood &lt;- practice_dataset2 |&gt;   filter(condition == \"experimental\") \n\n\n\n\n\n\nPrüfe nun (anhand des unter 4. erstellen Datensatzes) mittels eines gepaarten t-Test ob sich pre_mood und post_mood in der Gruppe experimental unterscheiden. Nutze dafür die Funktion t.test(). Lass dir das Ergebnis mit print() ausgeben.\n\n\n\n\n\n\nLösungen\n\n\n\n\n\n\nt_test_result &lt;- t.test(subset_mood$pre_mood, subset_mood$post_mood, paired = TRUE) \n\nprint(t_test_result)\n\n\n    Paired t-test\n\ndata:  subset_mood$pre_mood and subset_mood$post_mood\nt = -0.42731, df = 43, p-value = 0.6713\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -1.0399187  0.6762823\nsample estimates:\nmean difference \n     -0.1818182 \n\n# hier gilt paired = TRUE, da sich die beiden Messungen bedingen (sie sind beide von der selben Person, lediglich zu unterschiedlichen Zeitpunkten aufgenommen worden) = within-subjects Vergleich",
    "crumbs": [
      "Hausübungen",
      "Hausübung 2 - Mit Lösungen"
    ]
  },
  {
    "objectID": "scripts/02_excercises/hausuebung_loesung_2.html#rendern-und-hochladen",
    "href": "scripts/02_excercises/hausuebung_loesung_2.html#rendern-und-hochladen",
    "title": "Hausübung 2 Lösung",
    "section": "",
    "text": "Rendere dein Skript als HTML\nLade deine Abgabe (Skript + HTML) als ZIP ordner in ILIAS hoch und schicke sie deinem/deiner Peepartner:in.",
    "crumbs": [
      "Hausübungen",
      "Hausübung 2 - Mit Lösungen"
    ]
  },
  {
    "objectID": "scripts/04_misc/Memes.html",
    "href": "scripts/04_misc/Memes.html",
    "title": "Memes",
    "section": "",
    "text": "You did it! Viel Spass beim Memes anschauen!\n🔗\n🔗\n🔗\n🔗\n🔗\n🔗\n🔗\n🔗\n🔗\n🔗",
    "crumbs": [
      "Links und Ressourcen",
      "Memes :)"
    ]
  },
  {
    "objectID": "scripts/04_misc/Memes.html#memes",
    "href": "scripts/04_misc/Memes.html#memes",
    "title": "Memes",
    "section": "",
    "text": "You did it! Viel Spass beim Memes anschauen!\n🔗\n🔗\n🔗\n🔗\n🔗\n🔗\n🔗\n🔗\n🔗\n🔗",
    "crumbs": [
      "Links und Ressourcen",
      "Memes :)"
    ]
  },
  {
    "objectID": "scripts/04_misc/front_page.html",
    "href": "scripts/04_misc/front_page.html",
    "title": "Einleitung",
    "section": "",
    "text": "In diesem E-Book findest du alle wichtigen Informationen zum Methodenseminar “R u Ready”. Du kannst hier u. a. die wöchentlichen Folien, Hands-On R Übungen, den Leistungsnachweis, und Frequently Asked Questions einsehen. Du kannst über die Unterkapitel (links) zu den entsprechenden Inhalten navigieren, oder auch die Suchfunktion oben links verwenden, um nach einem bestimmten Begriff zu suchen.\n\nHinweisboxen\nHier einen Überblick über die auf den Seiten enthaltenen Hinweisboxen:\n\n\n\n\n\n\nNote\n\n\n\nVertiefung: Hier geht es in die Tiefe.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWichtig: Dies ist eine wichtige Information.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAchtung: Hier ist Vorsicht geboten.\n\n\n\n\n\n\n\n\nCaution\n\n\n\nVorsicht: Diese Information ist noch in Bearbeitung.\n\n\n\n\nSyllabus\n\n\n\n\n\n\nCaution\n\n\n\nVorsicht: Der Syllabus dient als grobe Richtlinie und kann angepasst werden, falls wir in einzelnen Einheiten mehr oder weniger Zeit benötigen.\n\n\n\n\nLetztes Update January 21, 2026 at 16:08",
    "crumbs": [
      "Einleitung"
    ]
  },
  {
    "objectID": "scripts/04_misc/index.html",
    "href": "scripts/04_misc/index.html",
    "title": "Einleitung",
    "section": "",
    "text": "In diesem E-Book findest du alle wichtigen Informationen zum Methodenseminar “R u Ready”. Du kannst hier u. a. die wöchentlichen Folien, Hands-On R Übungen, den Leistungsnachweis, und Frequently Asked Questions einsehen. Du kannst über die Unterkapitel (links) zu den entsprechenden Inhalten navigieren, oder auch die Suchfunktion oben links verwenden, um nach einem bestimmten Begriff zu suchen.\n\nHinweisboxen\nHier einen Überblick über die auf den Seiten enthaltenen Hinweisboxen:\n\n\n\n\n\n\nNote\n\n\n\nVertiefung: Hier geht es in die Tiefe.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWichtig: Dies ist eine wichtige Information.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nAchtung: Hier ist Vorsicht geboten.\n\n\n\n\n\n\n\n\nCaution\n\n\n\nVorsicht: Diese Information ist noch in Bearbeitung.\n\n\n\n\nSyllabus\n\n\n\n\n\n\nCaution\n\n\n\nVorsicht: Der Syllabus dient als grobe Richtlinie und kann angepasst werden, falls wir in einzelnen Einheiten mehr oder weniger Zeit benötigen.\n\n\n\n\nLetztes Update January 21, 2026 at 16:08"
  },
  {
    "objectID": "scripts/04_misc/muddiest_points_2.html",
    "href": "scripts/04_misc/muddiest_points_2.html",
    "title": "Muddiest Points 2",
    "section": "",
    "text": "Bei mir gibt es beim Einlesen des Datensatzes immer noch eine zusätzliche Spalte, welche nochmal durchnummeriert ist (also wie eine ID, aber ohne Namen). Wie lese ich den Datensatz richtig ein, damit ich diese Spalte nicht immer noch zusätzlich löschen muss?\nAntwort:\nWahrscheinlich hast du beim Speichern der Daten mit write.csv() das Argument row.names nicht gesetzt. Wenn du row.names = FALSE angibst, entsteht diese zusätzliche Spalte nicht. Genauere Erklärung findest du hier. Das Problem liegt also vermutlich nicht am Einlesen der Daten, sondern daran wie du die Daten abgespeichert hast. Wenn dem nicht so ist - bitte komm noch mal auf uns zu!\n\n\n\n\nManchmal sind mir die Pfade, die ich beim Einlesen und Abspeichern einer Datei angeben muss, nicht klar. Die kürzere Version funktioniert oft nicht, deshalb muss ich immer den ganzen Pfad eingeben.\nAntwort:\nWenn relative Pfade nicht funktionieren, überprüfe zuerst, ob du dein Projekt korrekt geöffnet hast. Falls das Problem bleibt, kannst du mit getwd() dein aktuelles Arbeitsverzeichnis ausgeben lassen. Dieses sollte auf deinen Projektordner zeigen.\nWenn das nicht funktionieren sollte prüfe ob du diese Einstellung unter “Tools - Global Options” vorgenommen hast: Evaluate Chunks in directory: Projekt\n\n\n\n\n\nWeitere Möglichkeiten:\nWenn du dich zum Beispiel im Ordner grinschgl2020/code/ befindest, aber eine Datei aus einem übergeordneten Ordner einlesen möchtest (z. B. grinschgl2020/data/), kannst du beim Einlesen .. verwenden. Damit geht R eine Ebene nach oben, und relative Pfade funktionieren wie erwartet.\nBeispiel:\n\n# Wir befinden uns in: grinschgl2020/code/\n\n# Eine Ebene nach oben gehen (..) und in den data-Ordner wechseln\ndaten &lt;- read.csv(\"../data/raw/daten_roh.csv\")\n\n\n\n\n\nEinige Funktionen wie across() werden in anderen Funktionen verschachtelt verwendet und brauchen zusätzliche Argumente. Die Logik der Verschachtelung ist mir noch nicht klar.\nAntwort:\nFunktionen wie across() werden verschachtelt, weil sie nur innerhalb von dplyr-Funktionen wie mutate() oder summarise() arbeiten. Die äussere Funktion bestimmt, was passieren soll (z. B. Spalten verändern). across() legt dann fest, welche Spalten betroffen sind und welche Transformation angewendet wird. Deshalb braucht across() Argumente wie .cols und .fns. Die äussere Funktion gibt den Rahmen vor, across() steuert die konkrete Operation.\nBeispiel:\nacross() hat zwei wichtige Argumente:\n\n.cols → Welche Spalten sollen ausgewählt werden?\nIm Beispiel: alle Spalten, die auf “_r” enden. Across geht wert für wert durch diese Spalten\n.fns → Welche Operation soll auf jeden einzelnen Wert dieser Spalten angewendet werden?\nIm Beispiel: Für jeden Wert wird 6 – Wert berechnet (Umkehrkodierung).\nDas .x steht für den aktuellen Wert durch den across durchgeht. Manchmal wird auch nur ein Punkt ausgeschrieben da beide Schreibweisen funktionieren.\n\n\ndata_reversed &lt;- data_numeric |&gt;\n  mutate(\n    across(ends_with(\"_r\"), ~ 6 - .x) #~ 6 - . --&gt; Für jede wert der col -6 \n  )\n\n\n\n\n\nIch habe manchmal ein Data Frame an eine Funktion übergeben, obwohl diese einen Vektor erwartet, oder umgekehrt. Mir ist noch nicht klar, welche Funktionen Vektoren und welche Data Frames erwarten.\nGibt es irgendeine “Merkhilfe” um zu wissen bei welchen Packages/ Funktionen ich die Variablen auf welche Art auflisten muss? –&gt; Also ob mit “Variable” oder c(Variable)?\nAntwort:\nEs gibt keine feste Regel, aber die Hilfeseite (?funktion) zeigt immer, welcher Datentyp erwartet wird. Grundsätzlich gilt: Funktionen, die Spaltenweise etwas berechnen (z. B. mean, sum, skew), erwarten Vektoren – oft extrahiert man diese mit $ aus einen Dataframe.\nFunktionen, die Daten transformieren (summarise, mutate, filter, select), erwarten dagegen Data Frames, da sie auf mehreren Variablen gleichzeitig arbeiten.\nDas c bei Vektoren steht für concatenate und wird verwendet, wenn wir mit Vektoren arbeiten. Wenn nur ein Element im Vektor vorhanden ist, brauchen wir kein c() (Skalar). Sobald mehrere Elemente enthalten sind, benötigen wir c().\n\n\n\n\nIch bin mir noch unsicher darin, wann bestimmte Datenstrukturen notwendig sind – zum Beispiel die Umwandlung von Variablen in Faktoren.\nAntwort:\nViele Transformationen sind notwendig, weil statistische Funktionen bestimmte Datentypen voraussetzen. Die ANOVA etwa benötigt Faktoren, wenn Gruppen verglichen werden sollen, damit R die Gruppen-Variable als kategorial erkennt. Solche Transformationen sind also Teil der korrekten Vorbereitung der Daten. Wenn du z.B. eine ANOVA durchführst und vergisst die Gruppen-Variable als Faktor umzuwandeln, bekommst du eine Warnung. Durch diese erkennst du dann, dass ein Faktor benötigt wird - es ist also nicht allzu schlimm, wenn du die Umwandlung zunächst verpasst hast.\nEs ist eine gute Faustregel, Variablen in Faktoren umzuwandeln, wenn sie klar kategoriale Gruppen darstellen – zum Beispiel eine Gruppenzugehörigkeit wie “above”, “below” oder “control”.\n\n\n\n\nIch wäre froh, wenn wir allgemeine Fehler beim Codieren durchgehen könnten – also häufige Syntaxfehler und worauf man achten sollte.\nAntwort:\n(Dieser Punkt ist als Wunsch notiert.)\n\n\n\n\nDaten korrekt einlesen, abspeichern, und im Projektkontext richtig organisieren. / Abspeichern der Daten, gute Ordnerstruktur? Das ist nur ein “kleiner” Punkt, aber ich habe immer ein bisschen ein Durcheinander, wie ich Skripts und Projekte am besten abspeichere, damit auch immer alles funktioniert bei der Analyse. Oft habe ich bspw. zu lange Dateipfade\nAntwort:\nGrundsätzlich gilt: Alle Rohdaten werden im raw/-Ordner gespeichert (und niemals überschrieben). Diese Daten werden dann im processing-Skript bereinigt und verarbeitet. Die verarbeiteten Datensaetze werden anschliessend mit write.csv() im processed/-Ordner gespeichert.\nIm analysis-Skript werden keine Bereinigungen mehr vorgenommen, sondern nur noch die eigentlichen Analyseschritte durchgefuehrt (mit Ausnahme kleiner Anpassungen wie das Setzen von Faktoren, da diese Aenderungen nicht gespeichert werden).\nDiese Struktur orientiert sich am PsychDS-Standard.\nHausübungen und Hands on: Da wir mit vielen verschiedenen Datensätzen und Skripten arbeiten, ist es sinnvoll, eine klare Ordnerstruktur zu verwenden, zum Beispiel einen Ordner für Skripte und einen für Daten. Man kann sich dabei an der PsychDS-Struktur orientieren und diese übernehmen, auch wenn wir nicht mit den dat_full-Daten arbeiten.\nZu den Pfaden: Achte darauf, relative Pfade zu verwenden. Lange Pfade sind grundsätzlich kein Problem, solange sie relativ, nachvollziehbar und konsistent aufgebaut sind.\n\n\n\n\nWide to long: Weshalb ist das notwendig, weshalb kann man nicht beim einen Format bleiben?\nAntwort:\nViele Funktionen setzen ein bestimmtes Datenformat voraus. Repeated-Measures-Funktionen sind das beste Beispiel – sie benötigen Long-Format, weil jede Zeile eine Beobachtung darstellt. Das wird in den nächsten Wochen noch verständlicher - wenn wir dann Berechnungen mit dem Wide als auch Long Format durchführen.\n\n\n\n\nWas ist der Unterschied zwischen class(), attributes() und table()?\nAntwort:\n\nclass() zeigt den Typ eines Objekts\n\n\n  class(penguins)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n  class(penguins$species)\n\n[1] \"factor\"\n\n\n\ntable() zeigt Häufigkeiten\n\n\ntable(penguins$island)\n\n\n   Biscoe     Dream Torgersen \n      168       124        52 \n\n\n\nattributes() zeigt die Attribute eines Objekts\n\nbei Data Frames: Variablennamen, rownames, Datentypen\nbei Faktoren: Levels und Klasse\n\n\n\nattributes(penguins)\n\n$class\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n$row.names\n  [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n [91]  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n[109] 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126\n[127] 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144\n[145] 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162\n[163] 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180\n[181] 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198\n[199] 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216\n[217] 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234\n[235] 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252\n[253] 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270\n[271] 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288\n[289] 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306\n[307] 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324\n[325] 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342\n[343] 343 344\n\n$names\n[1] \"species\"           \"island\"            \"bill_length_mm\"   \n[4] \"bill_depth_mm\"     \"flipper_length_mm\" \"body_mass_g\"      \n[7] \"sex\"               \"year\"             \n\nattributes(penguins$species)\n\n$levels\n[1] \"Adelie\"    \"Chinstrap\" \"Gentoo\"   \n\n$class\n[1] \"factor\"\n\n\n\n\n\n\nWie kann ich nachhaltige Anpassungen an Variablen im Datensatz vornehmen?\nAntwort:\nUm Änderungen im Datensatz festzuhalten, muss eine Zuweisung mit &lt;- vorgenommen werden. Wenn ein Befehl ohne Zuweisung ausgeführt wird, wird das Resultat nicht im Environment abgespeichert. Wenn ein Objekt im Environment ist, heisst das nicht, dass dieses automatisch als z. B. CSV gespeichert wird. Dafür sollte es mit einer passenden Write-Funktion gespeichert werden. Im Processing-Skript führt ihr alle Aufbereitungsschritte (z. B. Variablen umbenennen) durch und speichert am Ende den bereinigten Datensatz mit write.csv() oder einer ähnlichen Funktion ab, damit alle Änderungen nachhaltig gesichert sind.\nBeispiel –&gt; Keine Veränderung am Datensatzt weil keine Zuweisung\n\npenguins |&gt;  \n  mutate(mean_bill_length = mean(bill_length_mm, na.rm = TRUE))\n\nBeispiel mit Zuweisung: Gleicher Datensatz wird verändert\n\npenguins &lt;- penguins |&gt; \n  mutate(mean_bill_length = mean(bill_length_mm, na.rm = TRUE))\n\n\n\n\n\nFür mich persönlich ist die group_by() Funktion irgendwie nicht ganz klar. Die Vorstellung, wie die Daten sortiert werden, ist nicht so intuitiv. \nAntwort:\nFür viele ist die Funktion anfangs nicht intuitiv. Die Vorstellung, wie die Daten intern in Gruppen „aufgeteilt“ werden, ohne dass sie tatsächlich sortiert oder neu angeordnet werden, fühlt sich ungewohnt an. Das ist völlig normal – die Logik hinter group_by() entwickelt sich meist erst, wenn man sieht, wie sie gemeinsam mit Funktionen wie summarise() oder mutate() wirkt. Kategoriale Daten werden in ihre kategorien augeteilt, kontinuierliche Daten werden in ihre einzigartigen werte gruppiert.\nBeispiel Kontinuierliche Variable: Gruppe für jedes Gewicht\n\npenguins_summary &lt;- penguins |&gt; \n  group_by(body_mass_g) |&gt; \n  summarize(mean_bill_length = mean(bill_length_mm, na.rm = TRUE))\n  \npenguins_summary[1:10, 1:2]\n\n# A tibble: 10 × 2\n   body_mass_g mean_bill_length\n         &lt;int&gt;            &lt;dbl&gt;\n 1        2700             46.9\n 2        2850             36.4\n 3        2900             37.4\n 4        2925             37.9\n 5        2975             37.5\n 6        3000             37.2\n 7        3050             35.6\n 8        3075             37.7\n 9        3100             36  \n10        3150             36.6\n\n\nBeispiel kategoriale Variable\n\npenguins_summary_2 &lt;- penguins |&gt; \n  group_by(island) |&gt; \n  summarize(mean_bill_length = mean(bill_length_mm, na.rm = TRUE))\n  \npenguins_summary_2\n\n# A tibble: 3 × 2\n  island    mean_bill_length\n  &lt;fct&gt;                &lt;dbl&gt;\n1 Biscoe                45.3\n2 Dream                 44.2\n3 Torgersen             39.0\n\n\n\n\n\n\nIch habe auch ein bisschen ein Durcheinander, wann die Daten am besten wie abgespeichert/eingelesen werden. Also mit read_delim(), row.names = FALSE, csv2 vs csv usw. \n\nEinlesen:\nKurz zusammengefasst: Am einfachsten ist es, zunächst die Point-and-Click-Oberfläche in RStudio zu nutzen und die Optionen so einzustellen, dass die Daten sinnvoll eingelesen werden, und anschliessend den generierten Code zu übernehmen. read_csv() ist im Prinzip das Gleiche wie read_delim(), nur dass es standardmässig ein Komma als Trennzeichen verwendet (CSV bedeutet comma separated values). Bei read_delim() muss das Trennzeichen hingegen explizit angegeben werden, zum Beispiel ein Semikolon.\nSpeichern:\nZum Speichern nutzt ihr am besten write.csv(). Von write.csv2() sollte man eher die Finger lassen, da es historische Spezialfälle abdeckt und meist eher zu Verwirrung führt.",
    "crumbs": [
      "Muddiest Points"
    ]
  },
  {
    "objectID": "scripts/04_misc/muddiest_points_2.html#muddiest-points-session-2",
    "href": "scripts/04_misc/muddiest_points_2.html#muddiest-points-session-2",
    "title": "Muddiest Points 2",
    "section": "",
    "text": "Bei mir gibt es beim Einlesen des Datensatzes immer noch eine zusätzliche Spalte, welche nochmal durchnummeriert ist (also wie eine ID, aber ohne Namen). Wie lese ich den Datensatz richtig ein, damit ich diese Spalte nicht immer noch zusätzlich löschen muss?\nAntwort:\nWahrscheinlich hast du beim Speichern der Daten mit write.csv() das Argument row.names nicht gesetzt. Wenn du row.names = FALSE angibst, entsteht diese zusätzliche Spalte nicht. Genauere Erklärung findest du hier. Das Problem liegt also vermutlich nicht am Einlesen der Daten, sondern daran wie du die Daten abgespeichert hast. Wenn dem nicht so ist - bitte komm noch mal auf uns zu!\n\n\n\n\nManchmal sind mir die Pfade, die ich beim Einlesen und Abspeichern einer Datei angeben muss, nicht klar. Die kürzere Version funktioniert oft nicht, deshalb muss ich immer den ganzen Pfad eingeben.\nAntwort:\nWenn relative Pfade nicht funktionieren, überprüfe zuerst, ob du dein Projekt korrekt geöffnet hast. Falls das Problem bleibt, kannst du mit getwd() dein aktuelles Arbeitsverzeichnis ausgeben lassen. Dieses sollte auf deinen Projektordner zeigen.\nWenn das nicht funktionieren sollte prüfe ob du diese Einstellung unter “Tools - Global Options” vorgenommen hast: Evaluate Chunks in directory: Projekt\n\n\n\n\n\nWeitere Möglichkeiten:\nWenn du dich zum Beispiel im Ordner grinschgl2020/code/ befindest, aber eine Datei aus einem übergeordneten Ordner einlesen möchtest (z. B. grinschgl2020/data/), kannst du beim Einlesen .. verwenden. Damit geht R eine Ebene nach oben, und relative Pfade funktionieren wie erwartet.\nBeispiel:\n\n# Wir befinden uns in: grinschgl2020/code/\n\n# Eine Ebene nach oben gehen (..) und in den data-Ordner wechseln\ndaten &lt;- read.csv(\"../data/raw/daten_roh.csv\")\n\n\n\n\n\nEinige Funktionen wie across() werden in anderen Funktionen verschachtelt verwendet und brauchen zusätzliche Argumente. Die Logik der Verschachtelung ist mir noch nicht klar.\nAntwort:\nFunktionen wie across() werden verschachtelt, weil sie nur innerhalb von dplyr-Funktionen wie mutate() oder summarise() arbeiten. Die äussere Funktion bestimmt, was passieren soll (z. B. Spalten verändern). across() legt dann fest, welche Spalten betroffen sind und welche Transformation angewendet wird. Deshalb braucht across() Argumente wie .cols und .fns. Die äussere Funktion gibt den Rahmen vor, across() steuert die konkrete Operation.\nBeispiel:\nacross() hat zwei wichtige Argumente:\n\n.cols → Welche Spalten sollen ausgewählt werden?\nIm Beispiel: alle Spalten, die auf “_r” enden. Across geht wert für wert durch diese Spalten\n.fns → Welche Operation soll auf jeden einzelnen Wert dieser Spalten angewendet werden?\nIm Beispiel: Für jeden Wert wird 6 – Wert berechnet (Umkehrkodierung).\nDas .x steht für den aktuellen Wert durch den across durchgeht. Manchmal wird auch nur ein Punkt ausgeschrieben da beide Schreibweisen funktionieren.\n\n\ndata_reversed &lt;- data_numeric |&gt;\n  mutate(\n    across(ends_with(\"_r\"), ~ 6 - .x) #~ 6 - . --&gt; Für jede wert der col -6 \n  )\n\n\n\n\n\nIch habe manchmal ein Data Frame an eine Funktion übergeben, obwohl diese einen Vektor erwartet, oder umgekehrt. Mir ist noch nicht klar, welche Funktionen Vektoren und welche Data Frames erwarten.\nGibt es irgendeine “Merkhilfe” um zu wissen bei welchen Packages/ Funktionen ich die Variablen auf welche Art auflisten muss? –&gt; Also ob mit “Variable” oder c(Variable)?\nAntwort:\nEs gibt keine feste Regel, aber die Hilfeseite (?funktion) zeigt immer, welcher Datentyp erwartet wird. Grundsätzlich gilt: Funktionen, die Spaltenweise etwas berechnen (z. B. mean, sum, skew), erwarten Vektoren – oft extrahiert man diese mit $ aus einen Dataframe.\nFunktionen, die Daten transformieren (summarise, mutate, filter, select), erwarten dagegen Data Frames, da sie auf mehreren Variablen gleichzeitig arbeiten.\nDas c bei Vektoren steht für concatenate und wird verwendet, wenn wir mit Vektoren arbeiten. Wenn nur ein Element im Vektor vorhanden ist, brauchen wir kein c() (Skalar). Sobald mehrere Elemente enthalten sind, benötigen wir c().\n\n\n\n\nIch bin mir noch unsicher darin, wann bestimmte Datenstrukturen notwendig sind – zum Beispiel die Umwandlung von Variablen in Faktoren.\nAntwort:\nViele Transformationen sind notwendig, weil statistische Funktionen bestimmte Datentypen voraussetzen. Die ANOVA etwa benötigt Faktoren, wenn Gruppen verglichen werden sollen, damit R die Gruppen-Variable als kategorial erkennt. Solche Transformationen sind also Teil der korrekten Vorbereitung der Daten. Wenn du z.B. eine ANOVA durchführst und vergisst die Gruppen-Variable als Faktor umzuwandeln, bekommst du eine Warnung. Durch diese erkennst du dann, dass ein Faktor benötigt wird - es ist also nicht allzu schlimm, wenn du die Umwandlung zunächst verpasst hast.\nEs ist eine gute Faustregel, Variablen in Faktoren umzuwandeln, wenn sie klar kategoriale Gruppen darstellen – zum Beispiel eine Gruppenzugehörigkeit wie “above”, “below” oder “control”.\n\n\n\n\nIch wäre froh, wenn wir allgemeine Fehler beim Codieren durchgehen könnten – also häufige Syntaxfehler und worauf man achten sollte.\nAntwort:\n(Dieser Punkt ist als Wunsch notiert.)\n\n\n\n\nDaten korrekt einlesen, abspeichern, und im Projektkontext richtig organisieren. / Abspeichern der Daten, gute Ordnerstruktur? Das ist nur ein “kleiner” Punkt, aber ich habe immer ein bisschen ein Durcheinander, wie ich Skripts und Projekte am besten abspeichere, damit auch immer alles funktioniert bei der Analyse. Oft habe ich bspw. zu lange Dateipfade\nAntwort:\nGrundsätzlich gilt: Alle Rohdaten werden im raw/-Ordner gespeichert (und niemals überschrieben). Diese Daten werden dann im processing-Skript bereinigt und verarbeitet. Die verarbeiteten Datensaetze werden anschliessend mit write.csv() im processed/-Ordner gespeichert.\nIm analysis-Skript werden keine Bereinigungen mehr vorgenommen, sondern nur noch die eigentlichen Analyseschritte durchgefuehrt (mit Ausnahme kleiner Anpassungen wie das Setzen von Faktoren, da diese Aenderungen nicht gespeichert werden).\nDiese Struktur orientiert sich am PsychDS-Standard.\nHausübungen und Hands on: Da wir mit vielen verschiedenen Datensätzen und Skripten arbeiten, ist es sinnvoll, eine klare Ordnerstruktur zu verwenden, zum Beispiel einen Ordner für Skripte und einen für Daten. Man kann sich dabei an der PsychDS-Struktur orientieren und diese übernehmen, auch wenn wir nicht mit den dat_full-Daten arbeiten.\nZu den Pfaden: Achte darauf, relative Pfade zu verwenden. Lange Pfade sind grundsätzlich kein Problem, solange sie relativ, nachvollziehbar und konsistent aufgebaut sind.\n\n\n\n\nWide to long: Weshalb ist das notwendig, weshalb kann man nicht beim einen Format bleiben?\nAntwort:\nViele Funktionen setzen ein bestimmtes Datenformat voraus. Repeated-Measures-Funktionen sind das beste Beispiel – sie benötigen Long-Format, weil jede Zeile eine Beobachtung darstellt. Das wird in den nächsten Wochen noch verständlicher - wenn wir dann Berechnungen mit dem Wide als auch Long Format durchführen.\n\n\n\n\nWas ist der Unterschied zwischen class(), attributes() und table()?\nAntwort:\n\nclass() zeigt den Typ eines Objekts\n\n\n  class(penguins)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n  class(penguins$species)\n\n[1] \"factor\"\n\n\n\ntable() zeigt Häufigkeiten\n\n\ntable(penguins$island)\n\n\n   Biscoe     Dream Torgersen \n      168       124        52 \n\n\n\nattributes() zeigt die Attribute eines Objekts\n\nbei Data Frames: Variablennamen, rownames, Datentypen\nbei Faktoren: Levels und Klasse\n\n\n\nattributes(penguins)\n\n$class\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n$row.names\n  [1]   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n [19]  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n [37]  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n [55]  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n [73]  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n [91]  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n[109] 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126\n[127] 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144\n[145] 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162\n[163] 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180\n[181] 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198\n[199] 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216\n[217] 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234\n[235] 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252\n[253] 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270\n[271] 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288\n[289] 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306\n[307] 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324\n[325] 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342\n[343] 343 344\n\n$names\n[1] \"species\"           \"island\"            \"bill_length_mm\"   \n[4] \"bill_depth_mm\"     \"flipper_length_mm\" \"body_mass_g\"      \n[7] \"sex\"               \"year\"             \n\nattributes(penguins$species)\n\n$levels\n[1] \"Adelie\"    \"Chinstrap\" \"Gentoo\"   \n\n$class\n[1] \"factor\"\n\n\n\n\n\n\nWie kann ich nachhaltige Anpassungen an Variablen im Datensatz vornehmen?\nAntwort:\nUm Änderungen im Datensatz festzuhalten, muss eine Zuweisung mit &lt;- vorgenommen werden. Wenn ein Befehl ohne Zuweisung ausgeführt wird, wird das Resultat nicht im Environment abgespeichert. Wenn ein Objekt im Environment ist, heisst das nicht, dass dieses automatisch als z. B. CSV gespeichert wird. Dafür sollte es mit einer passenden Write-Funktion gespeichert werden. Im Processing-Skript führt ihr alle Aufbereitungsschritte (z. B. Variablen umbenennen) durch und speichert am Ende den bereinigten Datensatz mit write.csv() oder einer ähnlichen Funktion ab, damit alle Änderungen nachhaltig gesichert sind.\nBeispiel –&gt; Keine Veränderung am Datensatzt weil keine Zuweisung\n\npenguins |&gt;  \n  mutate(mean_bill_length = mean(bill_length_mm, na.rm = TRUE))\n\nBeispiel mit Zuweisung: Gleicher Datensatz wird verändert\n\npenguins &lt;- penguins |&gt; \n  mutate(mean_bill_length = mean(bill_length_mm, na.rm = TRUE))\n\n\n\n\n\nFür mich persönlich ist die group_by() Funktion irgendwie nicht ganz klar. Die Vorstellung, wie die Daten sortiert werden, ist nicht so intuitiv. \nAntwort:\nFür viele ist die Funktion anfangs nicht intuitiv. Die Vorstellung, wie die Daten intern in Gruppen „aufgeteilt“ werden, ohne dass sie tatsächlich sortiert oder neu angeordnet werden, fühlt sich ungewohnt an. Das ist völlig normal – die Logik hinter group_by() entwickelt sich meist erst, wenn man sieht, wie sie gemeinsam mit Funktionen wie summarise() oder mutate() wirkt. Kategoriale Daten werden in ihre kategorien augeteilt, kontinuierliche Daten werden in ihre einzigartigen werte gruppiert.\nBeispiel Kontinuierliche Variable: Gruppe für jedes Gewicht\n\npenguins_summary &lt;- penguins |&gt; \n  group_by(body_mass_g) |&gt; \n  summarize(mean_bill_length = mean(bill_length_mm, na.rm = TRUE))\n  \npenguins_summary[1:10, 1:2]\n\n# A tibble: 10 × 2\n   body_mass_g mean_bill_length\n         &lt;int&gt;            &lt;dbl&gt;\n 1        2700             46.9\n 2        2850             36.4\n 3        2900             37.4\n 4        2925             37.9\n 5        2975             37.5\n 6        3000             37.2\n 7        3050             35.6\n 8        3075             37.7\n 9        3100             36  \n10        3150             36.6\n\n\nBeispiel kategoriale Variable\n\npenguins_summary_2 &lt;- penguins |&gt; \n  group_by(island) |&gt; \n  summarize(mean_bill_length = mean(bill_length_mm, na.rm = TRUE))\n  \npenguins_summary_2\n\n# A tibble: 3 × 2\n  island    mean_bill_length\n  &lt;fct&gt;                &lt;dbl&gt;\n1 Biscoe                45.3\n2 Dream                 44.2\n3 Torgersen             39.0\n\n\n\n\n\n\nIch habe auch ein bisschen ein Durcheinander, wann die Daten am besten wie abgespeichert/eingelesen werden. Also mit read_delim(), row.names = FALSE, csv2 vs csv usw. \n\nEinlesen:\nKurz zusammengefasst: Am einfachsten ist es, zunächst die Point-and-Click-Oberfläche in RStudio zu nutzen und die Optionen so einzustellen, dass die Daten sinnvoll eingelesen werden, und anschliessend den generierten Code zu übernehmen. read_csv() ist im Prinzip das Gleiche wie read_delim(), nur dass es standardmässig ein Komma als Trennzeichen verwendet (CSV bedeutet comma separated values). Bei read_delim() muss das Trennzeichen hingegen explizit angegeben werden, zum Beispiel ein Semikolon.\nSpeichern:\nZum Speichern nutzt ihr am besten write.csv(). Von write.csv2() sollte man eher die Finger lassen, da es historische Spezialfälle abdeckt und meist eher zu Verwirrung führt.",
    "crumbs": [
      "Muddiest Points"
    ]
  },
  {
    "objectID": "scripts/04_misc/here.html",
    "href": "scripts/04_misc/here.html",
    "title": "Probleme beim Rendern",
    "section": "",
    "text": "Beim Rendern von Quarto-Files treten Probleme auf, die auf der Auswertung von Filepaths zurückzuführen sind.\nWährend Code beim einfachen Ausführen in RStudio relativ zum Projektordner interpretiert wird, erfolgt die Pfadauswertung beim Rendern relativ zum Skript selbst. Dies kann zu Render-Fehlern wie dem folgenden führen.",
    "crumbs": [
      "Probleme beim Rendern"
    ]
  },
  {
    "objectID": "scripts/04_misc/here.html#problem",
    "href": "scripts/04_misc/here.html#problem",
    "title": "Probleme beim Rendern",
    "section": "",
    "text": "Beim Rendern von Quarto-Files treten Probleme auf, die auf der Auswertung von Filepaths zurückzuführen sind.\nWährend Code beim einfachen Ausführen in RStudio relativ zum Projektordner interpretiert wird, erfolgt die Pfadauswertung beim Rendern relativ zum Skript selbst. Dies kann zu Render-Fehlern wie dem folgenden führen.",
    "crumbs": [
      "Probleme beim Rendern"
    ]
  },
  {
    "objectID": "scripts/04_misc/here.html#lösung-mit-here",
    "href": "scripts/04_misc/here.html#lösung-mit-here",
    "title": "Probleme beim Rendern",
    "section": "Lösung mit here",
    "text": "Lösung mit here\nUm dieses Problem zu beheben, kann das here-Package verwendet werden.\nhere evaluiert Pfade konsistent relativ zum Projektordner und verhindert dadurch solche Render-Probleme.\nDurch die Verwendung von here ändern sich die Angaben des Filepfades beim Einlesen und Schreiben von Dateien leicht. Die einzige Veränderung ist dass wir den Filepfad in die here Funktion übergeben (in Klammern). Siehe dafür das Beispiel unten.\nDazu muss das Package here zunächst installiert werden:\n\ninstall.packages(\"here\")\nlibrary(here)\n\nUnd aus diesem Code der zu Problemen führen kann\n\ndata_cb &lt;- read_csv(\"data/raw/data_cb.csv\") #Kann zu Problemen beim Rendern führen. \n\nwird:\n\ndata_cb &lt;- read_csv(here(\"data/raw/data_cb.csv\")) # Sichere Variante\n\nDas gleiche gilt für das schreiben von daten mit write.csv\n\n# Kann zu Problemen führen\nwrite.csv(dat_full, \"data/processed/dat_full.csv\")\n\n# Sicherer: Pfad wird immer relativ zum Projekt-Root aufgelöst\nwrite.csv(dat_full, here(\"data/processed/dat_full.csv\"))\n\nDas sollte die Probleme lösen!",
    "crumbs": [
      "Probleme beim Rendern"
    ]
  },
  {
    "objectID": "scripts/01_slides/1_presentation(1).html#beispielhafte-chunks-output",
    "href": "scripts/01_slides/1_presentation(1).html#beispielhafte-chunks-output",
    "title": "R u Ready",
    "section": "Beispielhafte Chunks & Output",
    "text": "Beispielhafte Chunks & Output\n\n\n\nprint(\"Hello world!\")\n\n[1] \"Hello world!\"\n\n\n\n\n2+2\n\n[1] 4"
  },
  {
    "objectID": "scripts/01_slides/1_presentation(1).html#beispielhafte-formatierung",
    "href": "scripts/01_slides/1_presentation(1).html#beispielhafte-formatierung",
    "title": "R u Ready",
    "section": "Beispielhafte Formatierung",
    "text": "Beispielhafte Formatierung\nDiese Präsentation verwendet Reveal.js in Quarto\n\n\n\n\n\n\nHinweis\n\n\nAuf den Folien sind erst einmal nur Beispiele zu sehen, wie man mit Quarto Präsentationen einfach Code einbinden und zeigen kann."
  },
  {
    "objectID": "scripts/01_slides/1_presentation(1).html#beispielhafter-datensatz",
    "href": "scripts/01_slides/1_presentation(1).html#beispielhafter-datensatz",
    "title": "R u Ready",
    "section": "Beispielhafter Datensatz",
    "text": "Beispielhafter Datensatz\n\nhead(mtcars)\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1"
  },
  {
    "objectID": "scripts/01_slides/1_presentation(1).html#beispielhafter-ggplot-code-und-plot",
    "href": "scripts/01_slides/1_presentation(1).html#beispielhafter-ggplot-code-und-plot",
    "title": "R u Ready",
    "section": "Beispielhafter ggplot-code und plot",
    "text": "Beispielhafter ggplot-code und plot\n\nggplot(data = mtcars, aes(x = hp, y = mpg, color = factor(cyl))) +\n  geom_point(size = 3) +\n  labs(\n    title = \"PS vs. Verbrauch\",\n    x = \"Horsepower (hp)\",\n    y = \"Miles per Gallon (mpg)\",\n    color = \"Zylinder\"\n  ) +\n  theme_minimal()\n\n\n\n\n\nR u Ready? HS2025 | Psychologie der Digialisierung"
  },
  {
    "objectID": "scripts/01_slides/1_presentation(1).html#beispielhafter-ggplot-code-und-plot-output",
    "href": "scripts/01_slides/1_presentation(1).html#beispielhafter-ggplot-code-und-plot-output",
    "title": "R u Ready",
    "section": "Beispielhafter ggplot-code und plot",
    "text": "Beispielhafter ggplot-code und plot"
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#r-u-ready-reprodzierbare-datenaufbereitung-und--analyse-mit-r",
    "href": "scripts/01_slides/EH_2.html#r-u-ready-reprodzierbare-datenaufbereitung-und--analyse-mit-r",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "R u Ready? Reprodzierbare Datenaufbereitung und -analyse mit R",
    "text": "R u Ready? Reprodzierbare Datenaufbereitung und -analyse mit R\nHS 2025 LV-Leitung: Dr. Sandra Grinschgl / MSc. Aaron Friedli Tutor: BSc. Lars Schilling2. Einheit, 24.09.2025",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#semesterplan",
    "href": "scripts/01_slides/EH_2.html#semesterplan",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Semesterplan",
    "text": "Semesterplan\n\n\nGibt es Fragen, die sich nach letzter Woche aufgetan haben?",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#ergebnisse-der-bedarfsanalyse-1",
    "href": "scripts/01_slides/EH_2.html#ergebnisse-der-bedarfsanalyse-1",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Ergebnisse der Bedarfsanalyse (1)",
    "text": "Ergebnisse der Bedarfsanalyse (1)\n10:15 (N = 24)\nWie würdest du aktuell deine R-Kenntnisse einschätzen?\n\n\n\n\n\n16:15 (N = 23)\nWie würdest du aktuell deine R-Kenntnisse einschätzen?",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#ergebnisse-der-bedarfsanalyse-2",
    "href": "scripts/01_slides/EH_2.html#ergebnisse-der-bedarfsanalyse-2",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Ergebnisse der Bedarfsanalyse (2)",
    "text": "Ergebnisse der Bedarfsanalyse (2)\nWie oft hast du R schon verwendet?\n10:15",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#ergebnisse-der-bedarfsanalyse-3",
    "href": "scripts/01_slides/EH_2.html#ergebnisse-der-bedarfsanalyse-3",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Ergebnisse der Bedarfsanalyse (3)",
    "text": "Ergebnisse der Bedarfsanalyse (3)\nIn welchen Lehrveranstaltungen hast du R verwendet?\n\nStatistik\nDiagnostik\nNeuowissenschaften/Computerlab\nBachelorarbeit/Masterarbeit\nWeitere Kurse und Seminar ( z.B. Datensatzaufbereitung in R)",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#ergebnisse-der-bedarfsanalyse-4",
    "href": "scripts/01_slides/EH_2.html#ergebnisse-der-bedarfsanalyse-4",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Ergebnisse der Bedarfsanalyse (4)",
    "text": "Ergebnisse der Bedarfsanalyse (4)\nHast du R auch außerhalb von Lehrveranstaltungen verwendet?\n10:15",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#ergebnisse-der-bedarfsanalyse-5",
    "href": "scripts/01_slides/EH_2.html#ergebnisse-der-bedarfsanalyse-5",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Ergebnisse der Bedarfsanalyse (5)",
    "text": "Ergebnisse der Bedarfsanalyse (5)\nWelche R-Pakete hast du bereits verwendet?\n\nFast alle von euch haben schon mit dem Tidyverse gearbeitet\n\n\nFast alle nur mit tidyverse, fast niemand mit BaseR und fast niemand mit einem anderen Package.",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#ergebnisse-der-bedarfsanalyse-6",
    "href": "scripts/01_slides/EH_2.html#ergebnisse-der-bedarfsanalyse-6",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Ergebnisse der Bedarfsanalyse (6)",
    "text": "Ergebnisse der Bedarfsanalyse (6)\nWie unsicher fühlst du dich im Umgang mit den folgenden Themen?\n10:15",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#ergebnisse-der-bedarfsanalyse-7",
    "href": "scripts/01_slides/EH_2.html#ergebnisse-der-bedarfsanalyse-7",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Ergebnisse der Bedarfsanalyse (7)",
    "text": "Ergebnisse der Bedarfsanalyse (7)\nWelche weiteren Schritte bereiten dir Schwierigkeiten in R?\n\nAllgemeine Unsicherheit / Überforderung\nGrundlegendes, Syntax & Fehleranalyse (Code funktioniert nicht)\nPakete und Funktionen (Wann brauche ich was?)\nCodes schreiben und verstehen (Eigenständig coden, nachvollziehen von generiertem Code)\nDatenverständnis & -aufbereitung\nStatistische Analysen & Anwendungen\nGanzheitliches Verständnis von Code\n\n\nUnsicherheit welche Pakete für welche Analysen\nOft nur codes kopieren, mühe logik oder reihenfolge nachzuvollziehen\nUnsicherheit welche schritte nötig sind, (umwandenlen und strukturieren von daten)\nAuswahl passender Tests\n–&gt; Allgemeine Überforderung, stark auf extrene Hilfe angewiesen.",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#ergebnisse-der-bedarfsanalyse-8",
    "href": "scripts/01_slides/EH_2.html#ergebnisse-der-bedarfsanalyse-8",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Ergebnisse der Bedarfsanalyse (8)",
    "text": "Ergebnisse der Bedarfsanalyse (8)\nBei welchen Schritten in R fühlst du dich sicher, wenn du auch daran denkst, die im Bachelor erworbenen Unterlagen zu Hilfe zu ziehen?\n\nBasics (z.B. Vektoren zuweisen)\nDatenimport & -aufbereitung\nDeskriptive & einfache Analysen\nVisualisierung mit ggplot2\nFortgeschrittene Analysen mit bereits vorbereiteten Daten\nAllgemeine Unsicherheit ➡️ mit Unterlagen, KI, oder Schritt für Schritt Anweisungen funktioniert bereits einiges\n\n\nWir werden versuchen unser “Programm” auf eure Needs abzustimmen - bitte gebt uns laufend Feedback dazu.",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#ergebnisse-der-bedarfsanalyse-9",
    "href": "scripts/01_slides/EH_2.html#ergebnisse-der-bedarfsanalyse-9",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Ergebnisse der Bedarfsanalyse (9)",
    "text": "Ergebnisse der Bedarfsanalyse (9)\nWas würdest du gerne in diesem Methodenseminar lernen?\n\nGrundlagen und Verständnis festigen ➡️ Sicherheit gewinnen\nDatenaufbereitung\nStatistische Analysen und Interpretation\n\nWann brauche ich welche Tests ➡️ Leider kann keine grundlegende Statistik-Auffrischung angeboten werden.\nAber: Strukturiertes Vorgehen z.B. Datenanalyseplan.\n\nVisualisierung und Dokumentation\nEigenständiger werden & Problemlöseskills\nMotivation und Sicherheit!\n\nUnser Motto: Üben, üben, üben",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#ergebnisse-der-bedarfsanalyse-10",
    "href": "scripts/01_slides/EH_2.html#ergebnisse-der-bedarfsanalyse-10",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Ergebnisse der Bedarfsanalyse (10)",
    "text": "Ergebnisse der Bedarfsanalyse (10)\nWelche Unterstützung um die Datenaufbereitung und -analyse in R würdest du dir innerhalb dieses Seminars wünschen?\n\noffene Fehlerkultur\nSchritt-für-Schritt-Anleitungen im individuellen Tempo → Musterlösungen\nÜben und Praxis ➡️ Hands-on!\n\n\n\nNiederschwellige Hilfe ➡️ Tutor, Sprechstunden\n\n\n\nVerknüpfung von „Warum“ und „Wie“ ➡️ konzeptionelle und praktische Kompetenz",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#ergebnisse-der-bedarfsanalyse-11",
    "href": "scripts/01_slides/EH_2.html#ergebnisse-der-bedarfsanalyse-11",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Ergebnisse der Bedarfsanalyse (11)",
    "text": "Ergebnisse der Bedarfsanalyse (11)\nWelche Unterstützung um die Datenaufbereitung und -analyse in R würdest du dir außerhalb dieses Seminars (z.B. im Studium allgemein) wünschen?\n\nAnlaufstellen & Beratung ➡️ Methodenberatung, Foren für Mitstudierende\nSkripte & Materialien ➡️ Frei Zugängliche Skripte, Templates, Cheat-Sheets\nKurse & Übungsangebote ➡️ Zusätzliche Kurse für Auffrischung und Übung\nPraxis & Anwendung im Studium ➡️ R stärker in VLs und Seminare & Projekte einbinden um Routine zu entwicklen\nTheorie-Verknüpfung & Verständnis\n\nDiese Frage stellen wir, weil wir bemüht sind etwas zu verbessern. 1ster Schritt: Methodenberatung",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#peer-pairing",
    "href": "scripts/01_slides/EH_2.html#peer-pairing",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Peer-Pairing:",
    "text": "Peer-Pairing:\n10:15\n\n16:15",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#peer-pairing-1",
    "href": "scripts/01_slides/EH_2.html#peer-pairing-1",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Peer-Pairing:",
    "text": "Peer-Pairing:\n\nVorgehen: Melden bis Sonntag 28.09 (ILIAS Forum, siehe EH2) mit Namen des 2er Teams\nAnsonsten: Zufällige Zuteilung am Montag - Kennenlernen in der nächsten Einheit\n\n\n\n\n\n\n\n\nIllustration von Freepik",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#open-science---menti",
    "href": "scripts/01_slides/EH_2.html#open-science---menti",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Open Science - Menti",
    "text": "Open Science - Menti\n\n\nWas verbindest du mit Open Science?\nMenti nach Vormittagseinheit zurücksetzen",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#replikationskrise",
    "href": "scripts/01_slides/EH_2.html#replikationskrise",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Replikationskrise",
    "text": "Replikationskrise\n\nAusgangspunkt: 9 Studien, die darauf hinweisen, dass Personen «in die Zukunft sehen können» (Bem , 2011)\nEtablierte psychologische Messmethoden (z.B. Priming)\nEin Ergebnis: Primes, die nach Antwort präsentiert werden, beeinflussen Antwortzeiten\nStarke Kritik, v.a. was Methodik betrifft; gerade kontroverse,„unwahrscheinliche“ Hypothesen sollten durch strikte, konfirmatorische Analysen überprüfen (Francis, 2012; LeBel & Peters, 2011; Wagenmakers et al., 2011)\nDiverse gescheiterte Replikationsversuche (Galak et al., 2012; Ritchie et al., 2012; Robinson, 2011)\n\n\nWeitere studien von bem unter anderem: erotic image detection –&gt; teilnehmende errieten die position von erotischen bildern signifikant öfter hinter einem vorhang - bevor die bilder überhaupt positioniert wurden.",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#replizierbarkeit-und-reproduzierbarkeit",
    "href": "scripts/01_slides/EH_2.html#replizierbarkeit-und-reproduzierbarkeit",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Replizierbarkeit und Reproduzierbarkeit",
    "text": "Replizierbarkeit und Reproduzierbarkeit\n\nSchönbrodt, 2023\n\nAuf deutsch: Reproduzierbarkeit = gleiche Daten, gleiche Analyse, gleiche Ergebnisse.\nReplizierbarkeit = neue Daten, gleiche Methode, ähnliche Ergebnisse.\n\n–&gt; Aufgrund von Bem haben sich Forschende das Ziel gesetzt die Replizierbarkeit von etablierten findings zu prüfen.",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#open-science-collaboration-2015",
    "href": "scripts/01_slides/EH_2.html#open-science-collaboration-2015",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Open Science Collaboration (2015)",
    "text": "Open Science Collaboration (2015)\nGemeinsames Projekt von 270 Autor:innen, mit dem Ziel 100 Studien aus drei verschiedenen Journals zu replizieren.",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#open-science-collaboration-2015-1",
    "href": "scripts/01_slides/EH_2.html#open-science-collaboration-2015-1",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Open Science Collaboration (2015)",
    "text": "Open Science Collaboration (2015)\n\n\nSignifikante Ergebnisse in den Original-Studien: 97%\n\nWie viele % der Effekte liessen sich replizieren - was glaubt ihr?",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#open-science-collaboration-2015-2",
    "href": "scripts/01_slides/EH_2.html#open-science-collaboration-2015-2",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Open Science Collaboration (2015)",
    "text": "Open Science Collaboration (2015)\n\n\n\nSignifikante Ergebnisse in den Replikationsstudien: 36%\nDie Effektgrössen in den Replikationsstudien sind im Schnitt halb so gross!",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#replikationskrise-in-anderen-fächern",
    "href": "scripts/01_slides/EH_2.html#replikationskrise-in-anderen-fächern",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Replikationskrise in anderen Fächern",
    "text": "Replikationskrise in anderen Fächern\n\nSchönbrodt, 2023; Hofer, 2024*Bei Wirtschaft geht es um Reproduzierbarkeit.\nSiehe auch: https://www.youtube.com/watch?v=FpCrY7x5nEE&ab_channel=TED-Ed",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#warum",
    "href": "scripts/01_slides/EH_2.html#warum",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Warum?",
    "text": "Warum?\n\nSammlung im Plenum von möglichen Gründen",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#gründe-für-die-replikationskrise",
    "href": "scripts/01_slides/EH_2.html#gründe-für-die-replikationskrise",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Gründe für die Replikationskrise:",
    "text": "Gründe für die Replikationskrise:\n\nAkademisches Umfeld:\n\nQuantität &gt; Qualität\n“publish or perish”\n\nQuestionable Research Practices:\n\nSelektive Berichterstattung\np-hacking\n\nBiases:\n\nConfirmation Bias\nPublication Bias\n\n\n“If you torture data long enough, it will confess to anything” - Ronald Coase\n(Spielt natürlich auch eine Rolle: Versuchsmethoden und Zufallsbefunde)",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#gründe-für-die-replikationskrise-1",
    "href": "scripts/01_slides/EH_2.html#gründe-für-die-replikationskrise-1",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Gründe für die Replikationskrise:",
    "text": "Gründe für die Replikationskrise:\nChambers, C. (2017). The seven deadly sins of psychology: A manifesto for reforming the culture of scientific practice. Princeton University Press. https://doi.org/10.1515/9781400884940",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#aktuelle-fälle",
    "href": "scripts/01_slides/EH_2.html#aktuelle-fälle",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Aktuelle Fälle:",
    "text": "Aktuelle Fälle:\nTop German psychologist fabricated data, investigation finds\n\nDer bekannte Psychologe Hans-Ulrich Wittchen soll in einer millionenschweren Studie Daten gefälscht und Whistleblower unter Druck gesetzt haben, was nun zu strafrechtlichen Ermittlungen und möglichen Sanktionen führt.\n\n“Here’s the Unsealed Report Showing How Harvard Concluded That a Dishonesty Expert Committed Misconduct”\n\nDie Forscherin Francesca Gino wird beschuldigt, Daten in mehreren Studien manipuliert zu haben, bestreitet jedoch die Vorwürfe und führt sie auf mögliche Fehler oder andere Personen zurück.\n\nA Scandal in Alzheimer’s Research Shows How Science Can Go Astray\n\nEine Untersuchung legt nahe, dass eine einflussreicher Alzheimer-Studie von 2006 manipulierte Bilder enthielt, was Zweifel an jahrelanger Forschung und der wissenschaftlichen Integrität aufwirft.\n\n\nAktueller Stand:\nHans-Ulrich Wittchen Er ist wegen Datenfälschung bei einer großen Studie angeklagt; sein Vertrag an der LMU wurde suspendiert, weitere Ermittlungen laufen.\nFrancesca Gino Harvard entließ sie 2025 und entzog ihr die Tenure wegen nachgewiesenem Forschungs­fehlverhalten; ihre Klagen gegen Harvard laufen, Teile davon wurden bereits abgewiesen.\nSylvain Lesné Sein zentraler Alzheimer-Artikel von 2006 wurde 2024 aus Nature zurückgezogen; er trat 2025 von seiner Professur in Minnesota zurück, Untersuchungen dauern an. Seine Forschung beinflusste grosse teile des Forschungsbereiches und ist eines der meistzitierten Papers die bis heute retracted wurden.",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#retraction-watch-leaderboard",
    "href": "scripts/01_slides/EH_2.html#retraction-watch-leaderboard",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Retraction Watch Leaderboard",
    "text": "Retraction Watch Leaderboard\n\n\nAn Stelle 8 ist Diederik Stapel - bekannter Fall aus der Psychologie",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#the-end-is-near",
    "href": "scripts/01_slides/EH_2.html#the-end-is-near",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "THE END IS NEAR",
    "text": "THE END IS NEAR\n\nBild generiert von ChatGPT Image Generator\n\nOder?\n„Science is never perfect, but what this crisis has shown is that there is never a shortage of scientists who will keep trying to make it better.” (Maki Naro)",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#lösungsansätze---open-science",
    "href": "scripts/01_slides/EH_2.html#lösungsansätze---open-science",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Lösungsansätze - Open Science",
    "text": "Lösungsansätze - Open Science\n\nAuch wichtig: Registered Reports und Replikationsstudien; Open Acces Publikationen, Open Peer Review, Educational Practices",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#lösungsansätze---open-science-2",
    "href": "scripts/01_slides/EH_2.html#lösungsansätze---open-science-2",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Lösungsansätze - Open Science (2)",
    "text": "Lösungsansätze - Open Science (2)\n\nPräregistrierung\n\nFestlegung der zentralen Aspekte der Studie (z.B. Hypothesen, Stichprobe, Analyse) vor ihrer Umsetzung (d.h. vor der Datenerhebung)\n\nAuch möglich vor der Datenanalyse —&gt; Datenanalyseplan\n\nPräregistrierung wird veröffentlicht, erhält einen Zeitstempel und ist schreibgeschützt\n\nwww.osf.io\nVerschiedene Templates\n\n\nPreprints:\n\nVersion des Manuskripts vor Peer-Review\nPostprint: Version des Manuskripts nach Peer Review.",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#lösungsansätze---open-science-2-1",
    "href": "scripts/01_slides/EH_2.html#lösungsansätze---open-science-2-1",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Lösungsansätze - Open Science (2)",
    "text": "Lösungsansätze - Open Science (2)\nOpen Material, Data & Code\n\nOpen Material: Untersuchungsmaterial (Fragebogen, Stimuli, usw.) wird online zur Verfügung gestellt\nOpen Data: Daten werden in anonymisierter Form veröffentlicht\nOpen Code: Reproduzierbare Analyseskripte werden zur Verfügung gestellt\n\nBadges: \n\nErlaubt Ergebnisse zu überprüfen; erhöht die Glaubwürdigkeit an Forschung; stärkt die gefundenen Ergebnisse",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#open-science-gute-wissenschaftliche-praxis",
    "href": "scripts/01_slides/EH_2.html#open-science-gute-wissenschaftliche-praxis",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Open Science = Gute wissenschaftliche Praxis",
    "text": "Open Science = Gute wissenschaftliche Praxis\n\nStefan et al. (2023)",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#weitere-ressourcen",
    "href": "scripts/01_slides/EH_2.html#weitere-ressourcen",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Weitere Ressourcen:",
    "text": "Weitere Ressourcen:\n\nPennington, C. R. (2023). A student’s guide to open science: Using the replication crisis to reform psychology. McGraw Hill​.\nOpen Science an der Universität Bern: https://www.ub.unibe.ch/service/open_science/index_ger.html ​\nBlogs über aktuelle Themen: https://datacolada.org\nJournal Club: https://reproducibilitea.org\nComic: https://thenib.com/repeat-after-me/?utm_campaign=web-share-links&utm_medium=social&utm_source=link\nLehrveranstaltungen der Abteilung „Psychologie der Digitalisierung“- Meta-Wissenschaft https://www.dig.psy.unibe.ch/studium/lehrveranstaltungen/index_ger.html\n\n„Spellchecker“ für Statistik https://michelenuijten.shinyapps.io/statcheck-web/\n\nFreie Plätze in Ian’s Seminar - Teilnahme noch möglich!",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#was-bedeutet-dies-nun-für-uns",
    "href": "scripts/01_slides/EH_2.html#was-bedeutet-dies-nun-für-uns",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Was bedeutet dies nun für uns?",
    "text": "Was bedeutet dies nun für uns?\n\nFesthalten der Analysen in Datenanalyseplänen\nAnalyse reproduzierbar gestalten ➡️ durch Kommentierung von Code, Codebook etc.\nIdealerweise: auch bei der Masterarbeit Präregistrierung oder Datenanalyseplan etc. (Unterstützung dafür bietet auch die Methodensprechstunde bei Aaron)\nRegt eure Betreuer:innen an!",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#präregistrierungdatenanalysepläne",
    "href": "scripts/01_slides/EH_2.html#präregistrierungdatenanalysepläne",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Präregistrierung/Datenanalysepläne",
    "text": "Präregistrierung/Datenanalysepläne\n\nVorteile, u.a.:\n\nkann davor festhalten, was ich erwarte und wie ich es analysiere = erhöhte Transparenz\nverringerte Möglichkeiten von p-hacking, HARKing, und Biases Stichprobengröße wird festgeschrieben und muss begründet werden\nUnterscheidung konfirmatorischer und explorativer Forschung\n\nkonfirmatorisch: Eine vorab festgelegte Theorie & Hypothese testen\nexplorativ: neue Zusammenhänge/Unterschiede entdecken; keine Annahmen vorab\n\n\n“Its a plan, not a prison” (Pennington, 2023)",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#präregistrierungdatenanalysepläne-1",
    "href": "scripts/01_slides/EH_2.html#präregistrierungdatenanalysepläne-1",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Präregistrierung/Datenanalysepläne",
    "text": "Präregistrierung/Datenanalysepläne\nNachteile?\n\n\nKeine Garantie für Qualität\nIst auch “hackable” –&gt; PARKing (Preregisitreing after Results are known)",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#grundlegender-artikel-grinschgl-et-al.-2020",
    "href": "scripts/01_slides/EH_2.html#grundlegender-artikel-grinschgl-et-al.-2020",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Grundlegender Artikel: Grinschgl et al. (2020)",
    "text": "Grundlegender Artikel: Grinschgl et al. (2020)\nFrom metacognitive beliefs to strategy selection: does fake performance feedback influence cognitive offloading?\n\n3 Gruppen und mehrere Messzeitpunkte\nbetween-within Design\nHauptanalysen: ANOVAs und t-Tests\nVerschiedene AVs (z.B. cognitive offloading, Arbeitsgedächtnisfähigkeiten, Selbsteinschätzung)\nPräregistriert auf OSF https://osf.io/9hpz5\n\n\nACHTUNG: Kein optimales Beispiel, an manchen Stellen zu knapp!",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#datenanalyseplan",
    "href": "scripts/01_slides/EH_2.html#datenanalyseplan",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Datenanalyseplan",
    "text": "Datenanalyseplan\n\nSecondary Data Analyses Preregistration (https://osf.io/x4gzt/)){.uri}\nBasierend auf Van den Akker et al. (2021) -&gt; siehe Paper für eine Anleitung & Youtube Video https://www.youtube.com/watch?v=fqvJx2_V3zY\nLeichte Modifikationen für unser Seminar Vorlage auf ILIAS unter «Abschlussprojekt» -&gt; ZIP-Ordner",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#datenanalyseplan---modifizierte-fragen",
    "href": "scripts/01_slides/EH_2.html#datenanalyseplan---modifizierte-fragen",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Datenanalyseplan - (Modifizierte) Fragen",
    "text": "Datenanalyseplan - (Modifizierte) Fragen\n\nTitel\nKurzbeschreibung der Studie\nForschungsfragen\nHypothesen & explorative Fragestellungen\nDatenzugang\nDatenerhebung\nUnabhängige Variablen\nAbhängige Variablen\nFehlende Daten\nDatenausschluss\nVorkenntnisse zu den Daten\nStatistische Modelle\nInferenz-Kriterien\n\nDiese Fragen sind für die Analysen von Grinschgl et al, (2020) zu beantworten –&gt; erste HÜ",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#datenanalyseplan---aufgabenstellung",
    "href": "scripts/01_slides/EH_2.html#datenanalyseplan---aufgabenstellung",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Datenanalyseplan - Aufgabenstellung",
    "text": "Datenanalyseplan - Aufgabenstellung\n\nDatenanalyseplan für Reproduzierung der Analysen von Grinschgl et al. (2020) erstellen (bis EH 4) ➡️4 Punkte\n\nPaper befindet sich ohne und mit Hinweisen auf ILIAS (Ordner «Abschlussprojekt» ➡️ Zip Ordner)\nAuf Deutsch oder Englisch\nNicht nur Kopie der Textteile aus dem Paper, sondern in eigene Worte fassen\nEs gibt nicht die EINE richtige Lösung\nEinfach mal probieren! Korrektheit zweitrangig!\n\nMusterlösung & Peer-Review (Zwischen EH 4-5) ➡️ 4 Punkte\nAbschlussarbeit: überarbeiteten Datenanalyseplan mit abgeben (Basis: Simulierte Daten) ➡️ Teil der 46 Punkte (Abschlussarbeit)\nFAQ anschauen, Ilias Forum für neue Fragen nutzen",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#fragen-wünsche-anregungen",
    "href": "scripts/01_slides/EH_2.html#fragen-wünsche-anregungen",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Fragen, Wünsche, Anregungen",
    "text": "Fragen, Wünsche, Anregungen\n\nIllustration von svstudioart/Freepik",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#ankündigung-collegium-generale",
    "href": "scripts/01_slides/EH_2.html#ankündigung-collegium-generale",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Ankündigung: Collegium Generale",
    "text": "Ankündigung: Collegium Generale",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#ankündigung-masterarbeit-praktikum-zu-vergeben",
    "href": "scripts/01_slides/EH_2.html#ankündigung-masterarbeit-praktikum-zu-vergeben",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Ankündigung: Masterarbeit / Praktikum zu vergeben",
    "text": "Ankündigung: Masterarbeit / Praktikum zu vergeben\n\nReplikationsstudie von Loftus und Palmer(1974) Car Crash Experiment\nLoftus, E. F., & Palmer, J. C. (1974). Reconstruction of auto-mobile destruction: An example of the interaction between language and memory. Journal of Verbal Learning and Verbal behavior, 13, 585-589.",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#heute-haben-wir",
    "href": "scripts/01_slides/EH_2.html#heute-haben-wir",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Heute haben wir:",
    "text": "Heute haben wir:\n\nDen Ursprung und Gründe der Replikationskrise kennengelernt\nDas Verbessern psychologischer Forschung mittels Open Science Praktiken diskutiert\nDas Konzept der Präregistrierung und des Datenanalyseplans kennengelernt\nWeitere Hands-On Übungen zu R Basics bearbeitet",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#hausübungen",
    "href": "scripts/01_slides/EH_2.html#hausübungen",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Hausübungen:",
    "text": "Hausübungen:\n\nPaper lesen (r_you_ready/Grinschgl2020/reports)\nDatenanalyseplan für Paper erstellen (auf Basis des Papers)\n\nAbgabe via ILIAS, Deadline: 08.10.2025\nWeiterleiten an Peer-Partner (EH4)\n\nUnterstützende Dokumente (Ordner: r_you_ready/Unterstützende_Dokumente/Datenanalyseplan):\n\nArtikel Van den Akker et al. (2021)\nForum & Peer Pairing (ab EH3)\nFAQ\nFragen zur nächsten Einheit mitbringen\n\nHands-On Übungen (Musterlösungen nächste Woche)\nPeer-Pairings melden, Deadline 28.09.2025\n\n\nOder direkt jetzt bei mir oder lars melden!",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_2.html#referenzen",
    "href": "scripts/01_slides/EH_2.html#referenzen",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 2",
    "section": "Referenzen:",
    "text": "Referenzen:\nBem, D. J. (2011). Feeling the future: Experimental evidence for anomalous retroactive influences on cognition and affect. Journal of Personality and Social Psychology, 100, 407–425. https://doi.org/10.1037/a0021524\nFrancis, G. (2012). Too good to be true: Publication bias in two prominent studies from experimental psychology. Psychonomic Bulletin & Review, 19, 151–156. https://doi.org/10.3758/s13423-012-0227-9\nGalak, J., LeBoeuf, R. A., Nelson, L. D., & Simmons, J. P. (2012). Correcting the past: Failures to replicate psi. Journal of Personality and Social Psychology, 103(6), 933–948. http://dx.doi.org/10.1037/a0029709\nGrinschgl, S., Meyerhoff, H. S., Schwan, S., & Papenmeier, F. (2021). From metacognitive beliefs to strategy selection: Does fake performance feedback influence cognitive offloading? Psychological Research, 85, 2654–2666. https://doi.org/10.1007/s00426-020-01435-9\nHofer, G. (2024, April 23). Open Science [Course presentation]. University of Graz.\nLeBel, E. P., & Peters, K. R. (2011). Fearing the future of empirical psychology: Bem’s (2011) evidence of psi as a case study of deficiencies in modal research practice. Review of General Psychology, 15(4), 371–379. https://doi.org/10.1037/a0025172\nOpen Science Collaboration. (2015). Estimating the reproducibility of psychological science. Science, 349(6251), Article aac4716. https://doi.org/10.1126/science.aac4716\nPennington, C. R. (2023). A student’s guide to open science: Using the replication crisis to reform psychology. McGraw Hill.",
    "crumbs": [
      "Präsentationen",
      "Einheit 2 - 24.09.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_7.html#r-u-ready-reproduzierbare-datenaufbereitung-und--analyse-mit-r",
    "href": "scripts/01_slides/EH_7.html#r-u-ready-reproduzierbare-datenaufbereitung-und--analyse-mit-r",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 7",
    "section": "R u Ready? Reproduzierbare Datenaufbereitung und -analyse mit R",
    "text": "R u Ready? Reproduzierbare Datenaufbereitung und -analyse mit R\nHS 2025 LV-Leitung: Dr. Sandra Grinschgl / MSc. Aaron Friedli Tutor: BSc. Lars Schilling7. Einheit, 29.10.2025",
    "crumbs": [
      "Präsentationen",
      "Einheit 7 - 29.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_7.html#heute",
    "href": "scripts/01_slides/EH_7.html#heute",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 7",
    "section": "Heute:",
    "text": "Heute:",
    "crumbs": [
      "Präsentationen",
      "Einheit 7 - 29.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_7.html#fragen-zu-hands-on-block-2",
    "href": "scripts/01_slides/EH_7.html#fragen-zu-hands-on-block-2",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 7",
    "section": "Fragen zu Hands On Block 2?",
    "text": "Fragen zu Hands On Block 2?",
    "crumbs": [
      "Präsentationen",
      "Einheit 7 - 29.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_7.html#pipe",
    "href": "scripts/01_slides/EH_7.html#pipe",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 7",
    "section": "Pipe:",
    "text": "Pipe:\n\nAus dem magrittr-Package %&gt;% (Teil des tidyverse) oder Base R |&gt;\n\n\n\nZweck: Macht Code leserlicher und verständlicher\n\n\n\nHilft bei Funktionen, die als erstes Argument Daten erwarten\n\n\n\nDer Name pipe ist so zu verstehen, dass wir ein Objekt an eine Funktionen “weiterleiten” oder “übergeben”.\nUnterschiede zwischen den beiden Pipes: Unterschiedliche Platzhalter, native pipe etwas schneller. Für uns spielt der Unterschied keine Rolle.",
    "crumbs": [
      "Präsentationen",
      "Einheit 7 - 29.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_7.html#pipe-beispiel",
    "href": "scripts/01_slides/EH_7.html#pipe-beispiel",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 7",
    "section": "Pipe: Beispiel",
    "text": "Pipe: Beispiel\n👎Unübersichtliche verschachtelte Funktion\n\nlibrary(palmerpenguins)\nlibrary(tidyverse)\n\nhead(select(filter(penguins, species == \"Adelie\"), species, bill_length_mm))\n\n👍 Übersichtlich und nachvollziehbar mit der Pipe\n\npenguins |&gt;  \n  filter(species == \"Adelie\") |&gt;  \n  select(species, bill_length_mm) |&gt;  \n  head()\n\n# A tibble: 6 × 2\n  species bill_length_mm\n  &lt;fct&gt;            &lt;dbl&gt;\n1 Adelie            39.1\n2 Adelie            39.5\n3 Adelie            40.3\n4 Adelie            NA  \n5 Adelie            36.7\n6 Adelie            39.3",
    "crumbs": [
      "Präsentationen",
      "Einheit 7 - 29.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_7.html#tidyverse-dplyr",
    "href": "scripts/01_slides/EH_7.html#tidyverse-dplyr",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 7",
    "section": "Tidyverse: dplyr",
    "text": "Tidyverse: dplyr\nBietet und einige der wichtigsten Funktionen für die Datenaufbereitung!",
    "crumbs": [
      "Präsentationen",
      "Einheit 7 - 29.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_7.html#dplyr-filter",
    "href": "scripts/01_slides/EH_7.html#dplyr-filter",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 7",
    "section": "dplyr: filter()",
    "text": "dplyr: filter()\n\n\nfehlendes ” bei “Gentoo”",
    "crumbs": [
      "Präsentationen",
      "Einheit 7 - 29.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_7.html#dplyr-filter-1",
    "href": "scripts/01_slides/EH_7.html#dplyr-filter-1",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 7",
    "section": "dplyr: filter()",
    "text": "dplyr: filter()\nFiltert den Datensatz basierend auf den logischen Argumenten die wir geben.\n\nRows (Zeilen) auswählen\n\n\nlibrary(palmerpenguins)\n\npenguins |&gt; \n  filter(species == \"Gentoo\")\n\n# A tibble: 124 × 8\n   species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Gentoo  Biscoe           46.1          13.2               211        4500\n 2 Gentoo  Biscoe           50            16.3               230        5700\n 3 Gentoo  Biscoe           48.7          14.1               210        4450\n 4 Gentoo  Biscoe           50            15.2               218        5700\n 5 Gentoo  Biscoe           47.6          14.5               215        5400\n 6 Gentoo  Biscoe           46.5          13.5               210        4550\n 7 Gentoo  Biscoe           45.4          14.6               211        4800\n 8 Gentoo  Biscoe           46.7          15.3               219        5200\n 9 Gentoo  Biscoe           43.3          13.4               209        4400\n10 Gentoo  Biscoe           46.8          15.4               215        5150\n# ℹ 114 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;",
    "crumbs": [
      "Präsentationen",
      "Einheit 7 - 29.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_7.html#dplyr-select",
    "href": "scripts/01_slides/EH_7.html#dplyr-select",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 7",
    "section": "dplyr: select()",
    "text": "dplyr: select()\n\nColums (Spalten) auswählen\n\n\n\n# A tibble: 344 × 3\n   species island    bill_length_mm\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;\n 1 Adelie  Torgersen           39.1\n 2 Adelie  Torgersen           39.5\n 3 Adelie  Torgersen           40.3\n 4 Adelie  Torgersen           NA  \n 5 Adelie  Torgersen           36.7\n 6 Adelie  Torgersen           39.3\n 7 Adelie  Torgersen           38.9\n 8 Adelie  Torgersen           39.2\n 9 Adelie  Torgersen           34.1\n10 Adelie  Torgersen           42  \n# ℹ 334 more rows",
    "crumbs": [
      "Präsentationen",
      "Einheit 7 - 29.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_7.html#dplyer-select",
    "href": "scripts/01_slides/EH_7.html#dplyer-select",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 7",
    "section": "dplyer: select ()",
    "text": "dplyer: select ()",
    "crumbs": [
      "Präsentationen",
      "Einheit 7 - 29.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_7.html#dplyr-select-1",
    "href": "scripts/01_slides/EH_7.html#dplyr-select-1",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 7",
    "section": "dplyr: select()",
    "text": "dplyr: select()\n\nMit Hilfsfunktionen wie starts_with\n\n\npenguins |&gt; \n  select(starts_with(\"bill\"))\n\n# A tibble: 344 × 2\n   bill_length_mm bill_depth_mm\n            &lt;dbl&gt;         &lt;dbl&gt;\n 1           39.1          18.7\n 2           39.5          17.4\n 3           40.3          18  \n 4           NA            NA  \n 5           36.7          19.3\n 6           39.3          20.6\n 7           38.9          17.8\n 8           39.2          19.6\n 9           34.1          18.1\n10           42            20.2\n# ℹ 334 more rows",
    "crumbs": [
      "Präsentationen",
      "Einheit 7 - 29.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_7.html#dplyr-select-2",
    "href": "scripts/01_slides/EH_7.html#dplyr-select-2",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 7",
    "section": "dplyr: select()",
    "text": "dplyr: select()\n\nAusschliessen mit -\n\n\npenguins |&gt; \n  select(-species, -island)\n\n# A tibble: 344 × 6\n   bill_length_mm bill_depth_mm flipper_length_mm body_mass_g sex     year\n            &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt; &lt;fct&gt;  &lt;int&gt;\n 1           39.1          18.7               181        3750 male    2007\n 2           39.5          17.4               186        3800 female  2007\n 3           40.3          18                 195        3250 female  2007\n 4           NA            NA                  NA          NA &lt;NA&gt;    2007\n 5           36.7          19.3               193        3450 female  2007\n 6           39.3          20.6               190        3650 male    2007\n 7           38.9          17.8               181        3625 female  2007\n 8           39.2          19.6               195        4675 male    2007\n 9           34.1          18.1               193        3475 &lt;NA&gt;    2007\n10           42            20.2               190        4250 &lt;NA&gt;    2007\n# ℹ 334 more rows",
    "crumbs": [
      "Präsentationen",
      "Einheit 7 - 29.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_7.html#dplyr-summarize",
    "href": "scripts/01_slides/EH_7.html#dplyr-summarize",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 7",
    "section": "dplyr: summarize()",
    "text": "dplyr: summarize()\n\nFasst Daten zusammen, indem Kennwerte (z. B. Mittelwerte) berechnet werden.\nReduziert viele Zeilen zu einer oder wenigen zusammengefassten Zeilen.\nWird oft mit group_by() kombiniert, um Kennwerte pro Gruppe zu berechnen.\n\n\npenguins |&gt; \n  summarise(\n    mean_bill_length = mean(bill_length_mm, na.rm = TRUE),\n    mean_flipper_length = mean(flipper_length_mm, na.rm = TRUE)\n  )\n\n# A tibble: 1 × 2\n  mean_bill_length mean_flipper_length\n             &lt;dbl&gt;               &lt;dbl&gt;\n1             43.9                201.",
    "crumbs": [
      "Präsentationen",
      "Einheit 7 - 29.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_7.html#dplyr-summarize-1",
    "href": "scripts/01_slides/EH_7.html#dplyr-summarize-1",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 7",
    "section": "dplyr: summarize()",
    "text": "dplyr: summarize()",
    "crumbs": [
      "Präsentationen",
      "Einheit 7 - 29.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_7.html#dplyr-mutate",
    "href": "scripts/01_slides/EH_7.html#dplyr-mutate",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 7",
    "section": "dplyr: mutate()",
    "text": "dplyr: mutate()\n\nErstellt neue Variablen oder verändert Bestehende.\nBehält alle Zeilen des ursprünglichen Datensatzes bei.\n\n\n\nWird oft genutzt, um berechnete Spalten hinzuzufügen (z. B. bill_to_flipper_ratio).\n\n\nlibrary(tidyverse)\nlibrary(palmerpenguins)\n\npenguins_upgraded &lt;- penguins |&gt; \n  mutate(\n    bill_to_flipper_ratio = bill_length_mm / flipper_length_mm,\n    body_mass_kg = body_mass_g / 1000\n  )\n\nhead(penguins_upgraded)\n\n# A tibble: 6 × 10\n  species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Adelie  Torgersen           39.1          18.7               181        3750\n2 Adelie  Torgersen           39.5          17.4               186        3800\n3 Adelie  Torgersen           40.3          18                 195        3250\n4 Adelie  Torgersen           NA            NA                  NA          NA\n5 Adelie  Torgersen           36.7          19.3               193        3450\n6 Adelie  Torgersen           39.3          20.6               190        3650\n# ℹ 4 more variables: sex &lt;fct&gt;, year &lt;int&gt;, bill_to_flipper_ratio &lt;dbl&gt;,\n#   body_mass_kg &lt;dbl&gt;",
    "crumbs": [
      "Präsentationen",
      "Einheit 7 - 29.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_7.html#dplyr-mutate-1",
    "href": "scripts/01_slides/EH_7.html#dplyr-mutate-1",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 7",
    "section": "dplyr: mutate()",
    "text": "dplyr: mutate()",
    "crumbs": [
      "Präsentationen",
      "Einheit 7 - 29.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_7.html#dplyr-group_by",
    "href": "scripts/01_slides/EH_7.html#dplyr-group_by",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 7",
    "section": "dplyr: group_by()",
    "text": "dplyr: group_by()\n\nTeilt den Datensatz in Gruppen auf (z. B. nach species).\nVerändert die Daten nicht, sondern markiert sie intern als gruppiert.\nBereitet Daten auf Aggregationen mit summarise() oder Berechnungen mit mutate() vor.\n\n\ngrouped_summary &lt;- penguins |&gt; \n  group_by(species) |&gt; \n  summarise(\n    mean_bill_length = mean(bill_length_mm, na.rm = TRUE),\n    mean_flipper_length = mean(flipper_length_mm, na.rm = TRUE)\n  )\n\ngrouped_summary\n\n# A tibble: 3 × 3\n  species   mean_bill_length mean_flipper_length\n  &lt;fct&gt;                &lt;dbl&gt;               &lt;dbl&gt;\n1 Adelie                38.8                190.\n2 Chinstrap             48.8                196.\n3 Gentoo                47.5                217.",
    "crumbs": [
      "Präsentationen",
      "Einheit 7 - 29.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_7.html#dplyr-group_by-1",
    "href": "scripts/01_slides/EH_7.html#dplyr-group_by-1",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 7",
    "section": "dplyr: group_by()",
    "text": "dplyr: group_by()",
    "crumbs": [
      "Präsentationen",
      "Einheit 7 - 29.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_7.html#heute-haben-wir",
    "href": "scripts/01_slides/EH_7.html#heute-haben-wir",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 7",
    "section": "Heute haben wir:",
    "text": "Heute haben wir:\n\nDie Pipe kennengelernt\nDplyr Funktionen (Teil des tidyverse) zur Datenaufbereitung kennengelernt",
    "crumbs": [
      "Präsentationen",
      "Einheit 7 - 29.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_7.html#hausübung",
    "href": "scripts/01_slides/EH_7.html#hausübung",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 7",
    "section": "Hausübung",
    "text": "Hausübung\n\nBis 7.11.2025 (Freitag nach EH 8)\nAlle Instruktionen auf der Website\nDanach Peer Feedback (Instruktionen folgen in EH 8)",
    "crumbs": [
      "Präsentationen",
      "Einheit 7 - 29.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_4.html#r-u-ready-reproduzierbare-datenaufbereitung-und--analyse-mit-r",
    "href": "scripts/01_slides/EH_4.html#r-u-ready-reproduzierbare-datenaufbereitung-und--analyse-mit-r",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 4",
    "section": "R u Ready? Reproduzierbare Datenaufbereitung und -analyse mit R",
    "text": "R u Ready? Reproduzierbare Datenaufbereitung und -analyse mit R\nHS 2025 LV-Leitung: Dr. Sandra Grinschgl / MSc. Aaron Friedli Tutor: BSc. Lars Schilling4. Einheit, 8.10.2025",
    "crumbs": [
      "Präsentationen",
      "Einheit 4 - 08.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_4.html#fragen-zum-datenanalyseplan-codebook",
    "href": "scripts/01_slides/EH_4.html#fragen-zum-datenanalyseplan-codebook",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 4",
    "section": "Fragen zum Datenanalyseplan & Codebook:",
    "text": "Fragen zum Datenanalyseplan & Codebook:",
    "crumbs": [
      "Präsentationen",
      "Einheit 4 - 08.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_4.html#heute",
    "href": "scripts/01_slides/EH_4.html#heute",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 4",
    "section": "Heute:",
    "text": "Heute:",
    "crumbs": [
      "Präsentationen",
      "Einheit 4 - 08.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_4.html#hands-on",
    "href": "scripts/01_slides/EH_4.html#hands-on",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 4",
    "section": "Hands On!",
    "text": "Hands On!\n🎯 Ziel: Heute mindestens bis zum Daten-Mergen und Speichern kommen!\n🏃 Für alle, die schneller fertig sind: Coding Basics, Funktionen und Styler\n✈️ Für besonders Schnelle: Weiterarbeiten am Codebook / Peer-Feedback",
    "crumbs": [
      "Präsentationen",
      "Einheit 4 - 08.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_4.html#daten-einlesen",
    "href": "scripts/01_slides/EH_4.html#daten-einlesen",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 4",
    "section": "Daten einlesen",
    "text": "Daten einlesen\n\nCode immer im Skript abspeichern!\nAusführung alleine in der Konsole reicht nicht\nBei Einlesen über Environment, Code in Skript kopieren!",
    "crumbs": [
      "Präsentationen",
      "Einheit 4 - 08.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_4.html#plenum-wie-funktionieren-joins",
    "href": "scripts/01_slides/EH_4.html#plenum-wie-funktionieren-joins",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 4",
    "section": "Plenum: Wie funktionieren Joins?",
    "text": "Plenum: Wie funktionieren Joins?\n\nFragen wie weit man letzte Einheit gekommen ist, ggf. zuerst weiter arbeiten lassen\n\n\ncbind() vs. full_join()\ncbind() verbindet Datensätze spaltenweise – warum ist das suboptimal?\nfull_join() Nimmt alle Variablen aus beiden Datensätzen. Um die Datensätze korrekt zu verbinden musst du einen Schlüssel festlegen.",
    "crumbs": [
      "Präsentationen",
      "Einheit 4 - 08.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_4.html#full_join",
    "href": "scripts/01_slides/EH_4.html#full_join",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 4",
    "section": "full_join()",
    "text": "full_join()\nWas ist der Schlüssel?\nEine gemeinsame Variable die in beiden Datensätzen vorhanden ist, mit der RStudio erkennen kann welche Werte miteinander verbunden werden müssen.\n\ndata_cb &lt;- read_delim(\"data/raw/data_cb.csv\", delim = \";\")\ndata_vp &lt;- read_delim(\"data/raw/data_vp.csv\", delim = \";\")\n\ndat_full_1 &lt;- full_join(data_cb, data_vp, by = \"code\")\nhead(dat_full_1)\n\n# A tibble: 6 × 5\n   code cb_sum cb_propcorrect vp_sum vp_propcorrect\n  &lt;dbl&gt;  &lt;dbl&gt;          &lt;dbl&gt;  &lt;dbl&gt;          &lt;dbl&gt;\n1     1     26          0.722     33          0.917\n2     2     27          0.75      27          0.75 \n3     3     30          0.833     33          0.917\n4     4     27          0.75      31          0.861\n5     5     25          0.694     32          0.889\n6     6     23          0.639     24          0.667\n\n\n\nIterativer Prozess: immer für 2 Datensätze bis man dat_full mit allen 7 Datensätzen hat –&gt; dafür wird dann Codebook geschrieben",
    "crumbs": [
      "Präsentationen",
      "Einheit 4 - 08.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_4.html#beispiel",
    "href": "scripts/01_slides/EH_4.html#beispiel",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 4",
    "section": "Beispiel",
    "text": "Beispiel\n\ndf1 &lt;- data.frame(id = c(1, 2, 3),\n                  name = c(\"Anna\", \"Ben\", \"Chris\"))\n\ndf2 &lt;- data.frame(id = c(2, 3, 4),\n                  score = c(80, 90, 70))\n\nfull_join(df1, df2, by = \"id\")\n\n  id  name score\n1  1  Anna    NA\n2  2   Ben    80\n3  3 Chris    90\n4  4  &lt;NA&gt;    70",
    "crumbs": [
      "Präsentationen",
      "Einheit 4 - 08.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_4.html#unterschiede-zwischen-den-diversen-joins",
    "href": "scripts/01_slides/EH_4.html#unterschiede-zwischen-den-diversen-joins",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 4",
    "section": "Unterschiede zwischen den diversen Joins:",
    "text": "Unterschiede zwischen den diversen Joins:\n\nBehält gemeinsame Zeilen bei",
    "crumbs": [
      "Präsentationen",
      "Einheit 4 - 08.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_4.html#unterschiede-zwischen-den-diversen-joins-1",
    "href": "scripts/01_slides/EH_4.html#unterschiede-zwischen-den-diversen-joins-1",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 4",
    "section": "Unterschiede zwischen den diversen Joins:",
    "text": "Unterschiede zwischen den diversen Joins:\n\nBehält gemeinsame + Zeilen von linken Datensatz bei",
    "crumbs": [
      "Präsentationen",
      "Einheit 4 - 08.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_4.html#unterschiede-zwischen-den-diversen-joins-2",
    "href": "scripts/01_slides/EH_4.html#unterschiede-zwischen-den-diversen-joins-2",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 4",
    "section": "Unterschiede zwischen den diversen Joins:",
    "text": "Unterschiede zwischen den diversen Joins:\n\nBehält gemeinsame + Zeilen von rechten Datensatz bei",
    "crumbs": [
      "Präsentationen",
      "Einheit 4 - 08.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_4.html#unterschiede-zwischen-den-diversen-joins-3",
    "href": "scripts/01_slides/EH_4.html#unterschiede-zwischen-den-diversen-joins-3",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 4",
    "section": "Unterschiede zwischen den diversen Joins:",
    "text": "Unterschiede zwischen den diversen Joins:\n\nBehält gemeinsame Zeilen, aber nur Inhalte von Datensatz x bei",
    "crumbs": [
      "Präsentationen",
      "Einheit 4 - 08.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_4.html#check-in",
    "href": "scripts/01_slides/EH_4.html#check-in",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 4",
    "section": "Check-in:",
    "text": "Check-in:\n\nNun sollte jede/r einen Datensatz dat_full haben, der alle 7 Einzeldatensätze beinhaltet mit 159 Versuchspersonen (= Zeilen) und 36 Variablen (= Spalten).\nCheckt mit euren Peer-Partner:innen/Sitznachbar:innen!\nMit diesem Datensatz werden wir die Analysen von Grinschgl et al. (2020) durchführen.\nZu diesem Datensatz sollt ihr bis zum 22.10. den ersten Entwurf für das Codebook schreiben!",
    "crumbs": [
      "Präsentationen",
      "Einheit 4 - 08.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_4.html#fehlererkennung-in-r",
    "href": "scripts/01_slides/EH_4.html#fehlererkennung-in-r",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 4",
    "section": "Fehlererkennung in R",
    "text": "Fehlererkennung in R\nDer Code läuft nicht. Wie könnt ihr vorgehen um den Fehler zu identifizieren und beheben?\n\nLies die Fehlermeldung!\n\n\nÜberprüfe:\n✅Tippfehler\n✅Klammern\n✅Syntaxfehler\n✅Datentypen\n✅Pakete\nGoogeln hilft oft weiter!\n\nFehlermeldungen lassen sich einfacher googeln, wenn R auf Englisch eingestellt ist:\n\n👉Sys.setenv(LANGUAGE = \"en\")\noft ist es auch hilfreich, das Betriebssystem anzugeben: sessionInfo()",
    "crumbs": [
      "Präsentationen",
      "Einheit 4 - 08.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_4.html#fehlererkennung-in-r-tipps",
    "href": "scripts/01_slides/EH_4.html#fehlererkennung-in-r-tipps",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 4",
    "section": "Fehlererkennung in R – Tipps",
    "text": "Fehlererkennung in R – Tipps\n\nclass() / str() zur Objektprüfung 👉\nIn mean.default(x) : argument is not numeric or logical: returning NA\nFunktionen schrittweise testen\nArgumente weglassen → Fehlerquelle finden\nZwischenergebnisse mit print()",
    "crumbs": [
      "Präsentationen",
      "Einheit 4 - 08.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_4.html#code-diagnostik",
    "href": "scripts/01_slides/EH_4.html#code-diagnostik",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 4",
    "section": "Code Diagnostik:",
    "text": "Code Diagnostik:",
    "crumbs": [
      "Präsentationen",
      "Einheit 4 - 08.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_4.html#r-studio-gibt-hinweise",
    "href": "scripts/01_slides/EH_4.html#r-studio-gibt-hinweise",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 4",
    "section": "R-Studio gibt Hinweise!",
    "text": "R-Studio gibt Hinweise!\n\n\nFehlermeldungen: Die Information vor dem Doppelpunkt gibt uns an, in welcher Funktion der Fehler steckt; die Information nach dem Doppelpunkt gibt Aufschluss über die Art des Fehlers. Zweiteres ist für die Fehlersuche (zumeist) von großer Bedeutung.\nWenn ein oder mehrere Zeichen überflüssig sind bzw. fehlen, dann bekommt man Unerwartete(s) ‘…’ in “…” ausgegeben. Hierbei teilt uns die Meldung mit, wo der Fehler liegt: In den Anführungszeichen “…” wird nur ein Teil des Codes ausgegeben und der Fehler ist zumeist das zuletzt ausgegebene Zeichen (oder es liegt unmittelbar davor).  z.B. daten[2]",
    "crumbs": [
      "Präsentationen",
      "Einheit 4 - 08.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_4.html#r-resourcen",
    "href": "scripts/01_slides/EH_4.html#r-resourcen",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 4",
    "section": "R-Resourcen",
    "text": "R-Resourcen\n\nNewsletter zu R\nInformationen zu Paketen\nPsyteacher AI Tutor\nR for Data Science (Basics wie Import, Aufbereitung, Visualisierung)\nPsychometrics in Exercises using R and RStudio (Psychometrische Analysen wie EFA, CFA, SEM)\nLearnr Shinyapps\nCheatsheets\nStack Overflow –&gt; Q&A Forum\nDatacamp\nÜberblick über weitere Ressourcen 👉 Arslan (2025)",
    "crumbs": [
      "Präsentationen",
      "Einheit 4 - 08.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_4.html#large-language-models-datenanalyse",
    "href": "scripts/01_slides/EH_4.html#large-language-models-datenanalyse",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 4",
    "section": "Large Language Models & Datenanalyse",
    "text": "Large Language Models & Datenanalyse\n\nModelle wie ChatGPT\nBerechnen Wahrscheinlichkeiten für Wörter und erzeugen dadurch Text, der menschlich wirkt.\nABER:\n\nVerstehen keine Bedeutung\nWissen nicht was inhaltlich korrekt ist\n\n\n\n\nFür welche Aufgaben nutzt du LLMs im Analyseprozess?",
    "crumbs": [
      "Präsentationen",
      "Einheit 4 - 08.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_4.html#vibe-coding",
    "href": "scripts/01_slides/EH_4.html#vibe-coding",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 4",
    "section": "Vibe coding",
    "text": "Vibe coding\n\n👉KI in natürlicher Sprache prompten ohne den generierten Code zu prüfen oder zu verstehen.\n\nVibe Coding bedeutet, dass Nutzer*innen mit KI-Codegeneratoren (z. B. ChatGPT, GitHub Copilot) Programme schreiben, indem sie nur Zielbeschreibungen in natürlicher Sprache eingeben, ohne den generierten Code wirklich zu verstehen oder gründlich zu überprüfen.\n\nEs ist also intuitives, versuchsorientiertes „Codieren nach Gefühl“, bei dem Schnelligkeit vor Verständnis steht.",
    "crumbs": [
      "Präsentationen",
      "Einheit 4 - 08.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_4.html#gefahren-von-vibe-coding",
    "href": "scripts/01_slides/EH_4.html#gefahren-von-vibe-coding",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 4",
    "section": "Gefahren von Vibe coding",
    "text": "Gefahren von Vibe coding\n\n\nWelche Chancen und Risiken siehst du bei der Nutzung von LLMs bei der Datenanalyse?",
    "crumbs": [
      "Präsentationen",
      "Einheit 4 - 08.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_4.html#ki---llms-chatgpt-copilot-rtutor",
    "href": "scripts/01_slides/EH_4.html#ki---llms-chatgpt-copilot-rtutor",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 4",
    "section": "KI - LLMs (ChatGPT, Copilot, Rtutor)",
    "text": "KI - LLMs (ChatGPT, Copilot, Rtutor)\n💚 Vorteile\n\nGenerieren schnell viel Code\nCode häufig syntaktisch korrekt\nOn-Demand-Assistenz für Fragen aller Art\nReduziert Einstiegshürden\nUnterstützung bei Debugging und Error Handling\nTutoring-Funktion –&gt; siehe Prompts",
    "crumbs": [
      "Präsentationen",
      "Einheit 4 - 08.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_4.html#sinnvolle-nutzung-von-ki-im-datenanalyseprozess",
    "href": "scripts/01_slides/EH_4.html#sinnvolle-nutzung-von-ki-im-datenanalyseprozess",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 4",
    "section": "Sinnvolle Nutzung von KI im Datenanalyseprozess:",
    "text": "Sinnvolle Nutzung von KI im Datenanalyseprozess:\n\n💚Sinnvoll: Unterstützend – nicht ersetzend\n\nKontrolle einfacher Fehler (Klammern, Typos)\nErklärung von Code und Syntax\nHilfe bei Fehlersuche (Debugging)\nKommentierung und Dokumentation\n\n💔Nicht sinnvoll: Ersatz statt Unterstützung\n\nGenerierung ganzer Analyse-Skripte\nAutomatische Auswahl von Methoden oder Tests\nInterpretation statistischer Ergebnisse durch KI\nErstellung kompletter Berichte oder Diskussionen\nHochladen sensibler Daten\nUnkritisches Übernehmen von Output",
    "crumbs": [
      "Präsentationen",
      "Einheit 4 - 08.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_4.html#github-copilot-in-r",
    "href": "scripts/01_slides/EH_4.html#github-copilot-in-r",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 4",
    "section": "Github CoPilot in R",
    "text": "Github CoPilot in R\n\nVoraussetzung ist ein Account sowie ein Copilot-Abo (kostenlos für Studierende) auf GitHub.\nGitHub ist ein Clouddienst von Microsoft, spezialisiert auf das Teilen und gemeinsame Bearbeiten von Code:\nhttps://github.com/\nEine Anleitung zur Einrichtung von GitHub Copilot in RStudio findet ihr hier:\nYouTube-Link (1:40–2:36)\nRechtliche Informationen für Studierende der Universität Bern findet ihr unter:\nGenerative KI Uni Bern",
    "crumbs": [
      "Präsentationen",
      "Einheit 4 - 08.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_4.html#chatgpt-in-r",
    "href": "scripts/01_slides/EH_4.html#chatgpt-in-r",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 4",
    "section": "ChatGPT in R",
    "text": "ChatGPT in R\n\nVoraussetzung ist ein Account bei OpenAI / ChatGPT:\nhttps://chatgpt.com/\nEine Anleitung zur Einrichtung von ChatGPT in RStudio findet ihr hier:\nYouTube-Link (2:36–5:08)\nRechtliche Informationen für Studierende der Universität Bern findet ihr unter:\nGenerative KI Uni Bern",
    "crumbs": [
      "Präsentationen",
      "Einheit 4 - 08.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_4.html#verwendung-von-llms",
    "href": "scripts/01_slides/EH_4.html#verwendung-von-llms",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 4",
    "section": "Verwendung von LLMs",
    "text": "Verwendung von LLMs",
    "crumbs": [
      "Präsentationen",
      "Einheit 4 - 08.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_4.html#peer-feedback-zum-datenanalyseplan",
    "href": "scripts/01_slides/EH_4.html#peer-feedback-zum-datenanalyseplan",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 4",
    "section": "Peer Feedback zum Datenanalyseplan",
    "text": "Peer Feedback zum Datenanalyseplan\n📋To Do’s:\n\nMusterlösung anschauen! (siehe Ordner Abschlussprojekt auf Ilias)\nDatenanalyseplan des Partners/der Partnerin bis 15.10. durchschauen und kommentieren (am besten mit Word oder PDF Kommentaren)\nUpload auf Ilias mit Kommentaren+ Weitergabe an Partner:in per Email\nAuch persönliches Feedback erwünscht 👉 selbstorganisiert\nSelbständigkeit: Wir geben kein Feedback, bei Fragen auf uns zukommen (Forum, Sprechstunde etc. nutzen)",
    "crumbs": [
      "Präsentationen",
      "Einheit 4 - 08.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_4.html#peer-feedback-zum-datenanalyseplan-1",
    "href": "scripts/01_slides/EH_4.html#peer-feedback-zum-datenanalyseplan-1",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 4",
    "section": "Peer Feedback zum Datenanalyseplan",
    "text": "Peer Feedback zum Datenanalyseplan\n\nKlarheit und Verständlichkeit (z.B. sind alle Begriffe und Konzepte ausreichend erklärt? Gibt es verwirrende oder unklare Formulierungen?)\nVollständigkeit (z.B. wurden alle notwendigen Fragen ausreichend beantwortet? Fehlen Informationen?)\nReproduzierbarkeit (Ist der Plan so formuliert, dass er von einer anderen Person nachvollzogen und reproduziert werden kann?)",
    "crumbs": [
      "Präsentationen",
      "Einheit 4 - 08.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_4.html#peer-feedback-regeln",
    "href": "scripts/01_slides/EH_4.html#peer-feedback-regeln",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 4",
    "section": "Peer Feedback Regeln",
    "text": "Peer Feedback Regeln\n\nGib fundiertes, konstruktives und gut strukturiertes Feedback!\nFokus sollte auf inhaltlicher Qualität und Übereinstimmung mit den Anforderungen liegen, nicht auf persönlichen Präferenzen.\nVerbesserungsvorschläge sind gewünscht, kein „Schön reden“ notwendig –&gt; wir wollen dazu lernen!\nVerbesserungsvorschläge sollten möglichst konkret sein.\nBleibt aber natürlich sachlich und verwendet eine respektvolle Sprache!\nAuch Lob für besonders gute Abschnitte darf nicht fehlen. Feedback ist ein Lernprozess, auch für den Gebenden. Seit bereit, euer Feedback anzupassen, wenn die andere Person es anders versteht oder weitere Informationen liefert.\nPeer Feedback sollte nicht nur auf die aktuelle Aufgabe abzielen, sondern auch helfen, den Lernprozess der beteiligten Personen langfristig zu verbessern",
    "crumbs": [
      "Präsentationen",
      "Einheit 4 - 08.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_4.html#heute-haben-wir",
    "href": "scripts/01_slides/EH_4.html#heute-haben-wir",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 4",
    "section": "Heute haben wir:",
    "text": "Heute haben wir:\n\nDatensätze gemerged und diverse joins kennengelernt\nTools für die Fehlerdiagnostik in R kennengelernt\nUns mit Ressourcen und dem Umgang mit LLMS befasst",
    "crumbs": [
      "Präsentationen",
      "Einheit 4 - 08.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_4.html#abfrage-muddiest-points",
    "href": "scripts/01_slides/EH_4.html#abfrage-muddiest-points",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 4",
    "section": "Abfrage Muddiest Points",
    "text": "Abfrage Muddiest Points\n\nDenke an die bisher besprochenen Inhalte zurück – was ist dir unklar geblieben? Was sollten wir noch einmal besprechen?\nDenke sowohl an die R Hands On Sessions als auch die theoretischen Inhalte (z.B. Open Science, Datenanalyseplan, Codebook).\nNotiere bitte max. drei konkrete Punkte. Falls du Vorschläge/Ideen zur Aufarbeitung dieser Punkte hast, gib diese auch gerne an.\nUmfrage auf ILIAS (siehe EH 4) bis Sonntag 12.10. 23:55",
    "crumbs": [
      "Präsentationen",
      "Einheit 4 - 08.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_4.html#zusammenfassung-der-to-dos",
    "href": "scripts/01_slides/EH_4.html#zusammenfassung-der-to-dos",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 4",
    "section": "Zusammenfassung der To Do’s",
    "text": "Zusammenfassung der To Do’s\n\nMuddiest Points Umfrage bis Sonntag 23:55\nPeer Feedback Datenanalyseplan bis Mittwoch\nSelbstständiges Durcharbeiten des Hands On Block 2 bis Mittwoch",
    "crumbs": [
      "Präsentationen",
      "Einheit 4 - 08.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_4.html#referenzen",
    "href": "scripts/01_slides/EH_4.html#referenzen",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 4",
    "section": "Referenzen:",
    "text": "Referenzen:\nArslan (2025, June 4). One lives only to make blunders: Resources for learning R. Retrieved from https://rubenarslan.github.io/posts/2025-06-04-resources-for-learning-r/",
    "crumbs": [
      "Präsentationen",
      "Einheit 4 - 08.10.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_8.html#r-u-ready-reproduzierbare-datenaufbereitung-und--analyse-mit-r",
    "href": "scripts/01_slides/EH_8.html#r-u-ready-reproduzierbare-datenaufbereitung-und--analyse-mit-r",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 8",
    "section": "R u Ready? Reproduzierbare Datenaufbereitung und -analyse mit R",
    "text": "R u Ready? Reproduzierbare Datenaufbereitung und -analyse mit R\nHS 2025 LV-Leitung: Dr. Sandra Grinschgl / MSc. Aaron Friedli Tutor: BSc. Lars Schilling8. Einheit, 05.11.2025",
    "crumbs": [
      "Präsentationen",
      "Einheit 8 - 05.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_8.html#heute",
    "href": "scripts/01_slides/EH_8.html#heute",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 8",
    "section": "Heute:",
    "text": "Heute:",
    "crumbs": [
      "Präsentationen",
      "Einheit 8 - 05.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_8.html#codebook",
    "href": "scripts/01_slides/EH_8.html#codebook",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 8",
    "section": "Codebook:",
    "text": "Codebook:\n\nMetadata\nResponse Labels\n\nStellt sicher dass diese Punkte auch ausgefüllt sind für die Schlussabgabe.",
    "crumbs": [
      "Präsentationen",
      "Einheit 8 - 05.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_8.html#nachtrag-row.names-false",
    "href": "scripts/01_slides/EH_8.html#nachtrag-row.names-false",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 8",
    "section": "Nachtrag: row.names = FALSE",
    "text": "Nachtrag: row.names = FALSE\nrow.names = FALSE sorgt dafür, dass keine neue Spalte eingefügt wird, die alle Zeilen durchnummeriert (also einen zusätzlichen „Spaltennamen“ erzeugt).\nWenn ihr in eurem dat_full als erste Spalte eine solche Bezeichnung wie „…1“ findet, habt ihr dat_full wahrscheinlich ohne das Argument row.names = FALSE abgespeichert. Das ist nicht weiter schlimm, sollte aber bereinigt werden (z. B. mit select()).\n\nwrite.csv(dat_full, \"data/raw/dat_full_rownames.csv\")\n\n\ndat_full_rownames[1:5, 1:3]\n\n# A tibble: 5 × 3\n   ...1  code question1\n  &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n1     1     1         2\n2     2     2         3\n3     3     3         2\n4     4     4         1\n5     5     5         3\n\n\nEntfernen mit select()\n\ndat_full_rownames &lt;- dat_full_rownames |&gt; \n  select(-\"...1\")",
    "crumbs": [
      "Präsentationen",
      "Einheit 8 - 05.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_8.html#nachtrag-write.csv2",
    "href": "scripts/01_slides/EH_8.html#nachtrag-write.csv2",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 8",
    "section": "Nachtrag: write.csv2()",
    "text": "Nachtrag: write.csv2()\nDie beiden Funktionen unterscheiden sich nur in den verwendeten Trennzeichen:\n\nwrite.csv() nutzt Kommas als Spaltentrenner und Punkte als Dezimaltrennzeichen.\nwrite.csv2() nutzt Semikolons als Spaltentrenner und Kommas als Dezimaltrennzeichen.\n\nBottom Line: Nutzt write.csv() – sonst kann es passieren, dass Werte mit Nachkommastellen nicht korrekt von R interpretiert werden.",
    "crumbs": [
      "Präsentationen",
      "Einheit 8 - 05.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_8.html#nachtrag-select",
    "href": "scripts/01_slides/EH_8.html#nachtrag-select",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 8",
    "section": "Nachtrag: select()",
    "text": "Nachtrag: select()\nKann nicht verwendet werden, um Rows/Zeilen auszuwählen! Auswahl von Spalten!\nAber: Dafür gibt es Funktionen wie slice() – allerdings wollen wir in der Regel keine Zeilen ohne logisches Kriterium auswählen.\n👉 filter() ist deshalb meist die bessere Option.\n\npenguins |&gt;\n  select(bill_depth_mm) |&gt;\n  slice(10) \n\n# A tibble: 1 × 1\n  bill_depth_mm\n          &lt;dbl&gt;\n1          20.2",
    "crumbs": [
      "Präsentationen",
      "Einheit 8 - 05.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_8.html#kombination-select-und-full_join---beispiel",
    "href": "scripts/01_slides/EH_8.html#kombination-select-und-full_join---beispiel",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 8",
    "section": "Kombination select() und full_join() - Beispiel",
    "text": "Kombination select() und full_join() - Beispiel\n\npenguins &lt;- palmerpenguins::penguins\npenguins &lt;- penguins |&gt;\n  mutate(id = row_number())\n\npenguins2 &lt;- palmerpenguins::penguins\npenguins2 &lt;- penguins2 |&gt;\n  mutate(id = row_number())\n\n\ndat_final &lt;- penguins |&gt;\n  select(id, species, year) |&gt;\n  full_join(\n    penguins2 |&gt; select(id, island, sex),\n    by = \"id\"\n  )",
    "crumbs": [
      "Präsentationen",
      "Einheit 8 - 05.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_8.html#arrange",
    "href": "scripts/01_slides/EH_8.html#arrange",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 8",
    "section": "arrange()",
    "text": "arrange()\nNützlich, um höchste und niedrigste Werte einzusehen – zum Beispiel, um eine Rangliste zu erstellen.\n\n\npenguins |&gt; \n  arrange(bill_depth_mm)\n\n# A tibble: 344 × 9\n   species island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Gentoo  Biscoe           42.9          13.1               215        5000\n 2 Gentoo  Biscoe           46.1          13.2               211        4500\n 3 Gentoo  Biscoe           44.9          13.3               213        5100\n 4 Gentoo  Biscoe           43.3          13.4               209        4400\n 5 Gentoo  Biscoe           46.5          13.5               210        4550\n 6 Gentoo  Biscoe           42            13.5               210        4150\n 7 Gentoo  Biscoe           44            13.6               208        4350\n 8 Gentoo  Biscoe           40.9          13.7               214        4650\n 9 Gentoo  Biscoe           45.5          13.7               214        4650\n10 Gentoo  Biscoe           42.6          13.7               213        4950\n# ℹ 334 more rows\n# ℹ 3 more variables: sex &lt;fct&gt;, year &lt;int&gt;, id &lt;int&gt;",
    "crumbs": [
      "Präsentationen",
      "Einheit 8 - 05.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_8.html#relocate",
    "href": "scripts/01_slides/EH_8.html#relocate",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 8",
    "section": "relocate()",
    "text": "relocate()\nWird genutzt, um Spalten zu verschieben – nützlich, um den Datensatz übersichtlicher zu gestalten, etwa indem man wichtige Variablen (z. B. ID, Gruppe) an den Anfang stellt.\n\n\npenguins |&gt; relocate(bill_depth_mm, .before = island)\n\n# A tibble: 344 × 9\n   species bill_depth_mm island    bill_length_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;           &lt;dbl&gt; &lt;fct&gt;              &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie           18.7 Torgersen           39.1               181        3750\n 2 Adelie           17.4 Torgersen           39.5               186        3800\n 3 Adelie           18   Torgersen           40.3               195        3250\n 4 Adelie           NA   Torgersen           NA                  NA          NA\n 5 Adelie           19.3 Torgersen           36.7               193        3450\n 6 Adelie           20.6 Torgersen           39.3               190        3650\n 7 Adelie           17.8 Torgersen           38.9               181        3625\n 8 Adelie           19.6 Torgersen           39.2               195        4675\n 9 Adelie           18.1 Torgersen           34.1               193        3475\n10 Adelie           20.2 Torgersen           42                 190        4250\n# ℹ 334 more rows\n# ℹ 3 more variables: sex &lt;fct&gt;, year &lt;int&gt;, id &lt;int&gt;",
    "crumbs": [
      "Präsentationen",
      "Einheit 8 - 05.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_8.html#fehlende-werte",
    "href": "scripts/01_slides/EH_8.html#fehlende-werte",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 8",
    "section": "Fehlende Werte",
    "text": "Fehlende Werte\nWieso müssen wir überhaupt fehlende Werte behandeln?\n\nViele Funktionen in R funktionieren nur mit vollständigen Datensätzen.\nKennwerte wie Mittelwerte oder Standardabweichungen können nicht berechnet werden, wenn fehlende Werte enthalten sind.\nFehlende Werte können Ergebnisse verzerren, insbesondere wenn sie nicht zufällig fehlen.\n\nUmgang mit fehlenden Werten:\n\nFinden / Identifizieren!\nNachvollziehen\nHandling - abhängig von eurem Studiendesign und Fragestellungen",
    "crumbs": [
      "Präsentationen",
      "Einheit 8 - 05.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_8.html#diverse-formen-von-fehlenden-werten",
    "href": "scripts/01_slides/EH_8.html#diverse-formen-von-fehlenden-werten",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 8",
    "section": "Diverse Formen von Fehlenden Werten",
    "text": "Diverse Formen von Fehlenden Werten\n\nNA (R-typische Kennzeichnung für Not Available)\n999 oder -999 (häufig manuell gesetzte Platzhalter)\nleere Zellen (\"\")\nNULL (in manchen Programmiersprachen, aber in R selten in Datensätzen verwendet)",
    "crumbs": [
      "Präsentationen",
      "Einheit 8 - 05.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_8.html#finden-und-identifizieren-von-fehlenden-werten",
    "href": "scripts/01_slides/EH_8.html#finden-und-identifizieren-von-fehlenden-werten",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 8",
    "section": "Finden und identifizieren von fehlenden Werten",
    "text": "Finden und identifizieren von fehlenden Werten\nDiverse Ansätze - Konkrete Übungen in den Hands On Übungen.\n\ntable(is.na(penguins))\n\n\nFALSE  TRUE \n 3077    19 \n\n\n\n\ncolSums(is.na(penguins))\n\n          species            island    bill_length_mm     bill_depth_mm \n                0                 0                 2                 2 \nflipper_length_mm       body_mass_g               sex              year \n                2                 2                11                 0 \n               id \n                0",
    "crumbs": [
      "Präsentationen",
      "Einheit 8 - 05.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_8.html#fortgeschritten-nachvollziehen",
    "href": "scripts/01_slides/EH_8.html#fortgeschritten-nachvollziehen",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 8",
    "section": "Fortgeschritten: Nachvollziehen!",
    "text": "Fortgeschritten: Nachvollziehen!\n\n\nMissing Completely at Random (MCAR): Fehlende Werte entstehen rein zufällig und stehen in keinem Zusammenhang mit anderen Daten.\n\nMissing at Random (MAR): Fehlende Werte hängen mit beobachteten, aber nicht mit den fehlenden Variablen selbst zusammen.\n\nMissing Not at Random (MNAR): Fehlende Werte stehen in direktem Zusammenhang mit den nicht beobachteten (fehlenden) Werten selbst.\n\n\nMCAR: Während einer Online-Studie bricht bei einigen Teilnehmenden zufällig die Internetverbindung ab, sodass ihre Antworten fehlen. → Das Fehlen ist rein zufällig und unabhängig von ihren Eigenschaften oder Antworten.\nMAR: In einer Befragung zu Stress und Schlafqualität überspringen jüngere Teilnehmende häufiger Fragen zur Schlafdauer. → Das Fehlen hängt mit dem beobachteten Merkmal Alter zusammen, aber nicht mit der tatsächlichen Schlafdauer.\nMNAR: Bei einer Angststudie brechen Teilnehmende mit besonders hoher Angst die Untersuchung ab, bevor sie den Angstfragebogen ausfüllen. → Das Fehlen hängt direkt mit dem nicht beobachteten Wert der Angstvariable zusammen.",
    "crumbs": [
      "Präsentationen",
      "Einheit 8 - 05.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_8.html#mögliche-ansätze-um-mit-missings-umzugehen",
    "href": "scripts/01_slides/EH_8.html#mögliche-ansätze-um-mit-missings-umzugehen",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 8",
    "section": "Mögliche Ansätze um mit Missings umzugehen:",
    "text": "Mögliche Ansätze um mit Missings umzugehen:\nFehlende Werte entfernen\nAchtung: Je nach Analysemethode kann bereits ein einziger fehlender Wert dazu führen, dass eine ganze Versuchsperson aus der Analyse ausgeschlossen wird!\n\nFehlende Werte imputieren\nDas bedeutet, fehlende Werte durch geschätzte Werte zu ersetzen (z. B. Mittelwert, Regression, Multiple Imputation).\n\n→ Das üben wir nicht in diesem Seminar.",
    "crumbs": [
      "Präsentationen",
      "Einheit 8 - 05.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_8.html#fehlende-werte-bei-berechnungen-beachten",
    "href": "scripts/01_slides/EH_8.html#fehlende-werte-bei-berechnungen-beachten",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 8",
    "section": "Fehlende Werte bei Berechnungen beachten",
    "text": "Fehlende Werte bei Berechnungen beachten\n\nViele R-Funktionen können fehlende Werte automatisch ausschliessen, z. B. mit na.rm = TRUE\n\n\n\nx &lt;- c(1, NA)\n\nmean(x, na.rm = FALSE)   # fehlende Werte werden in Berechnung  miteinbezogen, ergibt NA als Mittelwert; default Einstellung\n\n[1] NA\n\nmean(x, na.rm = TRUE)    #fehlende Werte werden ausgeschlossen, ergibt 1 als Mittelwert\n\n[1] 1",
    "crumbs": [
      "Präsentationen",
      "Einheit 8 - 05.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_8.html#skalenberechnung",
    "href": "scripts/01_slides/EH_8.html#skalenberechnung",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 8",
    "section": "Skalenberechnung",
    "text": "Skalenberechnung\nDamit wir unsere Analysen sinnvoll durchführen können, müssen wir oft Skalen berechnen, also mehrere Items zu einem Gesamtwert zusammenfassen.\n\nSchritte:\n\nTransformation der Antwortformate (z. B. von „Trifft häufig zu“ zu numerischen Werten).\n\nBeachtung von Reverse-Codierungen (z. B. beim Konstrukt Gewissenhaftigkeit: Item „Ich bin bequem, neige zur Faulheit“ muss umgepolt werden).\n\nBerechnung der Skalenwerte (z. B. durch Mittelwertbildung der entsprechenden Items).",
    "crumbs": [
      "Präsentationen",
      "Einheit 8 - 05.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_8.html#beispiele-berechnung-von-skalenwerten",
    "href": "scripts/01_slides/EH_8.html#beispiele-berechnung-von-skalenwerten",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 8",
    "section": "Beispiele Berechnung von Skalenwerten",
    "text": "Beispiele Berechnung von Skalenwerten\n\nEinfache Variante\n\n\n\ndat_full &lt;- dat_full |&gt; \n  mutate(mmq_mean = (question1 + question2 + question3 + question4 + question5 + question6 + question7 + question8 + question9 + question10 + question11 + question12 + question13 + question14 + question15 + question16 + question17 + question18)/18)\n\n\nSparsamerer Varianten: Dplyr Funktion verwenden um z.B. nicht alle Variablen auszuschreiben\n\n\n#Sparsamere Alternative:\n\ndat_full &lt;- dat_full |&gt; \n  mutate(mmq_mean = rowMeans(select(dat_full, starts_with(\"question\")),\n                             na.rm = TRUE))\n\n#Sparsamere Alternative:\n\ndat_full &lt;- dat_full |&gt;\n  mutate(mmq_mean = rowMeans(across(question1:question18), na.rm = TRUE))\n\n#Sparsamere Alternative:\n\ndat_full &lt;- dat_full %&gt;%\n  rowwise() %&gt;%\n  mutate(mmq_mean3 = mean(c_across(starts_with(\"question\")), na.rm = TRUE))\n\n\nna.rm = TRUE bedeutet, dass für eine Person ein Skalenwert berechnet wird wenn es mind. 1 vorhandenen Wert gibt\nWenn na.rm = FALSE, dann wird kein Skalenwert für eine Person berechnet wenn es mind 1 fehlenden Wert gibt\nc_across(), sodass die Spalten (columns) ausgewählt werden.",
    "crumbs": [
      "Präsentationen",
      "Einheit 8 - 05.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_8.html#heute-haben-wir",
    "href": "scripts/01_slides/EH_8.html#heute-haben-wir",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 8",
    "section": "Heute haben wir:",
    "text": "Heute haben wir:\n…Fehlende Werte und mögliche Umgangsformen angeschaut\n… Skalenberechnung angeschaut",
    "crumbs": [
      "Präsentationen",
      "Einheit 8 - 05.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_8.html#congrats-you-mastered-dplyr",
    "href": "scripts/01_slides/EH_8.html#congrats-you-mastered-dplyr",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 8",
    "section": "Congrats you mastered dplyr!!",
    "text": "Congrats you mastered dplyr!!",
    "crumbs": [
      "Präsentationen",
      "Einheit 8 - 05.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_8.html#bis-nächstes-mal",
    "href": "scripts/01_slides/EH_8.html#bis-nächstes-mal",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 8",
    "section": "Bis nächstes Mal",
    "text": "Bis nächstes Mal\n\nHausübung 1 - Abgabe bis Freitag 07.11.2025 via Ilias (Ordner: Abgaben)\nPeer-Feedback bis nächsten Mittwoch 12.11.2025\n\nDirekte Kommentierung des Quartoskripts\nKurze Zusammenfassung im Forum (Ordner: EH8)!\n\nHands On Block 4 fertigstellen",
    "crumbs": [
      "Präsentationen",
      "Einheit 8 - 05.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_9.html#r-u-ready-reproduzierbare-datenaufbereitung-und--analyse-mit-r",
    "href": "scripts/01_slides/EH_9.html#r-u-ready-reproduzierbare-datenaufbereitung-und--analyse-mit-r",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 9",
    "section": "R u Ready? Reproduzierbare Datenaufbereitung und -analyse mit R",
    "text": "R u Ready? Reproduzierbare Datenaufbereitung und -analyse mit R\nHS 2025 LV-Leitung: Dr. Sandra Grinschgl / MSc. Aaron Friedli Tutor: BSc. Lars Schilling9. Einheit, 12.11.2025",
    "crumbs": [
      "Präsentationen",
      "Einheit 9 - 12.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_9.html#heute",
    "href": "scripts/01_slides/EH_9.html#heute",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 9",
    "section": "Heute:",
    "text": "Heute:\n\n\n\nVerschiebung der Abgabe der Datensätze an die Studierenden auf EH13.",
    "crumbs": [
      "Präsentationen",
      "Einheit 9 - 12.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_9.html#besprechung-hands-on-block-4-hausübung-1",
    "href": "scripts/01_slides/EH_9.html#besprechung-hands-on-block-4-hausübung-1",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 9",
    "section": "Besprechung Hands On Block 4 & Hausübung 1:",
    "text": "Besprechung Hands On Block 4 & Hausübung 1:\n\nScheint sehr gut gelungen zu sein!\n\nProbleme beim Einlesen –&gt; Keine NAs sondern nur leere Zellen –&gt; Andere Funktionen als read_delim genutzt.\n\ndata &lt;- read_delim(\"raw/fake_bfi_dataset.csv\", delim = \";\")\n\nbfi_10 &lt;- drop_na(data)",
    "crumbs": [
      "Präsentationen",
      "Einheit 9 - 12.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_9.html#besprechung-hausübung-1",
    "href": "scripts/01_slides/EH_9.html#besprechung-hausübung-1",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 9",
    "section": "Besprechung Hausübung 1:",
    "text": "Besprechung Hausübung 1:\nEffizienter Code Beispiel aus den Musterlösungen mit across()\nArgument 1: cols = –&gt; welche colums sollen bearbeitet werden\nArgument 2: .fns 👉 Welche Funktion wenden wir auf die cols. an.\n\ndata_bfi_recoded &lt;- clean_data_bfi_10 |&gt; \n  mutate(\n    across(\n      c(bfi_extra_1_r, bfi_agree_2_r, bfi_consc_2_r, bfi_neuro_2_r, bfi_open_2_r),\n      ~ case_when(\n        . == 1 ~ 5,\n        . == 2 ~ 4,\n        . == 3 ~ 3,\n        . == 4 ~ 2,\n        . == 5 ~ 1\n      )\n    )\n  )\n\n#Sparsamere Alternative\n\ndata_bfi_recoded &lt;- clean_data_bfi_10 |&gt;\n  mutate(\n    across(ends_with(\"_r\"), ~ 6 - .)  # 6- Minus current Value . \n  )\n\n\ndata_bfi_recoded &lt;- clean_data_bfi_10 |&gt;\n  mutate(\n    across(ends_with(\"_r\"), function(x) 6 - x) # Umgeschrieben\n  )\n\nAnonyme Funktionen",
    "crumbs": [
      "Präsentationen",
      "Einheit 9 - 12.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_9.html#hausübung-1",
    "href": "scripts/01_slides/EH_9.html#hausübung-1",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 9",
    "section": "Hausübung 1",
    "text": "Hausübung 1\nFalls eure gerenderten Skripte bei den Peer-Partnern nicht richtig angezeigt werden 👉 Im Header des Quarto-Dokuments\nembed-resources = true",
    "crumbs": [
      "Präsentationen",
      "Einheit 9 - 12.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_9.html#genzplyr",
    "href": "scripts/01_slides/EH_9.html#genzplyr",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 9",
    "section": "Genzplyr 💅",
    "text": "Genzplyr 💅\n\nFalls euch die dplyr() Funktionen zu Öde sind 😄genzplyr - Hadley Wickham\n\n\nlibrary(genzplyr)\n\npenguins |&gt; \n  vibe_check(island, species, sex)\n  yeet(island == \"Biscoe\")",
    "crumbs": [
      "Präsentationen",
      "Einheit 9 - 12.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_9.html#heute-1",
    "href": "scripts/01_slides/EH_9.html#heute-1",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 9",
    "section": "Heute:",
    "text": "Heute:\n\nWide - Long\nDatenqualität (Schiefe, Kurtoseis, Ausreisser, Skalenreliabilität)",
    "crumbs": [
      "Präsentationen",
      "Einheit 9 - 12.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_9.html#wide-to-long-tranformation",
    "href": "scripts/01_slides/EH_9.html#wide-to-long-tranformation",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 9",
    "section": "Wide to Long Tranformation:",
    "text": "Wide to Long Tranformation:\n\nWide: Jede Zeile bezieht sich auf eine Person und beinhaltet alle Messzeitpunkte\nLong: Pro Messung (repeated measures) eine Zeile, Personen strecken sich über mehrere Zeilen hinweg.\n\n👉 Long Format is häufig benötigt für Analysen mit einem repeated measures Faktor",
    "crumbs": [
      "Präsentationen",
      "Einheit 9 - 12.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_9.html#transformation-wide-to-long",
    "href": "scripts/01_slides/EH_9.html#transformation-wide-to-long",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 9",
    "section": "Transformation wide to long",
    "text": "Transformation wide to long\n\nWie müssen wir den folgenden Datensatz transformieren, um ihn ins long Format zu bekommen?\n\n\n\nid\nmesszeitpunkt_t1\nmesszeitpunkt_t2\nmesszeitpunkt_t3\n\n\n\n\n1\n10\n14\n18\n\n\n2\n12\n15\n17\n\n\n3\n9\n13\n15\n\n\n4\n11\n12\n16",
    "crumbs": [
      "Präsentationen",
      "Einheit 9 - 12.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_9.html#long-to-wide-mit-pivot_longer",
    "href": "scripts/01_slides/EH_9.html#long-to-wide-mit-pivot_longer",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 9",
    "section": "Long to Wide mit pivot_longer()",
    "text": "Long to Wide mit pivot_longer()\nArgumente:\n\ncols 👉Welche Variablen sollen transformiert (also zusammengestapelt) werden?\nnames_to👉 Wie heisst die neue Variable, die den Messzeitpunkt (oder generell den ursprünglichen Spaltennamen) enthält?\nvalues_to👉 Wie heisst die neue Variable, in der die Werte aus den ursprünglichen Spalten gespeichert werden?\n\n\ndf_long &lt;- df_wide |&gt;\n  pivot_longer(\n    cols = starts_with(\"messzeitpunkt_t\"),\n    names_to = \"messzeitpunkt\",\n    values_to = \"score\"\n  )\n\ndf_long[1:3, 1:3]\n\n# A tibble: 3 × 3\n     id messzeitpunkt    score\n  &lt;int&gt; &lt;chr&gt;            &lt;dbl&gt;\n1     1 messzeitpunkt_t1    10\n2     1 messzeitpunkt_t2    14\n3     1 messzeitpunkt_t3    18\n\n\n\nnotwendig für dat_full um 2x3 ANOVA zu berechnen",
    "crumbs": [
      "Präsentationen",
      "Einheit 9 - 12.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_9.html#long-to-wide-mit-pivot_wider",
    "href": "scripts/01_slides/EH_9.html#long-to-wide-mit-pivot_wider",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 9",
    "section": "Long to Wide mit pivot_wider()",
    "text": "Long to Wide mit pivot_wider()\nArgumente:\n\nnames_from 👉Die Werte aus dieser Spalte (messzeitpunkt) werden wieder zu Spaltennamen.\nvalues_from👉Die Werte aus dieser Spalte (score) füllen die neu entstandenen Spalten.\n\n\ndf_wide_again &lt;- df_long |&gt; \n  pivot_wider(\n    names_from = messzeitpunkt,\n    values_from = score\n  )\n\ndf_wide_again[1:4, 1:4]\n\n# A tibble: 4 × 4\n     id messzeitpunkt_t1 messzeitpunkt_t2 messzeitpunkt_t3\n  &lt;int&gt;            &lt;dbl&gt;            &lt;dbl&gt;            &lt;dbl&gt;\n1     1               10               14               18\n2     2               12               15               17\n3     3                9               13               15\n4     4               11               12               16",
    "crumbs": [
      "Präsentationen",
      "Einheit 9 - 12.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_9.html#paket-tidyr",
    "href": "scripts/01_slides/EH_9.html#paket-tidyr",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 9",
    "section": "Paket tidyr",
    "text": "Paket tidyr\n\npivot_longer() und pivot_wider() stammen aus dem Paket tidyr - Teil des tidyverse\nCheatsheet tidyr\nUmgang mit fehlenden Werten: drop_na(), replace_na() stammen auch aus tidyr",
    "crumbs": [
      "Präsentationen",
      "Einheit 9 - 12.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_9.html#wichtige-funktionen-datenaufbereitung",
    "href": "scripts/01_slides/EH_9.html#wichtige-funktionen-datenaufbereitung",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 9",
    "section": "Wichtige Funktionen Datenaufbereitung:",
    "text": "Wichtige Funktionen Datenaufbereitung:\naus Einführung in R, Kapitel 4.1",
    "crumbs": [
      "Präsentationen",
      "Einheit 9 - 12.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_9.html#hands-on",
    "href": "scripts/01_slides/EH_9.html#hands-on",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 9",
    "section": "Hands On!",
    "text": "Hands On!\n\nCode korrigieren / verbessern\nLong Transformationen",
    "crumbs": [
      "Präsentationen",
      "Einheit 9 - 12.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_9.html#skewness-kurtosis",
    "href": "scripts/01_slides/EH_9.html#skewness-kurtosis",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 9",
    "section": "Skewness / Kurtosis",
    "text": "Skewness / Kurtosis\nSchiefe / Skewness: Funktion skew()\n\n\n\n\n\nKurtosis / Wölbung: Funktion kurtosi()\n\n\n\n\n\n\nKurtosis: Je kleiner der Wert, desto flacher ist die Kurve, je höher, desto steiler. Negative Werte sind dabei nicht möglich. Eine Normalverteilung hat eine Kurtosis von 3.\n\n\n\nEine Schiefe nahe 0 und eine Kurtosis von etwa 3 sprechen für eine Normalverteilung. Statt der Kurtosis wird oft der Exzess betrachtet. Dabei wird von der Kurtosis der Wert 3 abgezogen, sodass eine Normalverteilung den Wert 0 hat. Werte &lt; 0 sprechen für einen im Vergleich zur Normalverteilung flacheren, Werte &gt; 0 für einen steileren Verlauf",
    "crumbs": [
      "Präsentationen",
      "Einheit 9 - 12.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_9.html#residuen",
    "href": "scripts/01_slides/EH_9.html#residuen",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 9",
    "section": "Residuen",
    "text": "Residuen\nDie Normalverteilung der Residuen ist eine Voraussetzung für viele statistische Tests.\nMögliche Arten, diese Annahme zu ueberprüfen:\n\nVisuelle Verfahren (z.B. QQ-Plot)\nFormale Tests (z. B. Shapiro-Wilk) –&gt; “veraltete” Methode\n\n\nVisuelle Verfahren werden heute meist bevorzugt, da sie weniger sensitiv gegenüber Stichprobengrössen sind.\n\nAllerdings gilt: Verletzungen der Normalitätsannahme sind in der Praxis oft weniger problematisch als angenommen. Sollte es problematisch sein, kann auf nichtparametrische Verfahren ausgewichen werden.",
    "crumbs": [
      "Präsentationen",
      "Einheit 9 - 12.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_9.html#normalität-der-residuen",
    "href": "scripts/01_slides/EH_9.html#normalität-der-residuen",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 9",
    "section": "Normalität der Residuen",
    "text": "Normalität der Residuen\n\n\nEine Residuum ist die Abweichung eines vorhergesagten Wertes vom tatsächlich beobachteten Wert. Der vorhergesagte Wert wurde dabei mithilfe eines mathematischen Modells ermittelt. Indem die Residuen minimiert werden, wird das Modell optimiert und es können genauere Vorhersagen getroffen werden. Im Gegensatz zu den Störgrößen sind Residuen (lateinisch residuum = „das Zurückgebliebene“) berechnete Größen und messen den vertikalen Abstand zwischen Beobachtungspunkt und der geschätzten Regressionsgerade.",
    "crumbs": [
      "Präsentationen",
      "Einheit 9 - 12.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_9.html#residuen-qq-plot",
    "href": "scripts/01_slides/EH_9.html#residuen-qq-plot",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 9",
    "section": "Residuen: QQ-Plot",
    "text": "Residuen: QQ-Plot\nZweck: QQ-Plots prüfen, ob die Daten einer theoretischen Verteilung (z. B. Normalverteilung) folgen.\n\nX-Achse: Theoretische Quantile\nY-Achse: Beobachtete (empirische) Datenquantile\n\n\n\nDer QQ-Plot und das Histogramm zeigen, dass die Residuen insgesamt nahe an einer Normalverteilung liegen, jedoch im linken Extrembereich etwas mehr Werte (heavy tail) und im rechten Extrembereich etwas weniger Werte (light tail) aufweisen. Diese Abweichungen sind gering, sodass parametrische Analysen weiterhin angemessen sind.",
    "crumbs": [
      "Präsentationen",
      "Einheit 9 - 12.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_9.html#ausreisser",
    "href": "scripts/01_slides/EH_9.html#ausreisser",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 9",
    "section": "Ausreisser",
    "text": "Ausreisser\nSollten in Abhängigkeit des Studiendesigns und der Fragestellungen in einer Präregistrierung oder einem Datenanalyseplan definiert werden.\nz.B.:\n\nWerte +/- 3 SD vom Gruppenmittelwert\nVisuelle Ausreisser bei Boxplots und/oder Scatterplots\nABER: Nur weil ein Wert extrem aussieht sollte man den nicht unüberlegt entfernen! Mehr dazu in Leys et al. (2019)",
    "crumbs": [
      "Präsentationen",
      "Einheit 9 - 12.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_9.html#ausreisser-1",
    "href": "scripts/01_slides/EH_9.html#ausreisser-1",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 9",
    "section": "Ausreisser",
    "text": "Ausreisser\nStreudiagramme/Scatterplots\n\nggplot(data = penguins_dropped, aes( x = flipper_length_mm, y = body_mass_g))+\n  geom_point()",
    "crumbs": [
      "Präsentationen",
      "Einheit 9 - 12.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_9.html#ausreisser-2",
    "href": "scripts/01_slides/EH_9.html#ausreisser-2",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 9",
    "section": "Ausreisser",
    "text": "Ausreisser\nboxplot\n\n\nEin Ausreißer stammt vermutlich aus einer anderen Population und trägt daher nicht zu gültigen Schlussfolgerungen über die Zielpopulation bei, weshalb er grundsätzlich ausgeschlossen werden sollte. Extremwerte hingegen stammen aus derselben Population, sind lediglich sehr groß oder klein und dürfen daher nicht pauschal entfernt werden.\n–&gt; Beispiel: Pinguin wurde immer von menschen gefütteret und ist deswegen sehr dick –&gt; andere Polulation als die Zielpopulation",
    "crumbs": [
      "Präsentationen",
      "Einheit 9 - 12.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_9.html#skalenreliabilität",
    "href": "scripts/01_slides/EH_9.html#skalenreliabilität",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 9",
    "section": "Skalenreliabilität",
    "text": "Skalenreliabilität\n\nInterne Konsistsenz (Cronbach’s Alpha)\n\n\n#Mit psych Package\nlibrary(psych)\n\nbfi_10_extra &lt;- bfi_10_data |&gt;\n  select(bfi_extra_1_r, bfi_extra_2)\n\nalpha(bfi_10_extra, check.keys = TRUE)\n\n\nReliability analysis   \nCall: alpha(x = bfi_10_extra, check.keys = TRUE)\n\n  raw_alpha std.alpha G6(smc) average_r S/N   ase mean sd median_r\n      0.76      0.76    0.62      0.62 3.2 0.085    3  1     0.62\n\n    95% confidence boundaries \n         lower alpha upper\nFeldt      0.5  0.76  0.89\nDuhachek   0.6  0.76  0.93\n\n Reliability if an item is dropped:\n              raw_alpha std.alpha G6(smc) average_r S/N alpha se var.r med.r\nbfi_extra_1_r      0.54      0.62    0.38      0.62 1.6       NA     0  0.62\nbfi_extra_2        0.71      0.62    0.38      0.62 1.6       NA     0  0.62\n\n Item statistics \n               n raw.r std.r r.cor r.drop mean  sd\nbfi_extra_1_r 29  0.89   0.9  0.71   0.62    3 1.1\nbfi_extra_2   29  0.92   0.9  0.71   0.62    3 1.2\n\nNon missing response frequency for each item\n                 1    2    3    4    5 miss\nbfi_extra_1_r 0.07 0.24 0.41 0.17 0.10 0.03\nbfi_extra_2   0.10 0.28 0.28 0.21 0.14 0.03",
    "crumbs": [
      "Präsentationen",
      "Einheit 9 - 12.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_9.html#skalenreliabilität-2",
    "href": "scripts/01_slides/EH_9.html#skalenreliabilität-2",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 9",
    "section": "Skalenreliabilität (2)",
    "text": "Skalenreliabilität (2)\n\nMc Donalds Omega\n\n\n\nTest-Retest Reliabilität 👉 Korrelation zwischen Fragebögen an zwei Messzeitpunkten\n\n\n\nSplit-half Reliabilität 👉 Aufteilen des Fragebogens in zwei Hälften und deren Reliabilitäten (z.B. Cronbach‘s Alpha) vergleichen. Möglich mit der Funktion splitHalf() aus dem psych Paket.\n\n\nMehr Infos dazu: Psychometrics in R & Björn Walther\n\nIn diesem Beispiel werden nur zwei Items verwendet - wir gehen davon aus dass bfi_extra_1_r schon rekodiert wurde. Anonsten könnte man das auch im alpha befehl weiter spezifizieren.",
    "crumbs": [
      "Präsentationen",
      "Einheit 9 - 12.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_9.html#heute-haben-wir",
    "href": "scripts/01_slides/EH_9.html#heute-haben-wir",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 9",
    "section": "Heute haben wir:",
    "text": "Heute haben wir:\n\nWide to long Transformationen gemacht - You mastered the tidyr!\n\nDatenqualitätsindikatoren kennengelernt",
    "crumbs": [
      "Präsentationen",
      "Einheit 9 - 12.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_9.html#bis-nächste-woche",
    "href": "scripts/01_slides/EH_9.html#bis-nächste-woche",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 9",
    "section": "Bis nächste Woche",
    "text": "Bis nächste Woche\n\nMuddiest Points Umfrage bis Sonntag 23:55\nEs gibt sonst keine HÜ - nutzt die Zeit verpasstes nachzuholen, schwierige Aspekte noch mal anzuschauen etc.\nLars kann bei Bedarf kontaktiert werden\nForum nutzen!",
    "crumbs": [
      "Präsentationen",
      "Einheit 9 - 12.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_9.html#references",
    "href": "scripts/01_slides/EH_9.html#references",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 9",
    "section": "",
    "text": "References:\nWickham H (2025). genzplyr: dplyr but make it bussin fr fr no cap. R package version 0.0.0.9000, https://github.com/hadley/genzplyr.\n\n\n\n\n\n\n\n\n\nLeys, Christophe, Marie Delacre, Youri L. Mora, Daniël Lakens, and Christophe Ley. 2019. “How to Classify, Detect, and Manage Univariate and Multivariate Outliers, with Emphasis on Pre-Registration.” International Review of Social Psychology 32 (1). https://doi.org/10.5334/irsp.289.",
    "crumbs": [
      "Präsentationen",
      "Einheit 9 - 12.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/1_presentation.html#beispielhafte-chunks-output",
    "href": "scripts/01_slides/1_presentation.html#beispielhafte-chunks-output",
    "title": "R u Ready",
    "section": "Beispielhafte Chunks & Output",
    "text": "Beispielhafte Chunks & Output\n\n\n\nprint(\"Hello world!\")\n\n[1] \"Hello world!\"\n\n\n\n\n2+2\n\n[1] 4"
  },
  {
    "objectID": "scripts/01_slides/1_presentation.html#beispielhafte-formatierung",
    "href": "scripts/01_slides/1_presentation.html#beispielhafte-formatierung",
    "title": "R u Ready",
    "section": "Beispielhafte Formatierung",
    "text": "Beispielhafte Formatierung\nDiese Präsentation verwendet Reveal.js in Quarto\n\n\n\n\n\n\nHinweis\n\n\nAuf den Folien sind erst einmal nur Beispiele zu sehen, wie man mit Quarto Präsentationen einfach Code einbinden und zeigen kann."
  },
  {
    "objectID": "scripts/01_slides/1_presentation.html#beispielhafter-datensatz",
    "href": "scripts/01_slides/1_presentation.html#beispielhafter-datensatz",
    "title": "R u Ready",
    "section": "Beispielhafter Datensatz",
    "text": "Beispielhafter Datensatz\n\nhead(mtcars)\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1"
  },
  {
    "objectID": "scripts/01_slides/1_presentation.html#beispielhafter-ggplot-code-und-plot",
    "href": "scripts/01_slides/1_presentation.html#beispielhafter-ggplot-code-und-plot",
    "title": "R u Ready",
    "section": "Beispielhafter ggplot-code und plot",
    "text": "Beispielhafter ggplot-code und plot\n\nggplot(data = mtcars, aes(x = hp, y = mpg, color = factor(cyl))) +\n  geom_point(size = 3) +\n  labs(\n    title = \"PS vs. Verbrauch\",\n    x = \"Horsepower (hp)\",\n    y = \"Miles per Gallon (mpg)\",\n    color = \"Zylinder\"\n  ) +\n  theme_minimal()\n\n\n\n\n\nR u Ready? HS2025 | Psychologie der Digialisierung"
  },
  {
    "objectID": "scripts/01_slides/1_presentation.html#beispielhafter-ggplot-code-und-plot-output",
    "href": "scripts/01_slides/1_presentation.html#beispielhafter-ggplot-code-und-plot-output",
    "title": "R u Ready",
    "section": "Beispielhafter ggplot-code und plot",
    "text": "Beispielhafter ggplot-code und plot"
  },
  {
    "objectID": "scripts/01_slides/EH_13.html#r-u-ready-reproduzierbare-datenaufbereitung-und--analyse-mit-r",
    "href": "scripts/01_slides/EH_13.html#r-u-ready-reproduzierbare-datenaufbereitung-und--analyse-mit-r",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 13",
    "section": "R u Ready? Reproduzierbare Datenaufbereitung und -analyse mit R",
    "text": "R u Ready? Reproduzierbare Datenaufbereitung und -analyse mit R\nHS 2025 LV-Leitung: Dr. Sandra Grinschgl / MSc. Aaron Friedli Tutor: BSc. Lars Schilling13. Einheit, 10.12.2025",
    "crumbs": [
      "Präsentationen",
      "Einheit 13 - 10.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_13.html#heute",
    "href": "scripts/01_slides/EH_13.html#heute",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 13",
    "section": "Heute:",
    "text": "Heute:",
    "crumbs": [
      "Präsentationen",
      "Einheit 13 - 10.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_13.html#anova---analysis-of-variance",
    "href": "scripts/01_slides/EH_13.html#anova---analysis-of-variance",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 13",
    "section": "ANOVA - Analysis of Variance",
    "text": "ANOVA - Analysis of Variance\nTestet, ob sich Mittelwerte in mehreren Gruppen unterscheiden\nVerschiedene Arten\n\nOne-Way ANOVA (einfaktoriell):\nEin Faktor (eine UV) mit mehr als zwei Stufen.\nMehrfaktorielle ANOVA:\nZwei oder mehr Faktoren (UVs).\nMixed ANOVA:\nKombination aus Within-Subject-Faktoren (Messwiederholung) und Between-Subject-Faktoren.\nMultivariate ANOVA (MANOVA):\nMindestens zwei abhängige Variablen.\nANCOVA:\nKontrolle für eine zusätzliche Drittvariable (Kovariate).",
    "crumbs": [
      "Präsentationen",
      "Einheit 13 - 10.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_13.html#voraussetzungen",
    "href": "scripts/01_slides/EH_13.html#voraussetzungen",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 13",
    "section": "Voraussetzungen",
    "text": "Voraussetzungen\n\nNormalverteilung der abhängigen Variablen\nVarianzhomogenität (Levene-Test)\nSphärizität (Mauchly Test) bei Mixed ANOVA",
    "crumbs": [
      "Präsentationen",
      "Einheit 13 - 10.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_13.html#einfaktorielle-anova",
    "href": "scripts/01_slides/EH_13.html#einfaktorielle-anova",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 13",
    "section": "Einfaktorielle ANOVA",
    "text": "Einfaktorielle ANOVA\nUnterscheiden sich die Mittelwerte der drei Gruppen voneinander?\nAV: mean_rl_all\nFixed Effekt: group_all 👉 Dieser Effekt interessiert uns\nRandom Intercept: (1 | code) 👉 Irrelevant bei One-Way ANOVA wird aber von der Funktion afex verlangt.\n\n\nleveneTest(mean_rl_all ~ group_all, data = dat_full)\n\nLevene's Test for Homogeneity of Variance (center = median)\n       Df F value Pr(&gt;F)\ngroup   2  0.6889 0.5036\n      156               \n\n\n\nmodel_1 &lt;- aov_4(mean_rl_all ~ group_all + (1 | code), data = dat_full)\n\n\nDer Random Intercept (1 | code) ist bei einer einfaktoriellen One-Way ANOVA irrelevant, weil jede Person nur einen einzigen Messwert fuer die AV hat. Die Personenvariabilität wird vom Residuum aufgefangen. Wäre nur relevant bei multilevel strukturen oder messwiederholungen. AFEX ist aber für mixed designs gebaut, und verangt deshalb einen random Intercept obwohl dieser keinemn effekt hat.",
    "crumbs": [
      "Präsentationen",
      "Einheit 13 - 10.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_13.html#output-one-way-anova-beispiel",
    "href": "scripts/01_slides/EH_13.html#output-one-way-anova-beispiel",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 13",
    "section": "Output One-Way ANOVA (Beispiel)",
    "text": "Output One-Way ANOVA (Beispiel)\n\nmodel_1 &lt;- aov_4(mean_rl_all ~ group_all + (1 | code), data = dat_full)\n\nsummary(model_1)",
    "crumbs": [
      "Präsentationen",
      "Einheit 13 - 10.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_13.html#anova-different-package---same-result",
    "href": "scripts/01_slides/EH_13.html#anova-different-package---same-result",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 13",
    "section": "ANOVA: Different Package - same result",
    "text": "ANOVA: Different Package - same result\nBASE-R\n\n\nmodel_aov &lt;- aov(mean_rl_all ~ group_all, data = dat_full)\nsummary(model_aov)\n\n             Df Sum Sq Mean Sq F value Pr(&gt;F)\ngroup_all     2   2.63   1.317   1.045  0.354\nResiduals   156 196.59   1.260               \n\n\n\naov_ez\n\nmodel_aov_ez &lt;- aov_ez(\n  id = \"code\",\n  dv = \"mean_rl_all\",\n  between = \"group_all\",\n  data = dat_full\n)\n\nsummary(model_aov_ez)\n\nAnova Table (Type 3 tests)\n\nResponse: mean_rl_all\n          num Df den Df    MSE      F      ges Pr(&gt;F)\ngroup_all      2    156 1.2602 1.0448 0.013218 0.3542",
    "crumbs": [
      "Präsentationen",
      "Einheit 13 - 10.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_13.html#anova-effektstärken",
    "href": "scripts/01_slides/EH_13.html#anova-effektstärken",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 13",
    "section": "ANOVA: Effektstärken",
    "text": "ANOVA: Effektstärken\ngeneralisiertes η2 & partielles η2 - Wie viel Varianz wird durch die Gruppenzugehörigkeit erklärt?\n\neta_squared(model_1, generalized = TRUE)\n\n# Effect Size for ANOVA (Type III)\n\nParameter | Eta2 (generalized) |       95% CI\n---------------------------------------------\ngroup_all |               0.01 | [0.00, 1.00]\n\n- Observed variables: All\n- One-sided CIs: upper bound fixed at [1.00].\n\neta_squared(model_1, partial = TRUE)\n\n# Effect Size for ANOVA (Type III)\n\nParameter | Eta2 |       95% CI\n-------------------------------\ngroup_all | 0.01 | [0.00, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].",
    "crumbs": [
      "Präsentationen",
      "Einheit 13 - 10.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_13.html#unterschiede-generalisiertes-und-partielles-η²",
    "href": "scripts/01_slides/EH_13.html#unterschiede-generalisiertes-und-partielles-η²",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 13",
    "section": "Unterschiede generalisiertes und partielles η²",
    "text": "Unterschiede generalisiertes und partielles η²\n\n\nDas generalisierte und partielle η²sind beides Masse, welche den Anteil an erklärter Varianz einer abhängigen Variable angeben.\n\n\n\nDas generalisierte η² berechnet den Anteil der erklärten Varianz einer abhängigen Variable unter Einbezug der gesamten Varianz, also aller Effekte.\n\n\n\nDas partielle η² beachtet bei der Berechnung des Anteils an erklärter Varianz für die abhängige Variable nicht die gesamte Varianz, sondern nur jene, welche dem zuvor definierten Effekt zugeschrieben werden kann.\n\n\n\nPartielles Eta-Quadrat: Wie gross ist der Effekt dieses Faktors, wenn ich alle anderen Einfluessen ignoriere? Wenn eine Kovariate hinzugefuegt wird und weitere Varianz erklaert, vergroessert sich das partielle Eta-Quadrat tendenziell, da der verbleibende Fehleranteil kleiner wird.\nGeneralisertes Eta-Quadrat: Wie gross ist der Effekt im gesamten Datensatz, also unter Beruecksichtigung aller anderen Quellen der Varianz?",
    "crumbs": [
      "Präsentationen",
      "Einheit 13 - 10.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_13.html#post-hoc-t-tests-mit-pairs",
    "href": "scripts/01_slides/EH_13.html#post-hoc-t-tests-mit-pairs",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 13",
    "section": "Post-Hoc t-Tests mit pairs",
    "text": "Post-Hoc t-Tests mit pairs\nVerschiedene Möglichkeiten\n\nKlassische t-Tests, wie im Paper und in EH 12\n\n\n\nSchneller mit pairs(), womit alle möglichen Vergleiche simultan berechnet werden (aber ohne Effektstärken) –&gt; Ergänzung für Fortgeschrittene im Hands-On!\n\n\n\n\n contrast        estimate    SE  df t.ratio p.value\n above - below    -0.2925 0.218 156  -1.341  0.3747\n above - control  -0.0443 0.218 156  -0.203  0.9775\n below - control   0.2481 0.218 156   1.138  0.4924\n\nP value adjustment: tukey method for comparing a family of 3 estimates \n\n\n\nOptimalerweise: Präregistrieren, welche Post-Hoc-Tests berechnet werden und wie diese korrigiert werden sollen",
    "crumbs": [
      "Präsentationen",
      "Einheit 13 - 10.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_13.html#korrektur-für-multiples-testen",
    "href": "scripts/01_slides/EH_13.html#korrektur-für-multiples-testen",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 13",
    "section": "Korrektur für multiples Testen:",
    "text": "Korrektur für multiples Testen:",
    "crumbs": [
      "Präsentationen",
      "Einheit 13 - 10.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_13.html#reminder-2x3-anova",
    "href": "scripts/01_slides/EH_13.html#reminder-2x3-anova",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 13",
    "section": "Reminder 2x3 ANOVA",
    "text": "Reminder 2x3 ANOVA\nAV = Rating\nBetween Subjects Faktor = Feedbackgruppe (below vs. control vs. above)\nWithin Subjects Faktor: Messzeitpunkt (Messwiederholter Faktor, pre 1 vs. pre 4)",
    "crumbs": [
      "Präsentationen",
      "Einheit 13 - 10.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_13.html#x3-mixed-anova-vorbereitungen",
    "href": "scripts/01_slides/EH_13.html#x3-mixed-anova-vorbereitungen",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 13",
    "section": "2x3 mixed ANOVA: Vorbereitungen",
    "text": "2x3 mixed ANOVA: Vorbereitungen\nMixed-ANOVA mit afex\n\nAV = Rating\n\nBetween Subjects Faktor = Feedbackgruppe (below vs. control vs. above)\n\nWithin Subjects Faktor: Messzeitpunkt (Messwiederholter Faktor, pre 1 vs. pre 4)\n👉 Long Datensatz\nMuster:\n\nmixed_anova &lt;- aov_4(AV ~ between_factor + (messwiederholter_faktor | ID) data = dat_full_long)",
    "crumbs": [
      "Präsentationen",
      "Einheit 13 - 10.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_13.html#beispielhafter-output-mit-η2",
    "href": "scripts/01_slides/EH_13.html#beispielhafter-output-mit-η2",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 13",
    "section": "Beispielhafter Output mit η2",
    "text": "Beispielhafter Output mit η2\n\nmixed_anova &lt;- aov_4(rating ~ group_all + (time_rating | code), data = dat_full_long, anova_table = list(es = c(\"ges\" ,\"pes\")))\n\n\nsummary(mixed_anova)\n\n\nUnivariate Type III Repeated-Measures ANOVA Assuming Sphericity\n\n                      Sum Sq num Df Error SS den Df  F value\n(Intercept)           8198.9      1   500.58    156 2555.113\ngroup_all              126.7      2   500.58    156   19.736\ntime_rating             42.0      1   288.70    156   22.668\ngroup_all:time_rating   74.4      2   288.70    156   20.090\n                                     Pr(&gt;F)    \n(Intercept)           &lt; 0.00000000000000022 ***\ngroup_all                     0.00000002286 ***\ntime_rating                   0.00000436406 ***\ngroup_all:time_rating         0.00000001724 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmixed_anova$anova_table\n\nAnova Table (Type 3 tests)\n\nResponse: rating\n                      num Df den Df    MSE      F     pes      ges\ngroup_all                  2    156 3.2088 19.736 0.20193 0.138283\ntime_rating                1    156 1.8507 22.668 0.12687 0.050468\ngroup_all:time_rating      2    156 1.8507 20.090 0.20481 0.086102\n                             Pr(&gt;F)    \ngroup_all             0.00000002286 ***\ntime_rating           0.00000436406 ***\ngroup_all:time_rating 0.00000001724 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1",
    "crumbs": [
      "Präsentationen",
      "Einheit 13 - 10.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_13.html#vergleich-mit-grinschgl2021",
    "href": "scripts/01_slides/EH_13.html#vergleich-mit-grinschgl2021",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 13",
    "section": "Vergleich mit Grinschgl et al. (2021)",
    "text": "Vergleich mit Grinschgl et al. (2021)\nIm Paper wurde nur das reine η2 berichtet. Berechnet mit eta_squared() aus dem Package effectsize.\n\n\n# Effect Size for ANOVA (Type III)\n\nParameter             | Eta2 |       95% CI\n-------------------------------------------\ngroup_all             | 0.12 | [0.05, 1.00]\ntime_rating           | 0.04 | [0.01, 1.00]\ngroup_all:time_rating | 0.07 | [0.02, 1.00]\n\n- One-sided CIs: upper bound fixed at [1.00].\n\n\n\nWe observed a main effect of the factor “feedback group”, F(2, 156) = 19.74, p &lt; 0.001, η2 = 0.12, as well as a main effect of the factor “time of pre-rating”, F(1, 156) = 22.67, p &lt; 0.001, η2 = 0.04. Most importantly, we also found a significant interaction between these factors, F(2, 156) = 20.09, p &lt; 0.001, η2 = 0.07.",
    "crumbs": [
      "Präsentationen",
      "Einheit 13 - 10.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_13.html#verletzungen-der-voraussetzungen-in-anovas",
    "href": "scripts/01_slides/EH_13.html#verletzungen-der-voraussetzungen-in-anovas",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 13",
    "section": "Verletzungen der Voraussetzungen in ANOVAs",
    "text": "Verletzungen der Voraussetzungen in ANOVAs\nNormalverteilung (one-way ANOVA)\n\nKruskal-Wallis-Test –&gt; Besonders robust gegen Verletzungen der Normalverteilungsannahme\n\nVarianzhomogenität\n\nEinfaktoriell: Welch-ANOVA\n\nMixed ANOVA\n\nRelativ robust gegenüber Verletzungen der Normalverteilung\n\n\n\nRobuste ANOVA mit WRS2 Paket\nMultilevel Model mit lme4\n\nBei Grinschgl et al. (2021) wurde dies aber außer Acht gelassen. Auf jeden Fall sollte man sich im Vorfeld der Datenerhebung überlegen ob und wie man Voraussetzungen überprüft und wie man bei potenziellen Verletzungen vorgeht.",
    "crumbs": [
      "Präsentationen",
      "Einheit 13 - 10.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_13.html#verletzung-sphärizität",
    "href": "scripts/01_slides/EH_13.html#verletzung-sphärizität",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 13",
    "section": "Verletzung Sphärizität",
    "text": "Verletzung Sphärizität\nBeispiel aus den Daten Hausübung:\n\nDer Mauchly-Test ist relevant bei mindestens drei Within-Faktoren (z.B bei der Hausübung) .\nSollte nicht signifikant sein, sodass wir Sphärizität annehmen können (ähnlich zum Levene Test).\nDer Test wird automatisch ausgegeben. Wenn nicht signifikant ist Sphärizität gegeben, asonsten muss korrigiert werden. 👉 Werte nach Greenhouse-Geisser-Korrektur interpretieren.\n\nDiese werden mit model$anova_table automatisch ausgegeben. Mit summary() bekommt man in der ersten Tabelle die unkorrigierten Werte. Beispiel:\n\n\n\n\nSphärizität in der Statistik ist eine Annahme für Varianzanalysen mit Messwiederholung (Repeated Measures ANOVA) und bedeutet, dass die Varianzen der Differenzen zwischen allen Paaren von Messzeitpunkten gleich sind, was eine Art „Homogenität der Differenzen“ darstellt. Bei zwei Zeitpunkten gibt es nur eine differenz, also muss sphärizität gegeben sein (weil es keine zweite oder dritte differenz gibt mit der man vergleichen könnte).\nGreenhouse–Geisser verkleinert die Freiheitsgrade, um p-Werte zu korrigieren, wenn Sphärizität verletzt ist.\nJe stärker die Verletzung, desto konservativer die Korrektur.",
    "crumbs": [
      "Präsentationen",
      "Einheit 13 - 10.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_13.html#heute-haben-wir",
    "href": "scripts/01_slides/EH_13.html#heute-haben-wir",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 13",
    "section": "Heute haben wir:",
    "text": "Heute haben wir:\n\nANOVAs kennengelernt\nPost-hoc Tests und Effektstärken berechnet\nVorausetzungsprüfungen und Alternativen angeschaut",
    "crumbs": [
      "Präsentationen",
      "Einheit 13 - 10.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_13.html#bis-nächste-woche",
    "href": "scripts/01_slides/EH_13.html#bis-nächste-woche",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 13",
    "section": "Bis nächste Woche:",
    "text": "Bis nächste Woche:\n\nMuddiest Points!! Bis Sonntag! siehe Ilias EH 13\nHausübung bis Freitag und Peerfeedback bis Mittwoch!\n\n\n\n\n\n\n\n\n\n\nGrinschgl, Sandra, Hauke S. Meyerhoff, Stephan Schwan, and Frank Papenmeier. 2021. “From Metacognitive Beliefs to Strategy Selection: Does Fake Performance Feedback Influence Cognitive Offloading?” Psychological Research 85 (7): 2654–66. https://doi.org/10.1007/s00426-020-01435-9.",
    "crumbs": [
      "Präsentationen",
      "Einheit 13 - 10.12.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_10.html#r-u-ready-reproduzierbare-datenaufbereitung-und--analyse-mit-r",
    "href": "scripts/01_slides/EH_10.html#r-u-ready-reproduzierbare-datenaufbereitung-und--analyse-mit-r",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 10",
    "section": "R u Ready? Reproduzierbare Datenaufbereitung und -analyse mit R",
    "text": "R u Ready? Reproduzierbare Datenaufbereitung und -analyse mit R\nHS 2025 LV-Leitung: Dr. Sandra Grinschgl / MSc. Aaron Friedli Tutor: BSc. Lars Schilling10. Einheit, 19.11.2025",
    "crumbs": [
      "Präsentationen",
      "Einheit 10 - 19.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_10.html#heute",
    "href": "scripts/01_slides/EH_10.html#heute",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 10",
    "section": "Heute:",
    "text": "Heute:\n\n\n\nVerschiebung der Abgabe der Datensätze an die Studierenden auf EH12 auf Wunsch der Studierenden",
    "crumbs": [
      "Präsentationen",
      "Einheit 10 - 19.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_10.html#muddiest-points",
    "href": "scripts/01_slides/EH_10.html#muddiest-points",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 10",
    "section": "Muddiest Points!",
    "text": "Muddiest Points!",
    "crumbs": [
      "Präsentationen",
      "Einheit 10 - 19.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_10.html#gruppe-sandra",
    "href": "scripts/01_slides/EH_10.html#gruppe-sandra",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 10",
    "section": "Gruppe Sandra",
    "text": "Gruppe Sandra\nFortsetzung Datenqualität -&gt; Folien EH 9\nZuerst Theorie, dann Hands-On",
    "crumbs": [
      "Präsentationen",
      "Einheit 10 - 19.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_10.html#hands-on-block-5-check-in",
    "href": "scripts/01_slides/EH_10.html#hands-on-block-5-check-in",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 10",
    "section": "Hands-on Block 5: Check In",
    "text": "Hands-on Block 5: Check In\nHaben alle einen Long Datensatz (e.g. dat_full_long) mit 318 Zeilen = 2 Zeilen pro Versuchsperson?\nWenn nicht:\n\ndat_full_long &lt;- dat_full |&gt; \n  pivot_longer(cols = c(pre1, pre4),\n               names_to = \"time_rating\",         \n               values_to = \"rating\")\n\n❗Falls ihr bis Ende Lektion noch nicht den LONG Datensatz erstellt und gespeichert habt - meldet euch bei uns",
    "crumbs": [
      "Präsentationen",
      "Einheit 10 - 19.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_10.html#visualize-tabellen",
    "href": "scripts/01_slides/EH_10.html#visualize-tabellen",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 10",
    "section": "Visualize: Tabellen",
    "text": "Visualize: Tabellen\n\nMöglichkeit APA konforme Tabellen in R zu erstellen\n\nSchritt 1: Deskriptive Tabelle erstellen mit summarize\n\npenguins_full &lt;- drop_na(penguins)\npenguins_summary &lt;- penguins_full |&gt; \n  group_by(species) |&gt;\n  summarize(mean_body_mass = mean(body_mass_g),\n            min_body_mass = min(body_mass_g),\n            max_body_mass = max(body_mass_g)\n            )\n\npenguins_summary\n\n# A tibble: 3 × 4\n  species   mean_body_mass min_body_mass max_body_mass\n  &lt;fct&gt;              &lt;dbl&gt;         &lt;int&gt;         &lt;int&gt;\n1 Adelie             3706.          2850          4775\n2 Chinstrap          3733.          2700          4800\n3 Gentoo             5092.          3950          6300",
    "crumbs": [
      "Präsentationen",
      "Einheit 10 - 19.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_10.html#visualize-tabellen-1",
    "href": "scripts/01_slides/EH_10.html#visualize-tabellen-1",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 10",
    "section": "Visualize: Tabellen",
    "text": "Visualize: Tabellen\nSchritt 2: kable auf deskriptive Tabelle anwenden\n\nlibrary(knitr)\n\npenguins_summary |&gt;\n  kable(\n    caption = \"Summary of penguin body mass by species\",\n    digits = 1,\n    col.names = c(\"Species\", \"Mean body mass (g)\", \"Min\", \"Max\")\n  )\n\n\nSummary of penguin body mass by species\n\n\nSpecies\nMean body mass (g)\nMin\nMax\n\n\n\n\nAdelie\n3706.2\n2850\n4775\n\n\nChinstrap\n3733.1\n2700\n4800\n\n\nGentoo\n5092.4\n3950\n6300\n\n\n\n\n\nWeitere Formatierungen möglich, z.B. row.names, col.names…siehe Hilfefunktion",
    "crumbs": [
      "Präsentationen",
      "Einheit 10 - 19.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_10.html#apatables---apa-konforme-tabellen-von-statistischen-analysen",
    "href": "scripts/01_slides/EH_10.html#apatables---apa-konforme-tabellen-von-statistischen-analysen",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 10",
    "section": "apaTables - APA konforme Tabellen von statistischen Analysen",
    "text": "apaTables - APA konforme Tabellen von statistischen Analysen\nKorrelationstabelle im APA Format –&gt; Kann man auch für Regressionen und ANOVAs verwenden\n1.Schritt: Auswahl von Variablen\n\npenguins_subset &lt;- penguins |&gt;\n  select(bill_length_mm, bill_depth_mm, flipper_length_mm)",
    "crumbs": [
      "Präsentationen",
      "Einheit 10 - 19.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_10.html#apatables---apa-konforme-tabellen-von-statistischen-analysen-1",
    "href": "scripts/01_slides/EH_10.html#apatables---apa-konforme-tabellen-von-statistischen-analysen-1",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 10",
    "section": "apaTables - APA konforme Tabellen von statistischen Analysen",
    "text": "apaTables - APA konforme Tabellen von statistischen Analysen\n2.Schritt: Korrelationstabelle for ausgewählte Variablen\nSpeichert Tabelle als Word Datei\n\nlibrary(apaTables)\napa.cor.table(penguins_subset)",
    "crumbs": [
      "Präsentationen",
      "Einheit 10 - 19.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_10.html#abbildungen-visualize-fortsetzung-in-eh-11",
    "href": "scripts/01_slides/EH_10.html#abbildungen-visualize-fortsetzung-in-eh-11",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 10",
    "section": "Abbildungen: Visualize (Fortsetzung in EH 11)",
    "text": "Abbildungen: Visualize (Fortsetzung in EH 11)",
    "crumbs": [
      "Präsentationen",
      "Einheit 10 - 19.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_10.html#visualisierungen-reproduktion-der-figures-aus-grinschgl-2021",
    "href": "scripts/01_slides/EH_10.html#visualisierungen-reproduktion-der-figures-aus-grinschgl-2021",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 10",
    "section": "Visualisierungen: Reproduktion der Figures aus Grinschgl 2021",
    "text": "Visualisierungen: Reproduktion der Figures aus Grinschgl 2021",
    "crumbs": [
      "Präsentationen",
      "Einheit 10 - 19.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_10.html#visualisierungen",
    "href": "scripts/01_slides/EH_10.html#visualisierungen",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 10",
    "section": "Visualisierungen",
    "text": "Visualisierungen",
    "crumbs": [
      "Präsentationen",
      "Einheit 10 - 19.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_10.html#ggplot2",
    "href": "scripts/01_slides/EH_10.html#ggplot2",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 10",
    "section": "ggplot2()",
    "text": "ggplot2()\nSehr flexibles Paket.\n\nPlots werden schrittweise “befüllt”\n\n\n\nAlle plots beginnen mit ggplot() und dem verwendeten Datensatz\nMit aes() definieren wir die elemantaren Elemente der Plots - Variablen die geplottet werden sollen\nmit + können wir geoms, layers und weitere Elemente hinzufügen.",
    "crumbs": [
      "Präsentationen",
      "Einheit 10 - 19.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_10.html#ggplot2---cheatsheet",
    "href": "scripts/01_slides/EH_10.html#ggplot2---cheatsheet",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 10",
    "section": "ggplot2() - Cheatsheet",
    "text": "ggplot2() - Cheatsheet\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWith ggplot2, you begin a plot with the function ggplot(), defining a plot object that you then add layers to. The first argument of ggplot() is the dataset to use in the graph and so ggplot(data = penguins) creates an empty graph that is primed to display the penguins data, but since we haven’t told it how to visualize it yet, for now it’s empty. This is not a very exciting plot, but you can think of it like an empty canvas you’ll paint the remaining layers of your plot onto.\nNext, we need to tell ggplot() how the information from our data will be visually represented. The mapping argument of the ggplot() function defines how variables in your dataset are mapped to visual properties (aesthetics) of your plot. The mapping argument is always defined in the aes() function, and the x and y arguments of aes() specify which variables to map to the x and y axes. For now, we will only map flipper length to the x aesthetic and body mass to the y aesthetic. ggplot2 looks for the mapped variables in the data argument, in this case, penguins.\nTo do so, we need to define a geom: the geometrical object that a plot uses to represent data. These geometric objects are made available in ggplot2 with functions that start with geom_. People often describe plots by the type of geom that the plot uses. For example, bar charts use bar geoms (geom_bar()), line charts use line geoms (geom_line()), boxplots use boxplot geoms (geom_boxplot()), scatterplots use point geoms (geom_point()), and so on.\nZusammenhang bedeutet die Verwendung von +, dass wir einzelne Elemente eines Plot-Objektes zusammenfügen.",
    "crumbs": [
      "Präsentationen",
      "Einheit 10 - 19.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_10.html#argumente-von-ggplot",
    "href": "scripts/01_slides/EH_10.html#argumente-von-ggplot",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 10",
    "section": "Argumente von ggplot()",
    "text": "Argumente von ggplot()\n\nVariablen als Aestheatic Mappings defineren\nMapping ist immer das zweite argument, “call” kann also auch verkürzt werden.\n\n\np &lt;- penguins |&gt;\n  ggplot( \n       mapping = \n         aes(x = body_mass_g, \n           y = bill_length_mm))\np",
    "crumbs": [
      "Präsentationen",
      "Einheit 10 - 19.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_10.html#ggplot---geoms",
    "href": "scripts/01_slides/EH_10.html#ggplot---geoms",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 10",
    "section": "ggplot() - Geoms",
    "text": "ggplot() - Geoms\n\nLayers Hinzufügen z.B. ein geom mit +\nGeoms = geometrische Objekte, die die Daten darstellen (z.B. Punkte, Linien)\nMuss je nachdem welche Daten man hat und wie man diese darstellen will ausgewählt werden, z.B.\n\nKategoriale Variable: geom_bar()\nKontinuierliche Variable: geom_histogram()\n2 kontinuierliche Variablen: geom_point(), geom_line()\n2 Kategoriale Variablen: geom_count()\nKategorial + Kontinuierlich: geom_boxplot(), geom_violin()\n\n\n\np &lt;- p +\n  geom_point()\n\np",
    "crumbs": [
      "Präsentationen",
      "Einheit 10 - 19.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_10.html#ggplot---layers",
    "href": "scripts/01_slides/EH_10.html#ggplot---layers",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 10",
    "section": "ggplot() - Layers",
    "text": "ggplot() - Layers\n\nMappings können auch in den Layers definiert werden\n\n\np &lt;- p + \n  geom_point(aes(x = body_mass_g, \n           y = bill_length_mm))\n\np",
    "crumbs": [
      "Präsentationen",
      "Einheit 10 - 19.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_10.html#ggplot---layers-1",
    "href": "scripts/01_slides/EH_10.html#ggplot---layers-1",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 10",
    "section": "ggplot() - Layers",
    "text": "ggplot() - Layers\n\nTitel + Achsenbeschriftung (= labs), Regressionslinien, vereinfachtes Design\n\n\np &lt;- p +\n  geom_smooth(aes(group = 1), method = \"lm\") +\n  theme_classic() +\n  labs(\n    title = \"Relationship Between Body Mass and Bill Length\",\n    x = \"Body Mass (g)\",\n    y = \"Bill Length (mm)\"\n  )\n\np\n\n\nmit theme_ können verschiedene Formatierungen gewählt werden. theme_classic wird typischerweise für APA7 passende Formatierungen gewählt.",
    "crumbs": [
      "Präsentationen",
      "Einheit 10 - 19.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_10.html#ggplot---verschiedene-layersgeoms-kombiniert",
    "href": "scripts/01_slides/EH_10.html#ggplot---verschiedene-layersgeoms-kombiniert",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 10",
    "section": "ggplot() - Verschiedene Layers/Geoms kombiniert",
    "text": "ggplot() - Verschiedene Layers/Geoms kombiniert\n\np2 &lt;- penguins |&gt;\n  ggplot(aes(x = island, y = body_mass_g, color = island, shape = sex)) +\n  geom_boxplot() +\n  geom_jitter(alpha = 0.5)+\n  theme_classic()+\n  labs(\n    title = \"Body Mass Per Island and Species\", x = \"Island\", y = \"Body Mass (g)\")\np2\n\n\n\nAchtung: Nicht optimal formatiert, weil sonst der Plot zu klein dargestellt wird.",
    "crumbs": [
      "Präsentationen",
      "Einheit 10 - 19.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_10.html#abbildungen-speichern",
    "href": "scripts/01_slides/EH_10.html#abbildungen-speichern",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 10",
    "section": "Abbildungen speichern",
    "text": "Abbildungen speichern\n\nggsave(filename = \"my_first_plot.png\", plot = p2)",
    "crumbs": [
      "Präsentationen",
      "Einheit 10 - 19.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_10.html#weitere-ressourcen",
    "href": "scripts/01_slides/EH_10.html#weitere-ressourcen",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 10",
    "section": "Weitere Ressourcen:",
    "text": "Weitere Ressourcen:\nViel, viel mehr Möglichkeiten als wir hier besprechen, siehe z.B.:\nAuflistung von Argumenten\nggplot2 Cheatsheet\nR for Data Science – Kapitel 9 & 10:\nKapitel „Layers“\nKapitel „EDA“\nWeitere Textelemente in Abbildungen (Kapitel 11)\nHier findet man auch weitere Visualisierungsmöglichkeiten & Informationen dazu, wie man verschiedene Plots neben/untereinander abbilden kann.\nTop 50 Visualisierungen mit ggplot2\nfür Animationen, Signifikanztests, Wordclouds usw.",
    "crumbs": [
      "Präsentationen",
      "Einheit 10 - 19.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_10.html#heute-haben-wir",
    "href": "scripts/01_slides/EH_10.html#heute-haben-wir",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 10",
    "section": "Heute haben wir:",
    "text": "Heute haben wir:\n\nMuddiest Points besprochen\nBasics der Datenvisualisierungen kennengelernt\n\nErstellung von Tabellen\nggplot()\n\n\nReminder: Beim Abschlussprojekt müsst ihr 1 Tabelle oder Abbildung nach Wahl zu den simulierten Daten abgeben.",
    "crumbs": [
      "Präsentationen",
      "Einheit 10 - 19.11.2025"
    ]
  },
  {
    "objectID": "scripts/01_slides/EH_10.html#r-hausübung-2",
    "href": "scripts/01_slides/EH_10.html#r-hausübung-2",
    "title": "R u Ready? HS2025 | Psychologie der Digitalisierung - Einheit 10",
    "section": "R Hausübung 2",
    "text": "R Hausübung 2\nAbgabe bis Freitag 28.11.2025, 23:55\nPeerfeedback bis Mittwoch 03.12.2025 (vor der Einheit)\nAchtung: Einhalten der Namensvorgaben!\n\nNamenseinhaltung für Abgabe der Files (da wir diese via R-Funktion öffnen)",
    "crumbs": [
      "Präsentationen",
      "Einheit 10 - 19.11.2025"
    ]
  },
  {
    "objectID": "scripts/03_faq/datenanalyseplan.html",
    "href": "scripts/03_faq/datenanalyseplan.html",
    "title": "3 Datenanalyseplan",
    "section": "",
    "text": "Fragen zum Datenanalyseplan",
    "crumbs": [
      "FAQ",
      "3  Datenanalyseplan"
    ]
  },
  {
    "objectID": "scripts/03_faq/datenanalyseplan.html#müssen-die-anmerkungen-im-datenanalyseplan-nach-der-bearbeitung-gelöscht-werden-so-dass-nur-die-frage-und-der-titel-verbleiben",
    "href": "scripts/03_faq/datenanalyseplan.html#müssen-die-anmerkungen-im-datenanalyseplan-nach-der-bearbeitung-gelöscht-werden-so-dass-nur-die-frage-und-der-titel-verbleiben",
    "title": "3 Datenanalyseplan",
    "section": "Müssen die Anmerkungen im Datenanalyseplan nach der Bearbeitung gelöscht werden, so dass nur die Frage und der Titel verbleiben?",
    "text": "Müssen die Anmerkungen im Datenanalyseplan nach der Bearbeitung gelöscht werden, so dass nur die Frage und der Titel verbleiben?\nÜblicherweise werden Datenanalysepläne auf OSF (dem Open Science Framework) mitsamt den Anmerkungen veröffentlicht. Für das Seminar ist es möglich die Anmerkungen zu behalten oder zu löschen.",
    "crumbs": [
      "FAQ",
      "3  Datenanalyseplan"
    ]
  },
  {
    "objectID": "scripts/03_faq/datenanalyseplan.html#müssen-auch-zu-explorativen-fragestellungen-hypothesen-aufgestellt-werden",
    "href": "scripts/03_faq/datenanalyseplan.html#müssen-auch-zu-explorativen-fragestellungen-hypothesen-aufgestellt-werden",
    "title": "3 Datenanalyseplan",
    "section": "Müssen auch zu explorativen Fragestellungen Hypothesen aufgestellt werden?",
    "text": "Müssen auch zu explorativen Fragestellungen Hypothesen aufgestellt werden?\nKurzgesagt, nein. Bei explorativen Fragestellungen kann man auch einfach anmerken, dass diese explorativ sind – es also keine bisherige Theorie oder Evidenz für einen bestimmte Richtung gibt. Wichtig ist hierbei vor allem, transparent und vorausschauend zu arbeiten, in diesem Fall also den Umstand, explorativ zu arbeiten, klar zu benennen.",
    "crumbs": [
      "FAQ",
      "3  Datenanalyseplan"
    ]
  },
  {
    "objectID": "scripts/03_faq/datenanalyseplan.html#wenn-voraussetzungsprüfungen-oder-post-hoc-tests-durchgeführt-werden-müssen-diese-auch-im-datenanalyseplan-ergänzt-werden",
    "href": "scripts/03_faq/datenanalyseplan.html#wenn-voraussetzungsprüfungen-oder-post-hoc-tests-durchgeführt-werden-müssen-diese-auch-im-datenanalyseplan-ergänzt-werden",
    "title": "3 Datenanalyseplan",
    "section": "Wenn Voraussetzungsprüfungen oder post-hoc Tests durchgeführt werden, müssen diese auch im Datenanalyseplan ergänzt werden?",
    "text": "Wenn Voraussetzungsprüfungen oder post-hoc Tests durchgeführt werden, müssen diese auch im Datenanalyseplan ergänzt werden?\nGrundsätzlich gilt: Der Datenanalyseplan soll fremden Wissenschaftler:innen aus der Psychologie ermöglichen die Studie und die Datenanalyse ohne weiteren Aufwand nachvollziehen zu können. Dafür sollte auf Vollständigkeit und Genauigkeit geachtet werden. Dementsprechend gilt es, die Voraussetzungsprüfungen entweder komplett wegzulassen oder sie sowohl im Skript als auch im Datenanalyseplan zu ergänzen.",
    "crumbs": [
      "FAQ",
      "3  Datenanalyseplan"
    ]
  },
  {
    "objectID": "scripts/03_faq/datenanalyseplan.html#soll-der-abstract-bereits-die-resultate-von-grinschgl-et-al.-2020-erwähnen-oder-offenlassen-welche-resultate-zu-erwarten-sind",
    "href": "scripts/03_faq/datenanalyseplan.html#soll-der-abstract-bereits-die-resultate-von-grinschgl-et-al.-2020-erwähnen-oder-offenlassen-welche-resultate-zu-erwarten-sind",
    "title": "3 Datenanalyseplan",
    "section": "Soll der Abstract bereits die Resultate von Grinschgl et al. (2020) erwähnen oder offenlassen, welche Resultate zu erwarten sind?",
    "text": "Soll der Abstract bereits die Resultate von Grinschgl et al. (2020) erwähnen oder offenlassen, welche Resultate zu erwarten sind?\nÜblicherweise lässt der Datenanalyseplan die Resultate der beschriebenen Analyse im Abstract noch offen, da diese zu dem Zeitpunkt, zu welchem der Datenanalyseplan erstellt wird, noch nicht bekannt sind. Bei einer Replikation der Originalstudie – wie es hier der Fall ist – können die Ergebnisse aus dieser aber auch bereits genannt werden. Bezüglich der eigenen Datenanalyse sollte wiederum von erwarteten Ergebnissen ausgehen. Da die Analyse der Daten erst nach Verfassen des Datenanalyseplans folgt sind die Resultate bis dahin nicht bekannt.",
    "crumbs": [
      "FAQ",
      "3  Datenanalyseplan"
    ]
  },
  {
    "objectID": "scripts/03_faq/faq.html",
    "href": "scripts/03_faq/faq.html",
    "title": "FAQ",
    "section": "",
    "text": "Hier findest du häufig gestellte Fragen und Antworten. Wir updaten diese Sammlung laufend.",
    "crumbs": [
      "FAQ"
    ]
  },
  {
    "objectID": "scripts/03_faq/statistic.html",
    "href": "scripts/03_faq/statistic.html",
    "title": "4 Statistik",
    "section": "",
    "text": "Fragen zu Statistik",
    "crumbs": [
      "FAQ",
      "4  Statistik"
    ]
  },
  {
    "objectID": "scripts/03_faq/statistic.html#was-ist-das-partielle-η²-und-wie-unterscheidet-es-sich-von-dem-generalisierten-η²",
    "href": "scripts/03_faq/statistic.html#was-ist-das-partielle-η²-und-wie-unterscheidet-es-sich-von-dem-generalisierten-η²",
    "title": "4 Statistik",
    "section": "Was ist das partielle η² und wie unterscheidet es sich von dem generalisierten η²?",
    "text": "Was ist das partielle η² und wie unterscheidet es sich von dem generalisierten η²?\nDas generalisierte und partielle η² sind beides Masse, welche den Anteil an erklärter Varianz einer abhängigen Variable angeben. Das generalisierte η² berechnet den Anteil der erklärten Varianz einer abhängigen Variable unter Einbezug der gesamten Varianz, also aller Effekte. Das partielle η² beachtet bei der Berechnung des Anteils an erklärter Varianz für die abhängige Variable nicht die gesamte Varianz, sondern nur jene, welche dem zuvor definierten Effekt zugeschrieben werden kann.\n\n\n\n\n\n\nNote\n\n\n\nWeiterführende Informationen finden sich hier.",
    "crumbs": [
      "FAQ",
      "4  Statistik"
    ]
  },
  {
    "objectID": "scripts/03_faq/statistic.html#wozu-muss-sphärizität-gegeben-sein-und-wie-kann-man-diese-testen",
    "href": "scripts/03_faq/statistic.html#wozu-muss-sphärizität-gegeben-sein-und-wie-kann-man-diese-testen",
    "title": "4 Statistik",
    "section": "Wozu muss Sphärizität gegeben sein und wie kann man diese testen?",
    "text": "Wozu muss Sphärizität gegeben sein und wie kann man diese testen?\nUnter Sphärizität versteht man die Annahme, dass bei Messwiederholungen die Differenzen von zwei beliebigen Messwiederholungen ähnliche Varianzen aufweisen. Dies kann mit dem Mauchly-Test geprüft werden. Laut Nullhypothese sind die entsprechenden Varianzen gleich, laut Alternativhypothese sind die entsprechenden Varianzen unterschiedlich. Dementsprechend spricht ein signifikanter Mauchly-Test für eine Verletzung der Sphärizitätsannahme. In diesem Fall kann auf die Greenhouse-Geisser Korrektur zurückgegriffen werden.",
    "crumbs": [
      "FAQ",
      "4  Statistik"
    ]
  },
  {
    "objectID": "scripts/03_faq/statistic.html#was-macht-eine-tukey-korrektur-und-was-sagt-uns-das-ergebnis",
    "href": "scripts/03_faq/statistic.html#was-macht-eine-tukey-korrektur-und-was-sagt-uns-das-ergebnis",
    "title": "4 Statistik",
    "section": "Was macht eine Tukey-Korrektur und was sagt uns das Ergebnis?",
    "text": "Was macht eine Tukey-Korrektur und was sagt uns das Ergebnis?\nDie Tukey-Korrektur wird angewendet, um im Anschluss an eine signifikante ANOVA die Mittelwertsunterschiede der einzelnen Gruppen unter Kontrolle für multiples Testen einzeln zu untersuchen. Hierdurch wird eine Inflation der falsch-negativen Rate bzw. des p-Wertes vermieden. Bei Verwendung dieses Tests können die Ergebnisse der Mittelwertsvergleiche somit unmittelbar auf ihre Signifikanz hin bewertet werden.",
    "crumbs": [
      "FAQ",
      "4  Statistik"
    ]
  },
  {
    "objectID": "scripts/03_faq/statistic.html#wann-benötigt-die-berechnung-einer-anova-einen-wide-datensatz-und-wann-benötigt-die-berechnung-einer-anova-einen-long-datensatz",
    "href": "scripts/03_faq/statistic.html#wann-benötigt-die-berechnung-einer-anova-einen-wide-datensatz-und-wann-benötigt-die-berechnung-einer-anova-einen-long-datensatz",
    "title": "4 Statistik",
    "section": "Wann benötigt die Berechnung einer ANOVA einen wide-Datensatz und wann benötigt die Berechnung einer ANOVA einen long-Datensatz?",
    "text": "Wann benötigt die Berechnung einer ANOVA einen wide-Datensatz und wann benötigt die Berechnung einer ANOVA einen long-Datensatz?\nIn welchem Format der Datensatz vor der Berechnung einer ANOVA vorliegen muss hängt von der verwendeten ANOVA-Funktion ab und kann nicht pauschal beantwortet werden. Grundsätzlich gilt aber, für eine ANOVA ohne Messwiederholung ist ein wide-Datensatz meist ausreichend. Die Funktion aov_4(), welche bei ANOVAs mit Messwiederholung verwendet werden kann, benötigt eine gesonderte Variable, welche den Zeitpunkt der Messung angibt, sprich das long-Format. Hier ein Beispiel wie die Umwandlug in ein long-Format und eine anschliessende Berechnung von einer ANOVA mit Messwiederholung aussehen könnte:\n\ndata_long &lt;- data_wide |&gt; \n  pivot_longer(\n    cols = c(Spalte1, Spalte2, Spalte3), \n    names_to = \"Hier kommt der Name der Spalte rein, in welcher die früheren Spaltenüberschriften abgelegt sind\", \n    values_to = \"Hier kommt der Name der Spalte rein, in welcher die Werte der entsprechenden früheren Spalten abgelegt sind\"\n  )\n\nafex::aov_4(value ~ treatment + (time | Personenidentifikationscode), data = data_long) # Beispiel mit(!) Messwiederholung\n\n\n\n\n\n\n\nNote\n\n\n\nFür die Funktion aov_4() gibt es aus Statistik-IV von Boris Mayer und Stefan Thoma noch tiefere und beispielhafte Ausführungen.",
    "crumbs": [
      "FAQ",
      "4  Statistik"
    ]
  },
  {
    "objectID": "scripts/03_faq/statistic.html#was-wird-bei-einem-levene-test-berechnet-bzw.-geprüft",
    "href": "scripts/03_faq/statistic.html#was-wird-bei-einem-levene-test-berechnet-bzw.-geprüft",
    "title": "4 Statistik",
    "section": "Was wird bei einem Levene-Test berechnet bzw. geprüft?",
    "text": "Was wird bei einem Levene-Test berechnet bzw. geprüft?\nDer Levene-Test prüft die Varianzhomogenität zwischen Gruppen. Als Nullhypothese gilt hierbei, dass die Varianzen zwischen den Gruppen gleich sind. Als Alternativhypothese gilt, dass die Varianzen zwischen den Gruppen unterschiedlich sind. Dementsprechend besagt ein signifikanter Levene-Test, dass es Varianzunterschiede zwischen den Gruppen gibt und die Annahme der Varianzhomogenität verworfen werden muss.",
    "crumbs": [
      "FAQ",
      "4  Statistik"
    ]
  },
  {
    "objectID": "scripts/03_faq/statistic.html#wird-ein-levene-test-für-den-between-faktor-berechnet-und-muss-diese-berechnung-für-jede-abhängige-variable-einzeln-gemacht-werden",
    "href": "scripts/03_faq/statistic.html#wird-ein-levene-test-für-den-between-faktor-berechnet-und-muss-diese-berechnung-für-jede-abhängige-variable-einzeln-gemacht-werden",
    "title": "4 Statistik",
    "section": "Wird ein Levene-Test für den between-Faktor berechnet und muss diese Berechnung für jede abhängige Variable einzeln gemacht werden?",
    "text": "Wird ein Levene-Test für den between-Faktor berechnet und muss diese Berechnung für jede abhängige Variable einzeln gemacht werden?\nFür beide Fragen gilt: Ja! Der Levene-Test vergleicht die Varianzen von mindestens zwei Gruppen. Dementsprechend kann ein Levene-Test nur für einen between-Faktor durchgeführt werden. Darüber hinaus kann ein einzelner Levene-Test nur die Varianzverteilung einer abhängigen Variable (über alle Gruppen hinweg) betrachten. Daher muss für jede abhängige Variable, für die die Annahme der Varianzhomogenität benötigt wird und infrage steht, ein Levene-Test berechnet werden.",
    "crumbs": [
      "FAQ",
      "4  Statistik"
    ]
  },
  {
    "objectID": "scripts/03_faq/statistic.html#ist-vor-der-berechnung-einer-anova-notwendigerweise-ein-levene-test-durchzuführen",
    "href": "scripts/03_faq/statistic.html#ist-vor-der-berechnung-einer-anova-notwendigerweise-ein-levene-test-durchzuführen",
    "title": "4 Statistik",
    "section": "Ist vor der Berechnung einer ANOVA notwendigerweise ein Levene-Test durchzuführen?",
    "text": "Ist vor der Berechnung einer ANOVA notwendigerweise ein Levene-Test durchzuführen?\nDie Durchführung eines Levene-Tests vor der ANOVA ist dann notwendig, wenn die Varianzhomogenität zwischen Gruppen nicht anderweitig ersichtlich ist. Zeigen die Daten beispielsweise gleich grosse Stichproben und normalverteilte Verteilungen der Werte innerhalb der Gruppen, dann kann von Varianzhomogenität auch ohne den Levene-Test ausgegangen werden. Auf alle Fälle sollte man vor der Datenanalyse festlegen, ob ein Levene Test berechnet wird oder nicht, Und gegebenenfalls ein Verfahren definieren für den Fall das die Varianzhomogenität nicht gegeben ist (z.B. ein nichtparametrisches Verfahren wie die Welch-ANOVA)",
    "crumbs": [
      "FAQ",
      "4  Statistik"
    ]
  },
  {
    "objectID": "scripts/03_faq/statistic.html#welche-masse-für-effektstärken-werden-üblicherweise-bei-einer-anova-und-einem-post-hoc-t-test-berichtet",
    "href": "scripts/03_faq/statistic.html#welche-masse-für-effektstärken-werden-üblicherweise-bei-einer-anova-und-einem-post-hoc-t-test-berichtet",
    "title": "4 Statistik",
    "section": "Welche Masse für Effektstärken werden üblicherweise bei einer ANOVA und einem (post-hoc) t-Test berichtet?",
    "text": "Welche Masse für Effektstärken werden üblicherweise bei einer ANOVA und einem (post-hoc) t-Test berichtet?\nBei einer ANOVA wird im Rahmen des Seminars, sofern nicht anders verlangt, das Effektstärkemass η² berichtet. Bei (post-hoc) t-Tests wird im Rahmen des Seminars, sofern nicht anders verlangt, das Effektstärkemass von Cohens` d verwendet.",
    "crumbs": [
      "FAQ",
      "4  Statistik"
    ]
  },
  {
    "objectID": "scripts/03_faq/statistic.html#bei-der-analyse-der-internen-konsistenz-mit-der-funktion-alpha-erscheint-die-fehlermeldung-warnung-some-items-were-negatively-correlated-with-the-first-principal-component-and-probably-should-be-reversed.-to-do-this-run-the-function-again-with-the-check.keystrue-option.-was-bedeutet-diese-warnmeldung-und-kann-man-sie-einfach-ignorieren-oder-muss-sie-weiter-berücksichtigt-werden",
    "href": "scripts/03_faq/statistic.html#bei-der-analyse-der-internen-konsistenz-mit-der-funktion-alpha-erscheint-die-fehlermeldung-warnung-some-items-were-negatively-correlated-with-the-first-principal-component-and-probably-should-be-reversed.-to-do-this-run-the-function-again-with-the-check.keystrue-option.-was-bedeutet-diese-warnmeldung-und-kann-man-sie-einfach-ignorieren-oder-muss-sie-weiter-berücksichtigt-werden",
    "title": "4 Statistik",
    "section": "Bei der Analyse der internen Konsistenz mit der Funktion alpha() erscheint die Fehlermeldung: „Warnung: Some items were negatively correlated with the first principal component and probably should be reversed. To do this, run the function again with the ‘check.keys=TRUE’ option“. Was bedeutet diese Warnmeldung und kann man sie einfach ignorieren oder muss sie weiter berücksichtigt werden?",
    "text": "Bei der Analyse der internen Konsistenz mit der Funktion alpha() erscheint die Fehlermeldung: „Warnung: Some items were negatively correlated with the first principal component and probably should be reversed. To do this, run the function again with the ‘check.keys=TRUE’ option“. Was bedeutet diese Warnmeldung und kann man sie einfach ignorieren oder muss sie weiter berücksichtigt werden?\nDiese Warnmeldung - in Verbindung mit der Funktion alpha() zur Berechnung der internen Konsistenz - weist darauf hin, dass ein Item invers codiert sein könnte, da es nur einen geringen oder sogar negativen Zusammenhang zu den anderen Items aufweist. Dies kann daran liegen, dass das Item den Versuchspersonen invers vorgelegt worden war und lediglich vergessen wurde, die Skala anschliessend erneut zu invertieren. Das Item kann aber auch in die „richtige“ Richtung codiert sein und die Kennwerte des Items erklären sich durch weitere Umstände wie beispielsweise eine kleine Stichprobe. Abhängig davon welcher Fall zutrifft müsste das Item vor der Berechnung der internen Konsistenz entweder noch invertiert oder die Warnmeldung kann ignoriert werden.",
    "crumbs": [
      "FAQ",
      "4  Statistik"
    ]
  }
]